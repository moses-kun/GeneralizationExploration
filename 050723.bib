
@inproceedings{fuchs_matching_2021,
	address = {Milan, Italy},
	title = {Matching of {Matching}-{Graphs} - {A} {Novel} {Approach} for {Graph} {Classification}},
	isbn = {978-1-72818-808-9},
	url = {https://ieeexplore.ieee.org/document/9411926/},
	doi = {10.1109/ICPR48806.2021.9411926},
	abstract = {Due to fast developments in data acquisition, we observe rapidly increasing amounts of data available in diverse areas. Simultaneously, we observe that in many applications the underlying data is inherently complex, making graphs a very useful and adequate data structure for formal representation. A large amount of graph based methods for pattern recognition have been proposed. Many of these methods actually rely on graph matching. In the present paper a novel encoding of graph matching information is proposed. The idea of this encoding is to formalize the stable cores of speciﬁc classes by means of graphs. In an empirical evaluation we show that it can be highly beneﬁcial to focus on these stable parts of graphs during graph classiﬁcation.},
	language = {en},
	urldate = {2021-07-24},
	booktitle = {2020 25th {International} {Conference} on {Pattern} {Recognition} ({ICPR})},
	publisher = {IEEE},
	author = {Fuchs, Mathias and Riesen, Kaspar},
	month = jan,
	year = {2021},
	pages = {6570--6576},
	file = {Fuchs and Riesen - 2021 - Matching of Matching-Graphs - A Novel Approach for.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/U9ADXIGW/Fuchs and Riesen - 2021 - Matching of Matching-Graphs - A Novel Approach for.pdf:application/pdf},
}

@article{goudarzi_application_2021,
	title = {An {Application} {Placement} {Technique} for {Concurrent} {IoT} {Applications} in {Edge} and {Fog} {Computing} {Environments}},
	volume = {20},
	issn = {1536-1233, 1558-0660, 2161-9875},
	url = {https://ieeexplore.ieee.org/document/8960404/},
	doi = {10.1109/TMC.2020.2967041},
	abstract = {Fog/Edge computing emerges as a novel computing paradigm that harnesses resources in the proximity of the Internet of Things (IoT) devices so that, alongside with the cloud servers, provide services in a timely manner. However, due to the everincreasing growth of IoT devices with resource-hungry applications, fog/edge servers with limited resources cannot efﬁciently satisfy the requirements of the IoT applications. Therefore, the application placement in the fog/edge computing environment, in which several distributed fog/edge servers and centralized cloud servers are available, is a challenging issue. In this article, we propose a weighted cost model to minimize the execution time and energy consumption of IoT applications, in a computing environment with multiple IoT devices, multiple fog/edge servers and cloud servers. Besides, a new application placement technique based on the Memetic Algorithm is proposed to make batch application placement decision for concurrent IoT applications. Due to the heterogeneity of IoT applications, we also propose a lightweight pre-scheduling algorithm to maximize the number of parallel tasks for the concurrent execution. The performance results demonstrate that our technique signiﬁcantly improves the weighted cost of IoT applications up to 65 percent in comparison to its counterparts.},
	language = {en},
	number = {4},
	urldate = {2021-08-03},
	journal = {IEEE Transactions on Mobile Computing},
	author = {Goudarzi, Mohammad and Wu, Huaming and Palaniswami, Marimuthu and {Rajkumar Buyya}},
	month = apr,
	year = {2021},
	keywords = {review, Fog computing, Internet of Things (IoT), edge computing, application placement, optimization, application partitioning, ⛔ No INSPIRE recid found},
	pages = {1298--1311},
	file = {Goudarzi et al. - 2021 - An Application Placement Technique for Concurrent .pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/2DS5VPG3/Goudarzi et al. - 2021 - An Application Placement Technique for Concurrent .pdf:application/pdf},
}

@article{alturki_exploring_2019,
	title = {Exploring the {Effectiveness} of {Service} {Decomposition} in {Fog} {Computing} {Architecture} for the {Internet} of {Things}},
	issn = {2377-3782, 2377-3790},
	url = {https://ieeexplore.ieee.org/document/8676374/},
	doi = {10.1109/TSUSC.2019.2907405},
	abstract = {The Internet of Things (IoT) aims to connect everyday physical objects to the internet. These objects will produce a signiﬁcant amount of data. The traditional cloud computing architecture aims to process data in the cloud. As a result, a signiﬁcant amount of data needs to be communicated to the cloud. This creates a number of challenges, such as high communication latency between the devices and the cloud, increased energy consumption of devices during frequent data upload to the cloud, high bandwidth consumption, while making the network busy by sending the data continuously, and less privacy because of less control on the transmitted data to the server. Fog computing has been proposed to counter these weaknesses. Fog computing aims to process data at the edge and substantially eliminate the necessity of sending data to the cloud. However, combining the Service Oriented Architecture (SOA) with the fog computing architecture is still an open challenge. In this paper, we propose to decompose services to create linked-microservices (LMS). Linked-microservices are services that run on multiple nodes but closely linked to their linked-partners. Linked-microservices allow distributing the computation across different computing nodes in the IoT architecture. Using four different types of architectures namely cloud, fog, hybrid and fog+cloud, we explore and demonstrate the effectiveness of service decomposition by applying four experiments to three different type of datasets. Evaluation of the four architectures shows that decomposing services into nodes reduce the data consumption over the network by 10\% - 70\%. Overall, these results indicate that the importance of decomposing services in the context of fog computing for enhancing the quality of service.},
	language = {en},
	urldate = {2021-08-03},
	journal = {IEEE Transactions on Sustainable Computing},
	author = {Alturki, Badraddin and Reiff-Marganiec, Stephan and Perera, Charith and De, Suparna},
	year = {2019},
	keywords = {⛔ No INSPIRE recid found},
	pages = {1--1},
	file = {Alturki et al. - 2019 - Exploring the Effectiveness of Service Decompositi.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/297P6XC8/Alturki et al. - 2019 - Exploring the Effectiveness of Service Decompositi.pdf:application/pdf},
}

@incollection{bessis_fog_2014,
	address = {Cham},
	title = {Fog {Computing}: {A} {Platform} for {Internet} of {Things} and {Analytics}},
	volume = {546},
	isbn = {978-3-319-05028-7 978-3-319-05029-4},
	shorttitle = {Fog {Computing}},
	url = {http://link.springer.com/10.1007/978-3-319-05029-4_7},
	abstract = {Internet of Things (IoT) brings more than an explosive proliferation of endpoints. It is disruptive in several ways. In this chapter we examine those disruptions, and propose a hierarchical distributed architecture that extends from the edge of the network to the core nicknamed Fog Computing. In particular, we pay attention to a new dimension that IoT adds to Big Data and Analytics: a massively distributed number of sources at the edge.},
	language = {en},
	urldate = {2021-08-04},
	booktitle = {Big {Data} and {Internet} of {Things}: {A} {Roadmap} for {Smart} {Environments}},
	publisher = {Springer International Publishing},
	author = {Bonomi, Flavio and Milito, Rodolfo and Natarajan, Preethi and Zhu, Jiang},
	editor = {Bessis, Nik and Dobre, Ciprian},
	year = {2014},
	doi = {10.1007/978-3-319-05029-4_7},
	note = {Series Title: Studies in Computational Intelligence},
	keywords = {background},
	pages = {169--186},
	file = {Bonomi et al. - 2014 - Fog Computing A Platform for Internet of Things a.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/3BMDFPAU/Bonomi et al. - 2014 - Fog Computing A Platform for Internet of Things a.pdf:application/pdf},
}

@article{brogi_how_2020,
	title = {How to {Place} {Your} {Apps} in the {Fog} -- {State} of the {Art} and {Open} {Challenges}},
	volume = {50},
	issn = {0038-0644, 1097-024X},
	url = {http://arxiv.org/abs/1901.05717},
	doi = {10.1002/spe.2766},
	abstract = {Fog computing aims at extending the Cloud towards the IoT so to achieve improved QoS and to empower latency-sensitive and bandwidth-hungry applications. The Fog calls for novel models and algorithms to distribute multi-service applications in such a way that data processing occurs wherever it is best-placed, based on both functional and non-functional requirements.},
	language = {en},
	number = {5},
	urldate = {2021-08-05},
	journal = {Software: Practice and Experience},
	author = {Brogi, Antonio and Forti, Stefano and Guerrero, Carlos and Lera, Isaac},
	month = may,
	year = {2020},
	note = {arXiv: 1901.05717},
	keywords = {fog computing, application deployment, application placement, optimization algorithms, service placement, ⛔ No INSPIRE recid found},
	pages = {719--740},
	file = {Brogi et al. - 2020 - How to Place Your Apps in the Fog -- State of the .pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/ADWJ3PED/Brogi et al. - 2020 - How to Place Your Apps in the Fog -- State of the .pdf:application/pdf},
}

@article{salaht_overview_2020,
	title = {An {Overview} of {Service} {Placement} {Problem} in {Fog} and {Edge} {Computing}},
	volume = {53},
	issn = {0360-0300, 1557-7341},
	url = {https://dl.acm.org/doi/10.1145/3391196},
	doi = {10.1145/3391196},
	abstract = {To support the large and various applications generated by the Internet of Things (IoT), Fog Computing was introduced to complement the Cloud Computing and oﬀer Cloud-like services at the edge of the network with low latency and real-time responses. Large-scale, geographical distribution and heterogeneity of edge computational nodes make service placement in such infrastructure a challenging issue. Diversity of user expectations and IoT devices characteristics also complexify the deployment problem. This paper presents a survey of current research conducted on Service Placement Problem (SPP) in the Fog/Edge Computing. Based on a new classiﬁcation scheme, a categorization of current proposals is given and identiﬁed issues and challenges are discussed.},
	language = {en},
	number = {3},
	urldate = {2021-08-05},
	journal = {ACM Computing Surveys},
	author = {Salaht, Farah Aït and Desprez, Frédéric and Lebre, Adrien},
	month = jul,
	year = {2020},
	keywords = {review, Fog computing, edge computing, service placement, classification, deployment taxonomy, optimization, ⛔ No INSPIRE recid found},
	pages = {1--35},
	file = {Salaht et al. - 2020 - An Overview of Service Placement Problem in Fog an.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/P6P2LZ6Y/Salaht et al. - 2020 - An Overview of Service Placement Problem in Fog an.pdf:application/pdf},
}

@article{naha_fog_2018,
	title = {Fog {Computing}: {Survey} of {Trends}, {Architectures}, {Requirements}, and {Research} {Directions}},
	volume = {6},
	issn = {2169-3536},
	shorttitle = {Fog {Computing}},
	url = {https://ieeexplore.ieee.org/document/8444370/},
	doi = {10.1109/ACCESS.2018.2866491},
	abstract = {Emerging technologies such as the Internet of Things (IoT) require latency-aware computation for real-time application processing. In IoT environments, connected things generate a huge amount of data, which are generally referred to as big data. Data generated from IoT devices are generally processed in a cloud infrastructure because of the on-demand services and scalability features of the cloud computing paradigm. However, processing IoT application requests on the cloud exclusively is not an efﬁcient solution for some IoT applications, especially time-sensitive ones. To address this issue, Fog computing, which resides in between cloud and IoT devices, was proposed. In general, in the Fog computing environment, IoT devices are connected to Fog devices. These Fog devices are located in close proximity to users and are responsible for intermediate computation and storage. One of the key challenges in running IoT applications in a Fog computing environment are resource allocation and task scheduling. Fog computing research is still in its infancy, and taxonomy-based investigation into the requirements of Fog infrastructure, platform, and applications mapped to current research is still required. This survey will help the industry and research community synthesize and identify the requirements for Fog computing. This paper starts with an overview of Fog computing in which the deﬁnition of Fog computing, research trends, and the technical differences between Fog and cloud are reviewed. Then, we investigate numerous proposed Fog computing architectures and describe the components of these architectures in detail. From this, the role of each component will be deﬁned, which will help in the deployment of Fog computing. Next, a taxonomy of Fog computing is proposed by considering the requirements of the Fog computing paradigm. We also discuss existing research works and gaps in resource allocation and scheduling, fault tolerance, simulation tools, and Fog-based microservices. Finally, by addressing the limitations of current research works, we present some open issues, which will determine the future research direction for the Fog computing paradigm.},
	language = {en},
	urldate = {2021-08-11},
	journal = {IEEE Access},
	author = {Naha, Ranesh Kumar and Garg, Saurabh and Georgakopoulos, Dimitrios and Jayaraman, Prem Prakash and Gao, Longxiang and Xiang, Yong and Ranjan, Rajiv},
	year = {2018},
	keywords = {review, Fog computing, fault tolerance, fog devices, Internet of Things (IoT), IoT application, microservices, ⛔ No INSPIRE recid found},
	pages = {47980--48009},
	file = {Naha et al. - 2018 - Fog Computing Survey of Trends, Architectures, Re.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/2CUVXAKP/Naha et al. - 2018 - Fog Computing Survey of Trends, Architectures, Re.pdf:application/pdf},
}

@article{bellendorf_classification_2020,
	title = {Classification of optimization problems in fog computing},
	volume = {107},
	issn = {0167739X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167739X19323568},
	doi = {10.1016/j.future.2020.01.036},
	abstract = {Fog computing combines cloud services with geographically distributed resources near the network edge to oﬀer computational oﬄoading possibilities to end devices, featuring low latency. Optimization of various metrics (latency, bandwidth, energy consumption etc.) plays a vital role in fog computing. We present the results of a literature review on optimization in fog computing, covering 280 papers. In particular, we propose a taxonomy of diﬀerent optimization problems in fog computing, a categorization of the metrics used in constraints and objective functions, and a mapping study of the relevant literature.},
	language = {en},
	urldate = {2021-08-27},
	journal = {Future Generation Computer Systems},
	author = {Bellendorf, Julian and Mann, Zoltán Ádám},
	month = jun,
	year = {2020},
	keywords = {Edge computing, Fog computing, Optimization, ⛔ No INSPIRE recid found},
	pages = {158--176},
	file = {Bellendorf and Mann - 2020 - Classification of optimization problems in fog com.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/8DCHRBR4/Bellendorf and Mann - 2020 - Classification of optimization problems in fog com.pdf:application/pdf;PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/IRRY45MG/1-s2.0-S0167739X19323568-main.pdf:application/pdf},
}

@article{ghobaei-arani_resource_2019,
	title = {Resource {Management} {Approaches} in {Fog} {Computing}: a {Comprehensive} {Review}},
	doi = {10.1007/s10723-019-09491-1},
	abstract = {In recent years, the Internet of Things (IoT) has been one of the most popular technologies that facilitate new interactions among things and humans to enhance the quality of life. With the rapid development of IoT, the fog computing paradigm is emerging as an attractive solution for processing the data of IoT applications. In the fog environment, IoT applications are executed by the intermediate computing nodes in the fog, as well as the physical servers in cloud data centers. On the other hand, due to the resource limitations, resource heterogeneity, dynamic nature, and unpredictability of fog environment, it necessitates the resource management issues as one of the challenging problems to be considered in the fog landscape. Despite the importance of resource management issues, to the best of our knowledge, there is not any systematic, comprehensive and detailed survey on the field of resource management approaches in the fog computing context. In this paper, we provide a systematic literature review (SLR) on the resource management approaches in fog environment in the form of a classical taxonomy to recognize the state-of-the-art mechanisms on this important topic and providing open issues as well. The presented taxonomy are classified into six main fields: application placement, resource scheduling, task offloading, load balancing, resource allocation, and resource provisioning. The resource management approaches are compared with each other according to the important factors such as the performance metrics, case studies, utilized techniques, and evaluation tools as well as their advantages and disadvantages are discussed.},
	journal = {Journal of Grid Computing},
	author = {Ghobaei-Arani, Mostafa and Souri, Alireza and Rahmanian, Ali Asghar},
	year = {2019},
	pmid = {null},
	pmcid = {null},
	keywords = {Edge computing, Fog computing, Application placement, Resource management, Load balancing, Resource allocation, Resource provisioning, Resource scheduling, Task offloading},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/AWKKSMWK/s10723-019-09491-1.pdf:application/pdf},
}

@article{dastjerdi_fog_2016,
	title = {Fog {Computing}: {Principles}, architectures, and applications},
	doi = {10.1016/b978-0-12-805395-9.00004-6},
	abstract = {Abstract The Internet of Everything (IoE) solutions gradually bring every object online, and processing data in a centralized cloud does not scale to requirements of such an environment. This is because there are applications such as health monitoring and emergency response that require low latency, so delay caused by transferring data to the cloud and then back to the application can seriously impact the performance. To this end, Fog computing has emerged, where cloud computing is extended to the edge of the network to decrease the latency and network congestion. Fog computing is a paradigm for managing a highly distributed and possibly virtualized environment that provides compute and network services between sensors and cloud data centers. This chapter provides a background and motivations regarding the emergence of Fog computing, and defines its key characteristics. In addition, a reference architecture for Fog computing is presented, and recent related development and applications are discussed.},
	journal = {arXiv: Distributed, Parallel, and Cluster Computing},
	author = {Dastjerdi, Amir Vahid and Gupta, Harshit and Calheiros, Rodrigo N. and Ghosh, Soumya K. and Buyya, Rajkumar},
	year = {2016},
	pmid = {null},
	pmcid = {null},
}

@article{hu_survey_2017,
	title = {Survey on fog computing},
	doi = {10.1016/j.jnca.2017.09.002},
	abstract = {The emergence of Internet of Things (IoT) has enabled the interconnection and intercommunication among massive ubiquitous things, which caused an unprecedented generation of huge and heterogeneous amount of data, known as data explosions. On the other hand, although that cloud computing has served as an efficient way to process and store these data, however, challenges, such as the increasing demands of real time or latency-sensitive applications and the limitation of network bandwidth, still cannot be solved by using only cloud computing. Therefore, a new computing paradigm, known as fog computing, has been proposed as a complement to the cloud solution. Fog computing extends the cloud services to the edge of network, and makes computation, communication and storage closer to edge devices and end-users, which aims to enhance low-latency, mobility, network bandwidth, security and privacy. In this paper, we will overview and summarize fog computing model architecture, key technologies, applications, challenges and open issues. Firstly, we will present the hierarchical architecture of fog computing and its characteristics, and compare it with cloud computing and edge computing to emphasize the similarities and differences. Then, the key technologies like computing, communication and storage technologies, naming, resource management, security and privacy protection are introduced to present how to support its deployment and application in a detailed manner. Several application cases like health care, augmented reality, brain machine interface and gaming, smart environments and vehicular fog computing are also presented to further explain fog computing application scenarios. Finally, based on the observation, we propose some challenges and open issues which are worth further in-depth study and research in fog computing development.},
	journal = {Journal of Network and Computer Applications},
	author = {Hu, Pengfei and Dhelim, Sahraoui and Ning, Huansheng and Qiu, Tie},
	year = {2017},
	pmid = {null},
	pmcid = {null},
}

@article{javadzadeh_fog_2020,
	title = {Fog {Computing} {Applications} in {Smart} {Cities}: {A} {Systematic} {Survey}},
	doi = {10.1007/s11276-019-02208-y},
	abstract = {Nowadays, the smart city is a topic that has attracted the attention of many researchers, engineers and even the public because of to its pervasive and vast effect on everyday life. The technologies used to realize the smart cities are often based on cloud computing. As a result, they have carried the limitations of cloud computing, such as unreliable latency, lack of mobility support, and location awareness. Fog computing provides different solutions to these problems. Although efforts have been done in the area of fog computing applications in smart cities, it is still difficult to find a systematic reliable survey that covers this area. This article aims to provide a comprehensive overview based on a systematic literature review of current works that have been done in the area of fog computing applications in smart cities. In addition, a different analytical comparison of related works, the trends, and future research directions are pointed out in this article.},
	journal = {Wireless Networks},
	author = {Javadzadeh, Ghazaleh and Rahmani, Amir Masoud},
	year = {2020},
	pmid = {null},
	pmcid = {null},
}

@article{alli_fog_2020,
	title = {The fog cloud of things: {A} survey on concepts, architecture, standards, tools, and applications},
	doi = {10.1016/j.iot.2020.100177},
	abstract = {Abstract The Fog computing paradigms are becoming popular means of utilizing resources optimally by the IoT devices, extending quality of service to the vicinity of the user, and achieve fast processing in the IoT-cloud ecosystems. Fog models allow fast processing of data, easy to reach storage, and reduce bulky network transition. The inefficiencies of the cloud inspire unnecessarily big data to be sent to the backhaul of the network, which incapacitates the cloud infrastructure. Fog computing addresses the limitation of the cloud systems by improving robustness, efficiency, and performance of cloud infrastructure. The need to process some of the big data produced at the peripheral of the network using keen techniques in the fog—cloud ecosystems is a key to new interesting architectures filed in the recent literature. These architectures provide new business opportunities that drive the Internet of things devices to function according to users’ demands. In this paper, we provide an extensive survey on Fog—Edge computing to give a foundation to solutions proposed in studies that involve IoT—Fog—Cloud ecosystems. This is done by providing insights of new research aspects filed, the state—of—art in fog computing architectures, standards, tools and applications. We project the future development trends and provide open issues in fog cloud of things. This will focus developers to develop applications that work well in a cloud-based controlled ecosystem across a range of network terminals.},
	journal = {null},
	author = {Alli, Adam A. and Alam, Muhammad and Alam, Muhammad Mahbub},
	year = {2020},
	pmid = {null},
	pmcid = {null},
}

@article{gasmi_survey_2021,
	title = {A survey on computation offloading and service placement in fog computing-based {IoT}},
	doi = {10.1007/s11227-021-03941-y},
	abstract = {In recent years, fog computing has emerged as a computing paradigm to support the computationally intensive and latency-critical applications for resource limited Internet of Things (IoT) devices. The main feature of fog computing is to push computation, networking, and storage facilities closer to the network edge. This enables IoT user equipment (UE) to profit from the fog computing paradigm by mainly offloading their intensive computation tasks to fog resources. Thus, computation offloading and service placement mechanisms can overcome the resource constraints of IoT devices, and improve the system performance in terms of increasing battery lifetime of UE and reducing the total delay. In this paper, we survey the current research conducted on computation offloading and service placement in fog computing-based IoT in a comparative manner.},
	journal = {The Journal of Supercomputing},
	author = {Gasmi, Kaouther and Dilek, Selma and Tosun, Suleyman and Ozdemir, Suat},
	year = {2021},
	pmid = {null},
	pmcid = {null},
}

@article{chiang_fog_2016,
	title = {Fog and {IoT}: {An} {Overview} of {Research} {Opportunities}},
	doi = {10.1109/jiot.2016.2584538},
	abstract = {Fog is an emergent architecture for computing, storage, control, and networking that distributes these services closer to end users along the cloud-to-things continuum. It covers both mobile and wireline scenarios, traverses across hardware and software, resides on network edge but also over access networks and among end users, and includes both data plane and control plane. As an architecture, it supports a growing variety of applications, including those in the Internet of Things (IoT), fifth-generation (5G) wireless systems, and embedded artificial intelligence (AI). This survey paper summarizes the opportunities and challenges of fog, focusing primarily in the networking context of IoT.},
	journal = {IEEE Internet of Things Journal},
	author = {Chiang, Mung and Zhang, Tao and Zhang, Tao and Zhang, Tao},
	year = {2016},
	pmid = {null},
	pmcid = {null},
}

@article{mansouri_review_2021,
	title = {A review of edge computing features and resource virtualization},
	doi = {10.1016/j.jpdc.2020.12.015},
	abstract = {Abstract With the advent of Internet of Things (IoT) connecting billions of mobile and stationary devices to serve real-time applications, cloud computing paradigms face some significant challenges such as high latency and jitter, non-supportive location-awareness and mobility, and non-adaptive communication types. To address these challenges, edge computing paradigms, namely Fog Computing (FC), Mobile Edge Computing (MEC) and Cloudlet, have emerged to shift the digital services from centralized cloud computing to computing at edges. In this article, we analyse cloud and edge computing paradigms from features and pillars perspectives to identify the key motivators of the transitions from one type of virtualized computing paradigm to another one. We then focus on computing and network virtualization techniques as the essence of all these paradigms, and delineate why virtualization features, resource richness and application requirements are the primary factors for the selection of virtualization types in IoT frameworks. Based on these features, we compare the state-of-the-art research studies in the IoT domain. We finally investigate the deployment of virtualized computing and networking resources from performance perspective in an edge-cloud environment, followed by mapping of the existing work to the provided taxonomy for this research domain. The lessons from the reviewed are that the selection of virtualization technique, placement and migration of virtualized resources rely on the requirements of IoT services (i.e., latency, scalability, mobility, multi-tenancy, privacy, and security). As a result, there is a need for prioritizing the requirements, integrating different virtualization techniques, and exploiting a hierarchical edge-cloud architecture.},
	journal = {Journal of Parallel and Distributed Computing},
	author = {Mansouri, Yaser and Babar, M. Ali},
	year = {2021},
	pmid = {null},
	pmcid = {null},
	file = {Mansouri and Babar - 2021 - A review of edge computing features and resource v.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/A59IR2TH/Mansouri and Babar - 2021 - A review of edge computing features and resource v.pdf:application/pdf},
}

@article{sabireen_review_2021,
	title = {A review on fog computing: {Architecture}, fog with {IoT}, algorithms and research challenges},
	doi = {10.1016/j.icte.2021.05.004},
	abstract = {Abstract With the increasing advancement in the applications of the Internet of Things (IoT), the integrated Cloud Computing (CC) faces numerous threats such as performance, security, latency, and network breakdown. With the discovery of Fog Computing these issues are addressed by taking CC nearer to the Internet of Things (IoT). The key functionality of the fog is to provide the data generated by the IoT devices near the edge. Processing of the data and data storage is done locally at the fog node rather than moving the information to the cloud server. In comparison with the cloud, Fog Computing delivers services with high quality and quick response time. Hence, Fog Computing might be the optimal option to allow the Internet of Things to deliver an efficient and highly secured service to numerous IoT clients. It allows the administration of the services and resource provisioning outside CC, nearer to devices, at the network edge, or ultimately at places specified by Service Level Agreements (SLA’s). Fog Computing is not a replacement to CC, but a prevailing component. It allows the processing of the information at the edge though still delivering the option to connect with the data center of the cloud. In this paper, we put forward various computing paradigms, features of fog computing, an in-depth reference architecture of fog with its various levels, a detailed analysis of fog with IoT, various fog system algorithms and also systematically examine the challenges in Fog Computing which acts as a middle layer between IoT sensors or devices and data centers of the cloud.},
	journal = {ICT Express},
	author = {Sabireen, H. and Neelenarayanan, V. and Neelanarayanan, V.},
	year = {2021},
	pmid = {null},
	pmcid = {null},
	file = {Sabireen et al. - 2021 - A review on fog computing Architecture, fog with .pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/3IFG2QC3/Sabireen et al. - 2021 - A review on fog computing Architecture, fog with .pdf:application/pdf},
}

@article{ogundoyin_optimization_2021,
	title = {Optimization {Techniques} and {Applications} in {Fog} {Computing}: {An} {Exhaustive} {Survey}},
	doi = {10.1016/j.swevo.2021.100937},
	abstract = {Abstract This paper presents an all-inclusive review of the optimization methods and their applications in fog computing. We put forward a taxonomy of the optimization techniques and then discuss their applications to solving various optimization problems in this field. Moreover, we develop a glossary of different optimization metrics in the literature and classify various evaluation environments used to test the solutions of different algorithms. The distribution of the relevant publications and the threats to the validity of the study are also discussed. Finally, we present the challenges in the existing literature and the future trends for research in fog computing optimization.},
	journal = {Swarm and evolutionary computation},
	author = {Ogundoyin, Sunday Oyinlola and Kamil, Ismaila Adeniyi},
	year = {2021},
	pmid = {null},
	pmcid = {null},
}

@article{carvalho_edge_2021,
	title = {Edge computing current trends research challenges and future directions},
	doi = {10.1007/s00607-020-00896-5},
	abstract = {The edge computing (EC) paradigm brings computation and storage to the edge of the network where data is both consumed and produced. This variation is necessary to cope with the increasing amount of network-connected devices and data transmitted, that the launch of the new 5G networks will expand. The aim is to avoid the high latency and traffic bottlenecks associated with the use of Cloud Computing in networks where several devices both access and generate high volumes of data. EC also improves network support for mobility, security, and privacy. This paper provides a discussion around EC and summarized the definition and fundamental properties of the EC architectures proposed in the literature (Multi-access Edge Computing, Fog Computing, Cloudlet Computing, and Mobile Cloud Computing). Subsequently, this paper examines significant use cases for each EC architecture and debates some promising future research directions.},
	journal = {Computing},
	author = {Carvalho, Gonçalo and Cabral, Bruno and Pereira, Vasco and Bernardino, Jorge},
	year = {2021},
	pmid = {null},
	pmcid = {null},
}

@article{singh_sustainable_2021,
	title = {A sustainable resource allocation techniques for fog computing},
	doi = {10.1007/978-981-15-9554-7_13},
	abstract = {Fog Computing has emerged as an area that provides an efficient platform for computing to support sustainable development. This latest computing paradigm could be an expansion of cloud computing. The main focus of fog computing is to decrease the load on the cloud due to an extreme number of IoT devices increased in the last few years. Sustainable resource allocation is the most promising challenge in fog computing that can save bandwidth, reduce latency, and energy consumption. In this article, a comprehensive review is done on resource allocation techniques used by many researchers in fog computing to find shortcomings for further improvement. The future direction and research gaps are also discussed at the end, so the author can easily find the way to do future research.},
	journal = {null},
	author = {Singh, Jagdeep and Singh, Jagdeep and Singh, Parminder and Singh, P. R. and Singh, Parminder},
	year = {2021},
	pmid = {null},
	pmcid = {null},
}

@article{singh_fog_2021,
	title = {Fog {Computing}: {A} {Taxonomy}, {Systematic} {Review}, {Current} {Trends} and {Research} {Challenges}},
	doi = {10.1016/j.jpdc.2021.06.005},
	abstract = {Abstract There has been rapid development in the number of Internet of Things (IoT) connected nodes and devices in our daily life in recent times. With this increase in the number of devices, fog computing has become a well-established paradigm to optimize various key Quality of Service (QoS) requirements such as latency, bandwidth limitation, response time, scalability, privacy and security. In this paper, we present a systematic literature review of fog computing. This review article aims to classify recently published studies and investigate the current status in the area of fog computing. In this work, we have discussed the important characteristics of fog computing frameworks and identified various issues related to its architectural design, QoS metrics, implementation details, applications and communication modes. We have proposed taxonomy for fog computing frameworks based on the existing literature and compared the different research work based on taxonomy. Finally, various open research challenges and promising future directions are highlighted for further research in the area of fog computing.},
	journal = {Journal of Parallel and Distributed Computing},
	author = {Singh, Jagdeep and Singh, Jagdeep and Singh, Parminder and Gill, Sukhpal Singh},
	year = {2021},
	pmid = {null},
	pmcid = {null},
}

@article{nukala_exploring_2021,
	title = {Exploring the {Fog} {Computing} {Technology} in {Development} of {IoT} {Applications}},
	doi = {10.1007/978-981-16-1502-3_16},
	abstract = {null},
	journal = {null},
	author = {Nukala, Chaitanya and Shailaja, Varagiri and Prasuna, A. V. Lakshmi and Swetha, B.},
	year = {2021},
	pmid = {null},
	pmcid = {null},
}

@article{fersi_fog_2021,
	title = {Fog computing and {Internet} of {Things} in one building block: a survey and an overview of interacting technologies},
	doi = {10.1007/s10586-021-03286-4},
	abstract = {The rapid proliferation and progress of Wireless Sensor Networks (WSN) and Internet of Things (IoT) has conducted to the formation of a gigantic amount of data and agrowing need to multiple new services and resources. In spite of the main role of Cloud computing in solving these issues, IoT applications need more reduced latency with mobility support and location awareness. To overcome the mentioned limits, a new concept favouring the integration of Fog computing onto IoT is increasingly utilized. It is a motivating scheme that offers a timely task execution and data management at the network edge, in a distributed way, with the collaboration of nearby nodes. In this paper, we provide a complete study of the integration of Fog onto IoT. We discuss the various challenges that are facing the Fog/IoT paradigm and specify the main contributions that have been proposed to overcome these challenges. We give also an insight on the relationship between IoT/Fog integration concept, and other leading technologies. The open issues that need more investigation are highlighted in this paper to identify clearly the research gaps in the area of Fog computing integration onto IoT.},
	journal = {Cluster Computing},
	author = {Fersi, Ghofrane and Fersi, Ghofrane},
	year = {2021},
	pmid = {null},
	pmcid = {null},
	file = {Fersi and Fersi - 2021 - Fog computing and Internet of Things in one buildi.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/QWXA2LR8/Fersi and Fersi - 2021 - Fog computing and Internet of Things in one buildi.pdf:application/pdf},
}

@article{nayeri_application_2021,
	title = {Application placement in {Fog} computing with {AI} approach: {Taxonomy} and a state of the art survey},
	volume = {185},
	issn = {10848045},
	shorttitle = {Application placement in {Fog} computing with {AI} approach},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1084804521000989},
	doi = {10.1016/j.jnca.2021.103078},
	abstract = {With the increasing use of the Internet of Things (IoT) in various fields and the need to process and store huge volumes of generated data, Fog computing was introduced to complement Cloud computing services. Fog computing offers basic services at the network for supporting IoT applications with low response time requirements. However, Fogs are distributed, heterogeneous, and their resources are limited, therefore efficient distribution of IoT applications tasks in Fog nodes, in order to meet quality of service (QoS) and quality of experience (QoE) constraints is challenging. In this survey, at first, we have an overview of basic concepts of Fog computing, and then review the application placement problem in Fog computing with focus on Artificial intelligence (AI) techniques. We target three main objectives with considering a characteristics of AI-based methods in Fog application placement problem: (i) categorizing evolutionary algorithms, (ii) categorizing machine learning algorithms, and (iii) categorizing combinatorial algorithms into subcategories includes a combination of machine learning and heuristic, a combination of evolutionary and heuristic, and a combinations of evolutionary and machine learning. Then the security considerations of application placement have been reviewed. Finally, we provide a number of open questions and issues as future works.},
	language = {en},
	urldate = {2021-10-05},
	journal = {Journal of Network and Computer Applications},
	author = {Nayeri, Zahra Makki and Ghafarian, Toktam and Javadi, Bahman},
	month = jul,
	year = {2021},
	keywords = {Edge computing, Fog computing, Application placement, Artificial intelligence, Resource management, Service placement, Task scheduling},
	pages = {103078},
	file = {Nayeri et al. - 2021 - Application placement in Fog computing with AI app.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/SWRZ6U8T/Nayeri et al. - 2021 - Application placement in Fog computing with AI app.pdf:application/pdf},
}

@article{samani_multilayer_2021,
	title = {Multilayer {Resource}-{Aware} {Partitioning} for {Fog} {Application} {Placement}},
	url = {http://arxiv.org/abs/2105.11033},
	doi = {10.1109/ICFEC51620.2021.00010},
	abstract = {Fog computing emerged as a crucial platform for the deployment of IoT applications. The complexity of such applications require methods that handle the resource diversity and network structure of Fog devices, while maximizing the service placement and reducing the resource wastage. Prior studies in this domain primarily focused on optimizing application-specific requirements and fail to address the network topology combined with the different types of resources encountered in Fog devices. To overcome these problems, we propose a multilayer resourceaware partitioning method to minimize the resource wastage and maximize the service placement and deadline satisfaction rates in a Fog infrastructure with high multi-user application placement requests. Our method represents the heterogeneous Fog resources as a multilayered network graph and partitions them based on network topology and resource features. Afterwards, it identifies the appropriate device partitions for placing an application according to its requirements, which need to overlap in the same network topology partition. Simulation results show that our multilayer resource-aware partitioning method is able to place twice as many services, satisfy deadlines for three times as many application requests, and reduce the resource wastage by up to 15 − 32 times compared to two availability-aware and resourceaware state-of-the-art methods.},
	language = {english},
	urldate = {2021-10-05},
	journal = {2021 IEEE 5th International Conference on Fog and Edge Computing (ICFEC)},
	author = {Samani, Zahra Najafabadi and Saurabh, Nishant and Prodan, Radu},
	month = may,
	year = {2021},
	note = {arXiv: 2105.11033},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing, and Cluster Computing, Computer Science - Distributed, Parallel},
	pages = {9--18},
	file = {Samani et al. - 2021 - Multilayer Resource-aware Partitioning for Fog App:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/JDNTPGKM/Samani et al. - 2021 - Multilayer Resource-aware Partitioning for Fog App.pdf:application/pdf},
}

@article{Ottenwälder_2013,
	title = {{MigCEP}: operator migration for mobility driven distributed complex event processing},
	doi = {10.1145/2488222.2488265},
	abstract = {A recent trend in communication networks — sometimes referred to as fog computing — offers to execute computational tasks close to the access points of the networks. This enables real-time applications, like mobile Complex Event Processing (CEP), to significantly reduce end-to-end latencies and bandwidth usage. Most work studying the placement of operators in such an environment completely disregards the migration costs. However, the mobility of users requires frequent migration of operators, together with possibly large state information, to meet latency restrictions and save bandwidth in the infrastructure. This paper presents a placement and migration method for providers of infrastructures that incorporate cloud and fog resources. It ensures application-defined end-to-end latency restrictions and reduces the network utilization by planning the migration ahead of time. Furthermore, we present how the application knowledge of the CEP system can be used to improve current live migration techniques for Virtual Machines to reduce the required bandwidth during the migration. Our evaluations show that we safe up to 49\% of the network utilization with perfect knowledge about a users mobility pattern and up to 27\% of the network utilization when considering the uncertainty of those patterns.},
	journal = {null},
	author = {Ottenwälder, Beate and Koldehofe, Boris and Rothermel, Kurt and Ramachandran, Umakishore},
	year = {2013},
	pmid = {null},
	note = {tex.mag\_id: 2077517106
tex.pmcid: null},
}

@article{Wang_2017,
	title = {Online placement of multi-component applications in edge computing environments},
	doi = {10.1109/access.2017.2665971},
	abstract = {Mobile edge computing is a new cloud computing paradigm, which makes use of small-sized edge clouds to provide real-time services to users. These mobile edge-clouds (MECs) are located in close proximity to users, thus enabling users to seamlessly access applications running on MECs. Due to the co-existence of the core (centralized) cloud, users, and one or multiple layers of MECs, an important problem is to decide where (on which computational entity) to place different components of an application. This problem, known as the application or workload placement problem, is notoriously hard, and therefore, heuristic algorithms without performance guarantees are generally employed in common practice, which may unknowingly suffer from poor performance as compared with the optimal solution. In this paper, we address the application placement problem and focus on developing algorithms with provable performance bounds. We model the user application as an application graph and the physical computing system as a physical graph, with resource demands/availabilities annotated on these graphs. We first consider the placement of a linear application graph and propose an algorithm for finding its optimal solution. Using this result, we then generalize the formulation and obtain online approximation algorithms with polynomial-logarithmic (poly-log) competitive ratio for tree application graph placement. We jointly consider node and link assignment, and incorporate multiple types of computational resources at nodes.},
	journal = {IEEE access : practical innovations, open solutions},
	author = {Wang, Shiqiang and Zafer, Murtaza and Leung, Kin K.},
	year = {2017},
	pmid = {null},
	note = {tex.mag\_id: 2401898190
tex.pmcid: null},
}

@article{Hong_2016,
	title = {Dynamic module deployment in a fog computing platform},
	doi = {10.1109/apnoms.2016.7737202},
	abstract = {Several applications, such as smart cities, smart homes and smart hospitals adopt Internet of Things (IoT) networks to collect data from IoT devices. The incredible growing speed of the number of IoT devices congests the networks and the large amount of data, which are streamed to data centers for further analysis, overload the data centers. In this paper, we implement a fog computing platform that leverages end devices, edge networks, and data centers to serve the IoT applications. In this paper, we focus on implementing a fog computing platform, which dynamically pushes programs to the devices. The programs pushed to the devices pre-process the data before transmitting them over the Internet, which reduces the network traffic and the load of data centers. We survey the existing platforms and virtualization technologies, and leverage them to implement the fog computing platform. Moreover, we formulate a deployment problem of the programs. We propose an efficient heuristic deployment algorithm to solve the problem. We also implement an optimal algorithm for comparisons. We conduct experiments with a real testbed to evaluate our algorithms and fog computing platform. The proposed algorithm shows near-optimal performance, which only deviates from optimal algorithm by at most 2\% in terms of satisfied requests. Moreover, the proposed algorithm runs in real-time, and is scalable. More precisely, it computes 1000 requests with 500 devices in ¡ 2 seconds. Last, the implemented fog computing platform results in real-time deployment speed: it deploys 20 requests ¡ 10 seconds.},
	journal = {null},
	author = {Hong, Hua-Jun and Tsai, Pei-Hsuan and Hsu, Cheng-Hsin},
	year = {2016},
	pmid = {null},
	note = {tex.mag\_id: 2551296122
tex.pmcid: null},
}

@article{Arkian_2017,
	title = {{MIST}: {Fog}-based data analytics scheme with cost-efficient resource provisioning for {IoT} crowdsensing applications},
	doi = {10.1016/j.jnca.2017.01.012},
	abstract = {Abstract Development of Internet of things (IoT) has revitalized the feature scale of wearables and smart home/city applications. The landscape of these applications encountering big data needs to be replotted on cloud instead of solely relying on limited storage and computational resources of small devices. However, with the rapid increase in the number of Internet-connected devices, the increased demand of real-time, low-latency services is proving to be challenging for the traditional cloud computing framework. Although, fog computing, by providing elastic resources and services to end users at the edge of network, emerges as a promising solution, but the upsurge of novel social applications such as crowd sensing has fostered the need for scalable cost-efficient platforms that can enable distributed data analytics, while optimizing the allocation of resources and minimizing the response time. Following the existing trends, we are motivated to propose a fog computing based scheme, called MIST (i.e. a cloud near the earth's surface with lesser density than fog), to support crowd sensing applications in the context of IoT. For cost-efficient provisioning limited resources, we also jointly investigate data consumer association, task distribution, and virtual machine placement towards MIST. We first formulate the problem into a mixed-integer non-linear program (MINLP) and then linearise it into a mixed integer linear program (MILP). A comprehensive evaluation of MIST is performed by consideration of real world parameters of the Tehran province, the capital of Iran. Results show that as the number of applications demanding real-time service increases, the MIST fog-based scheme outperforms traditional cloud computing.},
	journal = {Journal of Network and Computer Applications},
	author = {Arkian, Hamid Reza and Diyanat, Abolfazl and Pourkhalili, Atefe},
	year = {2017},
	pmid = {null},
	note = {tex.mag\_id: 2579405208
tex.pmcid: null},
}

@article{Zeng_2016,
	title = {Joint optimization of task scheduling and image placement in fog computing supported software-defined embedded system},
	doi = {10.1109/tc.2016.2536019},
	abstract = {Traditional standalone embedded system is limited in their functionality, flexibility, and scalability. Fog computing platform, characterized by pushing the cloud services to the network edge, is a promising solution to support and strengthen traditional embedded system. Resource management is always a critical issue to the system performance. In this paper, we consider a fog computing supported software-defined embedded system, where task images lay in the storage server while computations can be conducted on either embedded device or a computation server. It is significant to design an efficient task scheduling and resource management strategy with minimized task completion time for promoting the user experience. To this end, three issues are investigated in this paper: 1) how to balance the workload on a client device and computation servers, i.e., task scheduling, 2) how to place task images on storage servers, i.e., resource management, and 3) how to balance the I/O interrupt requests among the storage servers. They are jointly considered and formulated as a mixed-integer nonlinear programming problem. To deal with its high computation complexity, a computation-efficient solution is proposed based on our formulation and validated by extensive simulation based studies.},
	journal = {IEEE Transactions on Computers},
	author = {Zeng, Deze and Gu, Lin and Guo, Song and Cheng, Zixue and Cheng, Zixue and Yu, Shui},
	year = {2016},
	pmid = {null},
	note = {tex.mag\_id: 2319396036
tex.pmcid: null},
}

@article{Souza_2016,
	title = {Handling service allocation in combined {Fog}-cloud scenarios},
	doi = {10.1109/icc.2016.7511465},
	abstract = {The recent technological advances related to computing, storage, cloud, networking and the unstoppable deployment of end-user devices, are all coining the so-called Internet of Things (IoT). IoT embraces a wide set of heterogeneous services in highly impacting societal sectors, such as Healthcare, Smart Transportation or Media delivery, all of them posing a diverse set of requirements, including real time response, low latency, or high capacity. In order to properly address such diverse set of requirements, the combined use of Cloud and Fog computing turns up as an emerging trend. Indeed, Fog provides low delay for services demanding real time response, constrained to support low capacity queries, whereas Cloud provides high capacity at the cost of a higher latency. It is with no doubt that a new strategy is required to ease the combined operation of cloud and fog infrastructures in IoT scenarios, also referred to as Combined Fog-Cloud (CFC), in terms of service execution performance metrics. To that end, in this paper, we introduce and formulate the QoS-aware service allocation problem for CFC architectures as an integer optimization problem, whose solution minimizes the latency experienced by the services while guaranteeing the fulfillment of the capacity requirements.},
	journal = {null},
	author = {Souza, Vitor Barbosa and Ramirez, W. and Masip-Bruin, Xavier and Masip-Bruin, Xavi and Marin-Tordera, Eva and Ren, Guang-Jie and Tashakor, G. and Tashakor, G. and Tashakor, Ghazal},
	year = {2016},
	pmid = {null},
	note = {tex.mag\_id: 2481050413
tex.pmcid: null},
}

@article{Barcelo_2016,
	title = {{IoT}-{Cloud} service optimization in next generation smart environments},
	doi = {10.1109/jsac.2016.2621398},
	abstract = {The impact of the Internet of Things (IoT) on the evolution toward next generation smart environments (e.g., smart homes, buildings, and cities) will largely depend on the efficient integration of IoT and cloud computing technologies. With the predicted explosion in the number of connected devices and IoT services, current centralized cloud architectures, which tend to consolidate computing and storage resources into a few large data centers, will inevitably lead to excessive network load, end-to-end service latencies, and overall power consumption. Thanks to recent advances in network virtualization and programmability, highly distributed cloud networking architectures are a promising solution to efficiently host, manage, and optimize next generation IoT services in smart environments. In this paper, we mathematically formulate the service distribution problem (SDP) in IoT-Cloud networks, referred to as the IoT-CSDP, as a minimum cost mixed-cast flow problem that can be efficiently solved via linear programming. We focus on energy consumption as the major driver of today’s network and cloud operational costs and characterize the heterogeneous set of IoT-Cloud network resources according to their associated sensing, computing, and transport capacity and energy efficiency. Our results show that, when properly optimized, the flexibility of IoT-Cloud networks can be efficiently exploited to deliver a wide range of IoT services in the context of next generation smart environments, while significantly reducing overall power consumption.},
	journal = {IEEE Journal on Selected Areas in Communications},
	author = {Barcelo, Marc and Correa, Alejandro and Llorca, Jaime and Tulino, Antonia M. and Vicario, Jose Lopez and Morell, Antoni},
	year = {2016},
	pmid = {null},
	note = {tex.mag\_id: 2536604331
tex.pmcid: null},
}

@article{Skarlat_2016,
	title = {Resource provisioning for {IoT} services in the fog},
	doi = {10.1109/soca.2016.10},
	abstract = {The advent of the Internet of Things (IoT) leadsto the pervasion of business and private spaces with ubiquitous, networked computing devices. These devices do not simply actas sensors, but feature computational, storage, and networkingresources. These resources are close to the edge of the network, and it is a promising approach to exploit them in order to executeIoT services. This concept is known as fog computing.Despite existing theoretical foundations, the adoption of fogcomputing is still at its very beginning. Especially, there is alack of approaches for the leasing and releasing of resources. Toresolve this shortcoming, we present a conceptual framework forfog resource provisioning. We formalize an optimization problemwhich is able to take into account existing resources in fog/IoTlandscapes. The goal of this optimization problem is to providedelay-sensitive utilization of available fog-based computationalresources. We evaluate the resource provisioning model to showthe benefits of our contributions. Our results show a decrease indelays of up to 39\% compared to a baseline approach, yieldingshorter round-trip times and makespans.},
	journal = {null},
	author = {Skarlat, Olena and Schulte, Stefan and Borkowski, Michael and Leitner, Philipp},
	year = {2016},
	pmid = {null},
	note = {tex.mag\_id: 2565437603
tex.pmcid: null},
}

@article{Huang_2014,
	title = {Co-locating services in {IoT} systems to minimize the communication energy cost},
	doi = {10.1016/j.jides.2015.02.005},
	abstract = {Abstract Ubiquitous sensing and actuating devices are now everywhere in our living environment as part of the global cyber–physical ecosystem. Sensing and actuating capabilities can be modeled as services to compose intelligent Internet of Things (IoT) applications. An issue for perpetually running and managing these IoT devices is the energy cost. One energy saving strategy is to co-locate several services on one device in order to reduce the computing and communication energy. In this paper, we propose a service merging strategy for mapping and co-locating multiple services on devices. In a multi-hop network, the service co-location problem is formulated as a quadratic programming problem. We show a reduction method that reduces it to the integer programming problem. In a single hop network, the service co-location problem can be modeled as the Maximum Weighted Independent Set (MWIS) problem. We show the algorithm to transform a service flow to a co-location graph, then use known heuristic algorithms to find the maximum independent set which is the basis for making service co-location decisions. The performance of different co-location algorithms are evaluated by simulation in this paper.},
	journal = {Journal of Innovation in Digital Ecosystems},
	author = {Huang, Zhenqiu and Lin, Kwei-Jay and Yu, Shih-Yuan and Hsu, Jane Yung-jen},
	year = {2014},
	pmid = {null},
	note = {tex.mag\_id: 2019413422
tex.pmcid: null},
}

@article{Deng_2015,
	title = {Towards power consumption-delay tradeoff by workload allocation in cloud-fog computing},
	doi = {10.1109/icc.2015.7248934},
	abstract = {Fog computing, characterized by extending cloud computing to the edge of the network, has recently received considerable attention. The fog is not a substitute but a powerful complement to the cloud. It is worthy of studying the interplay and cooperation between the edge (fog) and the core (cloud). To address this issue, we study the tradeoff between power consumption and delay in a cloud-fog computing system. Specifically, we first mathematically formulate the workload allocation problem. After that, we develop an approximate solution to decompose the primal problem into three subproblems of corresponding subsystems, which can be independently solved. Finally, based on extensive simulations and numerical results, we show that by sacrificing modest computation resources to save communication bandwidth and reduce transmission latency, fog computing can significantly improve the performance of cloud computing.},
	journal = {null},
	author = {Deng, Ruilong and Lu, Rongxing and Lai, Chengzhe and Luan, Tom H.},
	year = {2015},
	pmid = {null},
	note = {tex.mag\_id: 1605638720
tex.pmcid: null},
}

@article{Cardellini_2015,
	title = {Distributed {QoS}-aware scheduling in storm},
	doi = {10.1145/2675743.2776766},
	abstract = {Storm is a distributed stream processing system that has recently gained increasing interest. We extend Storm to make it suitable to operate in a geographically distributed and highly variable environment such as that envisioned by the convergence of Fog computing, Cloud computing, and Internet of Things.},
	journal = {null},
	author = {Cardellini, Valeria and Grassi, Vincenzo and Grassi, Vincenzo and Presti, Francesco Lo and Nardelli, Matteo},
	year = {2015},
	pmid = {null},
	note = {tex.mag\_id: 2117823778
tex.pmcid: null},
}

@article{Cardellini_2015,
	title = {On {QoS}-aware scheduling of data stream applications over fog computing infrastructures},
	doi = {10.1109/iscc.2015.7405527},
	abstract = {Fog computing is rapidly changing the distributed computing landscape by extending the Cloud computing paradigm to include wide-spread resources located at the network edges. This diffused infrastructure is well suited for the implementation of data stream processing (DSP) applications, by possibly exploiting local computing resources. Storm is an open source, scalable, and fault-tolerant DSP system designed for locally distributed clusters. We made it suitable to operate in a geographically distributed and highly variable environment; to this end, we extended Storm with new components that allow to execute a distributed QoS-aware scheduler and give self-adaptation capabilities to the system. In this paper we provide a thorough experimental evaluation of the proposed solution using two sets of DSP applications: the former is characterized by a simple topology with different requirements; the latter comprises some well known applications (i.e., Word Count, Log Processing). The results show that the distributed QoS-aware scheduler outperforms the centralized default one, improving the application performance and enhancing the system with runtime adaptation capabilities. However, complex topologies involving many operators may cause some instability that can decrease the DSP application availability.},
	journal = {null},
	author = {Cardellini, Valeria and Grassi, Vincenzo and Grassi, Vincenzo and Presti, Francesco Lo and Nardelli, Matteo},
	year = {2015},
	pmid = {null},
	note = {tex.mag\_id: 2291823293
tex.pmcid: null},
}

@article{Cardellini_2016,
	title = {Optimal operator placement for distributed stream processing applications},
	doi = {10.1145/2933267.2933312},
	abstract = {Data Stream Processing (DSP) applications are widely used to timely extract information from distributed data sources, such as sensing devices, monitoring stations, and social networks. To successfully handle this ever increasing amount of data, recent trends investigate the possibility of exploiting decentralized computational resources (e.g., Fog computing) to define the applications placement. Several placement policies have been proposed in the literature, but they are based on different assumptions and optimization goals and, as such, they are not completely comparable to each other. In this paper we study the placement problem for distributed DSP applications. Our contributions are twofold. We provide a general formulation of the optimal DSP placement (for short, ODP) as an Integer Linear Programming problem which takes explicitly into account the heterogeneity of computing and networking resources and which encompasses - as special cases - the different solutions proposed in the literature. We present an ODP-based scheduler for the Apache Storm DSP framework. This allows us to compare some well-known centralized and decentralized placement solutions. We also extensively analyze the ODP scalability with respect to various parameter settings.},
	journal = {null},
	author = {Cardellini, Valeria and Grassi, Vincenzo and Grassi, Vincenzo and Presti, Francesco Lo and Nardelli, Matteo},
	year = {2016},
	pmid = {null},
	note = {tex.mag\_id: 2434290318
tex.pmcid: null},
}

@article{Zhang_2017,
	title = {Computing resource allocation in three-tier {IoT} fog networks: a joint optimization approach combining stackelberg game and matching},
	doi = {null},
	abstract = {Fog computing is a promising architecture to provide economic and low latency data services for future Internet of things (IoT)-based network systems. It relies on a set of low-power fog nodes that are close to the end users to offload the services originally targeting at cloud data centers. In this paper, we consider a specific fog computing network consisting of a set of data service operators (DSOs) each of which controls a set of fog nodes to provide the required data service to a set of data service subscribers (DSSs). How to allocate the limited computing resources of fog nodes (FNs) to all the DSSs to achieve an optimal and stable performance is an important problem. In this paper, we propose a joint optimization framework for all FNs, DSOs and DSSs to achieve the optimal resource allocation schemes in a distributed fashion. In the framework, we first formulate a Stackelberg game to analyze the pricing problem for the DSOs as well as the resource allocation problem for the DSSs. Under the scenarios that the DSOs can know the expected amount of resource purchased by the DSSs, a many-to-many matching game is applied to investigate the pairing problem between DSOs and FNs. Finally, within the same DSO, we apply another layer of many-to-many matching between each of the paired FNs and serving DSSs to solve the FN-DSS pairing problem. Simulation results show that our proposed framework can significantly improve the performance of the IoT-based network systems.},
	journal = {arXiv: Computer Science and Game Theory},
	author = {Zhang, Huaqing and Xiao, Yong and Bu, Shengrong and Niyato, Dusit and Yu, Richard and Han, Zhu},
	year = {2017},
	pmid = {null},
	note = {tex.mag\_id: 2950195285
tex.pmcid: null},
}

@article{Mennes_2016,
	title = {{GRECO}: {A} distributed genetic algorithm for reliable application placement in hybrid clouds},
	doi = {10.1109/cloudnet.2016.45},
	abstract = {Hybrid clouds, consisting of multiple individual smaller clouds with heterogeneous capabilities, are becoming more and more popular through concepts such as inter-clouds, fog-and edge-computing. They provide fast computations without introducing large network latency. However, such cloud environments often contain unreliable nodes and links that are failure prone. Therefore, the deployment of applications requiring availability guarantees is a current research challenge. If such a placement algorithm is CPU-, memory-, network-and availability-aware, the applications can use the resources as optimal as possible with a small failure probability. The optimal deployment of applications in the network infrastructure is a NP-hard problem and, as a consequence, exact algorithms to solve it are not scalable. In this paper we propose GRECO, a distributed genetic algorithm to place service-oriented applications on a hybrid cloud, by defining a representation of an application placement in a biased-random-key chromosome and using a fault-tolerance distributed pool model. When compared with an existing Integer Linear Programming approach, simulations show that GRECO is scalable (speedup of a factor of 1000) and obtain near optimal performance results.},
	journal = {null},
	author = {Mennes, Ruben and Spinnewyn, Bart and Latre, Steven and Botero, Juan Felipe},
	year = {2016},
	pmid = {null},
	note = {tex.mag\_id: 2560141371
tex.pmcid: null},
}

@article{tang_migration_2019,
	title = {Migration modeling and learning algorithms for containers in fog computing},
	doi = {10.1109/tsc.2018.2827070},
	abstract = {Fog Computing (FC) is a flexible architecture to support distributed domain-specific applications with cloud-like quality of service. However, current FC still lacks the mobility support mechanism when facing many mobile users with diversified application quality requirements. Such mobility support mechanism can be critical such as in the industrial internet where human, products, and devices are moveable. To fill in such gaps, in this paper we propose novel container migration algorithms and architecture to support mobility tasks with various application requirements. Our algorithms are realized from three aspects: 1) We consider mobile application tasks can be hosted in a container of a corresponding fog node that can be migrated, taking the communication delay and computational power consumption into consideration; 2) We further model such container migration strategy as multiple dimensional Markov Decision Process (MDP) spaces. To effectively reduce the large MDP spaces, efficient deep reinforcement learning algorithms are devised to achieve fast decision-making and 3) We implement the model and algorithms as a container migration prototype system and test its feasibility and performance. Extensive experiments show that our strategy outperforms the existing baseline approaches 2.9, 48.5 and 58.4 percent on average in terms of delay, power consumption, and migration cost, respectively.},
	journal = {IEEE Transactions on Services Computing},
	author = {Tang, Zhiqing and Zhou, Xiaojie and Zhang, Fuming and Jia, Weijia and Zhao, Wei and Zhao, Wei},
	year = {2019},
	pmid = {null},
	note = {tex.mag\_id: 2801779586
tex.pmcid: null},
}

@article{Souza_2016,
	title = {Towards distributed service allocation in fog-to-cloud ({F2C}) scenarios},
	doi = {10.1109/glocom.2016.7842341},
	abstract = {The novel Fog-to-Cloud (F2C) computing paradigm has been recently proposed aiming at the enhanced integration of Fog Computing and Cloud Computing through the coordinated management of underlying resources, taking into account the peculiarities inherent to each computing model, and enabling the parallel and distributed execution of services into distinct fog/cloud resources. Nevertheless, studies on F2C are still premature and several issues remain unsolved yet. For instance, in an F2C scenario service allocation must cope with the specific aspects associated to cloud and fog resource models, requiring distinct strategies to properly map IoT services into the most suitable available resources. In this paper, we propose a QoS-aware service distribution strategy contemplating both service requirements and resource offerings. We model the service allocation problem as a multidimensional knapsack problem (MKP) aiming at an optimal service allocation taking into consideration delay, load balancing and energy consumption. The presented results, demonstrate that the adopted strategy may be applied by F2C computing reducing the service allocation delay, while also diminishing load and energy consumption on cloud and fog resources.},
	journal = {null},
	author = {Souza, Vitor Barbosa and Masip-Bruin, Xavi and Marin-Tordera, Eva and Ramirez, W. and Sanchez, Sergio},
	year = {2016},
	pmid = {null},
	note = {tex.mag\_id: 2584077101
tex.pmcid: null},
}

@article{Rahbari_2017,
	title = {Scheduling of fog networks with optimized knapsack by symbiotic organisms search},
	doi = {10.23919/fruct.2017.8250193},
	abstract = {Internet of things as a concept uses wireless sensor networks that have limitations in power, storage, and delay when processing and sending data to the cloud. Fog computing as an extension of cloud services to the edge of the network reduces latency and traffic, so it is very useful in healthcare, wearables, intelligent transportation systems and smart cities. Scheduling is the NP-hard issues in fog computing. Edge devices due to proximity to sensors and clouds are capable of processing power and are beneficial for resource management algorithms. We present a knapsack-based scheduling optimized by symbiotic organisms search that is simulated in iFogsim as a standard simulator for fog computing. The results show improvements in the energy consumption by 18\%, total network usage by 1.17\%, execution cost by 15\%, and sensor lifetime by 5\% in our scheduling method are better than the FCFS (First Come First Served) and knapsack algorithms.},
	journal = {null},
	author = {Rahbari, Dadmehr and Nickray, Mohsen and Nickray, Mohsen},
	year = {2017},
	pmid = {null},
	note = {tex.mag\_id: 2783073469
tex.pmcid: null},
}

@article{Abbasi_2016,
	title = {Scheduling tasks in the cloud computing environment with the effect of cuckoo optimization algorithm},
	doi = {10.14445/23488387/ijcse-v3i8p101},
	abstract = {null},
	journal = {International Journal on Computer Science and Engineering},
	author = {Abbasi, Mohammad Javad and Mohri, Mehrdad},
	year = {2016},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2553767083
tex.pmcid: null},
}

@article{Abdel-Basset_2020,
	title = {Energy-{Aware} {Metaheuristic} algorithm for {Industrial} {Internet} of {Things} task scheduling problems in fog computing applications},
	doi = {10.1109/jiot.2020.3012617},
	abstract = {null},
	journal = {IEEE Internet of Things Journal},
	author = {Abdel-Basset, Mohamed and El-Shahat, Doaa and Elhoseny, Mohamed and Song, Houbing},
	year = {2020},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3046293351
tex.pmcid: null},
}

@article{Akintoye_2019,
	title = {Improving quality-of-service in {Cloud}/{Fog} computing through efficient resource allocation},
	doi = {10.3390/s19061267},
	abstract = {Recently, a massive migration of enterprise applications to the cloud has been recorded in the IT world. One of the challenges of cloud computing is Quality-of-Service management, which includes the adoption of appropriate methods for allocating cloud-user applications to virtual resources, and virtual resources to the physical resources. The effective allocation of resources in cloud data centers is also one of the vital optimization problems in cloud computing, particularly when the cloud service infrastructures are built by lightweight computing devices. In this paper, we formulate and present the task allocation and virtual machine placement problems in a single cloud/fog computing environment, and propose a task allocation algorithmic solution and a Genetic Algorithm Based Virtual Machine Placement as solutions for the task allocation and virtual machine placement problem models. Finally, the experiments are carried out and the results show that the proposed solutions improve Quality-of-Service in the cloud/fog computing environment in terms of the allocation cost.},
	journal = {Sensors},
	author = {Akintoye, Samson B. and Bagula, Antoine},
	year = {2019},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2921575628
tex.pmcid: null},
	file = {Full Text:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/ERX9ERPH/Akintoye and Bagula - 2019 - Improving quality-of-service in CloudFog computin.pdf:application/pdf},
}

@article{Alam_2019,
	title = {Autonomic computation offloading in mobile edge for {IoT} applications},
	doi = {10.1016/j.future.2018.07.050},
	abstract = {Abstract Computation offloading is a protuberant elucidation for the resource-constrained mobile devices to accomplish the process demands high computation capability. The mobile cloud is the well-known existing offloading platform, which usually far-end network solution, to leverage computation of the resource-constrained mobile devices. Because of the far-end network solution, the user devices experience higher latency or network delay, which negatively affects the real-time mobile Internet of things (IoT) applications. Therefore, this paper proposed near-end network solution of computation offloading in mobile edge/fog. The mobility, heterogeneity and geographical distribution mobile devices through several challenges in computation offloading in mobile edge/fog. However, for handling the computation resource demand from the massive mobile devices, a deep Q-learning based autonomic management framework is proposed. The distributed edge/fog network controller (FNC) scavenging the available edge/fog resources i.e. processing, memory, network to enable edge/fog computation service. The randomness in the availability of resources and numerous options for allocating those resources for offloading computation fits the problem appropriate for modeling through Markov decision process (MDP) and solution through reinforcement learning. The proposed model is simulated through MATLAB considering oscillated resource demands and mobility of end user devices. The proposed autonomic deep Q-learning based method significantly improves the performance of the computation offloading through minimizing the latency of service computing. The total power consumption due to different offloading decisions is also studied for comparative study purpose which shows the proposed approach as energy efficient with respect to the state-of-the-art computation offloading solutions.},
	journal = {Future Generation Computer Systems},
	author = {Alam, Golam Rabiul and Hassan, Mohammad Mehedi and Uddin, Md. Zia and Almogren, Ahmad and Fortino, Giancarlo},
	year = {2019},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2885631546
tex.pmcid: null},
}

@article{Alelaiwi_2019,
	title = {An efficient method of computation offloading in an edge cloud platform},
	doi = {10.1016/j.jpdc.2019.01.003},
	abstract = {Abstract In a data-rich digital world, our hand-held resource-constrained mobile devices are restricted to performing small-to-medium-level computation processes and are incapable of performing high-computation processes. Computation offloading is a suitable solution for overcoming this shortcoming. Until recently, we have perceived cloud computing as an appropriate computation-offloading platform for mobile devices. However, cloud data centers, being far-end networks for mobile devices, increase the latency or network delay, which in turn affects the performance of real-time mobile Internet-of-Things applications. Hence, for critical real-time applications, a near-end network approach of computation offloading is required. Furthermore, the major hurdles for geographically distributed mobile devices are mobility and heterogeneity in the process of computation offloading. To overcome these challenges, the use of a deep-learning-based response-time-prediction framework is proposed in this paper to determine whether to offload in the nearby fog/edge node or neighbor fog/edge node, or cloud node. Furthermore, a restricted Boltzmann machines learning is applied to tackle the randomness in the availability of resources. We simulate the proposed model in MATLAB while considering the mobility and fluctuating resource demands of the end users. Implementing our deep-learning-based response-time-prediction framework improves the performance of the computation offloading because it facilitates a prompt selection of the offloading location.},
	journal = {Journal of Parallel and Distributed Computing},
	author = {Alelaiwi, Abdulhameed},
	year = {2019},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2913429011
tex.pmcid: null},
}

@article{Alfakih_2020,
	title = {Task offloading and resource allocation for mobile edge computing by deep reinforcement learning based on {SARSA}},
	doi = {10.1109/access.2020.2981434},
	abstract = {In recent years, computation offloading has become an effective way to overcome the constraints of mobile devices (MDs) by offloading delay-sensitive and computation-intensive mobile application tasks to remote cloud-based data centers. Smart cities can benefit from offloading to edge points in the framework of the so-called cyber–physical–social systems (CPSS), as for example in traffic violation tracking cameras. We assume that there are mobile edge computing networks (MECNs) in more than one region, and they consist of multiple access points, multi-edge servers, and N MDs, where each MD has M independent real-time massive tasks. The MDs can connect to a MECN through the access points or the mobile network. Each task be can processed locally by the MD itself or remotely. There are three offloading options: nearest edge server, adjacent edge server, and remote cloud. We propose a reinforcement-learning-based state-action-reward-state-action (RL-SARSA) algorithm to resolve the resource management problem in the edge server, and make the optimal offloading decision for minimizing system cost, including energy consumption and computing time delay. We call this method OD-SARSA (offloading decision-based SARSA). We compared our proposed method with reinforcement learning based Q learning (RL-QL), and it is concluded that the performance of the former is superior to that of the latter.},
	journal = {IEEE access : practical innovations, open solutions},
	author = {Alfakih, Taha and Hassan, Mohammad Mehedi and Gumaei, Abdu and Savaglio, Claudio and Fortino, Giancarlo},
	year = {2020},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3010723141
tex.pmcid: null},
}

@article{Alsaffar_2016,
	title = {An architecture of {IoT} service delegation and resource allocation based on collaboration between fog and cloud computing},
	doi = {10.1155/2016/6123234},
	abstract = {Despite the wide utilization of cloud computing (e.g., services, applications, and resources), some of the services, applications, and smart devices are not able to fully benefit from this attractive cloud computing paradigm due to the following issues: (1) smart devices might be lacking in their capacity (e.g., processing, memory, storage, battery, and resource allocation), (2) they might be lacking in their network resources, and (3) the high network latency to centralized server in cloud might not be efficient for delay-sensitive application, services, and resource allocations requests. Fog computing is promising paradigm that can extend cloud resources to edge of network, solving the abovementioned issue. As a result, in this work, we propose an architecture of IoT service delegation and resource allocation based on collaboration between fog and cloud computing. We provide new algorithm that is decision rules of linearized decision tree based on three conditions (services size, completion time, and VMs capacity) for managing and delegating user request in order to balance workload. Moreover, we propose algorithm to allocate resources to meet service level agreement (SLA) and quality of services (QoS) as well as optimizing big data distribution in fog and cloud computing. Our simulation result shows that our proposed approach can efficiently balance workload, improve resource allocation efficiently, optimize big data distribution, and show better performance than other existing methods.},
	journal = {Mobile Information Systems},
	author = {Alsaffar, Aymen Abdullah and Pham, Hung Phuoc and Hong, Choong Seon and Huh, Eui-Nam and Huh, Eui-Nam and Aazam, Mohammad},
	year = {2016},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2531208772
tex.pmcid: null},
	file = {Full Text:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/YINLY38N/Alsaffar et al. - 2016 - An architecture of IoT service delegation and reso.pdf:application/pdf},
}

@article{Arshad_2018,
	title = {Evaluating bio-inspired optimization techniques for utility price estimation in fog computing},
	doi = {10.1109/smartcloud.2018.00022},
	abstract = {With continuous advancements in the domain of information and communication technologies, large-scale enterprises and the Internet service providers have realized about the limited capacity of data storage available to them. This leads to the concept of sharing of resources among the enterprises by renting these services through the Service Level Agreements (SLAs). Fog Computing is proposed to be an extension of cloud computing architecture where the resources are brought near the end users. Fog computing, in contrast to cloud computing provides services along with the computing resources. To borrow the services, the enterprises have to pay according to their usage of the services or resources. In this paper, two nature inspired algorithms are compared to determine the efficient management of resources so that the cost of resources can be minimized and the billing can be achieved through calculation of the utilized resources. Pigeon Inspired Optimization (PIO) and Enhanced Differential Evolution (EDE) are used to determine the energy consumed by the cloudlets or edge nodes that in turn can be used for estimating the bill through the Time of Use pricing variable. We evaluate both of the aforementioned technique to determine their performance regarding the bill calculation on the basis of usage of fog servers. Simulation results demonstrate that PIO gives significantly better results than EDE in terms of resource utilization whereas for bill reduction EDE outperforms PIO based technique.},
	journal = {null},
	author = {Arshad, Hafsa and Shah, Munam Ali and Khattak, Hasan Ali and Ameer, Zoobia and Abbas, Assad and Khan, Samee U.},
	year = {2018},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2899375628
tex.pmcid: null},
}

@article{Arshad_2019,
	title = {Estimation of fog utility pricing: {A} bio-inspired optimisation techniques' perspective},
	doi = {10.1080/17445760.2019.1606913},
	abstract = {ABSTRACTDue to the limited data storage capacity available to Internet service providers and large-scale enterprises, the concept of resource sharing arises. The services can be given on lease to e...},
	journal = {International Journal of Parallel, Emergent and Distributed Systems},
	author = {Arshad, Hafsa and Khattak, Hasan Ali and Ameer, Zoobia and Abbas, Assad and Khan, Samee U.},
	year = {2019},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2939704869
tex.pmcid: null},
}

@article{Baek_2019,
	title = {Managing fog networks using reinforcement learning based load balancing algorithm},
	doi = {null},
	abstract = {The powerful paradigm of Fog computing is currently receiving major interest, as it provides the possibility to integrate virtualized servers into networks and brings cloud service closer to end devices. To support this distributed intelligent platform, Software-Defined Network (SDN) has emerged as a viable network technology in the Fog computing environment. However, uncertainties related to task demands and the different computing capacities of Fog nodes, inquire an effective load balancing algorithm. In this paper, the load balancing problem has been addressed under the constraint of achieving the minimum latency in Fog networks. To handle this problem, a reinforcement learning based decision-making process has been proposed to find the optimal offloading decision with unknown reward and transition functions. The proposed process allows Fog nodes to offload an optimal number of tasks among incoming tasks by selecting an available neighboring Fog node under their respective resource capabilities with the aim to minimize the processing time and the overall overloading probability. Compared with the traditional approaches, the proposed scheme not only simplifies the algorithmic framework without imposing any specific assumption on the network model but also guarantees convergence in polynomial time. The results show that, during average delays, the proposed reinforcement learning-based offloading method achieves significant performance improvements over the variation of service rate and traffic arrival rate. The proposed algorithm achieves 1.17\%, 1.02\%, and 3.21\% lower overload probability relative to random, least-queue and nearest offloading selection schemes, respectively.},
	journal = {arXiv: Distributed, Parallel, and Cluster Computing},
	author = {Baek, Jung-yeon and Kaddoum, Georges and Garg, Sahil and Garg, Sahil and Garg, Sahil and Kaur, Kuljeet and Kaur, Kuljeet and Gravel, Vivianne},
	year = {2019},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2912663582
tex.pmcid: null},
}

@article{Bashir_2019,
	title = {Resource allocation through logistic regression and multicriteria decision making method in {IoT} fog computing},
	doi = {10.1002/ett.3824},
	abstract = {null},
	journal = {null},
	author = {Bashir, Hayat and Lee, Seonah and Kim, Kyong Hoon},
	year = {2019},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2996482369
tex.pmcid: null},
}

@article{Bitam_2018,
	title = {Fog computing job scheduling optimization based on bees swarm},
	doi = {10.1080/17517575.2017.1304579},
	abstract = {ABSTRACTFog computing is a new computing architecture, composed of a set of near-user edge devices called fog nodes, which collaborate together in order to perform computational services such as running applications, storing an important amount of data, and transmitting messages. Fog computing extends cloud computing by deploying digital resources at the premise of mobile users. In this new paradigm, management and operating functions, such as job scheduling aim at providing high-performance, cost-effective services requested by mobile users and executed by fog nodes. We propose a new bio-inspired optimization approach called Bees Life Algorithm (BLA) aimed at addressing the job scheduling problem in the fog computing environment. Our proposed approach is based on the optimized distribution of a set of tasks among all the fog computing nodes. The objective is to find an optimal tradeoff between CPU execution time and allocated memory required by fog computing services established by mobile users. Our empi...},
	journal = {Enterprise Information Systems},
	author = {Bitam, Salim and Zeadally, Sherali and Mellouk, Abdelhamid},
	year = {2018},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2606939427
tex.pmcid: null},
}

@article{Boveiri_2019,
	title = {An efficient {Swarm}-{Intelligence} approach for task scheduling in cloud-based internet of things applications},
	doi = {10.1007/s12652-018-1071-1},
	abstract = {In our rapidly-growing big-data area, often the big sensory data from Internet of Things (IoT) cannot be sent directly to the far data-center in an efficient way because of the limitation in the network infrastructure. Fog computing, which has increasingly gained popularity for real-time applications, offers the utilization of local mini data-centers near the sensors to release the burden from the main data-center, and to exploit the full potential of cloud-based IoT. In this paper, a high-performance approach based on the Max–Min Ant System (MMAS), which is an efficient variation in the family of ant colony optimization algorithms, is proposed to tackle the static task-graph scheduling in homogeneous multiprocessor environments, the predominant technology used as mini-servers in fog computing. The main duty of the proposed approach is to properly manipulate the priority values of tasks so that the most optimal task-order can be achieved. Leveraging background knowledge of the problem, as heuristic values, has made the proposed approach very robust and efficient. Different random task-graphs with different shape parameters have been utilized to evaluate the proposed approach, and the results show its efficiency and superiority versus traditional counterparts from the performance perspective.},
	journal = {Journal of Ambient Intelligence and Humanized Computing},
	author = {Boveiri, Hamid Reza and Khayami, Raouf and Elhoseny, Mohamed and Gunasekaran, M.},
	year = {2019},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2895733006
tex.pmcid: null},
	file = {Full Text:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/E8R4QPC3/Boveiri et al. - 2019 - An efficient Swarm-Intelligence approach for task .pdf:application/pdf},
}

@article{Butt_2019,
	title = {Optimization of response and processing time for smart societies using particle swarm optimization and levy walk},
	doi = {10.1007/978-3-030-15032-7_2},
	abstract = {Reducing delay and latency in the cloud computing environment is a challenge for the present research community. This study performed a rigorous, comparative analysis of the fog computing paradigm and the conventional cloud computing paradigm in the context of the Smart Grid (SG). To meet the consumers’ demand and optimize cloud services to achieve service level objectives is of great importance. The fog is introduced to enhance the efficiency of the cloud and to fulfill the consumer requests at the edge of the network. When the requests of Smart Societies (SSs) are huge on fog, the increased demand for real-time response is becoming a challenge for the SG. In this study, Particle Swarm Optimization is implemented and compared with the proposed techniques: Improved PSO with Lewy Walk (IPSOLW). These load balancing algorithms are compared on the basis of Closest Data Center (CDC) and Optimize Response Time (ORT). These proposed algorithms handle the load of SS on fog. The proposed IPSOLW handles more requests because of LW, the requests are directly allocated to best DC.},
	journal = {null},
	author = {Butt, Ayesha Anjum and Khan, Zahoor Ali and Javaid, Nadeem and Chand, Annas and Fatima, Aisha and Islam, Muhammad Talha},
	year = {2019},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2924326506
tex.pmcid: null},
	file = {Full Text:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/M64HBGZF/Butt et al. - 2019 - Optimization of response and processing time for s.pdf:application/pdf},
}

@article{Canali_2019,
	title = {{GASP}: {Genetic} algorithms for service placement in fog computing systems},
	doi = {10.3390/a12100201},
	abstract = {Fog computing is becoming popular as a solution to support applications based on geographically distributed sensors that produce huge volumes of data to be processed and filtered with response time constraints. In this scenario, typical of a smart city environment, the traditional cloud paradigm with few powerful data centers located far away from the sources of data becomes inadequate. The fog computing paradigm, which provides a distributed infrastructure of nodes placed close to the data sources, represents a better solution to perform filtering, aggregation, and preprocessing of incoming data streams reducing the experienced latency and increasing the overall scalability. However, many issues still exist regarding the efficient management of a fog computing architecture, such as the distribution of data streams coming from sensors over the fog nodes to minimize the experienced latency. The contribution of this paper is two-fold. First, we present an optimization model for the problem of mapping data streams over fog nodes, considering not only the current load of the fog nodes, but also the communication latency between sensors and fog nodes. Second, to address the complexity of the problem, we present a scalable heuristic based on genetic algorithms. We carried out a set of experiments based on a realistic smart city scenario: the results show how the performance of the proposed heuristic is comparable with the one achieved through the solution of the optimization problem. Then, we carried out a comparison among different genetic evolution strategies and operators that identify the uniform crossover as the best option. Finally, we perform a wide sensitivity analysis to show the stability of the heuristic performance with respect to its main parameters.},
	journal = {Algorithms},
	author = {Canali, Claudia and Lancellotti, Riccardo},
	year = {2019},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2974697812
tex.pmcid: null},
	file = {Full Text:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/HPAFFPQB/Canali and Lancellotti - 2019 - GASP Genetic algorithms for service placement in .pdf:application/pdf},
}

@article{Cao_2018,
	title = {A machine learning-based algorithm for joint scheduling and power control in wireless networks},
	doi = {10.1109/jiot.2018.2853661},
	abstract = {Wireless network resource allocation is an important issue for designing Internet of Things systems. In this paper, we consider the problem of wireless network capacity optimization that involves issues such as flow allocation, link scheduling, and power control. We show that it can be decomposed into a linear program and a nonlinear weighted sum-rate maximization problem for power allocation. Unlike most traditional methods that iteratively search the optimal solutions of the nonlinear subproblem, we propose to directly compute approximated solutions based on machine learning techniques. Specifically, the learning systems consist of both support vector machines (SVMs) and deep belief networks (DBNs) that are trained based on offline computed optimal solutions. In the running phase, the SVMs perform classification for each link to decide whether to use maximal transmit power or be turned off. At the same time, the DBNs compute an approximation of the optimal power allocation. The two results are combined to obtain an approximated solution of the nonlinear program. Simulation results demonstrate the effectiveness of the proposed machine learning-based algorithm.},
	journal = {IEEE Internet of Things Journal},
	author = {Cao, Xianghui and Ma, Rui and Liu, Lu and Shi, Hongbao and Cheng, Yu and Sun, Changyin},
	year = {2018},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2879986537
tex.pmcid: null},
}

@article{Chen_2011,
	title = {A multi-facet survey on memetic computation},
	doi = {10.1109/tevc.2011.2132725},
	abstract = {Memetic computation is a paradigm that uses the notion of meme(s) as units of information encoded in computational representations for the purpose of problem-solving. It covers a plethora of potentially rich meme-inspired computing methodologies, frameworks and operational algorithms including simple hybrids, adaptive hybrids and memetic automaton. In this paper, a comprehensive multi-facet survey of recent research in memetic computation is presented.},
	journal = {IEEE Transactions on Evolutionary Computation},
	author = {Chen, Xianshun and Ong, Yew-Soon and Lim, Meng-Hiot and Tan, Kay Chen},
	year = {2011},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2104274529
tex.pmcid: null},
}

@article{Chen_2020,
	title = {Artificial intelligence aided joint bit rate selection and radio resource allocation for adaptive video streaming over f-rans},
	doi = {10.1109/mwc.001.1900351},
	abstract = {Recently, fog-computing-based radio access networks (F-RANs) have been conceptualized to provide high quality of experience (QoE) for adaptive bit rate (ABR) streaming, where additional computing capacity is supplemented on fog nodes to facilitate complicated cross-layer optimization (i.e., joint bit rate selection and radio resource allocation). However, finding an optimal global solution with acceptable complexity is still infeasible by the conventional optimization methods. In this work, we propose an artificial intelligence (AI) aided joint bit rate selection and radio resource allocation scheme referred to as iABR, which provides a new vision for handling the over-complicated optimization in F-RANs. Based on multi-agent hierarchy deep reinforcement learning, the proposed iABR can dynamically allocate radio resource and select bit rate in a multiuser scenario, by perceiving the network environment and clients' player information. Moreover, long short-term memory (LSTM) is employed by the iABR algorithm, which enables accurate prediction of the change of channel quality by learning the history of the wireless channel. Hence, iABR is able to adjust the action policy in advance to accommodate the future channel quality for avoiding bit rate fluctuation. According to the experimental results, the iABR exhibits higher QoE in terms of high average bit rate, low rebuffering ratio, and average bit rate variance. Last but not least, the QoE performance of all the clients are fairly guaranteed by the iABR algorithm, enhancing the practicality of AI-driven F-RANs for multimedia service delivery.},
	journal = {IEEE Wireless Communications},
	author = {Chen, Jienan and Wei, Zhongxiang and Wei, Zhongxiang and Wei, Zhongxiang and Wei, Zhongxiang and Li, Shuai and Li, Shuai and Cao, Bin and Cao, Bin},
	year = {2020},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3021066175
tex.pmcid: null},
	file = {Full Text:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/EDGBEWSC/Chen et al. - 2020 - Artificial intelligence aided joint bit rate selec.pdf:application/pdf},
}

@article{Dehury_2019,
	title = {Personalized service delivery using reinforcement learning in fog and cloud environment},
	doi = {10.1145/3366030.3366055},
	abstract = {null},
	journal = {null},
	author = {Dehury, Chinmaya Kumar and Dehury, Chinmaya Kumar and Srirama, Satish Narayana},
	year = {2019},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3007166121
tex.pmcid: null},
}

@article{Farhat_2020,
	title = {Reinforcement {R}-{Learning} model for time scheduling of on-{Demand} fog placement},
	doi = {10.1007/s11227-019-03032-z},
	abstract = {On the fly deployment of fog nodes near users provides the flexibility of pushing services anywhere and whenever needed. Nevertheless, taking a real-life scenario, the cloud might limit the number of fogs to place for minimizing the complexity of monitoring a large number of fogs and cost for volunteers that do not offer their resources for free. This implies choosing the right time and best volunteer to create a fog which the cloud can benefit from is essential. This choice is subject to study the demand of a particular location for services in order to maximize the resources utilization of these fogs. A simple algorithm will not be able to explore randomly changing users’ demands. Therefore, there is a need for an intelligent model capable of scheduling fog placement based on the user’s requests. In this paper, we propose a Fog Scheduling Decision model based on reinforcement R-learning, which focuses on studying the behavior of service requesters and produces a suitable fog placement schedule based on the concept of average reward. Our model aims to decrease the cloud’s load by utilizing the maximum available fogs resources over different locations. An implementation of our proposed R-learning model is provided in the paper, followed by a series of experiments on a real dataset to prove its efficiency in utilizing fog resources and minimizing the cloud’s load. We also demonstrate the ability of our model to improve over time by adapting the new demand of users. Experiments comparing the decisions of our model with two other potential fog placement approaches used for task/service scheduling (threshold based and random based) show that the number of processed requests performed by the cloud decreases from 100 to 30\% with a limited number of fogs to push. These results demonstrate that our proposed Fog Scheduling Decision model plays a crucial role in the placement of the on-demand fog to the right location at the right time while taking into account the user’s needs.},
	journal = {The Journal of Supercomputing},
	author = {Farhat, Peter and Sami, Hani and Mourad, Azzam},
	year = {2020},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2981421175
tex.pmcid: null},
	file = {Full Text:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/CF2TTL8E/Farhat et al. - 2020 - Reinforcement R-Learning model for time scheduling.pdf:application/pdf},
}

@article{Frohlich_2020,
	title = {Optimal fog services placement in sdn iot network using random neural networks and cognitive network map},
	doi = {10.1007/978-3-030-61401-0_8},
	abstract = {null},
	journal = {null},
	author = {Frohlich, Piotr and Gelenbe, Erol},
	year = {2020},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3093843803
tex.pmcid: null},
	file = {Full Text:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/FJ7HNFYZ/Frohlich and Gelenbe - 2020 - Optimal fog services placement in sdn iot network .pdf:application/pdf},
}

@article{Gazori_2019,
	title = {Saving time and cost on the scheduling of fog-based {IoT} applications using deep reinforcement learning approach},
	doi = {10.1016/j.future.2019.09.060},
	abstract = {Abstract Due to the rapid growth of intelligent devices and the Internet of Things (IoT) applications in recent years, the volume of data that is generated by these devices is increasing ceaselessly. Hence, moving all of these data to cloud datacenters would be impossible and would lead to more bandwidth usage, latency, cost, and energy consumption. In such cases, the fog layer would be the best place for data processing. In the fog layer, the computing equipment dedicates parts of its limited resources to process the IoT application tasks. Therefore, efficient utilization of computing resources is of great importance and requires an optimal and intelligent strategy for task scheduling. In this paper, we have focused on the task scheduling of fog-based IoT applications with the aim of minimizing long-term service delay and computation cost under the resource and deadline constraints. To address this problem, we have used the reinforcement learning approach and have proposed a Double Deep Q-Learning (DDQL)-based scheduling algorithm using the target network and experience replay techniques. The evaluation results reveal that our proposed algorithm outperforms some baseline algorithms in terms of service delay, computation cost, energy consumption and task accomplishment and also handles the Single Point of Failure (SPoF) and load balancing challenges.},
	journal = {Future Generation Computer Systems},
	author = {Gazori, Pegah and Rahbari, Dadmehr and Nickray, Mohsen and Nickray, Mohsen},
	year = {2019},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2990913508
tex.pmcid: null},
}

@article{Ghalehtaki_2019,
	title = {A bee colony-based algorithm for micro-cache placement close to end users in fog-based content delivery networks},
	doi = {10.1109/ccnc.2019.8651773},
	abstract = {Fog-based Content Delivery Networks (CDNs) distribute contents from origin servers to cloud replica servers and to fog caches. Some of these fog caches may be located on Set-top Boxes (STBs) close to end users, assuming that the STBs can host micro-caches. This can greatly reduce Latency. Network function virtualization (NFV) is a technology that can be used in fog systems. NFV-enabled STBs can therefore host micro-caches implemented as virtual network functions (VNFs). Appropriate placement mechanisms are needed to place these micro-caches to improve end-users’ QoS in terms of Latency while still minimizing cost. In this paper, this placement problem is modeled as an optimization problem. A bee colony-based algorithm is suggested to find the placement that minimizes an aggregation of Latency and micro-cache storage cost. The simulation results show an improvement in the aggregated Latency and cost when the proposed algorithm is deployed.},
	journal = {null},
	author = {Ghalehtaki, Razieh Abbasi and Kianpisheh, Somayeh and Glitho, Roch},
	year = {2019},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2918686014
tex.pmcid: null},
	keywords = {⛔ No INSPIRE recid found},
	file = {Ghalehtaki et al_2019_A bee colony-based algorithm for micro-cache placement close to end users in.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/GMPDHQQJ/Ghalehtaki et al_2019_A bee colony-based algorithm for micro-cache placement close to end users in.pdf:application/pdf},
}

@article{Ghobaei-Arani_2020,
	title = {An efficient task scheduling approach using {Moth}‐flame optimization algorithm for {Cyber}‐physical system applications in fog computing},
	doi = {10.1002/ett.3770},
	abstract = {null},
	journal = {null},
	author = {Ghobaei-Arani, Mostafa and Souri, Alireza and Safara, Fatemeh and Norouzi, Monire},
	year = {2020},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2982054674
tex.pmcid: null},
}

@article{Gill_2019,
	title = {{ROUTER}: {Fog} enabled cloud based intelligent resource management approach for smart home {IoT} devices},
	doi = {10.1016/j.jss.2019.04.058},
	abstract = {There is a growing requirement for Internet of Things (IoT) infrastructure to ensure low response time to provision latency-sensitive real-time applications such as health monitoring, disaster management, and smart homes. Fog computing offers a means to provide such requirements, via a virtualized intermediate layer to provide data, computation, storage, and networking services between Cloud datacenters and end users. A key element within such Fog computing environments is resource management. While there are existing resource manager in Fog computing, they only focus on a subset of parameters important to Fog resource management encompassing system response time, network bandwidth, energy consumption and latency. To date no existing Fog resource manager considers these parameters simultaneously for decision making, which in the context of smart homes will become increasingly key. In this paper, we propose a novel resource management technique (ROUTER) for fog-enabled Cloud computing environments, which leverages Particle Swarm Optimization to optimize simultaneously. The approach is validated within an IoT-based smart home automation scenario, and evaluated within iFogSim toolkit driven by empirical models within a small-scale smart home experiment. Results demonstrate our approach results a reduction of 12\% network bandwidth, 10\% response time, 14\% latency and 12.35\% in energy consumption.},
	journal = {Journal of Systems and Software},
	author = {Gill, Sukhpal Singh and Garraghan, Peter and Buyya, Rajkumar},
	year = {2019},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2942094488
tex.pmcid: null},
	file = {Accepted Version:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/7JRDQR4X/Gill et al. - 2019 - ROUTER Fog enabled cloud based intelligent resour.pdf:application/pdf},
}

@article{Govindan_2017,
	title = {A hybrid approach for minimizing makespan in permutation flowshop scheduling},
	doi = {10.1007/s11518-016-5297-1},
	abstract = {This work proposes a hybrid approach for solving traditional flowshop scheduling problems to reduce the makespan (total completion time). To solve scheduling problems, a combination of Decision Tree (DT) and Scatter Search (SS) algorithms are used. Initially, the DT is used to generate a seed solution which is then given input to the SS to obtain optimal / near optimal solutions of makespan. The DT used the entropy function to convert the given problem into a tree structured format / set of rules. The SS provides an extensive investigation of the search space through diversification. The advantages of both DT and SS are used to form a hybrid approach. The proposed algorithm is tested with various benchmark datasets available for flowshop scheduling. The statistical results prove that the proposed method is competent and efficient for solving flowshop problems.},
	journal = {Journal of Systems Science and Systems Engineering},
	author = {Govindan, Kannan and Balasundaram, R. and Baskar, N. and Asokan, P.},
	year = {2017},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2276796519
tex.pmcid: null},
	file = {Full Text:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/ZH93RRPT/Govindan et al. - 2017 - A hybrid approach for minimizing makespan in permu.pdf:application/pdf},
}

@article{Gudi_2017,
	title = {Fog robotics: {An} introduction},
	doi = {null},
	abstract = {null},
	journal = {null},
	author = {Gudi, Slkc and Ojha, Suman and Clark, Jesse and Johnston, Benjamin and williams, M-A},
	year = {2017},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2771231152
tex.pmcid: null},
}

@article{Hassan_2018,
	title = {A cloud fog based framework for efficient resource allocation using firefly algorithm},
	doi = {10.1007/978-3-030-02613-4_38},
	abstract = {Information Technology (IT) is progressing day by day. With the effective and efficient use of IT new techniques are emerging introducing new Platforms for the development of computing based System. One of the emerging technologies of present era is cloud computing. However, Cloud computing is a new technique, yet it has broader scope in every aspect of Technology. Cloud computing as an Internet based technique allows Consumption of resources efficiently in cost effective way. Fog is also an internet based solution for sharing resources but has less storage and increased Security than Cloud. Load balancing is very important factor effecting any Cloud or Fog environment. Resource sharing in a way that there is maximum utilization of resources is very difficult yet worthy challenge. Different Algorithms work for Load balancing. This paper uses FireFly Algorithm for Load balancing along with Cost reduction.},
	journal = {null},
	author = {Hassan, Kanza and Javaid, Nadeem and Zafar, Farkhanda and Rehman, Saniah and Zahid, Maheen and Rasheed, Sadia},
	year = {2018},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2897800147
tex.pmcid: null},
	file = {Full Text:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/6U9XC7G4/Hassan et al. - 2018 - A cloud fog based framework for efficient resource.pdf:application/pdf},
}

@article{Hosseinioun_2020,
	title = {A new energy-aware tasks scheduling approach in fog computing using hybrid meta-heuristic algorithm},
	doi = {10.1016/j.jpdc.2020.04.008},
	abstract = {Abstract In recent years, large computational problems have solved by the distributed environment in which applications are executed in parallel. Also, lately, fog computing or edge computing as a new environment is applied to collect data from the devices and preprocessing is done before sending for main processing in cloud computing. Since one of the crucial issues in such systems is task scheduling, this issue is addressed by considering reducing energy consumption. In this study, an energy-aware method is introduced by using the Dynamic Voltage and Frequency Scaling (DVFS) technique to reduce energy consumption. In addition, in order to construct valid task sequences, a hybrid Invasive Weed Optimization and Culture (IWO-CA) evolutionary algorithm is applied. The experimental results revealed that the proposed algorithm improves some current algorithms in terms of energy consumption.},
	journal = {Journal of Parallel and Distributed Computing},
	author = {Hosseinioun, Pejman and Kheirabadi, Maryam Asadollahi and Tabbakh, Seyed Reza Kamel and Ghaemi, Reza},
	year = {2020},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3018892364
tex.pmcid: null},
}

@article{Hussain_2019,
	title = {Fog computing for internet of things ({IoT})-{Aided} smart grid architectures},
	doi = {10.3390/bdcc3010008},
	abstract = {The fast-paced development of power systems necessitates the smart grid (SG) to facilitate real-time control and monitoring with bidirectional communication and electricity flows. In order to meet the computational requirements for SG applications, cloud computing (CC) provides flexible resources and services shared in network, parallel processing, and omnipresent access. Even though CC model is considered to be efficient for SG, it fails to guarantee the Quality-of-Experience (QoE) requirements for the SG services, viz. latency, bandwidth, energy consumption, and network cost. Fog Computing (FC) extends CC by deploying localized computing and processing facilities into the edge of the network, offering location-awareness, low latency, and latency-sensitive analytics for mission critical requirements of SG applications. By deploying localized computing facilities at the premise of users, it pre-stores the cloud data and distributes to SG users with fast-rate local connections. In this paper, we first examine the current state of cloud based SG architectures and highlight the motivation(s) for adopting FC as a technology enabler for real-time SG analytics. We also present a three layer FC-based SG architecture, characterizing its features towards integrating massive number of Internet of Things (IoT) devices into future SG. We then propose a cost optimization model for FC that jointly investigates data consumer association, workload distribution, virtual machine placement and Quality-of-Service (QoS) constraints. The formulated model is a Mixed-Integer Nonlinear Programming (MINLP) problem which is solved using Modified Differential Evolution (MDE) algorithm. We evaluate the proposed framework on real world parameters and show that for a network with approximately 50\% time critical applications, the overall service latency for FC is nearly half to that of cloud paradigm. We also observed that the FC lowers the aggregated power consumption of the generic CC model by more than 44\%.},
	journal = {null},
	author = {Hussain, Md. Muzakkir and Beg, M. M. Sufyan},
	year = {2019},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2909845618
tex.pmcid: null},
	file = {Full Text:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/DWTJ7UJD/Hussain and Beg - 2019 - Fog computing for internet of things (IoT)-Aided s.pdf:application/pdf},
}

@article{Hussain_2020,
	title = {Code v multi hop computation offloading in vehicular fog computing},
	doi = {10.1016/j.future.2020.09.039},
	abstract = {Abstract Vehicular Fog Computing (VFC) is an extension of fog computing in Intelligent Transportation Systems (ITS). It is an emerging computing model that leverages latency-aware and energy-aware application deployment in ITS. In this paper, we consider the problem of multi-hop computation offloading in a VFC network, where the client vehicles are connected to fog computing nodes by multi-hop LTE access points. Our scheme addresses three key aspects in a VFC architecture namely: (i) Optimal decision on local or remote task execution, (ii) Optimal fog node assignment, and (iii) Optimal path (multi-hop) selection for computation offloading. Considering the constraints on service latency, hop-limit, and computing capacity, the process of workload allocation across host vehicles, stationary and mobile fog nodes, and the cloud servers is formulated into a multi-objective, non-convex, and NP-hard Quadratic Integer Problem (QIP). Accordingly, an algorithm named Computation Offloading with Differential Evolution in VFC (CODE-V) is proposed. For each client task, CODE-V takes into account inter-fog cooperation, fog node acceptance probability, and the topological variations in the transportation fleets, towards optimal selection of a target fog node. We conduct extensive simulations on the real-world mobility traces of Shenzhen, China, to show that CODE-V reduces the average service latency and energy consumption by approximately 28\% and 61\%, respectively, compared to the state-of-the-art. Moreover, the CODE-V also gives better solution quality compared to standard D E ∕ r a n d ∕ 1 ∕ b i n algorithm and the solutions generated by a CPLEX solver.},
	journal = {Future Generation Computer Systems},
	author = {Hussain, Md. Muzakkir and Hussain, Md. Muzakkir and Beg, M. M. Sufyan},
	year = {2020},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3092029133
tex.pmcid: null},
}

@article{Hussein_2020,
	title = {Efficient task offloading for {IoT}-{Based} applications in fog computing using ant colony optimization},
	doi = {10.1109/access.2020.2975741},
	abstract = {null},
	journal = {IEEE access : practical innovations, open solutions},
	author = {Hussein, Mohamed-K and Hussein, Mohamed-K. and Mousa, Mohamed-Hamed},
	year = {2020},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3008403241
tex.pmcid: null},
	file = {Full Text:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/RB7FMP96/Hussein et al. - 2020 - Efficient task offloading for IoT-Based applicatio.pdf:application/pdf},
}

@article{Ismail_2018,
	title = {Cloud-fog based smart grid paradigm for effective resource distribution},
	doi = {10.1007/978-3-319-98530-5_20},
	abstract = {Smart grid (SG) provides observable energy distribution where utility and consumers are enabled to control and monitor their production, consumption, and pricing in almost, real time. Due to increase in the number of smart devices complexity of SG increases. To overcome these problems, this paper proposes cloud-fog based SG paradigm. The proposed model comprises three layers: cloud layer, fog layer, and end user layer. The 1st layer consists of the cluster of buildings. The renewable energy source is installed in each building so that buildings become self-sustainable with respect to the generation and consumption. The second layer is fog layer which manages the user’s requests, network resources and acts as a middle layer between end users and cloud. Fog creates virtual machines to process multiple users request simultaneously, which increases the overall performance of the communication system. MG is connected with the fogs to fulfill the energy requirement of users. The top layer is cloud layer. All the fogs are connected with a central cloud. Cloud provides services to end users by itself or through the fog. For efficient allocation of fog resources, artificial bee colony (ABC) load balancing algorithm is proposed. Finally, simulation is done to compare the performance of ABC with three other load balancing algorithms, particle swarm optimization (PSO), round robin (RR) and throttled. While considering the proposed scenario, results of these algorithms are compared and it is concluded that performance of ABC is better than RR, PSO and throttled.},
	journal = {null},
	author = {Ismail, Muhammad and Javaid, Nadeem and Zakria, Muhammad and Zubair, Muhammad and Zubair, Muhammad and Saeed, Faizan and Zaheer, Muhammad Asad},
	year = {2018},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2888849991
tex.pmcid: null},
	file = {Full Text:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/J3KPCQWJ/Ismail et al. - 2018 - Cloud-fog based smart grid paradigm for effective .pdf:application/pdf},
}

@article{Jangiti_2019,
	title = {Scalable hybrid and ensemble heuristics for economic virtual resource allocation in cloud and fog cyber-physical systems},
	doi = {10.3233/jifs-179004},
	abstract = {null},
	journal = {Journal of Intelligent and Fuzzy Systems},
	author = {Jangiti, Saikishor and Ram, E. Sri and Ravi, Logesh and Sriram, V. S. Shankar},
	year = {2019},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2914962567
tex.pmcid: null},
}

@article{Javaid_2019,
	title = {Cloud and fog based integrated environment for load balancing using cuckoo levy distribution and flower pollination for smart homes},
	doi = {10.1109/iccisci.2019.8716467},
	abstract = {Reducing delay and latency in cloud computing environment is a challenging task for the research community. There are several smart cities in the world. These smart cities contain numerous Smart Communities (SCs), which have number of Smart Buildings (SBs) and Smart Homes (SHs). They require resources to process and store data in cloud. To overcome these challenges, another infrastructure fog computing environment is introduced, which plays an important role to enhance the efficiency of cloud. The Virtual Machines (VMs) are installed on fog server to whom consumers' requests are allocated. In this paper, the cloud and fog based integrated environment is proposed. To overcome the delay and latency issues of cloud and to enhance the performance of fog. When there are a large number of incoming requests on fog and cloud, load balancing is another major issue. This issue has also been resolved in this paper. The load balancing algorithm Cuckoo search with Levy Walk distribution (CLW) and Flower Pollination (FP) are proposed. The proposed algorithms are compared with existing Cuckoo Search (CS) and BAT algorithm. The comparative analysis of these proposed and existing techniques are performed on the basis of Closest Data Center (CDC), Optimize Response Time (ORT) and Reconfigure Dynamically with Load (RDL). The RT of DCs of cloud and clusters, Processing Time (PT) of fogs is also optimized on the basis of CLW and FP.},
	journal = {null},
	author = {Javaid, Nadeem and Butt, Ayesha Anjum and Latif, K. and Rehman, Amjad},
	year = {2019},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2945804229
tex.pmcid: null},
}

@article{Javanmardi_2020,
	title = {Fpfts a joint fuzzy particle swarm optimization mobility aware approach to fog task scheduling algorithm for internet of things devices},
	doi = {10.1002/spe.2867},
	abstract = {null},
	journal = {Software - Practice and Experience},
	author = {Javanmardi, Saeed and Shojafar, Mohammad and Persico, Valerio and Pescape, Antonio},
	year = {2020},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3080161935
tex.pmcid: null},
}

@article{La_2019,
	title = {Enabling intelligence in fog computing to achieve energy and latency reduction},
	doi = {10.1016/j.dcan.2018.10.008},
	abstract = {Abstract Fog computing is an emerging architecture intended for alleviating the network burdens at the cloud and the core network by moving resource-intensive functionalities such as computation, communication, storage, and analytics closer to the End Users (EUs). In order to address the issues of energy efficiency and latency requirements for the time-critical Internet-of-Things (IoT) applications, fog computing systems could apply intelligence features in their operations to take advantage of the readily available data and computing resources. In this paper, we propose an approach that involves device-driven and human-driven intelligence as key enablers to reduce energy consumption and latency in fog computing via two case studies. The first one makes use of the machine learning to detect user behaviors and perform adaptive low-latency Medium Access Control (MAC)-layer scheduling among sensor devices. In the second case study on task offloading, we design an algorithm for an intelligent EU device to select its offloading decision in the presence of multiple fog nodes nearby, at the same time, minimize its own energy and latency objectives. Our results show a huge but untapped potential of intelligence in tackling the challenges of fog computing.},
	journal = {Digital Communications and Networks},
	author = {La, Quang Duy and Ngo, Mao V. and Dinh, Thinh Quang and Quek, Tony Q. S. and Shin, Hyundong},
	year = {2019},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2898485069
tex.pmcid: null},
}

@article{Lan_2020,
	title = {Deep reinforcement learning for intelligent migration of fog services in smart cities},
	doi = {null},
	abstract = {Fog computing plays a crucial role in future smart city applications, enabling services running along the cloud-to-thing continuum with low latency and high quality of service (QoS) requirements. However, the mobility of end users in smart city systems can result in considerable network performance and QoS degradation, hence interrupting fog services provisioning. Service migration is considered an effective solution to avoid service interruption and ensure service continuity, which can be carried out proactively or reactively. Existing work lacks intelligent and efficient migration solutions for fog services migrations. In this paper, we propose Octofog, a fog services migration model and framework in the context of smart cities, featuring artificial intelligence for resource-efficient migration. We formulate proactive and reactive migration policies as an optimization problem, minimizing migration cost in terms of delay and energy consumption. We use a deep reinforcement learning (DRL) algorithm to solve the optimization problem to make fast migration decisions, using deep deterministic policy gradient (DDPG) based schemes. The evaluation results illustrate that Octofog effectively reduces the total migration cost (i.e., latency and energy).},
	journal = {null},
	author = {Lan, Dapeng and Taherkordi, Amir and Eliassen, Frank and Chen, Zhuang and Liu, Lei and Liu, Lei},
	year = {2020},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3091299613
tex.pmcid: null},
}

@article{Lee_2020,
	title = {Resource allocation for vehicular fog computing using reinforcement learning combined with heuristic information},
	doi = {10.1109/jiot.2020.2996213},
	abstract = {Internet of Vehicles (IoV) has emerged as a key component of smart cities. Connected vehicles are increasingly processing real-time data to respond immediately to user requests. However, the data must be sent to a remote cloud for processing. To resolve this issue, vehicular fog computing (VFC) has emerged as a promising paradigm that improves the quality of computation experiences for vehicles by offloading computation tasks from the cloud to network edges. Nevertheless, due to the resource restrictions of fog computing, only a limited number of vehicles are able to use it while it is still challenging to provide real-time responses for vehicular applications, such as traffic and accident warnings in the highly dynamic IoV environment. Therefore, in this article, we formulate the problem of allocating the limited fog resources to vehicular applications such that the service latency is minimized, by utilizing parked vehicles. We then propose a heuristic algorithm to efficiently find the solutions of the problem formulation. In addition, the proposed algorithm is combined with reinforcement learning to make more efficient resource allocation decisions, leveraging the vehicles’ movement and parking status collected from the smart environment of the city. Our simulation results show that our VFC resource allocation algorithm can achieve higher service satisfaction compared to conventional resource allocation algorithms.},
	journal = {IEEE Internet of Things Journal},
	author = {Lee, Seung-Seob and Lee, SuKyoung},
	year = {2020},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3026449395
tex.pmcid: null},
}

@article{Li_2018,
	title = {K-means based edge server deployment algorithm for edge computing environments},
	doi = {10.1109/smartworld.2018.00203},
	abstract = {In mobile edge computing environments, edge servers are deployed at the edge of the network to provide low-latency and high-bandwidth services for mobile terminals. This paper proposed a k-means based algorithm for deploying edge servers, compared the performance of this algorithm on the average completion time of the system with the random deployment algorithm and the density based clustering algorithm. Experimental results show that the k-means based algorithm is effective for deploying edge servers.},
	journal = {null},
	author = {Li, Bo and Wang, Keyue and Xue, Duan and Pei, Yijian},
	year = {2018},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2904383881
tex.pmcid: null},
}

@article{Li_2018,
	title = {{SMDP}-{Based} coordinated virtual machine allocations in cloud-fog computing systems},
	doi = {10.1109/jiot.2018.2818680},
	abstract = {Heterogeneous computing powered by remote clouds and local fogs is a promising technology to improve the performance of user terminals in the Internet of Things. In this paper, two semi-Markov decision process (SMDP)-based coordinated virtual machine (VM) allocation methods are proposed to balance the tradeoff between the high cost of providing services by the remote cloud and the limited computing capacity of the local fog. We first present a model-based planning method in which it is necessary to train the state transition probabilities and the expected time intervals between adjacent decision epochs. To facilitate training them, the SMDP is degraded into a continuous-time Markov decision process (CTMDP) in which the service requests and ongoing service completions follow a continuous-time Markov chain. The relative value iterative algorithm for the CTMDP is used to find an asymptotically optimal VM allocation policy. In addition, we also propose a model-free reinforcement learning (RL) method, where an optimal coordinated VM allocation policy is approximated by learning from the states and rewards of feedback. The simulation results show that the performance of the model-free RL method can converge to a level similar to that of the model-based planning method and outperform the greedy VM allocation method.},
	journal = {IEEE Internet of Things Journal},
	author = {Li, Qizhen and Zhao, Lianwen and Gao, Jie and Liang, Hongbin and Zhao, Lian and Tang, Xiaohu},
	year = {2018},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2795765720
tex.pmcid: null},
}

@article{Li_2019,
	title = {Deep reinforcement scheduling for mobile crowdsensing in fog computing},
	doi = {10.1145/3234463},
	abstract = {Mobile crowdsensing becomes a promising technology for the emerging Internet of Things (IoT) applications in smart environments. Fog computing is enabling a new breed of IoT services, which is also a new opportunity for mobile crowdsensing. Thus, in this article, we introduce a framework enabling mobile crowdsensing in fog environments with a hierarchical scheduling strategy. We first introduce the crowdsensing framework that has a hierarchical structure to organize different resources. Since different positions and performance of fog nodes influence the quality of service (QoS) of IoT applications, we formulate a scheduling problem in the hierarchical fog structure and solve it by using a deep reinforcement learning–based strategy. From extensive simulation results, our solution outperforms other scheduling solutions for mobile crowdsensing in the given fog computing environment.},
	journal = {ACM Transactions on Internet Technology},
	author = {Li, He and Ota, Kaoru and Dong, Mianxiong},
	year = {2019},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2938135176
tex.pmcid: null},
	file = {Full Text:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/MJY86BZJ/Li et al. - 2019 - Deep reinforcement scheduling for mobile crowdsens.pdf:application/pdf},
}

@article{Li_2019,
	title = {Methods of resource scheduling based on optimized fuzzy clustering in fog computing},
	doi = {10.3390/s19092122},
	abstract = {Cloud computing technology is widely used at present. However, cloud computing servers are far from terminal users, which may lead to high service request delays and low user satisfaction. As a new computing architecture, fog computing is an extension of cloud computing that can effectively solve the aforementioned problems. Resource scheduling is one of the key technologies in fog computing. We propose a resource scheduling method for fog computing in this paper. First, we standardize and normalize the resource attributes. Second, we combine the methods of fuzzy clustering with particle swarm optimization to divide the resources, and the scale of the resource search is reduced. Finally, we propose a new resource scheduling algorithm based on optimized fuzzy clustering. The experimental results show that our method can improve user satisfaction and the efficiency of resource scheduling.},
	journal = {Sensors},
	author = {Li, Guangshun and Liu, Yuncui and Wu, Junhua and Lin, Dandan and Zhao, Shuaishuai},
	year = {2019},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2944083578
tex.pmcid: 6539192},
	file = {Full Text:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/A5G4UP68/Li et al. - 2019 - Methods of resource scheduling based on optimized .pdf:application/pdf},
}

@article{Li_2019,
	title = {Optimizing resources allocation for fog computing-based internet of things networks},
	doi = {10.1109/access.2019.2917557},
	abstract = {In the wireless Internet of Things (IoT) networks with resource-constrained devices, fog computing has been introduced to deal with the computation-intensive applications at the edges of the networks. While fog computing decreases the computation delay and fronthaul traffic data, it also brings the severe challenge on complex resource allocation of the available computation and communication resources under the stringent quality of service (QoS) requirements. In this paper, we investigate the problem of tasks scheduling and heterogeneous resource allocation for multiple devices in the wireless IoT networks. The IoT devices that collect a massive amount of data need to make proper offloading decision to transfer the data to the fog computing nodes (FNs). Moreover, to support a massive number of device connections and transfer a huge amount of data with low latency and limited resource, we consider the deployment of non-orthogonal multiple access (NOMA) in IoT networks, which enables multiple IoT devices to simultaneously transmit data to the same FN at the same time, frequency, and code domain. We jointly optimize the allocation of resource blocks and transmit power of multiple IoT devices, subject to the respective QoS requirements. Furthermore, the optimization problem is formulated as a mixed-integer nonlinear programming problem to minimize the system energy consumption. Since it is an NP-hard problem, we introduce an improved genetic algorithm (IGA) to solve it. The simulation results show that the proposed scheme achieves good performance in throughput, delay, outage probability, and energy consumption.},
	journal = {IEEE access : practical innovations, open solutions},
	author = {Li, Xi and Liu, Yiming and Ji, Hong and Zhang, Heli and Leung, Victor C. M.},
	year = {2019},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2945233415
tex.pmcid: null},
	file = {Full Text:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/VUPUDSEK/Li et al. - 2019 - Optimizing resources allocation for fog computing-.pdf:application/pdf},
}

@article{Li_2020,
	title = {An intelligent adaptive algorithm for servers balancing and tasks scheduling over mobile fog computing networks},
	doi = {10.1155/2020/8863865},
	abstract = {With the increasing popularity of terminals and applications, the corresponding requirements of services have been growing significantly. In order to improve the quality of services in resource restrained user devices and reduce the large latency of service migration caused by long distance in cloud computing, mobile fog computing (MFC) is presented to provide supplementary resources by adding a fog layer with several servers near user devices. Focusing on cloud-aware MFC networks with multiple servers, we formulate a problem with the optimization objective to improve the quality of service, relieve the restrained resource of user device, and balance the workload of participant server. In consideration of the data size of remaining task, the power consumption of user device, and the appended workload of participant server, this paper designs a machine learning-based algorithm which aims to generate intelligent adaptive strategies related with load balancing of collaborative servers and dynamic scheduling of sequential tasks. Based on the proposed algorithm and software-defined networking technology, the tasks can be executed cooperatively by the user device and the servers in the MFC network. Besides, we conducted some experiments to verify the algorithm effectiveness under different numerical parameters including task arrival rate, avaliable server workload, and wireless channel condition. The simulation results show that the proposed intelligent adaptive algorithm achieves a superior performance in terms of latency and power consumption compared to candidate algorithms.},
	journal = {Wireless Communications and Mobile Computing},
	author = {Li, Xuejing and Qin, Yajuan and Zhou, Huachun and Chen, Du and Yang, Shujie and Zhang, Zhewei},
	year = {2020},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3044182804
tex.pmcid: null},
	file = {Full Text:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/9YFIB94J/Li et al. - 2020 - An intelligent adaptive algorithm for servers bala.pdf:application/pdf},
}

@article{Lin_2017,
	title = {An ensemble random forest algorithm for insurance big data analysis},
	doi = {10.1109/access.2017.2738069},
	abstract = {Due to the imbalanced distribution of business data, missing user features, and many other reasons, directly using big data techniques on realistic business data tends to deviate from the business goals. It is difficult to model the insurance business data by classification algorithms, such as logistic regression and support vector machine (SVM). In this paper, we exploit a heuristic bootstrap sampling approach combined with the ensemble learning algorithm on the large-scale insurance business data mining, and propose an ensemble random forest algorithm that uses the parallel computing capability and memory-cache mechanism optimized by Spark. We collected the insurance business data from China Life Insurance Company to analyze the potential customers using the proposed algorithm. We use F-Measure and G-mean to evaluate the performance of the algorithm. Experiment result shows that the ensemble random forest algorithm outperformed SVM and other classification algorithms in both performance and accuracy within the imbalanced data, and it is useful for improving the accuracy of product marketing compared to the traditional artificial approach.},
	journal = {IEEE access : practical innovations, open solutions},
	author = {Lin, Weiwei and Lin, Weiwei and Wu, Ziming and Lin, Longxin and Lin, Longxin and Wen, Angzhan and Li, Jin and Li, Jin},
	year = {2017},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2752032793
tex.pmcid: null},
	file = {Full Text:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/3E22K3D5/Lin et al. - 2017 - An ensemble random forest algorithm for insurance .pdf:application/pdf},
}

@article{Liu_2018,
	title = {A task scheduling algorithm based on classification mining in fog computing environment},
	doi = {10.1155/2018/2102348},
	abstract = {Fog computing (FC) is an emerging paradigm that extends computation, communication, and storage facilities towards the edge of a network. In this heterogeneous and distributed environment, resource allocation is very important. Hence, scheduling will be a challenge to increase productivity and allocate resources appropriately to the tasks. We schedule tasks in fog computing devices based on classification data mining technique. A key contribution is that a novel classification mining algorithm I-Apriori is proposed based on the Apriori algorithm. Another contribution is that we propose a novel task scheduling model and a TSFC (Task Scheduling in Fog Computing) algorithm based on the I-Apriori algorithm. Association rules generated by the I-Apriori algorithm are combined with the minimum completion time of every task in the task set. Furthermore, the task with the minimum completion time is selected to be executed at the fog node with the minimum completion time. We finally evaluate the performance of I-Apriori and TSFC algorithm through experimental simulations. The experimental results show that TSFC algorithm has better performance on reducing the total execution time of tasks and average waiting time.},
	journal = {Wireless Communications and Mobile Computing},
	author = {Liu, Lindong and Qi, Deyu and Qi, Deyu and Zhou, Naqin and Wu, Yilin},
	year = {2018},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2887317025
tex.pmcid: null},
	file = {Full Text:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/WYERZFPK/Liu et al. - 2018 - A task scheduling algorithm based on classificatio.pdf:application/pdf},
}

@article{Lu_2020,
	title = {Optimization of lightweight task offloading strategy for mobile edge computing based on deep reinforcement learning},
	doi = {10.1016/j.future.2019.07.019},
	abstract = {Abstract With the maturity of 5G technology and the popularity of intelligent terminal devices, the traditional cloud computing service model cannot deal with the explosive growth of business data quickly. Therefore, the purpose of mobile edge computing (MEC) is to effectively solve problems such as latency and network load. In this paper, deep reinforcement learning (DRL) is first proposed to solve the offloading problem of multiple service nodes for the cluster and multiple dependencies for mobile tasks in large-scale heterogeneous MEC. Then the paper uses the LSTM network layer and the candidate network set to improve the DQN algorithm in combination with the actual environment of the MEC. Finally, the task offloading problem is simulated by using iFogSim and Google Cluster Trace. The simulation results show that the offloading strategy based on the improved IDRQN algorithm has better performance in energy consumption, load balancing, latency and average execution time than other algorithms.},
	journal = {Future Generation Computer Systems},
	author = {Lu, Haifeng and Gu, Chunhua and Luo, Fei and Luo, Fei and Ding, Weichao and Liu, Xinping},
	year = {2020},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2959276766
tex.pmcid: null},
}

@article{Mai_2018,
	title = {Real-time task assignment approach leveraging reinforcement learning with evolution strategies for long-term latency minimization in fog computing.},
	doi = {10.3390/s18092830},
	abstract = {The emerging fog computing technology is characterized by an ultralow latency response, which benefits a massive number of time-sensitive services and applications in the Internet of things (IoT) era. To this end, the fog computing infrastructure must minimize latencies for both service delivery and execution phases. While the transmission latency significantly depends on external factors (e.g., channel bandwidth, communication resources, and interferences), the computation latency can be considered as an internal issue that the fog computing infrastructure could actively self-handle. From this view point, we propose a reinforcement learning approach that utilizes the evolution strategies for real-time task assignment among fog servers to minimize the total computation latency during a long-term period. Experimental results demonstrate that the proposed approach reduces the latency by approximately 16.1\% compared to the existing methods. Additionally, the proposed learning algorithm has low computational complexity and an effectively parallel operation; therefore, it is especially appropriate to be implemented in modern heterogeneous computing platforms.},
	journal = {Sensors},
	author = {Mai, Long and Mai, Long and Dao, Nhu-Ngoc and Park, Minho},
	year = {2018},
	note = {tex.eprint: 30150577
tex.eprinttype: pmid
tex.mag\_id: 2889043402
tex.pmcid: 6163362},
	file = {Full Text:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/YSIDEBEZ/Mai et al. - 2018 - Real-time task assignment approach leveraging rein.pdf:application/pdf},
}

@article{Maiti_2019,
	title = {An effective approach of latency-aware fog smart gateways deployment for {IoT} services},
	doi = {10.1016/j.iot.2019.100091},
	abstract = {Abstract Fog computing has become a new cutting-edge technology to bring cloud applications closer to physical IoT devices at the edge of the network. In Fog computing use case scenarios latency is the main challenge that must be addressed since mission-critical environments are mostly delay sensitive. To achieve this goal, the fog nodes placement is needed to minimize the delays in the service access layer. There is neither a common fog computing architecture nor a generally accepted concept of fog nodes, how and where to deploy fog nodes or how it supports the real-time Internet of Things (IoT) service execution. Edge devices such as the switch, router, gateway, mobile phones, smart car etc., are the candidates for deployment of fog nodes but the deployment differs according to the application. In this work, we have taken gateways as candidates for fog node deployment. The gateway collects data from smart sensors, but it does not have any pre-processing or decision-making capabilities. Therefore, the gateway is made smarter with Fog capabilities and named as Fog Smart Gateway (FSG). The processing of IoT traffic is taken care of by Virtual Machines (VMs) facilitated by distributed Fog nodes. We optimized the number of fog nodes for deployment to reduce the total latency induced by traffic aggregation and processing. Our results show that the optimal deployment of fog nodes in the IoT network could yield a reduction in latency compared to processing IoT data in a conventional cloud system.},
	journal = {null},
	author = {Maiti, Prasenjit and Apat, Hemant Kumar and Sahoo, Bibhudatta and Sahoo, Bibhudatta and Sahoo, Bibhudatta and Turuk, Ashok Kumar},
	year = {2019},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2969817674
tex.pmcid: null},
}

@article{Majeed_2019,
	title = {Performance estimation of container-based cloud-to-fog offloading},
	doi = {null},
	abstract = {Fog computing offloads latency critical application services running on the Cloud in close proximity to end-user devices onto resources located at the edge of the network. The research in this paper is motivated towards characterising and estimating the time taken to offload a service using containers, which is investigated in the context of the `Save and Load' container migration technique. To this end, the research addresses questions such as whether fog offloading can be accurately modelled and which system and network related parameters influence offloading. These are addressed by exploring a catalogue of 21 different metrics both at the system and process levels that is used as input to four estimation techniques using collective model and individual models to predict the time taken for offloading. The study is pursued by collecting over 1.1 million data points and the preliminary results indicate that offloading can be modelled accurately.},
	journal = {arXiv: Distributed, Parallel, and Cluster Computing},
	author = {Majeed, Ayesha Abdul and Kilpatrick, Peter and Kilpatrick, Peter and Spence, Ivor and Spence, Ivor and Varghese, Blesson},
	year = {2019},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2972755603
tex.pmcid: null},
}

@article{Manasrah_2019,
	title = {An optimized service broker routing policy based on differential evolution algorithm in {Fog}/{Cloud} environment},
	doi = {10.1007/s10586-017-1559-z},
	abstract = {A cloud service provider (CP) offers computing resources with their own interface type and pricing policies besides other services such as storage on a pay-per-use model. Client’s requests should be processed in an appropriate CP datacenters in a trade-off relation between price and performance. The appropriate choice of a CP datacenters is the responsibility of the cloud-based service broker routing policy which acts as an intermediate between the users and the CP’s datacenters. However, due to the distribution nature of the CP’s datacenters, these datacenters can be overloaded with the increasing number of users and their requests being served at the same time if the datacenters are unwisely chosen. Therefore, choosing the appropriate datacenter is significant to the overall performance of the cloud computing systems. This paper aims to propose an optimized service broker routing policy based on different parameters that aims to achieve minimum processing time, minimum response time and minimum cost through employing a searching algorithm to search for the optimal solution from a possible solution space. A simulation-based deployment of the proposed algorithm along with a comparison study with other known algorithms form the field, confirms the ability of the proposed algorithm to minimize the load on service provider datacenters with minimum processing time, response time and overall cost.},
	journal = {Cluster Computing},
	author = {Manasrah, Ahmad M. and Aldomi, Ala’a and Gupta, Brij B. and Gupta, B. B.},
	year = {2019},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2779958744
tex.pmcid: null},
	file = {Full Text:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/AHPYQH2P/Manasrah et al. - 2019 - An optimized service broker routing policy based o.pdf:application/pdf},
}

@article{Manukumar_2020,
	title = {A novel resource management framework for fog computing by using machine learning algorithm},
	doi = {10.4018/978-1-7998-0194-8.ch002},
	abstract = {null},
	journal = {null},
	author = {Manukumar, Shanthi Thangam and Manukumar, Shanthi Thangam and Manukumar, Shanthi Thangam and Muthuswamy, Vijayalakshmi and Muthuswamy, Vijayalakshmi and Muthuswamy, Vijayalakshmi},
	year = {2020},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2970361472
tex.pmcid: null},
}

@article{Martin_2020,
	title = {Mobility aware autonomic approach for the migration of application modules in fog computing environment},
	doi = {10.1007/s12652-020-01854-x},
	abstract = {The fog computing paradigm has emanated as a widespread computing technology to support the execution of the internet of things applications. The paradigm introduces a distributed, hierarchical layer of nodes collaboratively working together as the Fog layer. User devices connected to Fog nodes are often non-stationary. The location-aware attribute of Fog computing, deems it necessary to provide uninterrupted services to the users, irrespective of their locations. Migration of user application modules among the Fog nodes is an efficient solution to tackle this issue. In this paper, an autonomic framework MAMF, is proposed to perform migrations of containers running user modules, while satisfying the Quality of Service requirements. The hybrid framework employing MAPE loop concepts and Genetic Algorithm, addresses the migration of containers in the Fog environment, while ensuring application delivery deadlines. The approach uses the pre-determined value of user location for the next time instant, to initiate the migration process. The framework was modelled and evaluated in iFogSim toolkit. The re-allocation problem was also mathematically modelled as an Integer Linear Programming problem. Experimental results indicate that the approach offers an improvement in terms of network usage, execution cost and request execution delay, over the existing approaches.},
	journal = {Journal of Ambient Intelligence and Humanized Computing},
	author = {Martin, John Paul and Martin, John Paul and Kandasamy, A. and Chandrasekaran, K.},
	year = {2020},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3012196348
tex.pmcid: null},
	file = {Full Text:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/76SZ6A79/Martin et al. - 2020 - Mobility aware autonomic approach for the migratio.pdf:application/pdf},
}

@article{Mishra_2018,
	title = {Sustainable service allocation using a metaheuristic technique in a fog server for industrial applications},
	doi = {10.1109/tii.2018.2791619},
	abstract = {Reducing energy consumption in the fog computing environment is both a research and an operational challenge for the current research community and industry. There are several industries such as finance industry or healthcare industry that require a rich resource platform to process big data along with edge computing in fog architecture. As a result, sustainable computing in a fog server plays a key role in fog computing hierarchy. The energy consumption in fog servers depends on the allocation techniques of services (user requests) to a set of virtual machines (VMs). This service request allocation in a fog computing environment is a nondeterministic polynomial-time hard problem. In this paper, the scheduling of service requests to VMs is presented as a bi-objective minimization problem, where a tradeoff is maintained between the energy consumption and makespan. Specifically, this paper proposes a metaheuristic-based service allocation framework using three metaheuristic techniques, such as particle swarm optimization (PSO), binary PSO, and bat algorithm. These proposed techniques allow us to deal with the heterogeneity of resources in the fog computing environment. This paper has validated the performance of these metaheuristic-based service allocation algorithms by conducting a set of rigorous evaluations.},
	journal = {IEEE Transactions on Industrial Informatics},
	author = {Mishra, Sambit Kumar and Puthal, Deepak and Rodrigues, Joel J. P. C. and Sahoo, Bibhudatta and Dutkiewicz, Eryk},
	year = {2018},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2783999187
tex.pmcid: null},
}

@article{Mseddi_2019,
	title = {Intelligent resource allocation in dynamic fog computing environments},
	doi = {10.1109/cloudnet47604.2019.9064110},
	abstract = {Fog computing emerged as a new paradigm that pushes cloud applications to the network edge. The fog infrastructure contains mainly distributed and heterogeneous fog nodes that are characterized by their complex distribution, high mobility and sporadic resources availability. This dynamic fog nodes behavior triggers new challenges in the resource management process, such as resources coordination for continuous quality-of-service satisfaction. In this paper, we propose a smart online resource allocation approach adapted for dynamic fog computing environments, aiming at maximizing the number of satisfied user requests within a predefined delay threshold. We model the fog computing environment as a Markov discrete process, where dynamic fog node behavior / mobility and resources availability are considered. Then, we present our smart deep-reinforcement-learning resource allocation algorithm. Considering real-world mobility data sets, the near-optimal performance of the proposed solution is illustrated through simulations, and its superiority over heuristic state-of-the-art approaches is exposed.},
	journal = {null},
	author = {Mseddi, Amina and Jaafar, Wael and Elbiaze, Halima and Ajib, Wessam},
	year = {2019},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3015397983
tex.pmcid: null},
}

@article{Naveen_2018,
	title = {In search of the future technologies: {Fusion} of machine learning, fog and edge computing in the internet of things},
	doi = {10.1007/978-3-030-24643-3_33},
	abstract = {With the rapid growth of smart devices connected to the internet, the paradigm Internet of Things (IoT) is used in plenty of applications. This led to the emergence of different computing paradigm such as Cloud computing, Fog computing, Edge Computing using artificial intelligence model such as machine learning to analyze and to get some valuable information and to predict the future from the raw data. This paper provides details about computing paradigm, applications, and its advantages and limitations. This paper also brings different kinds of important neural networks and its usability for distinct inputs such as images, audio, video etc. We envision this paper helps for student researcher for understanding the IoT, computing paradigms and artificial neural networks, to work further in these emerging domains.},
	journal = {null},
	author = {Naveen, Soumyalatha and Kounte, Manjunath R and Kounte, Manjunath R.},
	year = {2018},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2964948534
tex.pmcid: null},
	file = {Full Text:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/G36I7X7U/Naveen et al. - 2018 - In search of the future technologies Fusion of ma.pdf:application/pdf},
}

@article{Nazir_2018,
	title = {Cuckoo optimization algorithm based job scheduling using cloud and fog computing in smart grid},
	doi = {10.1007/978-3-319-98557-2_4},
	abstract = {The integration of Smart Grid (SG) with cloud and fog computing has improved the energy management system. The conversion of traditional grid system to SG with cloud environment results in enormous amount of data at the data centers. Rapid increase in the automated environment has increased the demand of cloud computing. Cloud computing provides services at the low cost and with better efficiency. Although problems still exists in cloud computing such as Response Time (RT), Processing Time (PT) and resource management. More users are being attracted towards cloud computing which is resulting in more energy consumption. Fog computing is emerged as an extension of cloud computing and have added more services to the cloud computing like security, latency and load traffic minimization. In this paper a Cuckoo Optimization Algorithm (COA) based load balancing technique is proposed for better management of resources. The COA is used to assign suitable tasks to Virtual Machines (VMs). The algorithm detects under and over utilized VMs and switch off the under-utilized VMs. This process turn down many VMs which puts a big impact on energy consumption. The simulation is done in Cloud Sim environment, it shows that proposed technique has better response time at low cost than other existing load balancing algorithms like Round Robin (RR) and Throttled.},
	journal = {null},
	author = {Nazir, Saqib and Shafiq, Sundas and Iqbal, Zafar and Iqbal, Zafar and Zeeshan, Muhammad and Zeeshan, Muhammad and Tariq, Subhan and Javaid, Nadeem},
	year = {2018},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2888469080
tex.pmcid: null},
	file = {Full Text:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/JGF9KPLT/Nazir et al. - 2018 - Cuckoo optimization algorithm based job scheduling.pdf:application/pdf},
}

@article{Nguyen_2019,
	title = {Evolutionary algorithms to optimize task scheduling problem for the {IoT} based bag-of-tasks application in {Cloud}–{Fog} computing environment},
	doi = {10.3390/app9091730},
	abstract = {In recent years, constant developments in Internet of Things (IoT) generate large amounts of data, which put pressure on Cloud computing’s infrastructure. The proposed Fog computing architecture is considered the next generation of Cloud Computing for meeting the requirements posed by the device network of IoT. One of the obstacles of Fog Computing is distribution of computing resources to minimize completion time and operating cost. The following study introduces a new approach to optimize task scheduling problem for Bag-of-Tasks applications in Cloud–Fog environment in terms of execution time and operating costs. The proposed algorithm named TCaS was tested on 11 datasets varying in size. The experimental results show an improvement of 15.11\% compared to the Bee Life Algorithm (BLA) and 11.04\% compared to Modified Particle Swarm Optimization (MPSO), while achieving balance between completing time and operating cost.},
	journal = {Applied Sciences},
	author = {Nguyen, Binh Minh and Binh, Huynh Thi Thanh and Son, Do Bao},
	year = {2019},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2940867210
tex.pmcid: null},
	file = {Full Text:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/AT6ZKUDH/Nguyen et al. - 2019 - Evolutionary algorithms to optimize task schedulin.pdf:application/pdf},
}

@article{Orhean_2017,
	title = {New scheduling approach using reinforcement learning for heterogeneous distributed systems},
	doi = {10.1016/j.jpdc.2017.05.001},
	abstract = {Abstract Computer clusters, cloud computing and the exploitation of parallel architectures and algorithms have become the norm when dealing with scientific applications that work with large quantities of data and perform complex and time-consuming calculations. With the rise of social media applications and smart devices, the amount of digital data and the velocity at which it is produced have increased exponentially, determining the development of distributed system frameworks and platforms that increase productivity, consistency, fault-tolerance and security of parallel applications. The performance of such systems is mainly influenced by the architectural disposition and composition of the physical machines, the resource allocation and the scheduling of jobs and tasks. This paper proposes a reinforcement learning algorithm to solve the scheduling problem in distributed systems. The machine learning technique takes into consideration the heterogeneity of the nodes and their disposition within the grid, and the arrangement of tasks in a directed acyclic graph of dependencies, ultimately determining a scheduling policy for a better execution time. This paper also proposes a platform, in which the algorithm is implemented, that offers scheduling as a service to distributed systems.},
	journal = {Journal of Parallel and Distributed Computing},
	author = {Orhean, Alexandru Iulian and Pop, Florin and Raicu, Ioan},
	year = {2017},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2674963269
tex.pmcid: null},
}

@article{Peng_2018,
	title = {Intrusion detection system based on decision tree over big data in fog environment},
	doi = {10.1155/2018/4680867},
	abstract = {Fog computing, as the supplement of cloud computing, can provide low-latency services between mobile users and the cloud. However, fog devices may encounter security challenges as a result of the fog nodes being close to the end users and having limited computing ability. Traditional network attacks may destroy the system of fog nodes. Intrusion detection system IDS is a proactive security protection technology and can be used in the fog environment. Although IDS in tradition network has been well investigated, unfortunately directly using them in the fog environment may be inappropriate. Fog nodes produce massive amounts of data at all times, and, thus, enabling an IDS system over big data in the fog environment is of paramount importance. In this study, we propose an IDS system based on decision tree. Firstly, we propose a preprocessing algorithm to digitize the strings in the given dataset and then normalize the whole data, to ensure the quality of the input data so as to improve the efficiency of detection. Secondly, we use decision tree method for our IDS system, and then we compare this method with Naive Bayesian method as well as KNN method. Both the 10\% dataset and the full dataset are tested. Our proposed method not only completely detects four kinds of attacks but also enables the detection of twenty-two kinds of attacks. The experimental results show that our IDS system is effective and precise. Above all, our IDS system can be used in fog computing environment over big data.},
	journal = {null},
	author = {Peng, Kai and Leung, Victor C. M. and Zheng, Lixin and Wang, Shangguang and Huang, Chao and Lin, Tao},
	year = {2018},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2793174642
tex.pmcid: null},
	file = {Full Text:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/EQGGJVQS/Peng et al. - 2018 - Intrusion detection system based on decision tree .pdf:application/pdf},
}

@article{Pham_2017,
	title = {Applying {Ant} {Colony} {System} algorithm in multi-objective resource allocation for virtual services*},
	doi = {10.1080/24751839.2017.1356159},
	abstract = {ABSTRACTOver the past few years, using cloud computing technology has become popular. With the cloud computing service providers, reducing the number of physical machines providing resources for virtual services in cloud computing is one of the efficient ways to reduce the amount of energy consumption which in turn enhance the performance of data centres. However, using a minimum of physical machines to allocate resources for virtual services can result in system overload and break the SLA of service. Consequently, providing resources for virtual services which do not only satisfy the constraint of reducing the energy consumption but also ensure the load balancing of the whole system is necessary. In this study, we present the multi-objective resource allocation problem for virtual services. This problem aims at both reducing the energy consumption and balancing the load of physical machines. The MORA-ACS algorithm is proposed to resolve the problem by the Ant Colony System method. The experimental result...},
	journal = {null},
	author = {Pham, Nguyen Minh Nhut and Le, Van Son},
	year = {2017},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2742117858
tex.pmcid: null},
	file = {Full Text:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/3W5EVE5X/Pham and Le - 2017 - Applying Ant Colony System algorithm in multi-obje.pdf:application/pdf},
}

@article{Priyabhashana_2019,
	title = {Data analytics with deep neural networks in fog computing using {TensorFlow} and google cloud platform},
	doi = {10.1109/iciis47346.2019.9063284},
	abstract = {Fog computing introduced by Cisco for local processing of tasks on edge Internet of Things (IoT) devices known as fog devices. Nowadays IoT applications produce a large amount of data and require powerful analytical approaches. These data should transmit to cloud data centres to extract useful information. In fog computing, these kinds of data handling by fog layer. The fog layer consists of geo-allocated servers which are deployed on the network periphery. Each fog server can be known as a lightweight version of the cloud server. In particular, it is preferred to the expand fog server, which reduces data amount before sending them to cloud data centres by using TensorFlow, one of the most popular deep learning library, Google Cloud Platform (GCP) and Deep Neural Network. Deep neural networks can be known as a computer system modelled on the human brain and neural system. In data classification, neural network provides fast and efficient results. In this scenario fog server known as fog station and focused on implement analytical applications in fog stations with the help of Docker and Kubernetes, except implement them in the main cloud server. Those applications belong to one or more fog devices. Through the research work, studied and compared the effects of using TensorFlow based application with multiple hidden layers. TensorFlow library with the help of keras used to build the neural network model. The experiment results of Rectified Linear Unit (ReLu), Leaky ReLU, Hyperbolic Tangent (tanH), Exponential Linear Unit (eLu), sigmoid, softplus, softmax and softsign activation functions have been evaluated. The experiment results demonstrate the feasibility, efficiency and the applicability of the proposed fog station. Finally, achieved (i) Centralized Management using Fog Station, (ii) Dynamic Deployment using Docker, (iii) Efficient Management \& Resource Monitoring using Kubernetes, (iv) Real-Time Data Analytics using TensorFlow and GCP as objectives.},
	journal = {null},
	author = {Priyabhashana, H.M.B. and Jayasena, K.P.N. and Jayasena, K.P.N. and Jayasena, K.P.N.},
	year = {2019},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3015971471
tex.pmcid: null},
}

@article{Rafique_2019,
	title = {A novel bio-inspired hybrid algorithm ({NBIHA}) for efficient resource management in fog computing},
	doi = {10.1109/access.2019.2924958},
	abstract = {Fog computing has emerged as a revolutionary paradigm to serve massive data in the Internet of Things (IoT) environment. It is a derivative of cloud computing that provides cloud-like services at the edge of the network. Subsequently, it resolves the significant issue of higher delay faced in cloud-IoT paradigm. According to the literature, the inefficient scheduling of users tasks in fog computing may result in higher delays in comparison to cloud computing. Hence, the real benefits of fog computing can only be obtained by applying effective job scheduling strategies. In fact, task scheduling is an NP-hard problem that cannot be solved by any specific algorithm to reach an ideal solution. Hence, it requires the optimal and efficient techniques to cater to the issues of latency, response time and efficient resource utilization of the available fog resources at the edge of the network. Given this, we proposed a novel bioinspired hybrid algorithm (NBIHA) which is a hybrid of modified particle swarm optimization (MPSO) and modified cat swarm optimization (MCSO). In the proposed scheme, MPSO is used to schedule the tasks among fog devices and the hybrid of MPSO and MCSO is used to manage resources at the fog device level. In the proposed approach, the resources are assigned and managed on the basis of the demand of incoming requests. The main objective of the proposed work is to reduce the average response time and to optimize resource utilization by efficiently scheduling the tasks and managing available fog resources. The simulations are carried out using iFogSim. The evaluation results show that the proposed approach (NBIHA) shows promising results in terms of energy consumption, execution time and average response time in comparison to the state-of-the-art scheduling techniques.},
	journal = {IEEE access : practical innovations, open solutions},
	author = {Rafique, Hina and Shah, Munam Ali and Islam, Saiful and Islam, Saif Ul and Maqsood, Tahir and Khan, Suleman and Maple, Carsten},
	year = {2019},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2953904117
tex.pmcid: null},
	file = {Full Text:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/5VHBWG8P/Rafique et al. - 2019 - A novel bio-inspired hybrid algorithm (NBIHA) for .pdf:application/pdf},
}

@article{Rahbari_2020,
	title = {Task offloading in mobile fog computing by classification and regression tree},
	doi = {10.1007/s12083-019-00721-7},
	abstract = {Fog computing (FC) as an extension of cloud computing provides a lot of smart devices at the network edge, which can store and process data near end users. Because FC reduces latency and power consumption, it is suitable for the Internet of Things (IoT) applications as healthcare, vehicles, and smart cities. In FC, the mobile devices (MDs) can offload their heavy tasks to fog devices (FDs). The selection of best FD for offloading has serious challenges in the time and energy. In this paper, we present a Module Placement method by Classification and regression tree Algorithm (MPCA). We select the best FDs for modules by MPCA. Initially, the power consumption of MDs are checked, if this value is greater than Wi-Fi’s power consumption, then offloading will be done. The MPCA’s decision parameters for selecting the best FD include authentication, confidentiality, integrity, availability, capacity, speed, and cost. To optimize MPCA, we analyze and apply the probability of network’s resource utilization in the module offloading. This method is called by (MPMCP). To evaluate our proposed approach, we simulate MPCA and MPMCP algorithms and compare them with First Fit (FF) and local mobile processing methods in Cloud, FDs, and MDs. The results include the power consumption, response time and performance show that the proposed methods are superior to other compared methods.},
	journal = {Peer-to-peer Networking and Applications},
	author = {Rahbari, Dadmehr and Nickray, Mohsen and Nickray, Mohsen},
	year = {2020},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2913773671
tex.pmcid: null},
}

@article{Reddy_2020,
	title = {A genetic algorithm for energy efficient fog layer resource management in context aware smart cities},
	doi = {10.1016/j.scs.2020.102428},
	abstract = {Abstract The development of novel Information and Communication Technology (ICT) based solutions becomes essential to meet the ever increasing rate of global urbanization in order to satiate the constraint in resources. The popular ‘smart city paradigm is characterized by ubiquitous cyber provisions for the monitoring and control of such city's critical infrastructures, encompassing healthcare, environment, transportation and utilities among others. In order to manage the numerous services keeping their Quality of Service (QoS) demands upright, it is imperative to employ context aware computing as well as fog computing simultaneously. This paper investigates the feasibility of energy minimization at the fog layer through intelligent sleep and wake-up cycles of the fog nodes which are context-aware. It proposes a virtual machine management approach for effectively allocating service requests with a minimal number of active fog nodes using a genetic algorithm (GA); and thereafter, a reinforcement learning (RL) approach is incorporated to optimize the period of fog nodes’ duty cycle. Simulations are carried out using MATLAB and the results demonstrate that the proposed scheme improves energy consumption of the fog layer by approximately 11–21\% when compared to existing context sharing based algorithms.},
	journal = {Sustainable Cities and Society},
	author = {Reddy, K. Hemant Kumar and Luhach, Ashish Kr. and Pradhan, Buddhadeb and Dash, Jatindra Kumar and Dash, Jatindra Kumar and Roy, Diptendu Sinha},
	year = {2020},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3082763595
tex.pmcid: null},
}

@article{Ren_2020,
	title = {An energy aware approach for resource managing in the fog based internet of things using a hybrid algorithm},
	doi = {10.1002/dac.4652},
	abstract = {null},
	journal = {International Journal of Communication Systems},
	author = {Ren, Xiaojun and Zhang, Zhijun and Arefzadeh, Seyedeh Maryam},
	year = {2020},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3093927778
tex.pmcid: null},
}

@article{Saleh_2019,
	title = {Task scheduling for cloud computing based on firefly algorithm},
	doi = {10.1088/1742-6596/1294/4/042004},
	abstract = {null},
	journal = {null},
	author = {Saleh, Ibrahim Ahmed and Alsaif, Omar Ibrahim and Muhamed, Sundus Abduttalib and Essa, Essa Ibrahim and Essa, Essa Ibrahim},
	year = {2019},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2981531077
tex.pmcid: null},
}

@article{Selimi_2019,
	title = {A lightweight service placement approach for community network micro-clouds},
	doi = {10.17863/cam.20193},
	abstract = {Community networks (CNs) have gained momentum in the last few years with the increasing number of spontaneously deployed WiFi hotspots and home networks. These networks, owned and managed by volunteers, offer various services to their members and to the public. While Internet access is the most popular service, the provision of services of local interest within the network is enabled by the emerging technology of CN micro-clouds. By putting services closer to users, micro-clouds pursue not only a better service performance, but also a low entry barrier for the deployment of mainstream Internet services within the CN. Unfortunately, the provisioning of these services is not so simple. Due to the large and irregular topology, high software and hardware diversity of CNs, a “careful” placement of micro-clouds services over the network is required to optimize service performance. This paper proposes to leverage state information about the network to inform service placement decisions, and to do so through a fast heuristic algorithm, which is critical to quickly react to changing conditions. To evaluate its performance, we compare our heuristic with one based on random placement in Guifi.net, the biggest CN worldwide. Our experimental results show that our heuristic consistently outperforms random placement by 2x in bandwidth gain. We quantify the benefits of our heuristic on a real live video-streaming service, and demonstrate that video chunk losses decrease significantly, attaining a 37\% decrease in the packet loss rate. Further, using a popular Web 2.0 service, we demonstrate that the client response times decrease up to an order of magnitude when using our heuristic. Since these improvements translate in the QoE (Quality of Experience) perceived by the user, our results are relevant for contributing to higher QoE, a crucial parameter for using services from volunteer-based systems and adapting CN micro-clouds as an eco-system for service deployment.},
	journal = {Journal of Grid Computing},
	author = {Selimi, Mennan and Cerdà-Alabern, Llorenç and Freitag, Felix and Veiga, Luís and Sathiaseelan, Arjuna and Crowcroft, Jon},
	year = {2019},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2790685630
tex.pmcid: null},
}

@article{Sharma_2019,
	title = {Efficient solution for load balancing in fog computing utilizing artificial bee colony},
	doi = {10.4018/ijaci.2019100104},
	abstract = {null},
	journal = {International Journal of Ambient Computing and Intelligence},
	author = {Sharma, Shivi and Saini, Hemraj},
	year = {2019},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2974503039
tex.pmcid: null},
}

@article{Sharma_2019,
	title = {A novel four-tier architecture for delay aware scheduling and load balancing in fog environment},
	doi = {10.1016/j.suscom.2019.100355},
	abstract = {Abstract Fog computing paradigm is located between IoT devices and cloud paradigm that aim is to minimize the latency in terms of task scheduling and load balancing. To deal with the huge amount of data sensing from different IoT devices, in this paper we propose a four tiers architecture for delay aware scheduling and Load Balancing in the fog environment. Tier-1 is the bottom tier which consists of IoT devices. In the second tier, the applications (workloads) are categorized into two categories: High Priority (HP) and Low Priority (LP) by router based on the Dual Fuzzy Logic Algorithm. Fuzzifier considers four input metrics: task size, arrival time, minimum execution time and maximum completion time. A task with high priority is transmitted to the third tier (fog tier). In the third tier, a novel fog structure has been invoked namely Artificial Fractals consists of nodes. The fog nodes are clustered using K-means++ clustering algorithm. Each fog node is carried out several actions such as scheduling, monitoring, and communication. To schedule tasks within the fog node, we propose the Earliest Deadline First (EDF) task scheduling algorithm. The current usage of fog node is determined by Artificial Neural Network (ANN). If an IoT device does not get the required resource then the request is forwarded to the cloud tier. Our proposed work has been validated over a real-time VSOT (Video Surveillance/Object Tracking) application using iFogSim and the performance is evaluated in terms of response time, scheduling time, load balancing rate, delay, and energy consumption.},
	journal = {Sustainable Computing: Informatics and Systems},
	author = {Sharma, Shivi and Saini, Hemraj},
	year = {2019},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2980400530
tex.pmcid: null},
}

@article{Shooshtarian_2019,
	title = {A clustering-based approach to efficient resource allocation in fog computing},
	doi = {10.1007/978-3-030-30143-9_17},
	abstract = {Fog computing, which provides low-latency computing services at the network edge, is an enabler for the next generation Internet of Things (IoT) systems. In scenarios such as smart cities, multiple applications are simultaneously deployed and distributed across the Cloud and fog nodes, offering various IoT-based services. Moreover, each application has its own quality of service (QoS) and resource requirements that must be met. Appropriate resource allocation mechanisms are needed to determine which fog node or group of nodes can host the services of a given application. A critical challenge is how to select fog nodes for resource allocation in order to maximize fog resources utilization and minimize service latency, while satisfying QoS requirements of the application. This paper is aimed to address this challenge through a two-phase QoS-aware resource allocation scheme. Firstly, in the layering phase, we assume a hierarchical architecture for fog nodes—organizing heterogeneous nodes into a multi-layered hierarchy based on node resources capacity and network characteristics. Layering facilitates finding fog node(s) based on application requirements, and improves resource management. In the second phase, the fog nodes are grouped to facilitate resource pooling and reducing delay in service provisioning. We use the Agglomerative Hierarchical Clustering algorithm for classifying fog nodes. This helps selecting those fog node(s) in a fog layer with which the latency will be minimized. We evaluate the proposed approach through simulation. The evaluation results show that the proposed approach promises high application acceptance rate (80\% on average), and reduces considerably the application placement time.},
	journal = {null},
	author = {Shooshtarian, Leila and Lan, Dapeng and Taherkordi, Amir},
	year = {2019},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2990219024
tex.pmcid: null},
	file = {Full Text:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/STHLCBXK/Shooshtarian et al. - 2019 - A clustering-based approach to efficient resource .pdf:application/pdf},
}

@article{Talaat_2020,
	title = {A load balancing and optimization strategy ({LBOS}) using reinforcement learning in fog computing environment},
	doi = {10.1007/s12652-020-01768-8},
	abstract = {Fog computing (FC) can be considered as a computing paradigm which performs Internet of Things (IoT) applications at the edge of the network. Recently, there is a great growth of data requests and FC which lead to enhance data accessibility and adaptability. However, FC has been exposed to many challenges as load balancing (LB) and adaptation to failure. Many LB strategies have been proposed in cloud computing, but they are still not applied effectively in fog. LB is an important issue to achieve high resource utilization, avoid bottlenecks, avoid overload and low load, and reduce response time. In this paper, a LB and optimization strategy (LBOS) using dynamic resource allocation method based on Reinforcement learning and genetic algorithm is proposed. LBOS monitors the traffic in the network continuously, collects the information about each server load, handles the incoming requests, and distributes them between the available servers equally using dynamic resource allocation method. Hence, it enhances the performance even when it’s the peak time. Accordingly, LBOS is simple and efficient in real-time systems in fog computing such as in the case of healthcare system. LBOS is concerned with designing an IoT-Fog based healthcare system. The proposed IoT-Fog system consists of three layers, namely: (1) IoT layer, (2) fog layer, and (3) cloud layer. Finally, the experiments are carried out and the results show that the proposed solution improves the quality-of-service in the cloud/fog computing environment in terms of the allocation cost and reduce the response time. Comparing the LBOS with the state-of-the-art algorithms, it achieved the best load balancing Level (85.71\%). Hence, LBOS is an efficient way to establish the resource utilization and ensure the continuous service.},
	journal = {Journal of Ambient Intelligence and Humanized Computing},
	author = {Talaat, Fatma M. and Talaat, Fatma M. and Saraya, Mohamed S. and Saleh, Ahmed I. and Ali, Hesham A. and Ali, Shereen H.},
	year = {2020},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3006104596
tex.pmcid: null},
	file = {Full Text:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/GB8VJUFJ/Talaat et al. - 2020 - A load balancing and optimization strategy (LBOS) .pdf:application/pdf},
}

@article{Tanwani_2019,
	title = {A fog robotics approach to deep robot learning: {Application} to object recognition and grasp planning in surface decluttering},
	doi = {null},
	abstract = {The growing demand of industrial, automotive and service robots presents a challenge to the centralized Cloud Robotics model in terms of privacy, security, latency, bandwidth, and reliability. In this paper, we present a `Fog Robotics' approach to deep robot learning that distributes compute, storage and networking resources between the Cloud and the Edge in a federated manner. Deep models are trained on non-private (public) synthetic images in the Cloud; the models are adapted to the private real images of the environment at the Edge within a trusted network and subsequently, deployed as a service for low-latency and secure inference/prediction for other robots in the network. We apply this approach to surface decluttering, where a mobile robot picks and sorts objects from a cluttered floor by learning a deep object recognition and a grasp planning model. Experiments suggest that Fog Robotics can improve performance by sim-to-real domain adaptation in comparison to exclusively using Cloud or Edge resources, while reducing the inference cycle time by 4×to successfully declutter 86\% of objects over 213 attempts.},
	journal = {arXiv: Robotics},
	author = {Tanwani, Ajay Kumar and Mor, Nitesh and Kubiatowicz, John and Gonzalez, Joseph E. and Goldberg, Ken},
	year = {2019},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2923135776
tex.pmcid: null},
}

@article{Wan_2018,
	title = {Fog computing for energy-aware load balancing and scheduling in smart factory},
	doi = {10.1109/tii.2018.2818932},
	abstract = {Due to the development of modern information technology, the emergence of the fog computing enhances equipment computational power and provides new solutions for traditional industrial applications. Generally, it is impossible to establish a quantitative energy-aware model with a smart meter for load balancing and scheduling optimization in smart factory. With the focus on complex energy consumption problems of manufacturing clusters, this paper proposes an energy-aware load balancing and scheduling (ELBS) method based on fog computing. First, an energy consumption model related to the workload is established on the fog node, and an optimization function aiming at the load balancing of manufacturing cluster is formulated. Then, the improved particle swarm optimization algorithm is used to obtain an optimal solution, and the priority for achieving tasks is built toward the manufacturing cluster. Finally, a multiagent system is introduced to achieve the distributed scheduling of manufacturing cluster. The proposed ELBS method is verified by experiments with candy packing line, and experimental results showed that proposed method provides optimal scheduling and load balancing for the mixing work robots.},
	journal = {IEEE Transactions on Industrial Informatics},
	author = {Wan, Jiafu and Chen, Baotong and Wang, Shiyong and Xia, Min and Li, Di and Liu, Chengliang},
	year = {2018},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2790265691
tex.pmcid: null},
}

@article{Wang_2019,
	title = {Task scheduling based on a hybrid heuristic algorithm for smart production line with fog computing.},
	doi = {10.3390/s19051023},
	abstract = {Fog computing provides computation, storage and network services for smart manufacturing. However, in a smart factory, the task requests, terminal devices and fog nodes have very strong heterogeneity, such as the different task characteristics of terminal equipment: fault detection tasks have high real-time demands; production scheduling tasks require a large amount of calculation; inventory management tasks require a vast amount of storage space, and so on. In addition, the fog nodes have different processing abilities, such that strong fog nodes with considerable computing resources can help terminal equipment to complete the complex task processing, such as manufacturing inspection, fault detection, state analysis of devices, and so on. In this setting, a new problem has appeared, that is, determining how to perform task scheduling among the different fog nodes to minimize the delay and energy consumption as well as improve the smart manufacturing performance metrics, such as production efficiency, product quality and equipment utilization rate. Therefore, this paper studies the task scheduling strategy in the fog computing scenario. A task scheduling strategy based on a hybrid heuristic (HH) algorithm is proposed that mainly solves the problem of terminal devices with limited computing resources and high energy consumption and makes the scheme feasible for real-time and efficient processing tasks of terminal devices. Finally, the experimental results show that the proposed strategy achieves superior performance compared to other strategies.},
	journal = {Sensors},
	author = {Wang, Juan and Li, Di and Li, Di},
	year = {2019},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2915641590
tex.pmcid: 6427198},
}

@article{Wang_2019,
	title = {A reinforcement learning approach for online service tree placement in edge computing},
	doi = {10.1109/icnp.2019.8888150},
	abstract = {We consider the problem of optimally mapping an edge computing service that is modeled as a tree with multiple processing sub-tasks and data flows onto the underlying physical network. As new computing and data analytics applications require more complicated data processing structures, and different types of data (e.g., images, videos, and numbers) sensed at geographically distributed locations must be collected and processed to obtain a complex and comprehensive result, highly intelligent algorithms are needed to solve this challenging problem. In this paper, we propose a learning-based hierarchical service tree placement strategy that aims to optimize the net utility, defined as achieved utility minus network congestion. The key idea is to decouple a service tree into appropriate sub-trees each containing a single computing sub-task as well as associated data flows and to recursively leverage Q-learning to place each sub-tree while maintaining the dependencies of sub-tasks in the service tree structure. It enables a scalable solution for large networks with unknown arrival statistics and complex service structures. Numerical results show that our solution can significantly outperform baseline heuristics in online service tree placement.},
	journal = {null},
	author = {Wang, Yimeng and Li, Yongbo and Lan, Tian and Choi, Nakjung},
	year = {2019},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2982344943
tex.pmcid: null},
}

@article{Wu_2012,
	title = {A simulated annealing algorithm for energy efficient virtual machine placement},
	doi = {null},
	abstract = {Improving energy efficiency has become increasingly important in data centers in recent years to reduce the rapidly growing tremendous amounts of electricity consumption. The power dissipation of the physical servers is the root cause of power usage of other systems, such as cooling systems. Many efforts have been made to make data centers more energy efficient. One of them is to minimize the total power consumption of these servers in a data center through virtual machine consolidation, which is implemented by virtual machine placement. The placement problem is often modeled as a bin packing problem. Due to the NP-hard nature of the problem, heuristic solutions such as First Fit and Best Fit algorithms have been often used and have generally good results. However, their performance leaves room for further improvement. In this paper we propose a Simulated Annealing based algorithm, which aims at further improvement from any feasible placement. This is the first published attempt of using SA to solve the VM placement problem to optimize the power consumption. Experimental results show that this SA algorithm can generate better results, saving up to 25 percentage more energy than First Fit Decreasing in an acceptable time frame.},
	journal = {Division of Technology, Information and Library Services},
	author = {Wu, Yongqiang and Tang, Maolin and Fraser, Warren L.},
	year = {2012},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3014460189
tex.pmcid: null},
}

@article{Wu_2019,
	title = {Mobility-aware tasks offloading in mobile edge computing environment},
	doi = {10.1109/candar.2019.00034},
	abstract = {In the mobile edge computing (MEC) paradigm, the underlying business processes of mobile applications can be modeled as application graphs, and mobile users are allowed to offload mobile tasks in these graphs to nearby edge servers to speed up their mobile applications. Nevertheless, various challenges, especially the quality of such a mobile task offloading in edge computing environment, are yet to be properly tackled. Most studies and related offloading strategies based on the assumption that mobile users are fully stationary when they are offloading tasks to edge servers. However, this is not realistic in real-world where edge users are keeping moving, which has a great impact on the success of task offloading and further affects the response time of mobile applications. In this paper, we take the mobility of edge users into consideration and employ a deep learning method to predict the future trajectories of mobile users. Then we develop an online method to solve the offloading problem based on the quality-of-service (QoS) and the predicted user trajectories in real-time. Experiments based on real-world user trajectories and edge server dataset show that our proposed approach can achieve lower offloading failure count and shorter response time than traditional ones.},
	journal = {null},
	author = {Wu, Chunrong and Peng, Qinglan and Xia, Yunni and Lee, Jia},
	year = {2019},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2999423573
tex.pmcid: null},
}

@article{Xu_2018,
	title = {Improved particle swarm optimization based workflow scheduling in cloud-fog environment},
	doi = {10.1007/978-3-030-11641-5_27},
	abstract = {Mobile edge devices with high requirements typically need to obtain faster response on local network services. Fog computing is an emerging computing paradigm motivated by this need, which currently is viewed as an extension of cloud computing. This computing paradigm is presented to provide low commutation latency service for workflow applications. However, how to schedule workflow applications for seeking the tradeoff between makespan and cost in cloud-fog environment is facing huge challenge. To address this issue, in current paper, we propose a workflow scheduling algorithm based on improved particle swarm optimization (IPSO), where a nonlinear decreasing function of inertia weight in PSO is designed for promoting PSO to gain the optimal solution. Finally, comprehensive simulation experiment results show that our proposed scheduling algorithm is more cost-effective and can obtain better performance than baseline approach.},
	journal = {null},
	author = {Xu, Rongbin and Wang, Yeguo and Cheng, Yongliang and Zhu, Yuanwei and Xie, Ying and Sani, Abubakar Sadiq and Yuan, Dong},
	year = {2018},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2911982960
tex.pmcid: null},
	file = {Full Text:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/Z2UMGL42/Xu et al. - 2018 - Improved particle swarm optimization based workflo.pdf:application/pdf},
}

@article{Xu_2019,
	title = {A method based on the combination of laxity and ant colony system for cloud-fog task scheduling},
	doi = {10.1109/access.2019.2936116},
	abstract = {null},
	journal = {IEEE access : practical innovations, open solutions},
	author = {Xu, Jiuyun and Xu, Jiuyun and Xu, Jiuyun and Xu, Jiuyun and Hao, Zhuangyuan and Zhang, Ruru and Sun, Xiaoting and Sun, Xiaoting and Sun, Xiaoting},
	year = {2019},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2969892921
tex.pmcid: null},
	file = {Full Text:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/KW9Y4VLW/Xu et al. - 2019 - A method based on the combination of laxity and an.pdf:application/pdf},
}

@article{Xu_2019,
	title = {A computation offloading method over big data for {IoT}-{Enabled} cloud-edge computing},
	doi = {10.1016/j.future.2018.12.055},
	abstract = {Abstract The Internet of mobile things is a burgeoning technique that generates, stores and processes big real-time data to render rich services for mobile users. In order to mitigate conflicts between the resource limitation of mobile devices and users’ demands of decreasing processing latency as well as prolonging battery life, it spurs a popular wave of offloading mobile applications for execution to centralized and decentralized data centers, such as cloud and edge servers. Due to the complexity and difference of mobile big data, arbitrarily offloading the mobile applications poses a remarkable challenge to optimizing the execution time and the energy consumption for mobile devices, despite the improved performance of Internet of Things (IoT) in cloud-edge computing. To address this challenge, we propose a c omputation o ffloading m ethod, named COM, for IoT-enabled cloud-edge computing. Specifically, a system model is investigated, including the execution time and energy consumption for mobile devices. Then dynamic schedules of data/control-constrained computing tasks are confirmed. In addition, NSGA-III (non-dominated sorting genetic algorithm III) is employed to address the multi-objective optimization problem of task offloading in cloud-edge computing. Finally, systematic experiments and comprehensive simulations are conducted to corroborate the efficiency of our proposed method.},
	journal = {Future Generation Computer Systems},
	author = {Xu, Xiaolong and Liu, Qingxiang and Luo, Yun and Peng, Kai and Peng, Kai and Zhang, Xuyun and Meng, Shunmei and Qi, Lianyong},
	year = {2019},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2911353037
tex.pmcid: null},
}

@article{Yan_2020,
	title = {Machine-learning approach for user association and content placement in fog radio access networks},
	doi = {10.1109/jiot.2020.2973339},
	abstract = {The joint user association and cache placement problem is challenging in fog radio access networks (F-RANs) due to its difficulty to present the optimal solution with low complexity. Motivated by the recent development of artificial intelligence, we divide the original optimization problem into two subproblems. In particular, the user association problem is solved by a reinforcement-learning-based algorithm in which the enhanced fog access point content placement profiles and the fronthaul constraint are considered. On the other hand, since the popularity profile of the contents is hard to acquire in practice, a stacked autoencoder-based scheme is presented to predict the content popularity, which considers both the local and global user request status within a specified time interval. Based on the popularity prediction, the edge content placement problem is solved by a deep-reinforcement-learning-based algorithm, aiming at maximizing the F-RAN network payoff. Moreover, the complicated interactions and the cyclic dependency among the short time-scale user association and the long time-scale content popularity prediction and placement problems are studied by applying the Stackelberg game theory. The simulation validates the accuracy of the analytical results and proves that the proposal can further improve the performance of F-RANs.},
	journal = {IEEE Internet of Things Journal},
	author = {Yan, Shi and Jiao, Minghan and Zhou, Yangcheng and Peng, Mugen and Daneshmand, Mahmoud},
	year = {2020},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3006617398
tex.pmcid: null},
}

@article{yang_cost_2016,
	title = {Cost aware service placement and load dispatching in mobile cloud systems},
	doi = {10.1109/tc.2015.2435781},
	abstract = {With proliferation of smart phones and an increasing number of services provisioned by clouds, it is commonplace for users to request cloud services from their mobile devices. Accessing services directly from the Internet data centers inherently incurs high latency due to long RTTs and possible congestions in WAN. To lower the latency, some researchers propose to ‘cache’ the services at edge clouds or smart routers in the access network which are closer to end users than the Internet cloud. Although ‘caching’ is a promising technique, placing the services and dispatching users’ requests in a way that can minimize the users’ access delay and service providers’ cost has not been addressed so far. In this paper, we study the joint optimization of service placement and load dispatching in the mobile cloud systems. We show this problem is unique to both the traditional caching problem in mobile networks and the content distribution problem in content distribution networks. We develop a set of efficient algorithms for service providers to achieve various trade-offs among the average latency of mobile users’ requests, and the cost of service providers. Our solution utilizes user's mobility pattern and services access pattern to predict the distribution of user's future requests, and then adapt the service placement and load dispatching online based on the prediction. We conduct extensive trace driven simulations. Results show our solution not only achieves much lower latency than directly accessing service from remote clouds, but also outperforms other classical benchmark algorithms in term of the latency, cost and algorithm running time.},
	journal = {IEEE Transactions on Computers},
	author = {Yang, Lei and Cao, Jiannong and Liang, Guanqing and Han, Xu},
	year = {2016},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2315975036
tex.pmcid: null},
}

@article{Yasmeen_2018,
	title = {Efficient resource provisioning for smart buildings utilizing fog and cloud based environment},
	doi = {10.1109/iwcmc.2018.8450410},
	abstract = {The integration of Smart Grid (SG) with cloud computing promises to develop an improved energy management system for utilities and consumers. New applications and services are developed which create large amount of data to be processed on cloud. Fog computing as an extension of cloud computing which helps to mitigate load on cloud data centers. In this paper, a three layered model based on cloud and fog framework is proposed to reduce load of consumers and power generation system. End user layer contains clusters of buildings which are connected to fog server layer. Fog layer is an intermediate layer which connects the end user layer to cloud layer. Three load balancing algorithms Round Robin (RR), throttled and proposed Particle Swarm Optimization with Simulated Annealing (PSOSA) are used for resource allocation. The service broker policy considered in this paper is optimized response time. The findings demonstrate that PSO-SA performs better than RR and throttled in order to alleviate response time, processing time and cost of virtual machine, microgrid and data transfer.},
	journal = {null},
	author = {Yasmeen, Anila and Javaid, Nadeem and Rehman, Obaid Ur and Iftikhar, Hina and Malik, Muhammad Faizan and Malik, Muhammad Faizan and Malik, Muhammad Faizan and Muhammad, Fatima J.},
	year = {2018},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2888812216
tex.pmcid: null},
}

@article{Yuan_2020,
	title = {A dynamic deep-learning-based virtual edge node placement scheme for edge cloud systems in mobile environment},
	doi = {10.1109/tcc.2020.2974948},
	abstract = {Edge node placement is a key topic to edge cloud systems for that it affects their service performances significantly. Previous solutions based on the existing information are not suitable for the mobile environment due to the mobility and random Internet access of end users. In this paper, we propose a dynamic virtual edge node placement scheme, in which the edge node placement strategy is generated based on the prediction information. Our placement scheme applies the pay-as-you-go and Spot Instance model of cloud computing, which may allocate the service resources with low cost conveniently and flexibly. What's more, Long Short-Term Memory is implemented to predict the information of end users' requests and the resources' prices, endowing the generated placement strategy with the adaptability to the change of end users. At last, a set of hierarchical-clustering-based placement algorithms are proposed, which not only locate virtual edge nodes and allocate their corresponding service resources actively, but also guarantee the service quality of end users with low time complexity. The simulation with trace data shows that compared with K-means-clustering-based placement schemes, our virtual edge node placement scheme can provide users with high-quality service in terms of network delay with relatively low placement cost time-efficiently.},
	journal = {IEEE Transactions on Cloud Computing},
	author = {Yuan, Xiaoqun and Yuan, Xiaoqun and Sun, Mengting and Lou, Wenjing and Lou, Wenjing},
	year = {2020},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3008421805
tex.pmcid: null},
}

@article{Zafar_2018,
	title = {Resource allocation over cloud-fog framework using {BA}},
	doi = {10.1007/978-3-319-98530-5_19},
	abstract = {Edge computing or fog computing (FG) are introduced to minimize the load on cloud and for providing low latency. However, FG is specified to a comparatively small area and stores data temporarily. A cloud-fog based model is proposed for efficient allocation of resources from different buildings on fog. FG provides low latency hence, makes the system more efficient and reliable for consumer’s to access available resources. This paper proposes an cloud and fog based environment for management of energy. Six fogs are considered for six different regions around the globe. Moreover, one fog is interconnected with two clusters and each cluster contains fifteen numbers of buildings. All the fogs are connected to a centralized cloud for the permanent storage of data. To manage the energy requirements of consumers, Microgrids (MGs) are available near the buildings and are accessible by the fogs. So, the load on fog should be balanced and hence, a bio-inspired Bat Algorithm (BA) is proposed which is used to manage the load using Virtual Machines (VMs). Service broker policy considered in this paper is closest data center. While considering the proposed technique, results are compared with Active VM Load Balancer (AVLB) and Particle Swarm Optimization (PSO). Results are simulated in the Cloud Analyst simulator and hence, the proposed technique gives better results than other two load balancing algorithms.},
	journal = {null},
	author = {Zafar, Farkhnada and Javaid, Nadeem and Hassan, Kanza and Murtaza, Shakeeb and Rehman, Saniah and Rasheed, Sadia},
	year = {2018},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2889303900
tex.pmcid: null},
	file = {Full Text:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/C5QPTTN9/Zafar et al. - 2018 - Resource allocation over cloud-fog framework using.pdf:application/pdf},
}

@article{Zahoor_2018,
	title = {Cloud–{Fog}–{Based} smart grid model for efficient resource management},
	doi = {10.3390/su10062079},
	abstract = {A smart grid (SG) is a modernized electric grid that enhances the reliability, efficiency, sustainability, and economics of electricity services. Moreover, it plays a vital role in modern energy infrastructure. The core challenge faced by SGs is how to efficiently utilize different kinds of front-end smart devices, such as smart meters and power assets, and in what manner to process the enormous volume of data received from these devices. Furthermore, cloud and fog computing provide on-demand resources for computation, which is a good solution to overcome SG hurdles. Fog-based cloud computing has numerous good characteristics, such as cost-saving, energy-saving, scalability, flexibility, and agility. Resource management is one of the big issues in SGs. In this paper, we propose a cloud–fog–based model for resource management in SGs. The key idea of the proposed work is to determine a hierarchical structure of cloud–fog computing to provide different types of computing services for SG resource management. Regarding the performance enhancement of cloud computing, different load balancing techniques are used. For load balancing between an SG user’s requests and service providers, five algorithms are implemented: round robin, throttled, artificial bee colony (ABC), ant colony optimization (ACO), and particle swarm optimization. Moreover, we propose a hybrid approach of ACO and ABC known as hybrid artificial bee ant colony optimization (HABACO). Simulation results show that our proposed technique HABACO outperformed the other techniques.},
	journal = {Sustainability},
	author = {Zahoor, Saman and Javaid, Sakeena and Javaid, Nadeem and Ashraf, Mahmood and Ishmanov, Farruh and Afzal, Muhammad Khalil},
	year = {2018},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2809058834
tex.pmcid: null},
	file = {Full Text:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/2NXWD6W8/Zahoor et al. - 2018 - Cloud–Fog–Based smart grid model for efficient res.pdf:application/pdf},
}

@article{Zhang_2019,
	title = {A double deep q-learning model for energy-efficient edge scheduling},
	doi = {10.1109/tsc.2018.2867482},
	abstract = {Reducing energy consumption is a vital and challenging problem for the edge computing devices since they are always energy-limited. To tackle this problem, a deep Q-learning model with multiple DVFS (dynamic voltage and frequency scaling) algorithms was proposed for energy-efficient scheduling (DQL-EES). However, DQL-EES is highly unstable when using a single stacked auto-encoder to approximate the Q-function. Additionally, it cannot distinguish the continuous system states well since it depends on a Q-table to generate the target values for training parameters. In this paper, a double deep Q-learning model is proposed for energy-efficient edge scheduling (DDQ-EES). Specially, the proposed double deep Q-learning model includes a generated network for producing the Q-value for each DVFS algorithm and a target network for producing the target Q-values to train the parameters. Furthermore, the rectified linear units (ReLU) function is used as the activation function in the double deep Q-learning model, instead of the Sigmoid function in QDL-EES, to avoid gradient vanishing. Finally, a learning algorithm based on experience replay is developed to train the parameters of the proposed model. The proposed model is compared with DQL-EES on EdgeCloudSim in terms of energy saving and training time. Results indicate that our proposed model can save average 2\%-2.4\%2\%-2.4\% energy and achieve a higher training efficiency than QQL-EES, proving its potential for energy-efficient edge scheduling.},
	journal = {IEEE Transactions on Services Computing},
	author = {Zhang, Qingchen and Lin, Man and Yang, Laurence T. and Chen, Zhikui and Chen, Zhikui and Khan, Samee U. and Li, Peng and Li, Peng},
	year = {2019},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2888896501
tex.pmcid: null},
}

@article{Zubair_2018,
	title = {Integration of cloud-fog based platform for load balancing using hybrid genetic algorithm using bin packing technique},
	doi = {10.1007/978-3-030-02607-3_25},
	abstract = {The smart girds (SGs) are used to accommodate the growing demand of electric systems and monitor the power consumption with bidirectional communication and power flows. Smart buildings as key partners of the smart grid for the energy transition. Smart grids co-ordinate the needs and capabilities of all generators, grid operators, end-users and electricity market stakeholders to operate all parts of the system as efficiently as possible, minimising costs and environmental impacts while maximising system reliability, resilience and stability. The users demand for energy varies dynamically in different time slots. The power grids needs ideal load balancing for supply and demand of electricity between end-users and utility providers. The main characteristics of the SGs are its heterogeneous architecture that includes reduce the costly impact of blackouts, help measure and reduce energy consumption, reduce their carbon footprint and provides the power quality for the range of needs. The cloud-fog based computing model is used to achieve the objective of load balancing in the SG. The cloud layer provides on-demand delivery of resources. The fog layer is the extension of the cloud that lies between the cloud and end-user layer. The fog layer minimizes the latency, enhances the reliability of cloud facilities and reduced the load on the cloud because fog is an edge computing and it analyzing data close to the device that collected the data can make the difference between averting disaster and a cascading system failure. The end-users required electricity through the Macrogrids (MGs) and Utilities installed on fog and cloud layer respectively. The cloud-fog computing framework uses different algorithms for load balancing objective. In this paper, three algorithms are used such as Round Robin (RR), throttled and Hybrid Genetic Algorithm using Bin Packing Technique for load balancing.},
	journal = {null},
	author = {Zubair, Muhammad and Zubair, Muhammad and Javaid, Nadeem and Ismail, Muhammad and Zakria, Muhammad and Zaheer, Muhammad Asad and Saeed, Faizan},
	year = {2018},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2895781619
tex.pmcid: null},
	file = {Full Text:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/RBCM3BIB/Zubair et al. - 2018 - Integration of cloud-fog based platform for load b.pdf:application/pdf},
}

@article{Marin-Tordera2017,
	title = {Do we all really know what a fog node is? {Current} trends towards an open definition},
	volume = {109},
	issn = {01403664},
	doi = {10.1016/j.comcom.2017.05.013},
	abstract = {Fog computing has emerged as a promising technology that can bring cloud applications closer to the physical IoT devices at the network edge. While it is widely known what cloud computing is, how data centers can build the cloud infrastructure and how applications can make use of this infrastructure, there is no common picture on what fog computing and particularly a fog node, as its main building block, really is. One of the first attempts to define a fog node was made by Cisco, qualifying a fog computing system as a “mini-cloud” located at the edge of the network and implemented through a variety of edge devices, interconnected by a variety, mostly wireless, communication technologies. Thus, a fog node would be the infrastructure implementing the said mini-cloud. Other proposals have their own definition of what a fog node is, usually in relation to a specific edge device, a specific use case or an application. In this paper, we first survey the state of the art in technologies for fog computing nodes, paying special attention to the contributions that analyze the role edge devices play in the fog node definition. We summarize and compare the concepts, lessons learned from their implementation, and end up showing how a conceptual framework is emerging towards a unifying fog node definition. We focus on core functionalities of a fog node as well as in the accompanying opportunities and challenges towards their practical realization in the near future.},
	journal = {Computer Communications},
	author = {Marín-Tordera, Eva and Masip-Bruin, Xavi and García-Almiñana, Jordi and Jukan, Admela and Ren, Guang Jie and Zhu, Jiafeng},
	year = {2017},
	keywords = {Edge computing, Edge devices, Fog computing, Fog node, IoT},
	pages = {117--130},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/WWC226TI/1-s2.0-S0140366416307113-main.pdf:application/pdf},
}

@article{perera_fog_2017,
	title = {Fog computing for sustainable smart cities: {A} survey},
	volume = {50},
	issn = {15577341},
	doi = {10.1145/3057266},
	abstract = {The Internet of Things (IoT) aims to connect billions of smart objects to the Internet, which can bring a promising future to smart cities. These objects are expected to generate large amounts of data and send the data to the cloud for further processing, especially for knowledge discovery, in order that appropriate actions can be taken. However, in reality sensing all possible data items captured by a smart object and then sending the complete captured data to the cloud is less useful. Further, such an approach would also lead to resource wastage (e.g., network, storage, etc.). The Fog (Edge) computing paradigm has been proposed to counterpart the weakness by pushing processes of knowledge discovery using data analytics to the edges. However, edge devices have limited computational capabilities. Due to inherited strengths and weaknesses, neither Cloud computing nor Fog computing paradigm addresses these challenges alone. Therefore, both paradigms need to work together in order to build a sustainable IoT infrastructure for smart cities. In this article, we review existing approaches that have been proposed to tackle the challenges in the Fog computing domain. Specifically, we describe several inspiring use case scenarios of Fog computing, identify ten key characteristics and common features of Fog computing, and compare more than 30 existing research efforts in this domain. Based on our review, we further identify several major functionalities that ideal Fog computing platforms should support and a number of open challenges toward implementing them, to shed light on future research directions on realizing Fog computing for building sustainable smart cities.},
	number = {3},
	journal = {ACM Computing Surveys},
	author = {Perera, Charith and Qin, Yongrui and Estrella, Julio C. and Reiff-Marganiec, Stephan and Vasilakos, Athanasios V.},
	year = {2017},
	note = {arXiv: 1703.07079
tex.arxivid: 1703.07079},
	keywords = {Fog computing, Internet of Things, Smart cities, Sustainability},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/6K2X2FG7/Fog_Computing_for_Sustainable_Smart_Cities_A_Surve.pdf:application/pdf;Perera et al. - 2017 - Fog Computing for Sustainable Smart Cities A Surv.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/8HAVD5ED/Perera et al. - 2017 - Fog Computing for Sustainable Smart Cities A Surv.pdf:application/pdf},
}

@article{Consortium2017,
	title = {Open fog reference architecture for fog computing},
	abstract = {Digital innovation from the Internet of Things (IoT), Artificial Intelligence, Virtual Reality, Tactile Internet and 5G applications is transforming the way we work, commute, shop and play. Data from newly-connected factories, homes, communities, cars, hospitals and more is expected to grow from 1.1 zettabytes (or 89 exabytes) per year in 2016 to 2.3 zettabytes (or 194 exabytes) per year by 2020.1 Current “cloud-only” architectures cannot keep up with the volume and velocity of this data across the network, thereby reducing the value that can be created and captured from these investments.},
	number = {February},
	journal = {Open Fog Consortium Architecture Working Group},
	author = {Consortium, Openfog and Working, Architecture},
	year = {2017},
	pages = {1--162},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/FAS9F3EB/OpenFog_Reference_Architecture_2_09_17-FINAL-1.pdf:application/pdf},
}

@incollection{Sunyaev2020,
	title = {Internet computing},
	booktitle = {Internet computing},
	author = {Sunyaev, Ali},
	year = {2020},
	doi = {10.1007/978-3-030-34957-8},
}

@article{mahmud_application_2020,
	title = {Application management in fog computing environments: {A} taxonomy, review and future directions},
	volume = {53},
	issn = {15577341},
	doi = {10.1145/3403955},
	abstract = {The Internet of Things (IoT) paradigm is being rapidly adopted for the creation of smart environments in various domains. The IoT-enabled cyber-physical systems associated with smart city, healthcare, Industry 4.0 and Agtech handle a huge volume of data and require data processing services from different types of applications in real time. The Cloud-centric execution of IoT applications barely meets such requirements as the Cloud datacentres reside at a multi-hop distance from the IoT devices. Fog computing, an extension of Cloud at the edge network, can execute these applications closer to data sources. Thus, Fog computing can improve application service delivery time and resist network congestion. However, the Fog nodes are highly distributed and heterogeneous, and most of them are constrained in resources and spatial sharing. Therefore, efficient management of applications is necessary to fully exploit the capabilities of Fog nodes. In this work, we investigate the existing application management strategies in Fog computing and review them in terms of architecture, placement and maintenance. Additionally, we propose a comprehensive taxonomy and highlight the research gaps in Fog-based application management. We also discuss a perspective model and provide future research directions for further improvement of application management in Fog computing.},
	number = {4},
	journal = {ACM Computing Surveys},
	author = {Mahmud, Redowan and Ramamohanarao, Kotagiri and Buyya, Rajkumar},
	year = {2020},
	note = {arXiv: 2005.10460
tex.arxivid: 2005.10460},
	keywords = {Fog computing, Internet of Things, application placement, application architecture, application maintenance},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/UQ9CUREP/2005.10460(1).pdf:application/pdf;PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/NXAWLED3/08894519.pdf:application/pdf},
}

@article{yousefpour_all_2019,
	title = {All one needs to know about fog computing and related edge computing paradigms: {A} complete survey},
	volume = {98},
	issn = {13837621},
	url = {https://doi.org/10.1016/j.sysarc.2019.02.009},
	doi = {10.1016/j.sysarc.2019.02.009},
	abstract = {With the Internet of Things (IoT) becoming part of our daily life and our environment, we expect rapid growth in the number of connected devices. IoT is expected to connect billions of devices and humans to bring promising advantages for us. With this growth, fog computing, along with its related edge computing paradigms, such as multi-access edge computing (MEC) and cloudlet, are seen as promising solutions for handling the large volume of security-critical and time-sensitive data that is being produced by the IoT. In this paper, we first provide a tutorial on fog computing and its related computing paradigms, including their similarities and differences. Next, we provide a taxonomy of research topics in fog computing, and through a comprehensive survey, we summarize and categorize the efforts on fog computing and its related computing paradigms. Finally, we provide challenges and future directions for research in fog computing.},
	number = {February},
	journal = {Journal of Systems Architecture},
	author = {Yousefpour, Ashkan and Fung, Caleb and Nguyen, Tam and Kadiyala, Krishna and Jalali, Fatemeh and Niakanlahiji, Amirreza and Kong, Jian and Jue, Jason P.},
	year = {2019},
	note = {arXiv: 1808.05283
Publisher: Elsevier B.V.
tex.arxivid: 1808.05283},
	keywords = {Edge computing, Fog computing, Mobile edge computing, Cloud computing, Cloudlet, Internet of things (IoT), Mist computing, Multi-access edge computing, ⛔ No INSPIRE recid found, notion},
	pages = {289--330},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/SI69RZE4/1-s2.0-S1383762118306349-main.pdf:application/pdf},
}

@article{gatut_batik_2010,
	title = {Batik {Industry} of {Indonesia}: the {Rise}, {Fall} and {Prospects}.},
	volume = {5},
	issn = {18424120},
	url = {http://w3.bgu.ac.il/lib/customproxy.php?url=http://search.ebscohost.com/login.aspx?direct=true&db=bth&AN=80448985&site=eds-live&authtype=ip,uid&custid=s4309548&groupid=main&profile=eds},
	abstract = {Batik clothes are a society national cultural heritage of Indonesia. In the last four decades has experienced profit, loss and legal intellectual property rights disputes in its business development. It has huge economic income contribution to economy development of Indonesia. The problem of lack of property rights to be implemented has made several losses of income and legal ownership. A better production technology combined together with high cultural philosophical value needs to be paid attention to maintain quality and its exclusivity. The government should be more serious to protect batik craft pattern designers in order ascertain legal ownership product and design through a formal laws confirmations. Batik needs a better and competitive business strategy to win future market globally. [ABSTRACT FROM AUTHOR]},
	number = {3},
	journal = {Studies in Business \& Economics},
	author = {Gatut, Budiono and Aryanto, Vincent},
	year = {2010},
	keywords = {BATIK, BUSINESS planning, business strategy, COMPETITION (Economics), competitiveness, cultural heritage, CULTURAL property, globalization, income, INDONESIA, INTELLECTUAL property, product, property rights, technology, TEXTILE industry},
	pages = {156--170},
}

@article{sabiq_sistem_2017,
	title = {Sistem {Pemantauan} {Kadar} {pH}, {Suhu} dan {Warna} pada {Air} {Sungai} {Melalui} {Web} {Berbasis} {Wireless} {Sensor} {Network}},
	volume = {5},
	issn = {2338-0403},
	url = {http://jtsiskom.undip.ac.id/index.php/jtsiskom/article/view/12908},
	doi = {10.14710/jtsiskom.5.3.2017.94-100},
	abstract = {{\textless}p{\textgreater}Water is a very important natural resource for human life and other living things. Water pollution, especially in river water, should be controlled because of the rapid development. One technology to monitor multiple physical quantities scattered in a region is the Wireless Sensor Network (WSN). WSN technology has the ability to transmit data from sensor readings and forward data received from other nodes. In this study, prototype monitoring system of pH level, temperature, and color based on WSN that can be monitored through the developed web. The sensors at each node are connected to Arduino Uno as a processing unit, data read from the sensor is sent to the sync node via XBee wireless device. In the sink, the PC also serves as a database server and a web server is used. Test results with two different dispersion indicate that sensor readings can be read by all nodes and received by the sync node and can be displayed on web pages that have been built.Air merupakan sumber daya alam yang sangat penting bagi kehidupan manusia dan mahluk hidup lainnya. Pencemaran air khususnya air sungai perlu dikendalikan seiring makin cepatnya pembangunan. Salah satu teknologi untuk melakukan pemantauan besaran fisik dalam wilayah yang tersebar adalah Wireless Sensor Network (WSN), yang memiliki kemampuan untuk mengirimkan data hasil pembacaan sensor serta meneruskan data yang diterima dari node lain. Pada penelitian ini dikembangkan purwarupa sistem pemantauan kadar pH, suhu dan warna berbasis WSN yang dapat dipantau melalui web. Sensor pada setiap node dihubungkan ke Arduino Uno sebagai unit pemroses, data yang dibaca dari sensor dikirimkan ke node sink melalui perangkat XBee nirkabel. Pada sink digunakan PC yang berfungsi juga sebagai database server dan web server. Hasil dari pengujian dengan dua penyebaran yang berbeda didapatkan hasil bahwa pembacaan sensor dapat dibaca oleh seluruh node dan diterima oleh sink serta dapat ditampilkan melalui laman web yang telah dibangun.{\textless}/p{\textgreater}},
	number = {3},
	journal = {Jurnal Teknologi dan Sistem Komputer},
	author = {Sabiq, Ahmad and Budisejati, Prabowo Nugroho},
	year = {2017},
	pages = {94},
}

@article{akhila_iot_2017,
	title = {An {IoT} based {Patient} {Health} {Monitoring} {System} using {Arduino} {Uno}},
	volume = {1},
	number = {1},
	journal = {International Journal of Research in Information Technology},
	author = {Akhila, V and Vasavi, Y and Nissie, K and Rao, P Venkat},
	year = {2017},
	keywords = {arduino, health care, internet of things, sensors},
	pages = {1--9},
}

@article{kurniawan_strategi_2013,
	title = {Strategi {Pengelolaan} {Air} {Limbah} {Sentra} {UMKM} {Batik} yang {Berkelanjutan} di {Kabupaten} {Sukoharjo}},
	volume = {11},
	number = {2},
	journal = {Jurnal Ilmu Lingkungan},
	author = {Kurniawan, M Wawan (Program Magister Ilmu Lingkungan UNDIP Semarang) and Purwanto, P (Jurusan Teknik Kimia Fakultas Teknik UNDIP Semarang) and Sudarno, S (Jurusan Teknik Lingkungan Fakultas Teknik UNDIP Semarang)},
	year = {2013},
	keywords = {batik smes wastewater management, good governance, strategic priorities},
	pages = {62--72},
}

@article{seye_evaluation_2017,
	title = {An evaluation of {LoRa} coverage in {Dakar} {Peninsula}},
	doi = {10.1109/IEMCON.2017.8117211},
	journal = {2017 8th IEEE Annual Information Technology, Electronics and Mobile Communication Conference, IEMCON 2017},
	author = {Seye, Madoune R. and Gueye, Bamba and Diallo, Moussa},
	year = {2017},
	note = {ISBN: 9781538633717},
	pages = {478--482},
}

@article{hsieh_vehicle_2017,
	title = {A {Vehicle} {Monitoring} {System} {Based} on the {LoRa} {Technique}},
	url = {http://www.waset.org/Publications/a-vehicle-monitoring-system-based-on-the-lora-technique/10007161},
	journal = {World Academy of …},
	author = {Hsieh, C L and Ye, Z W and Huang, C K and Lee, Y C and Sun, C H and {...}},
	year = {2017},
}

@article{maulana_perancangan_2016,
	title = {Perancangan {Sistem} {Sensor} {Pemonitor} {Lingkungan} {Berbasis} {Jaringan} {Sensor} {Nirkabel}},
	volume = {4},
	issn = {2338-0403},
	abstract = {Air pollution is a problem that get a lot of people’s attention, especially at campus environment. It is evocate the stakeholder of campus to monitor the environmental conditions at the campus which themed a green campus. Advances in science and technology, especially in computer and embedded systems in principle can be applied to solve this problem. There are creating an application system that is equipped with sensor to monitor the air quality level wirelessly. The system supports several environmental monitoring sensors that are connected in a wireless sensor network. The objective of this research was to design and create a sensor system that can monitor environment condition quantity by providing the appropriate output value. Sensors that used to read the air quality parameters is TGS 2600 to read the gas concentration of carbon monoxide (CO), TGS 2201 for nitrogen dioxide (NO2), GP2Y1010AU0F for particulate matter, BH1750 for light ambient, and SHT11 for humidity and temperature. This sensor system using Arduino board that based on Atmega 2560 microcontroller. This system is equipped with RTC as a time and GPS as a coordinate where the sensor system is placed as a node. The result of this reseach is the system able to read parameters as air quality monitoring well. The error reading in this sensor system is 0.69 ppm CO gas, 2.8 lx on the intensity of light, 0.22 C in temperature reading, and 0.98\% in humidity readings.},
	number = {2},
	journal = {Jurnal Teknologi dan Sistem Komputer},
	author = {Maulana, Nurhuda and Nurhayati, Oky Dwi and Widianto, Eko Didik},
	year = {2016},
	keywords = {Arduino, Atmega 2560, Sistem sensor, Wireless Sensor Network},
	pages = {353--360},
}

@article{augustin_study_2016,
	title = {A {Study} of {LoRa}: {Long} {Range} \& {Low} {Power} {Networks} for the {Internet} of {Things}},
	volume = {16},
	issn = {1424-8220},
	doi = {10.3390/s16091466},
	abstract = {LoRa is a long-range, low-power, low-bitrate, wireless
telecommunications system, promoted as an infrastructure solution for
the Internet of Things: end-devices use LoRa across a single wireless
hop to communicate to gateway(s), connected to the Internet and which
act as transparent bridges and relay messages between these end-devices
and a central network server. This paper provides an overview of LoRa
and an in-depth analysis of its functional components. The physical and
data link layer performance is evaluated by field tests and simulations.
Based on the analysis and evaluations, some possible solutions for
performance enhancements are proposed.},
	number = {9},
	journal = {Sensors},
	author = {Augustin, Aloys and Yi, Jiazi and Clausen, Thomas and Townsley, William Mark},
	year = {2016},
	keywords = {LoRa, Internet of things, Long range, Low power},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/XMZYG6YF/sensors-16-01466.pdf:application/pdf},
}

@article{sornin_real-world_nodate,
	title = {Real-world {LoRaWAN} ™ {Network} {Capacity} for {Electrical} {Metering} {Applications}},
	author = {Sornin, By Nicolas},
}

@article{gilson_lorawan_nodate,
	title = {{LoRaWAN} {TM} {CAPACITY} {TRIAL} {IN} {DENSE} {URBAN} {ENVIRONMENT}},
	author = {Gilson, Ross and Grudsky, Michael},
	keywords = {2G, 3G, 4G, 5G, 900 Mhz, aes-128, AMI, amr, api, b},
}

@article{iova_lora_2017,
	title = {{LoRa} from the {City} to the {Mountains}: {Exploration} of {Hardware} and {Environmental} {Factors}},
	abstract = {LoRa technology is an increasingly popular option for ap-plications that can exploit its low power and long range ca-pabilities. While most efforts to date have studied its char-acteristics for smart city environments, we take LoRa out-side the city limits, exploring how the environment affects its core communication properties. Specifically, we offer two novel parameter explorations to understand first how vegeta-tion affects communication range and second how antennas change radio behavior. Our results provide insight into LoRa in non-urban environments, specifically showing that vegeta-tion dramatically reduces the communication range and that the antenna selection can have a profound effect.},
	journal = {Proceedings for the 2nd International Workshop on New Wireless Communication Paradigms for the Internet of Things (MadCom)},
	author = {Iova, Oana and Murphy, Amy L and Picco, Gian Pietro and Ghiro, Lorenzo and Molteni, Davide and Ossi, Federico and Cagnacci, Francesca},
	year = {2017},
	note = {ISBN: 9780994988614},
	keywords = {Internet of Things, Categories and Subject Descriptors [Networks], communication range, experiments Keywords LoRa, LPWAN},
	pages = {20--22},
}

@article{gregora_indoor_2016,
	title = {Indoor {Signal} {Propagation} of {LoRa} {Technology}},
	abstract = {—With an increasing number of small devices, the concept of LPWANs becomes more popular. The most important requirements on LPWANs include long battery lifetime, low price of devices, ability to connect millions of devices and long range coverage; the long range coverage is the most critical issue of this technology. In this paper we discuss indoor signal propagation of LoRa technology. At the beginning of the paper, there is an introduction to LoRa technology. Later, the paper presents a measurement of an indoor propagation of LoRa signal in a reinforced concrete building in Prague, the Czech Republic. The measurement is realized with one mobile transmitter and one receiver with a fixed location for each experiment. The measurement is performed for two experiments, one with the receiver in the basement of the building, one with the receiver on the roof of the building. Results of the measurement are graphically visualized for both measurement experiments at the end of this paper and show that the best signal coverage is for the roof location, where it includes also flats of neighboring entrances.},
	journal = {2016 17th International Conference on Mechatronics - Mechatronika (ME)},
	author = {Gregora, Lukas and Vojtech, Lukas and Neruda, Marek},
	year = {2016},
	note = {ISBN: 9788001058831},
	keywords = {-attenuation, coverage, indoor propagation, iot, lora},
	pages = {13--16},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/C2TCNRG9/ieeexplore.ieee.org@7827865.pdf:application/pdf},
}

@article{noauthor_understanding_nodate,
	title = {Understanding the limit of {LoRaWAN}},
}

@article{sanchez-iborra_performance_2018,
	title = {Performance evaluation of lora considering scenario conditions},
	volume = {18},
	issn = {14248220},
	doi = {10.3390/s18030772},
	abstract = {New verticals within the Internet of Things (IoT) paradigm such as smart cities, smart farming, or goods monitoring, among many others, are demanding strong requirements to the Radio Access Network (RAN) in terms of coverage, end-node’s power consumption, and scalability. The technologies employed so far to provide IoT scenarios with connectivity, e.g., wireless sensor network and cellular technologies, are not able to simultaneously cope with these three requirements. Thus, a novel solution known as Low Power - Wide Area Network (LP-WAN) has emerged as a promising alternative to provide with low-cost and low-power-consumption connectivity to end-nodes spread in a wide area. Concretely, the Long-Range Wide Area Network (LoRaWAN) technology is one of the LP-WAN platforms that is receiving greater attention from both the industry and the academia. For that reason, in this work, a comprehensive performance evaluation of LoRaWAN under different environmental conditions is presented. The results are obtained from three real scenarios, namely, urban, suburban, and rural, considering both dynamic and static conditions, hence a discussion about the most proper LoRaWAN physical-layer configuration for each scenario is provided. Besides, a theoretical coverage study is also conducted by the use of a radio planning tool considering topographic maps and a precise propagation model. From the attained results, it can be concluded that it is necessary to evaluate the propagation conditions of the deployment scenario prior to the system implantation in order to reach a compromise between the robustness of the network and the transmission data-rate.},
	number = {3},
	journal = {Sensors (Switzerland)},
	author = {Sanchez-Iborra, Ramon and Sanchez-Gomez, Jesus and Ballesta-Viñas, Juan and Cano, Maria Dolores and Skarmeta, Antonio F.},
	year = {2018},
	keywords = {IoT, Smart cities, LoRa, LoRaWAN, LP-WAN},
}

@article{sanchez-iborra_state_2016,
	title = {State of the art in {LP}-{WAN} solutions for industrial {IoT} services},
	volume = {16},
	issn = {14248220},
	doi = {10.3390/s16050708},
	abstract = {The emergence of low-cost connected devices is enabling a new wave of sensorization services. These services can be highly leveraged in industrial applications. However, the technologies employed so far for managing this kind of system do not fully cover the strict requirements of industrial networks, especially those regarding energy efficiency. In this article a novel paradigm, called Low-Power Wide Area Networking (LP-WAN), is explored. By means of a cellular-type architecture, LP-WAN–based solutions aim at fulfilling the reliability and efficiency challenges posed by long-term industrial networks. Thus, the most prominent LP-WAN solutions are reviewed, identifying and discussing the pros and cons of each of them. The focus is also on examining the current deployment state of these platforms in Spain. Although LP-WAN systems are at early stages of development, they represent a promising alternative for boosting future industrial IIoT (Industrial Internet of Things) networks and services.},
	number = {5},
	journal = {Sensors (Switzerland)},
	author = {Sanchez-Iborra, Ramon and Cano, Maria Dolores},
	year = {2016},
	pmid = {27196909},
	note = {ISBN: 978-3-03842-370-6},
	keywords = {Internet of things (IoT), Industrial internet of things (IIoT), Low-power wide area networks (LP-WAN), Machine-to-machine (M2M) communications, Wireless sensor networks},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/EWNV7T9J/sensors-16-00708.pdf:application/pdf},
}

@article{boonsawat_xbee_2010,
	title = {{XBee} {Wireless} {Sensor} {Networks} for {Temperature} {Monitoring}},
	abstract = {This paper presents an embedded wireless sensor network (WSN) prototype system for temperature monitoring in a building. This network will be used for management of air conditioning systems at SIIT. The ultimate goal is to help saving the energy cost and reducing energy consumption. The system provides a web user interface for any user to access the current and past temperature readings in different rooms. The network consists of a data gateway or coordinator which wirelessly polls each WSN temperature-monitoring node located in each classroom. Each WSN node consists of a microcontroller on Arduino board and an Xbee wireless communication module based on the IEEE 802.15.4/Zigbee standards. The coordinator also has an Ethernet interface and runs a simple data web server. Hence, the coordinator allows data collection over Xbee and data access from web browsers.},
	journal = {2nd ECTI-Conference on Application Research and Development},
	author = {Boonsawat, Vongsagon and Ekchamanonta, Jurarat and Bumrungkhet, Kulwadee and Kittipiyakul, Somsak},
	year = {2010},
	keywords = {Arduino, microcontroller, temperature monitoring, Wireless sensor network, Xbee, Zigbee},
	pages = {6},
}

@misc{knight_reversing_2016,
	title = {Reversing {LoRa}},
	urldate = {2018-05-25},
	journal = {Bastille Networks},
	author = {Knight, Matt},
	year = {2016},
	note = {Pages: 128},
}

@misc{noauthor_lora_nodate,
	title = {{LoRa} {White} {Papers}},
	url = {https://www.lora-alliance.org/lorawan-white-papers},
	urldate = {2017-12-17},
}

@misc{noauthor_perda_nodate,
	title = {Perda {No}. 5 tahun 2012 {Provinsi} {Jawa} {Tengah}},
	urldate = {2017-12-16},
}

@misc{noauthor_spreading_nodate,
	title = {Spreading {Factor} on {LoRa}},
	url = {https://docs.exploratory.engineering/lora/dr_sf/, 20 Juni 2018},
	urldate = {2018-06-20},
}

@misc{noauthor_aloha_nodate,
	title = {{ALOHA} - {What} is {ALOHA}?},
	url = {http://ecomputernotes.com/   computernetworkingnotes/ communication-networks/ what-is-aloha},
	urldate = {2018-05-20},
}

@article{okafor_development_2017,
	title = {Development of {Arduino} {Based} {IoT} {Metering} {System} for {On}-{Demand} {Energy} {Monitoring}},
	volume = {7},
	abstract = {intelligent energy management strategy for cost optimization offers a new paradigm for energy users in Nigeria. This research developed Arduino based energy consumption rate meter for residential homes using multidisciplinary concepts in Mechatronics. The system features real time demand side management using composite design methodology (CDM). It comprises the metering and cloud server cluster units. The work introduced ACS712 Hall Effect current sensor, Arduino Uno (with ATmega328 chipset), and SIM800L GSM modules to achieve the system functionalities. The design description on editor run-time environment enabled direct debugging in the open source Integrated Development Environment (IDE). The approach was evaluated through selected case studies and usability experiments. With the latter, the suitability of the system provided an efficient means of monitoring energy consumption with minimal errors. The results showed that when the meter was switched-ON with no load, an output of 0.00kWh was read. By connecting i-core7 Dell Inspiron laptop to it, an output of 10.75kWh was then observed on the cloud web application (real time). The output kept increasing whilst the load was still connected to the meter as expected. Utilities can smartly provide value-added services using the system, thereby increasing their revenues while ensuring customers satisfaction.},
	number = {23},
	journal = {International Journal of Mechatronics, Electrical and Computer Technology},
	author = {Okafor, K. C. and Ononiwu, G. C. and Precious, U. and Godis, A.C},
	year = {2017},
	keywords = {internet of things, cloud computing, demand side management, smart meter, utility},
	pages = {3208--3224},
}

@article{rozikin_sistem_2017,
	title = {Sistem {Akuisisi} {Data} {Multi} {Node} untuk {Irigasi} {Otomatis} {Berbasis} {Wireless} {Sensor} {Network}},
	volume = {6},
	issn = {2460-5719},
	url = {http://ejnteti.jteti.ugm.ac.id/index.php/JNTETI/article/view/293},
	doi = {10.22146/jnteti.v6i1.293},
	number = {1},
	journal = {Jurnal Nasional Teknik Elektro dan Teknologi Informasi (JNTETI)},
	author = {Rozikin, Chaerur and Sukoco, Heru and Saptomo, Satyanto Krido},
	year = {2017},
}

@misc{quer_arduino_2012,
	title = {Arduino {UNO}},
	url = {http://arduino.cc/en/Main/ArduinoBoardUno},
	urldate = {2018-06-27},
	author = {Quer, J Call},
	year = {2012},
	note = {Pages: 13
Volume: 328
Issue: Timer 1},
}

@article{lalwan_iot_2018,
	title = {{IoT} {Based} {Industrial} {Parameters} {Monitoring} and {Alarming} {System} using {Arduino} - {A} {Novel} {Approach}},
	volume = {8},
	number = {4},
	journal = {International Journal of Engineering Science and Computing},
	author = {Lalwan, Prem Sagar and Khurana, Mehakpreet Kaur and Khandare, Swati Jaikumar and Ansari, Obaid Ur Rehman and Pokle, Sanjay B.},
	year = {2018},
}

@misc{noauthor_datasheet_nodate,
	title = {Datasheet {LG01} indoor {LoRa} {Gateway} by {Dragino}},
	urldate = {2017-12-17},
}

@misc{noauthor_lora_nodate-1,
	title = {Lora {Shield} for {Arduino}},
	url = {http://wiki.dragino.com/ index.php? title= Lora_Shield},
	urldate = {2017-12-17},
}

@misc{noauthor_lorawan_nodate,
	title = {{LoraWan} {Frequencies} by {Country}},
	url = {https://www.thethingsnetwork.org/docs/lorawan/frequencies-by-country.html},
	urldate = {2018-04-01},
}

@article{maureira_thingspeak_2011,
	title = {{ThingSpeak} – an {API} and {Web} {Service} for the {Internet} of {Things}},
	abstract = {In this report we describe the use of ThingSpeak, an " Application Programming Interface " (API) and web service for the " Internet of Things " (IoT). While the interpretation as to what should be understood under the term is changing over time, here we refer to enabling objects or simple devices to be identified and communicated with via the Internet. The ThingSpeak API is an open source interface which listens to incoming data, timestamps it, and outputs it for both human users (through visual graphs) and machines (through easily parse-able code). We look into practical examples using the Arduino micro-controller as well as communication with graphical interface operating systems through a Python script. Our report concludes that ThingSpeak is especially useful for smaller hardware projects where connectivity over the Internet is required but in which the maintenance of a dedicated communication server is not practical. Alternative IoT services exist but tend to require payment for some of their functionality and are consequently not open source. PURPOSE, CONTEXT AND HISTORY},
	author = {Maureira, Marcello A Gómez and Teernstra, Livia},
	year = {2011},
}

@article{astria_rancang_2014,
	title = {Rancang {Bangun} {Alat} {Ukur} {pH} {Dan} {Suhu} {Berbasis} {Short} {Message} {Service} ({SMS}) {Gateway}},
	volume = {1},
	abstract = {Sistem alat ukur pH dan suhu berbasis SMS ga t e w a y ini merupakan alat ukur yang berkomunikasi dengan provider, sehingga dapat digunakan untuk memantau kadar pH dan suhu dalam air dari jarak jauh. Alat ini bekerja dengan menggunakan sensor pH dan suhu sebagai detektor. Alat ukur pH dan suhu berbasis SMS pH 14, sedangkan untuk pengukuran suhu sendiri dapat diukur dengan skala antara -100C hingga ga t e w a y ini dapat mengukur kadar pH dalam air dengan skala antara pH 0 hingga 1000C. Untuk membuat sistem ini dibutuhkan modem wavecom untuk komunikasi dengan sensor pH dan suhu sebagai detektor, dan ATMega 128 sebagai kontrolernya. Untuk m ic ropa provide r , pemrogramannya sistem ini menggunakan bahasa pemrograman Delphi 7 dan aplikasi l . Pada penelitian ini dirancang sebuah alat ukur pH dan suhu berbasis SMS Sh ort Me ssa ge Servi ga s c a t e w a y dengan SMS ( c e ) sebagai media informasinya untuk jarak jauh. Data hasil pengukuran dapat dilihat langsung melalui LCD pada modul pH dan suhu. Selain itu dapat pula dilihat dari jarak jauh melalui sebuah PC yang telah tersambung pada modem wavecom dan pada sebuah ponsel.},
	number = {1},
	journal = {Jurnal METRIK},
	author = {Astria, Fanny and Subito, Mery and Nugraha, Deny Wiria},
	year = {2014},
	keywords = {gateway, ph sensor, short message service, sms, temperature sensor},
	pages = {47--55},
}

@article{wulandari_analisis_2016,
	title = {Analisis {QoS} ({Quality} of {Service}) {Pada} {Jaringan} {Internet} ({Studi} {Kasus} : {UPT} {Loka} {Uji} {Teknik} {Penambangan} {Jampang} {Kulon} - {LIPI})},
	volume = {2},
	abstract = {Technical Implementation Unit for Mine’s Technology Assessment Jampang Kulon - LIPI, organizationally is under and responsible to the Head of Geotechnology Research Center, Deputy of Earth Sciences, Indonesian Institute of Sciences. To support research and development activities, administration and cooperation is in need of Internet-based information systems. Quality of Service (QoS) is defined as a measure of how well the network and an attempt to define the characteristics and nature of the service. In an Internet Protocol (IP), IP QoS refers to the performance of the -Package IP packets passing through one or more networks. QoS is designed to help end users become more productive by ensuring that end users get reliable performance of network-based applications. QoS refers to the ability of a network to provide better service at a specific network traffic through different technologies. Computer network performance can vary due to several problems, such as problems of bandwidth, latency and jitter, which can make large effect for many applications. Features of Quality of Service (QoS) can make the bandwidth, latency and jitter are predicted and matched to the need of applications in the existing network. Keywords},
	journal = {Jurnal Teknik Informatika dan Sistem Informasi},
	author = {Wulandari, Rika},
	year = {2016},
	keywords = {bandwith, internet protocol, quality of service},
	pages = {162--172},
}

@misc{noauthor_datasheet_nodate-1,
	title = {Datasheet {SN0161}},
	urldate = {2018-04-23},
}

@misc{noauthor_datasheet_nodate-2,
	title = {Datasheet {Atlas} {Scientific} {pH} {Probe}},
	urldate = {2018-04-23},
}

@misc{noauthor_datasheet_nodate-3,
	title = {Datasheet {SEN0189}},
	urldate = {2018-04-23},
}

@phdthesis{olsson_exploring_2017,
	title = {Exploring {LoRa} and {LoRaWAN} {A} suitable protocol for {IoT} weather stations ?},
	school = {Chalmers University of Technology},
	author = {Olsson, Kristoffer and Finnsson, Sveinn},
	year = {2017},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/DDD84J8L/m-api-49e113bd-6a91-a2b7-1789-a8ff2ca2819c.pdf:application/pdf},
}

@book{freeman_radio_2007,
	title = {Radio {System} {Design} for {Telecommunications}},
	isbn = {0-471-75713-6 978-0-471-75713-9},
	publisher = {IEEE Press (John Wiley \& Sons)},
	author = {Freeman, Roger L},
	year = {2007},
}

@misc{noauthor_lorawan_nodate-1,
	title = {{LoRaWAN} 1.1 {Regional} {Parameters}},
	urldate = {2018-09-20},
}

@misc{noauthor_sensor_nodate,
	title = {Sensor {Terminology}},
	url = {http://www.ni.com/white-paper/14860/en/},
	urldate = {2018-08-12},
	note = {ISBN: 0138494312},
}

@article{de_poorter_sub-ghz_2017,
	title = {Sub-{GHz} {LPWAN} {Network} {Coexistence}, {Management} and {Virtualization}: {An} {Overview} and {Open} {Research} {Challenges}},
	volume = {95},
	issn = {1572834X},
	doi = {10.1007/s11277-017-4419-5},
	abstract = {© 2017, Springer Science+Business Media New York. The IoT domain is characterized by many applications that require low-bandwidth communications over a long range, at a low cost and at low power. Low power wide area networks (LPWANs) fulfill these requirements by using sub-GHz radio frequencies (typically 433 or 868 MHz) with typical transmission ranges in the order of 1 up to 50 km. As a result, a single base station can cover large areas and can support high numbers of connected devices ( {\textgreater} 1000 per base station). Notorious initiatives in this domain are LoRa, Sigfox and the upcoming IEEE 802.11ah (or “HaLow”) standard. Although these new technologies have the potential to significantly impact many IoT deployments, the current market is very fragmented and many challenges exists related to deployment, scalability, management and coexistence aspects, making adoption of these technologies difficult for many companies. To remedy this, this paper proposes a conceptual framework to improve the performance of LPWAN networks through in-network optimization, cross-technology coexistence and cooperation and virtualization of management functions. In addition, the paper gives an overview of state of the art solutions and identifies open challenges for each of these aspects.},
	number = {1},
	journal = {Wireless Personal Communications},
	author = {De Poorter, Eli and Hoebeke, Jeroen and Strobbe, Matthias and Moerman, Ingrid and Latré, Steven and Weyn, Maarten and Lannoo, Bart and Famaey, Jeroen},
	year = {2017},
	keywords = {LPWAN, LoRa, Coexistence, DASH7, Energy efficiency, IEEE 802.11ah, Network management, QoS, Scalability, SigFox, Sub-GHz networks, Virtualization},
	pages = {187--213},
}

@article{noauthor_comparative_nodate,
	title = {A {Comparative} {Study} between {Genetic} {Algorithm}, {Simulated} {Annealing} and a {Hybrid} {Algorithm} for solving a {University} {Course} {Timetabling} {Problem}},
}

@article{adelantado_understanding_2017,
	title = {Understanding the limit of {LoRaWAN}},
	volume = {55},
	doi = {10.1109/MCOM.2017.1600613},
	number = {9},
	journal = {IEEE Communications Magazine},
	author = {Adelantado, Ferran and Vilajosana, Xavier and Tuset-Piero, Pere and Martinez, Borja and Melia-Segui, Joan and Watteyne, Thomas},
	year = {2017},
	pages = {34--40},
}

@article{noauthor_no_nodate,
	title = {No {Title}},
}

@article{krupka_issue_2016,
	title = {The {Issue} of {LPWAN} {Technology} {Coexistence} in {IoT} {Environment}},
	url = {http://ieeexplore.ieee.org/abstract/document/7827866/},
	doi = {Electronic ISBN: 978-8-0010-5883-1},
	abstract = {This paper discusses Low Power Wide Area Network technologies. The purpose of this work is a presentation of these technologies in a mutual context in order to analyse their coexistence. In this work there are described Low Power Wide Area Network terms and their representatives LoRa, Sigfox and IQRF, of which characteristics, topology and some significant technics are inspected. The technologies are also compared together in a frequency spectrum in order to detect risk bands causing collisions. A potential increased risk of collisions is found around 868.2 MHz. The main contribution of this paper is a summary of characteristics, which have an influence on the resulting coexistence.},
	journal = {Mechatronics - Mechatronika (ME), 2016 17th International Conference on Mechatronics - Mechatronika (ME)},
	author = {Krupka, Lukas and Vojtech, Lukas and Neruda, Marek},
	year = {2016},
	keywords = {-coexistence, iqrf, low power wide area, network},
	pages = {1 -- 8},
}

@article{huan_li_scheduling_2004,
	title = {Scheduling communication in real-time sensor applications},
	doi = {10.1109/rttas.2004.1317244},
	abstract = {has received increased research attention in recentyears. In this work, we consider a class of wireless sensorapplications---such as mobile robotics---that impose timelinessconstraints. We assume that these applications are builtusing commodity 802.11 wireless networks and focus on theproblem of providing qualitatively-better QoS during networktransmission of sensor data. Our techniques are designed toexplicitly avoid network collisions and minimize the completiontime to transmit a set of sensor messages. We argue thatthis problem is NP-complete and present several heuristics,based on edge coloring, to achieve these goals. We presentdetailed simulation results to evaluate our heuristics and tocompare them to the optimal solution.},
	author = {{Huan Li} and Shenoy, P. and Ramamritham, K.},
	year = {2004},
	pages = {10--18},
}

@article{abdellaoui_dynamic_2018,
	title = {Dynamic {Reconfiguration} of {LPWANs} {Pervasive} {System} using {Multi}-agent {Approach}},
	volume = {9},
	issn = {2158107X},
	doi = {10.14569/ijacsa.2018.090242},
	number = {2},
	journal = {International Journal of Advanced Computer Science and Applications},
	author = {ABDELLAOUI, Ghouti and Tarik, Fethi},
	year = {2018},
}

@article{noauthor_scheduling_nodate,
	title = {Scheduling {Communication} in {Real}-{Time} {Sensor} {Applications}},
}

@article{wixted_evaluation_2017,
	title = {Evaluation of {LoRa} and {LoRaWAN} for wireless sensor networks},
	issn = {21689229},
	doi = {10.1109/ICSENS.2016.7808712},
	abstract = {© 2016 IEEE. LoRa is a new ISM band wireless technology designed for low power, unlicensed, Long Range operation. LoRaWAN is a Wide Area Network protocol that incorporates the LoRa wireless into a networked infrastructure. The indoor and outdoor performance of these technologies, the physical layer wireless and multi-gateway wide area network, was evaluated across the central business district (CBD) of Glasgow city (Scotland). The results indicated that this technology can be a reliable link for low cost remote sensing applications.},
	journal = {Proceedings of IEEE Sensors},
	author = {Wixted, Andrew J. and Kinnaird, Peter and Larijani, Hadi and Tait, Alan and Ahmadinia, Ali and Strachan, Niall},
	year = {2017},
	note = {ISBN: 9781479982875},
}

@article{de_carvalho_silva_lorawan_2017,
	title = {{LoRaWAN} - {A} low power {WAN} protocol for {Internet} of {Things}: {A} review and opportunities},
	abstract = {© 2017 Univeristy of Split, FESB. The Internet of Things (IoT) vision requires increasingly more sensor nodes interconnected and a network solution that may accommodate these requirements accordingly. In wireless sensor networks, there are energy-limited devices; therefore techniques to save energy have become a significant research trend. Other issues such as latency, range coverage, and bandwidth are important aspects in IoT. It is considering the massive number of expected nodes connected to the Internet. The LoRaWAN (Low Power WAN Protocol for Internet of Things), a data-link layer with long range, low power, and low bit rate, appeared as a promising solution for IoT in which, end-devices use LoRa to communicate with gateways through a single hop. While proprietary LPWAN (Low Power Wide Area Network) technologies are already hitting a large market, this paper addresses the LoRa architecture and the LoRaWAN protocol that is expected to solve the connectivity problem of tens of billions of devices in the next decade. Use cases are considered to illustrate its application alongside with a discussion about open issues and research opportunities.},
	journal = {2017 2nd International Multidisciplinary Conference on Computer and Energy Science, SpliTech 2017},
	author = {De Carvalho Silva, J. and Rodrigues, J.J.P.C. and Alberti, A.M. and Solic, P. and Aquino, A.L.L.},
	year = {2017},
	note = {ISBN: 9789532900712},
	keywords = {IoT, Internet of Things, LoRa, LoRaWAN, Long range, Low power, Sigfox},
}

@article{neumann_indoor_2016,
	title = {Indoor deployment of low-power wide area networks ({LPWAN}): {A} {LoRaWAN} case study},
	issn = {21619654},
	doi = {10.1109/WiMOB.2016.7763213},
	abstract = {The last decade saw the emergence of the Internet of Things (IoT) paradigm, which aims to connect any object to the Internet. In this context, a new type of wireless com- munication network emerged known as Low-Power Wire-Area Network (LPWAN). By contrast to well-known short range and multi-hop wireless networks, LPWAN networks allow long range communications at a low bit rate. Furthermore, LPWAN networks are considered to be integrated into 5G. Among LPWAN networks, the LoRaWAN technology gains more and more interest from the research and industrial communities. In this article, we have led a thorough experimental performance evaluation of LoRaWAN in an indoor environment. From this study, we quantify the limits of this technology and expose the merits of using LoRaWAN for IoT communications in the context of 5G.},
	journal = {International Conference on Wireless and Mobile Computing, Networking and Communications},
	author = {Neumann, Pierre and Montavont, Julien and Noel, Thomas},
	year = {2016},
	note = {ISBN: 9781509007240},
	keywords = {Internet of Things, LPWAN, LoRaWAN, Experimental Study},
}

@article{bankov_limits_2017,
	title = {On the limits of {LoRaWAN} channel access},
	doi = {10.1109/EnT.2016.9},
	abstract = {The rising tide of the Internet of Things has brought to the surface numerous low-power, long-range and low-bitrate wireless network technologies. One of them, LoRaWAN, is being intensely popularized as a solution for sensor networks, however, its potential and limitations are unclear, because there is still neither accurate study nor massive LoRaWAN deployment. This paper surveys and analyzes LoRaWAN operation, focusing on performance evaluation of its channel access as the most crucial component for massive machine type communication. We reveal and point out weaknesses of the LoRaWAN specification and propose solutions to improve LoRaWAN performance.},
	journal = {Proceedings - 2016 International Conference on Engineering and Telecommunication, EnT 2016},
	author = {Bankov, Dmitry and Khorov, Evgeny and Lyakhov, Andrey},
	year = {2017},
	note = {ISBN: 9781509045532},
	keywords = {Performance evaluation, LPWAN, LoRa, LoRaWAN, Channel access},
	pages = {10--14},
}

@article{bardyn_iot:_2016,
	title = {{IoT}: {The} era of {LPWAN} is starting now},
	volume = {2016-Octob},
	issn = {19308833},
	doi = {10.1109/ESSCIRC.2016.7598235},
	abstract = {This paper focusses on LPWAN segment of IoT, describing network constraints and comparing existing and upcoming solutions in unlicensed and licensed frequency bands.},
	journal = {European Solid-State Circuits Conference},
	author = {Bardyn, Jean Paul and Melly, Thierry and Seller, Olivier and Sornin, Nicolas},
	year = {2016},
	note = {ISBN: 9781509029723},
	keywords = {IoT, LPWAN, LoRa, NB-IoT, Spread Spectrum, UNB},
	pages = {25--30},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/YSM2JJDY/bardyn2016(1).pdf:application/pdf},
}

@article{nor_smart_2017,
	title = {Smart traffic light for congestion monitoring using {LoRaWAN}},
	doi = {10.1109/ICSGRC.2017.8070582},
	abstract = {raffic light congestion normally occurs in urban areas where the number of vehicles is too many on the road. This problem drives the need for innovation and provide efficient solutions regardless this problem. Smart system that will monitor the congestion level at the traffic light will be a new option to replace the old system which is not practical anymore. Implementing internet of thinking (IoT) technology will provide the full advantage for monitoring and creating a congestion model based on sensor readings. Multiple sensor placements for each lane will give a huge advantage in detecting vehicle and increasing the accuracy in collecting data. To gather data from each sensor, the LoRaWAN technology is utilized where it features low power wide area network, low cost of implementation and the communication is secure bi-directional for the internet of thinking. The radio frequency used between end nodes to gateways range is estimated around 15-kilometer radius. A series of test is carried out to estimate the range of signal and it gives a positive result. The level of congestion for each lane will be displayed on Grafana dashboard and the algorithm can be calculated. This provides huge advantages to the implementation of this project, especially the scope of the project will be focus in urban areas where the level of congestion is bad.},
	journal = {2017 IEEE 8th Control and System Graduate Research Colloquium, ICSGRC 2017 - Proceedings},
	author = {Nor, Ruhaizan Fazrren Ashraff Mohd and Zaman, Fadhlan H.K. and Mubdi, Shamry},
	year = {2017},
	note = {ISBN: 9781538603802},
	keywords = {LPWAN, LoRa, 3-axis magnetic sensor, Congestion monitoring, Gy-271, LoRaWAN Technology, Smart traffic light},
	pages = {132--137},
}

@article{tzortzakis_wireless_2018,
	title = {Wireless self powered environmental monitoring system for smart cities based on {LoRa}},
	volume = {2018-Janua},
	doi = {10.1109/PACET.2017.8259970},
	abstract = {—This work presents the design and implementation of a wireless sensor network based on the LoRa protocol. Sensor nodes with embedded temperature, humidity, luminance, carbon monoxide, methane, alcohol and smoke detection sensors transmit the collected data to a base station (gateway) using LoRa. The base station collects all the data and uploads them to the cloud using GPRS, where data gathered is stored and processed in order to be accessible to users.},
	journal = {4th Panhellenic Conference on Electronics and Telecommunications, PACET 2017},
	author = {Tzortzakis, Konstantinos and Papafotis, Konstantinos and Sotiriadis, Paul P.},
	year = {2018},
	note = {ISBN: 9781538622872},
	keywords = {Cloud, Environmental monitoring, LoRa protocol, Smart Cities, Wireless networks},
	pages = {1--4},
}

@article{pakpahan_analysis_2018,
	title = {Analysis on {Batik} {Water} {Waste} {Monitoring} {System} based on {LoRa} {Communication}},
	doi = {10.1109/ICITACEE.2018.8576954},
	journal = {Proceedings - 2018 5th International Conference on Information Technology, Computer and Electrical Engineering, ICITACEE 2018},
	author = {Pakpahan, Michael S.M. and Widianto, Eko Didik and Septiana, Risma},
	year = {2018},
	note = {ISBN: 9781538655276},
	keywords = {Arduino, LoRa, Batik waste},
	pages = {171--175},
}

@article{hour_low-power_2018,
	title = {A {Low}-{Power} {Wide}-{Area} {Network} {Information} {Monitoring} {System} by {Combining} {NB}-{IoT} and {LoRa}},
	volume = {6},
	doi = {10.1109/jiot.2018.2847702},
	number = {1},
	journal = {IEEE Internet of Things Journal},
	author = {Hour, Seng Hout and Xu, Suijia and Qiao, Yue and Zhang, Mingming and Meng, Fanfeng and Zhang, Xihai},
	year = {2018},
	pages = {1--1},
}

@article{liu_low-power_2016,
	title = {A low-power real-time air quality monitoring system using {LPWAN} based on {LoRa}},
	doi = {10.1109/ICSICT.2016.7998927},
	abstract = {This paper presents a low-power real-time air quality monitoring system based on the LoRa Wireless Communication technology. The proposed system can be laid out in a large number in the monitoring area to form sensor network. The system integrates a single-chip microcontroller, several air pollution sensors (NO2, SO2, O3, CO, PM1, PM10, PM2.5), LongRange (LoRa) -Modem, a solar PV-battery part and graphical user interface (GUI). As communication module LoRa sends the data to the central monitoring unit and then the data would be saved in the could. The range tests at an outdoor area show that LoRa is able to reach to approximately 2Km. The TX power is only about 110mA which is lower compared with other used wireless technology. An easy to use GUI was designed in the system. Based on LoRa technology, GUI, and Solar PV-battery part the system has several progressive features such as low cost, long distance, high coverage, long device battery life, easy to operate.},
	journal = {2016 13th IEEE International Conference on Solid-State and Integrated Circuit Technology, ICSICT 2016 - Proceedings},
	author = {Liu, Sujuan and Xia, Chuyu and Zhao, Zhenzhen},
	year = {2016},
	note = {ISBN: 9781467397179},
	pages = {379--381},
}

@article{widianto_lora_2019,
	title = {{LoRa} {QoS} {Performance} {Analysis} on {Various} {Spreading} {Factor} in {Indonesia}},
	doi = {10.1109/ISESD.2018.8605471},
	abstract = {In the development and implementation of a communication system, QoS is one of the main objective that must be considered. Same goes with LoRa, which is also a communication system designed to be implemented in IoT. However, the focus of IoT is a low powered system that could handle a lot of end devices, different with other type of communication that focus on speed and bandwidth to transfer multimedia files. To be able to reach the maximum effectiveness, a LoRa system must be set with the correct Spreading Factor (SF) based on the distance between client and gateway. This study had conducted a test to analyze the best SF used in some various distance, using 925 Mhz ISM frequency band in Indonesia. Based on the measurement, SF recommendations are SF7 for maximum throughput, SF8 for a balance of high throughput and long-range capabilities, and SF11 for maximum range and optimal range for LoRa application.},
	journal = {ISESD 2018 - International Symposium on Electronics and Smart Devices: Smart Devices for Big Data Analytic and Machine Learning},
	author = {Widianto, Eko Didik and Pakpahan, Michael S.M. and Faizal, Al Arthur and Septiana, Risma},
	year = {2019},
	note = {ISBN: 9781538666708},
	keywords = {LoRa, QoS, Measurement, Spreading Factor},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/C8MLBBVC/LoRa QoS Performance Analysis on Various Spreading Factor in Indonesia (99).pdf:application/pdf},
}

@article{m._pervasive_2001,
	title = {Pervasive computing: vision and challenges},
	volume = {8.},
	number = {4},
	journal = {IEEE Personal Communications},
	author = {M., Satyanarayanan},
	year = {2001},
	pages = {10--7},
}

@article{m._computer_1991,
	title = {The computer for the 21st {Century}},
	volume = {Sept},
	journal = {Scientific American},
	author = {M., Weiser},
	year = {1991},
	pages = {94--104},
}

@article{van_bunningen_context_2005,
	title = {Context for ubiquitous data management},
	doi = {10.1109/UDM.2005.7},
	abstract = {In response to the advance of ubiquitous computing technologies, we believe that for computer systems to be ubiquitous, they must be context-aware. In this paper, we address the impact of context-awareness on ubiquitous data management. To do this, we overview different characteristics of context in order to develop a clear understanding of context, as well as its implications and requirements for context-aware data management. References to recent research activities and applicable techniques are also provided.},
	journal = {Proceedings of the International Workshop on Ubiquitous Data Management , UDM 2005},
	author = {Van Bunningen, Arthur H. and Feng, Ling and Apers, Feter M.G.},
	year = {2005},
	note = {ISBN: 0769524117},
	pages = {17--24},
}

@article{schilit_context-aware_1995,
	title = {Context-aware computing applications},
	abstract = {Describes systems that examine and react to an individual's{\textbackslash}nchanging context. Such systems can promote and mediate people's{\textbackslash}ninteractions with devices, computers and other people, and they can help{\textbackslash}nnavigate unfamiliar places. We believe that a limited amount of{\textbackslash}ninformation covering a person's proximate environment is most important{\textbackslash}nfor this form of computing, since the interesting part of the world{\textbackslash}naround us is what we can see, hear and touch. In this paper, we define{\textbackslash}ncontext-aware computing and describe four categories of context-aware{\textbackslash}napplications: proximate selection, automatic contextual reconfiguration,{\textbackslash}ncontextual information and commands, and content-triggered actions.{\textbackslash}nInstances of these application types have been prototyped on the{\textbackslash}nPARCTAB, a wireless palm-sized computer},
	journal = {Mobile Computing Systems and Applications - Workshop Proceedings},
	author = {Schilit, Bill and Adams, Norman and Want, Roy},
	year = {1995},
	pages = {85--90},
}

@article{henricksen_framework_2003,
	title = {A framework for context-aware pervasive computing applications},
	abstract = {À lire surtout pour son modèle de context et context attributes.},
	journal = {The School of Information Technology and Electrical Engineering, The University of Queensland},
	author = {Henricksen, Karen},
	year = {2003},
	pages = {13--20},
}

@article{perera_context_2014,
	title = {Context aware computing for the internet of things: {A} survey},
	volume = {16},
	issn = {1553877X},
	doi = {10.1109/SURV.2013.042313.00197},
	abstract = {As we are moving towards the Internet of Things (IoT), the number of sensors deployed around the world is growing at a rapid pace. Market research has shown a significant growth of sensor deployments over the past decade and has predicted a significant increment of the growth rate in the future. These sensors continuously generate enormous amounts of data. However, in order to add value to raw sensor data we need to understand it. Collection, modelling, reasoning, and distribution of context in relation to sensor data plays critical role in this challenge. Context-aware computing has proven to be successful in understanding sensor data. In this paper, we survey context awareness from an IoT perspective. We present the necessary background by introducing the IoT paradigm and context-aware fundamentals at the beginning. Then we provide an in-depth analysis of context life cycle. We evaluate a subset of projects (50) which represent the majority of research and commercial solutions proposed in the field of context-aware computing conducted over the last decade (2001-2011) based on our own taxonomy. Finally, based on our evaluation, we highlight the lessons to be learnt from the past and some possible directions for future research. The survey addresses a broad range of techniques, methods, models, functionalities, systems, applications, and middleware solutions related to context awareness and IoT. Our goal is not only to analyse, compare and consolidate past research work but also to appreciate their findings and discuss their applicability towards the IoT.},
	number = {1},
	journal = {IEEE Communications Surveys and Tutorials},
	author = {Perera, Charith and Zaslavsky, Arkady and Christen, Peter and Georgakopoulos, Dimitrios},
	year = {2014},
	keywords = {mobile, Internet of things, context awareness, context life cycle, context modelling, context reasoning, middleware, pervasive, sensor data, sensor networks, ubiquitous},
	pages = {414--454},
}

@article{abowd_towards_1999,
	title = {Towards a better understanding of context and context-awareness},
	volume = {1707},
	issn = {16113349},
	doi = {10.1007/3-540-48157-5_29},
	abstract = {In biology teaching, ecological subjects play an important role in dealing with nature in a responsible way. Empirical research has shown that, even after school instruction, students do not understand essential ecological concepts. The main reason is that preconceptions which influence learning are not taken into account in the construction of curricula. We combine findings from two independently-designed studies which have their main objectives in common. In both studies the focus is on students' conceptions of ecological terms and phenomena-ecosystem, and balance-and-change in nature. The studies were conducted within the framework of Educational Reconstruction, where three components of research are linked together: 'scientific clarification', 'comprehension of students' perspectives' and 'construction of instruction'. In order to capture the structure and quality of students' conceptions, qualitative methods were used. The results of both studies indicate that students tend to refer to more or less constant properties, in particular those which are visible in the everyday world. Processes are rarely their concern. Therefore the scientific conceptions of ecosystem, imbalance and the dynamics of biodiversity would be difficult for them to understand. For a better understanding, the dimensions of both space and time should be included in curricular design.},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Abowd, Gregory D. and Dey, Anind K. and Brown, Peter J. and Davies, Nigel and Smith, Mark and Steggles, Pete},
	year = {1999},
	note = {ISBN: 3540665501},
	pages = {304--307},
}

@article{alegre_engineering_2016,
	title = {Engineering context-aware systems and applications: {A} survey},
	volume = {117},
	issn = {01641212},
	doi = {10.1016/j.jss.2016.02.010},
	abstract = {Context-awareness is an essential component of systems developed in areas like Intelligent Environments, Pervasive \& Ubiquitous Computing and Ambient Intelligence. In these emerging fields, there is a need for computerized systems to have a higher understanding of the situations in which to provide services or functionalities, to adapt accordingly. The literature shows that researchers modify existing engineering methods in order to better fit the needs of context-aware computing. These efforts are typically disconnected from each other and generally focus on solving specific development issues. We encourage the creation of a more holistic and unified engineering process that is tailored for the demands of these systems. For this purpose, we study the state-of-the-art in the development of context-aware systems, focusing on: (A) Methodologies for developing context-aware systems, analyzing the reasons behind their lack of adoption and features that the community wish they can use; (B) Context-aware system engineering challenges and techniques applied during the most common development stages; (C) Context-aware systems conceptualization.},
	journal = {Journal of Systems and Software},
	author = {Alegre, Unai and Augusto, Juan Carlos and Clark, Tony},
	year = {2016},
	keywords = {Ambient Intelligence, Context-aware computing, Context-Aware Systems Engineering, Context-awareness, Context-sensitive, Intelligent Environments, Pervasive \& Ubiquitous Computing, Sentient computing, Software engineering},
	pages = {55--83},
}

@article{dey_understanding_1999,
	title = {Understanding and {Using} {Context}},
	journal = {Proceedings of the 1st international symposium on Handheld and Ubiquitous Computing},
	author = {Dey, Anind K. and Abowd, Gregory D.},
	year = {1999},
	pages = {304--307},
}

@article{dey_context_2000,
	title = {The context toolkit: {Aiding} the development of context-aware applications},
	journal = {Workshop on Software Engineering for wearable and pervasive computing},
	author = {Dey, Anind K and Abowd, Gregory D and {others}},
	year = {2000},
	pages = {431--441},
}

@article{erickson_problems_2002,
	title = {Some problems with the notion of context-aware computing},
	volume = {45},
	issn = {00010782},
	doi = {10.1145/503124.503154},
	abstract = {(From the book) the author's position is that the distinction between metaphorical and literal language does not have any psychological correlate in the underlying processes involved in their comprehension metaphor plays a crucial role in language acquisition in applying old words to new objects or situations, children engage in a kind of metaphorical extension from Rumelhart's perspective, metaphor is still immensely important, but its role in language is now viewed from a constructivist position (PsycINFO Database Record (c) 2003 APA},
	number = {2},
	journal = {Communications of the ACM},
	author = {Erickson, Thomas},
	year = {2002},
	pages = {102--104},
}

@article{zou_robust_2016,
	title = {A {Robust} {Indoor} {Positioning} {System} {Based} on the {Procrustes} {Analysis} and {Weighted} {Extreme} {Learning} {Machine}},
	volume = {15},
	issn = {15361276},
	url = {http://ieeexplore.ieee.org/document/7293674/},
	doi = {10.1109/TWC.2015.2487963},
	abstract = {? 2002-2012 IEEE.Indoor positioning system (IPS) has become one of the most attractive research fields due to the increasing demands on location-based services (LBSs) in indoor environments. Various IPSs have been developed under different circumstances, and most of them adopt the fingerprinting technique to mitigate pervasive indoor multipath effects. However, the performance of the fingerprinting technique severely suffers from device heterogeneity existing across commercial off-the-shelf mobile devices (e.g., smart phones, tablet computers, etc.) and indoor environmental changes (e.g., the number, distribution and activities of people, the placement of furniture, etc.). In this paper, we transform the received signal strength (RSS) to a standardized location fingerprint based on the Procrustes analysis, and introduce a similarity metric, termed signal tendency index (STI), for matching standardized fingerprints. An analysis of the capability of the proposed STI to handle device heterogeneity and environmental changes is presented. We further develop a robust and precise IPS by integrating the merits of both the STI and weighted extreme learning machine (WELM). Finally, extensive experiments are carried out and a performance comparison with existing solutions verifies the superiority of the proposed IPS in terms of robustness to device heterogeneity.},
	number = {2},
	urldate = {2019-09-21},
	journal = {IEEE Transactions on Wireless Communications},
	author = {Zou, Han and Huang, Baoqi and Lu, Xiaoxuan and Jiang, Hao and Xie, Lihua},
	month = feb,
	year = {2016},
	keywords = {Device Heterogeneity, Indoor Positioning System (IPS), Procrustes Analysis, Weighted Extreme Learning Machine},
	pages = {1252--1266},
}

@article{lam_smartmood:_2015,
	title = {{SmartMood}: {Toward} pervasive mood tracking and analysis for manic episode detection},
	volume = {45},
	issn = {21682291},
	url = {http://ieeexplore.ieee.org/document/6932469/},
	doi = {10.1109/THMS.2014.2360469},
	abstract = {This paper describes SmartMood, a mood tracking and analysis system designed for patients with mania. By analyzing the voice data captured from a smartphone while the user is having a conversation, statistics are generated for each behavioral factor to quantitatively describe his/her mood status. By comparing the newly generated statistics with those under normal mood, SmartMood tries to identify any new manic episodes so that appropriate consultation and medication actions can be taken. The daily behavioral statistics may serve as important references for psychiatrists to show the effectiveness of treatments. To reduce the probability of false alarms, we propose an adaptive running range method to estimate the normal mood range for each behavioral factor, and study methods to minimize the effects of background noise on the generated statistics. The preliminary experimental results on SmartMood show that a method using the pitch of a voice data sample to identify silent periods can better differentiate the voice of a normal or manic user in a call session than other methods. The results from the limited proof of concept testing indicate that moving to clinical testing is warranted.},
	number = {1},
	urldate = {2019-09-21},
	journal = {IEEE Transactions on Human-Machine Systems},
	author = {Lam, Kam Yiu and Wang, Jiantao and Ng, Joseph Kee Yin and Han, Song and Zheng, Limei and Kam, Calvin Ho Chuen and Zhu, Chun Jiang},
	month = feb,
	year = {2015},
	keywords = {Biomedicine, Mood disorder, Pervasive computing, Surveillance},
	pages = {126--131},
}

@article{rodda_behaviour_2018,
	title = {Behaviour change strategies for internet, pornography and gaming addiction: {A} taxonomy and content analysis of professional and consumer websites},
	volume = {84},
	issn = {07475632},
	url = {https://doi.org/10.1016/j.chb.2018.03.021},
	doi = {10.1016/j.chb.2018.03.021},
	abstract = {There is a growing body of literature on internet-related behaviours and their associated problems, including Internet Addiction (IA). Although evidence suggests most people self-treat, little is known about the type, or efficacy, of the methods they implement. The current study sought to identify and describe the change strategies used to limit or reduce IA (including internet gaming and internet pornography). The study explored the content of 79 websites containing behaviour change advice provided by experts and consumers. A total of 4459 change strategies were identified. Through pragmatic content analysis, they were classified into 19 categories and organised into four phases of goal achievement. Across the entire sample, the most frequently promoted or discussed change strategy was seeking alternatives to internet usage (20\% of total strategies), followed by maintaining readiness to change (10\%), and avoidance of triggers of internet usage (10\%). We found the frequency and content of 16 out of the 19 change strategies differs according to the type of internet problem (i.e., general, gaming, or pornography). This research provides detailed information for the development of tailored interventions. It indicates that interventions for IA could contain the same types of change strategies, but that the specific detail of strategies needs to be tailored towards the specific type of internet problem.},
	journal = {Computers in Human Behavior},
	author = {Rodda, Simone N. and Booth, Natalia and Vacaru, Michael and Knaebe, Brenna and Hodgins, David C.},
	year = {2018},
	note = {Publisher: Elsevier Ltd},
	keywords = {Change strategies, Internet addiction, Natural recovery, Rubikon, Self-help, Treatment},
	pages = {467--476},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/8X4R6CZ9/rodda2018.pdf:application/pdf},
}

@article{fargas_gps-free_2017,
	title = {{GPS}-free geolocation using {LoRa} in low-power {WANs}},
	doi = {10.1109/GIOTS.2017.8016251},
	abstract = {Internet of Things (IoT) has been growing over the last few years in multiple applications and due to a growing need for geolocation and tracking capabilities, an innovative opportunity arises. Whereas geolocation is traditionally based on GPS units this paper reports on a design and implementation of a LoRaWAN tracking system which is capable exploiting transmitted packages to calculate the current position without the use of GPS or GSM. This is done using the low power technology LoRa where the geolocation is calculated applying a multilateration algorithm on the gateways timestamps from received packages. The whole system consisted of an end-node, four gateways, a server and a java application to store the obtained data in a MySQL database.},
	journal = {GIoTS 2017 - Global Internet of Things Summit, Proceedings},
	author = {Fargas, Bernat Carbones and Petersen, Martin Nordal},
	year = {2017},
	note = {ISBN: 9781509058730},
	keywords = {IoT, LoRaWAN, geolocation, TDOA},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/L3WMZFDZ/fargas2017.pdf:application/pdf},
}

@article{gotthard_low-cost_2018,
	title = {Low-cost car park localization using {RSSI} in supervised {LoRa} mesh networks},
	doi = {10.1109/WPNC.2018.8555792},
	abstract = {In this paper, we present an RSSI-based localization solution that merely relies on the LoRa technology without requiring any anchors. It is primarily designed for large used car dealerships. Cars to be tracked are fitted with battery-powered tags that send each other plain LoRa messages and then report over LoRaWAN the observed RSSI to the server. The server estimates tag coordinates using multi-dimensional scaling and a novel corrective transformation based on tag clustering. We designed a low-cost tag for RSSI measurement and an energy efficient solution for managing a mesh of 1000 tags on one site using time division multiplexing. The tags are fully controlled and synchronized by the server. To stay synchronized for several hours until a next downlink the tags estimate and compensate the real-time clock error. Large-scale tests are yet to be performed, but lab-based and small-scale tests in real conditions show a maximal error of 8 meters and a battery lifetime of 5 years.{\textless}br/{\textgreater} \&copy; 2018 IEEE.},
	journal = {2018 15th Workshop on Positioning, Navigation and Communications, WPNC 2018},
	author = {Gotthard, Petr and Jankech, Tomas},
	year = {2018},
	note = {Publisher: IEEE
ISBN: 9781538664360},
	keywords = {LoRa, clustering, localization, mesh, multi-dimensional scaling, time-division multiplex},
	pages = {1--6},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/Q44LD7HQ/08555792(1).pdf:application/pdf},
}

@article{carrino_loraloc:_2019,
	title = {{LoRaLoc}: {Machine} {Learning}-{Based} {Fingerprinting} for {Outdoor} {Geolocation} using {LoRa}},
	doi = {10.1109/sds.2019.000-2},
	author = {Carrino, Francesco and Janka, Ales and Abou Khaled, Omar and Mugellini, Elena},
	year = {2019},
	note = {ISBN: 9781728131054},
	keywords = {geolocation, deep learning, learning},
	pages = {82--86},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/WP8ZJ2QV/08789861.pdf:application/pdf},
}

@article{he_enhanced_2019,
	title = {Enhanced {Gaussian} {Process}-{Based} {Localization} {Using} a {Low} {Power} {Wide} {Area} {Network}},
	volume = {23},
	issn = {15582558},
	doi = {10.1109/LCOMM.2018.2878704},
	abstract = {With the recent advances of technology innovation in the Internet-of-Things (IoT) era, radio chips are able to transmit over long distances with extremely low energy consumption. While extending the range of communication links, the ability to provide large scale location-based services (LBS) solutions using native physical layer parameters from IoT networks will dramatically widen the availability of IoT applications. This letter proposes an enhanced Gaussian process-based localization solution for such a low power wide area network (LPWAN). It effectively deals with intermittent signals over a large area caused by low communication throughput, interference or packet collisions in LPWAN. Furthermore, a parametric model enhancement combining indoor and outdoor hypotheses and signal propagation statistics is proposed and evaluated. Field tests over a 37,500 square meter area have been conducted. Results show that the proposed method can provide LBS-quality positioning with a 2-D root mean square error of 20 to 30 meters, with an accuracy improvement of 29.8\% outdoors and 40.6\% indoors, respectively, compared to the traditional fingerprinting method.{\textless}br/{\textgreater} \&copy; 2019 IEEE.},
	number = {1},
	journal = {IEEE Communications Letters},
	author = {He, Zhe and Li, You and Pei, Ling and O'Keefe, Kyle},
	year = {2019},
	note = {Publisher: IEEE},
	keywords = {Gaussian process, maximum likelihood estimation, multipath interference, navigation},
	pages = {164--167},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/KBXG8WTP/he2018.pdf:application/pdf},
}

@article{robyns_physical-layer_2017,
	title = {Physical-layer fingerprinting of {LoRa} devices using supervised and zero-shot learning},
	doi = {10.1145/3098243.3098267},
	abstract = {© 2017 Copyright held by the owner/author(s). Publication rights licensed to ACM. Physical-layer fingerprinting investigates how features extracted from radio signals can be used to uniquely identify devices. This paper proposes and analyses a novel methodology to ingerprint LoRa devices, which is inspired by recent advances in supervised machine learning and zero-shot image classification. Contrary to previous works, our methodology does not rely on localized and low-dimensional features, such as those extracted from the signal transient or preamble, but uses the entire signal. We have performed our experiments using 22 LoRa devices with 3 different chipsets. Our results show that identical chipsets can be distinguished with 59\% to 99\% accuracy per symbol, whereas chipsets from different vendors can be fingerprinted with 99\% to 100\% accuracy per symbol. The ingerprinting can be performed using only inexpensive commercial off-the-shelf software defined radios, and a low sample rate of 1 Msps. Finally, we release all datasets and code pertaining to these experiments to the public domain.},
	journal = {Proceedings of the 10th ACM Conference on Security and Privacy in Wireless and Mobile Networks, WiSec 2017},
	author = {Robyns, Pieter and Marin, Eduard and Lamotte, Wim and Quax, Peter and Singelee, Dave and Preneel, Bart},
	year = {2017},
	note = {ISBN: 9781450350846},
	keywords = {LoRa, Fingerprinting, Phy layer},
	pages = {58--63},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/YJE6P644/article-2765.pdf:application/pdf},
}

@article{baharudin_long-range_2017,
	title = {Long-range wireless sensor networks for geo-location tracking: {Design} and evaluation},
	doi = {10.1109/ELECSYM.2016.7860979},
	abstract = {© 2016 IEEE. Nowadays, a long-range data transmission is required in numerous Internet of Things (IoT) applications. This paper introduces a long-range Wireless Sensor Networks (WSN) for geo-location tracking of mobile objects as one of the applications. In the proposed system, the geo-location information of moving objects is collected and sent over wireless networks with a reconfigured GPS and LoRa (Long Range) modules. This work presents the design of long-range WSN system and the prototype implementation. We implement multiple sensor nodes deployment, which move away from a static base station called dock. Further, the reliability of geo-location data collection and the quality of wireless communication are evaluated. The results from RSSI test show a high reliability of LoRa module as a transceiver for our targeted long-range geo-location tracking application.},
	journal = {Proceedings - 2016 International Electronics Symposium, IES 2016},
	author = {Baharudin, Ahmad Muzaffar and Yan, Wanglin},
	year = {2017},
	note = {ISBN: 9781509016402},
	keywords = {Internet of Things (IoT), Geo-location Tracking, Long Range (LoRa), Mobile Objects, Wireless Sensor Networks (WSN)},
	pages = {76--80},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/FRXDF7AN/baharudin2016.pdf:application/pdf},
}

@article{plets_experimental_2018,
	title = {Experimental {Performance} {Evaluation} of {Outdoor} {TDoA} and {RSS} {Positioning} in a {Public} {LoRa} {Network}},
	doi = {10.1109/IPIN.2018.8533761},
	number = {September},
	journal = {IPIN 2018 - 9th International Conference on Indoor Positioning and Indoor Navigation},
	author = {Plets, D. and Podevijn, N. and Trogh, J. and Martens, L. and Joseph, W.},
	year = {2018},
	note = {Publisher: IEEE
ISBN: 9781538656358},
	pages = {1--8},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/PRE9J7SU/plets2018.pdf:application/pdf},
}

@article{ieee_machine_2012,
	title = {Machine {Learning} {Untuk} {Localization} {Dalam} {Gedung} {Berbasis} {Rss} {Fingerprint}},
	author = {Ieee, Menggunakan},
	year = {2012},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/T4HPR77K/Mike - MACHINE LEARNING UNTUK LOCALIZATION.pdf:application/pdf},
}

@article{lemic_regression-based_2019,
	title = {Regression-{Based} {Estimation} of {Individual} {Errors} in {Fingerprinting} {Localization}},
	volume = {7},
	issn = {21693536},
	doi = {10.1109/ACCESS.2019.2903880},
	abstract = {© 2013 IEEE. Practical location estimation is never ideal, and each location estimate is burdened with a certain level of error. In many use-case scenarios, knowing the magnitude of these errors can significantly improve the usability of the location estimates. The localization errors for different localization approaches are currently assessed using static performance benchmarks. These benchmarks typically provide aggregate metrics that statistically characterize the localization errors across the entire deployment environment. Due to the potentially dynamic nature and spatial heterogeneity of the environment, this characterization can be too generic to be really useful from the point of view of an individual location estimate. To address this issue for fingerprinting-based localization, we propose a regression-based procedure for estimating the individual (i.e., per-location estimate) localization errors. We use the received signal strength (RSS) values from various locations in an environment, as well as the observed localization errors in case the location estimates are generated using these RSS values, for training a number of contemporary regression models. Using the trained models, we are able to estimate the localization error of a location estimate at a new location using only RSS values collected at that location. Both by simulation and experimentally, we demonstrate the feasibility of the proposed procedure for Wi-Fi-based indoor and LoRa- and SigFox-based outdoor fingerprinting approaches. We do that by showing that the proposed procedure can, in the best-case scenario, yield more than 50\% more accurate estimation than the reference procedure based on the average localization errors derived from the static performance benchmarks.},
	journal = {IEEE Access},
	author = {Lemic, Filip and Handziski, Vlado and Aernouts, Michiel and Janssen, Thomas and Berkvens, Rafael and Wolisz, Adam and Famaey, Jeroen},
	year = {2019},
	note = {Publisher: IEEE},
	keywords = {LoRa, SigFox, fingerprinting, localization error estimation, localization error prediction, Location-quality estimation, regression, Wi-Fi},
	pages = {33652--33664},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/UTJ5NKYJ/08663281.pdf:application/pdf},
}

@article{lam_rssi-based_2019,
	title = {{RSSI}-based {LoRa} localization systems for large-scale indoor and outdoor environments},
	volume = {PP},
	issn = {0018-9545},
	doi = {10.1109/tvt.2019.2940272},
	number = {XX},
	journal = {IEEE Transactions on Vehicular Technology},
	author = {Lam, Ka-Ho and Cheung, Chi-Chung and Lee, Wah-Ching},
	year = {2019},
	note = {Publisher: IEEE},
	pages = {1--1},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/AXGEEY9S/08827665(1).pdf:application/pdf},
}

@article{yunus_aplikasi_2011,
	title = {Aplikasi sistem pendukung keputusan diagnosa penyakit paru- paru dengan metode forward chaining},
	volume = {2},
	abstract = {In Indonesian lung disease have a high death. Tubercolosis (TB) world report (2006) by World Health Organization (WHO), Indonesia still the third biggest after India and China with around 539.000 cases and around 101.000 peoples die for a year. Derived from those fact it need more attention from mass society. My research can be used to decision support system which used to lung disease diagnosed, and know what kind of disease from their symptom. Decision support system use production rule method for representating knowledge about the kind of lung disease and their symptom. This inference engine use tree method and forward chaining. Result derived from this research shown that tree method and forward chaining can be used in finding lung disease from their symptom.},
	number = {2},
	journal = {Aplikasi sistem pendukung keputusan diagnosa penyakit paru- paru dengan metode forward chaining},
	author = {Yunus, Mahmud and Setyowibowo, Sigit},
	year = {2011},
	keywords = {dapat menyebabkan kematian bila, forward chaining, lung, tidak segera, tree},
	pages = {95--114},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/9XZC9QK8/130-294-1-SM.pdf:application/pdf},
}

@article{zulkifli_sistem_nodate,
	title = {{SISTEM} {PAKAR} {DETEKSI} {DINI} {FAKTOR} {RISIKO} {PENYAKIT} {YANG} {DISEBABKAN} {OLEH} {PAPARAN} {ASAP} {ROKOK} {MENGGUNAKAN} {METODE} {CERTAINTY} {FACTOR}},
	author = {Zulkifli, Ridho Ilham and Komputer, Fakultas Ilmu},
	pages = {1--5},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/GAXAU346/14430.pdf:application/pdf},
}

@article{hidayat_sistem_2017,
	title = {Sistem {Pakar} {Diagnosis} {Penyakit} {Yang} {Disebabkan} {Oleh} {Rokok} {Dengan} {Metode} {Forward} {Chaining}},
	volume = {3},
	url = {http://jurnal.stmik-dci.ac.id/index.php/jutekin/article/download/179/140},
	abstract = {Rokok merupakan benda yang memiliki berbagai macam sumber penyakit apabila kita mengisapnya secara langsung atau menghirup asapnya. Di dalam sebatang rokok terdapat lebih dari 4000 bahan kimia, yang 200 di antaranya berbahaya bagi manusia, dan 40 di antaranya merupakan penyebab kanker. Merokok dapat mengakibatkan perubahan fungsi, struktur jaringan, dan saluran pernapasan pada paru-paru. Sistem pakar adalah sebuah sistem yang menggunakan pengetahuan manusia di mana pengetahuan tersebut dimasukkan ke dalam sebuah komputer dan kemudian digunakan untuk menyelesaikan masalah-masalah yang biasanya membutuhkan kepakaran atau keahlian manusia. Sistem yang digunakan dalam penulisah tugas akhir ini adalah sistem pakar untuk mendiagnosis penyakit yang disebabkan oleh rokok. Sistem ini dibuat dengan menggunakan metode forward chaining. Di dalam membangun sistem ini dibuat dengan metode pembangunana perangkat lunak Waterfall sebagai proses pengembangan perangkat lunak berurutan yang melewati fase perencanaan, pemodelan, implementasi, dan pengujian. Sistem ini dirancang dengan bahasa pemrograman PHP dan MySQL sebagai pengolah pangkalan data. Kata Kunci: sistem pakar, rokok, forward chaining I.},
	number = {1},
	journal = {Jutekin},
	author = {Hidayat, H. Akik and Gumilang, Gilang},
	year = {2017},
	keywords = {forward chaining, expert, faraidh science, inheritance, website applications},
	pages = {27--36},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/V3292YAY/179-428-2-PB.pdf:application/pdf},
}

@article{baidawi_sistem_2017,
	title = {Sistem {Pakar} {Diagnosis} {Penyakit} {Pada} {Perokok} {Dengan} {Metode} {Forward} {Chaining} {Berbasis} {Web}},
	volume = {19},
	issn = {2579-3500},
	url = {https://ejournal.bsi.ac.id/ejurnal/index.php/paradigma/article/view/1782},
	doi = {10.31294/P.V19I1.1782},
	abstract = {Abstract — Diabetes mellitus (DM) is a disease caused due to deficiency in production of insulin (a hormone produced by the pancreas and regulates glucose Tertiary) in the human body. Judging from the development of life now, not just adults who are stricken with diabetes mellitus but children can also get the disease due to irregular eating patterns and history of diabetes from parents. Lack of knowledge about the symptoms and how to deal with diabetes as well as the number of specialist diabetes mellitus is still limited and the reluctance of people to see a doctor is one ssebab increasing number of people affected by the disease . Keywords: Expert System, Diabetes Children Abstrak – Diabtes Melitus (DM) adalah penyakit yang ditimbulkan karena kekurangan produksi insulin (hormon yang diproduksi oleh pankreas dan mengatur tingakat glukosa) di dalam tubuh manusia. Dilihat dari perkembangan kehidupan sekarang, bukan hanya orang dewasa yang dapat terserang penyakit diabetes mellitus tetapi anak-anak juga dapat terserang penyakit tersebut dikarenakan pola makan yang tidak teratur serta riwayat penyakit diabetes dari orang tua. Pengetahuan yang kurang mengenai gejala dan cara menangani penyakit diabetes serta jumlah dokter spesialis diabetes mellitus yang masih terbatas dan keengganan masyarakat untuk memeriksakan diri ke dokter merupakan salah satu ssebab meningkatnya jumlah orang yang terkena penyakit tersebut.},
	number = {1},
	journal = {Paradigma - Jurnal Komputer dan Informatika},
	author = {Baidawi, Taufik and Nurjanah, Nurjanah},
	year = {2017},
	pages = {69--73},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/KRCSWMVW/NASKAH%20PUBLIKASI_L200130131.pdf:application/pdf},
}

@article{widati_efektivitas_2013,
	title = {Efektivitas pesan bahaya rokok pada bungkus rokok terhadap perilaku merokok masyarakat miskin},
	volume = {1},
	url = {http://download.portalgaruda.org/article.php?article=160499&val=1092&title=HAZARD MESSAGE EFFECTIVENESS OF CIGARETTE PACK TO THE CIGARETTE SMOKING POOR SOCIETY BEHAVIOR},
	abstract = {Abstrak: Kelompok keluarga miskin mempunyai prevalensi merokok lebih tinggi daripada kelompok pendapatan keluarga kaya. Dari 19 juta keluarga miskin di Indonesia 63\% kepala rumah tangganya adalah perokok. Jika sehari rata-rata 10 batang rokok dihisap maka mereka telah membelanjakan Rp 23 triliun pertahunnya untuk rokok (Sujai, 2009). Padahal pada bungkus rokok telah tertera pesan kesehatan: “Rokok dapat menyebabkan kanker, serangan jantung, impotensi, gangguan kehamilan dan janin.” Penelitian ini untuk mengetahui efektivitas pesan kesehatan pada bungkus rokok. Ini merupakan penelitian deskriptif dengan metode pengambilan data kuantitatif dan kualitatif dengan menggunakan kuesioner dan indept interview. Informan sebanyak 40 orang. Hasil penelitian menunjukkan 1) informan mengetahui bahaya rokok dari pesan di bungkus rokok. Walaupun mengetahui namun sebagian besar informan tidak bisa menyebutkan isi pesan kesehatan pada bungkus rokok secara lengkap dan benar. 2) Pesan bahaya rokok di bungkus rokok belum bisa menaikkan pengetahuan informan mengenai substansi rokok, bahaya rokok bagi diri sendiri, bahaya rokok bagi orang lain ataupun dampaknya bagi kesehatan. 3) Sebagian besar informan merasa biasa saja ketika membaca isi pesan kesehatan pada bungkus rokok. Hanya sebagian kecil yang merasa ngeri dan takut. Dapat disimpulkan bahwa pesan kesehatan pada bungkus rokok belum efektif meningkatkan pengetahuan dan pencegahan perilaku merokok para informan. Kata Kunci: rokok, sigaret, miskin, bungkus rokok PENDAHULUAN “Rokok dapat menyebabkan kanker, serangan jantung, impotensi, gangguan kehamilan dan janin.” Pesan ini tertera dalam setiap bungkus rokok yang ada di Indonesia. Setiap perokok, sebelum mengambil dari bungkus rokok dan menghisapnya akan membaca tulisan tersebut. Namun kenyataannya, prevalensi perokok di Indonesia tidaklah menurun melainkan terus membumbung. Sebanyak 4,8\% dari 1,3 miliar perokok dunia ada di Indonesia},
	number = {2},
	journal = {Jurnal Promkes},
	author = {Widati, Sri},
	year = {2013},
	keywords = {23 triliun, abstrak, batang rokok dihisap maka, cigarette, cigarrettes packaging, dari 19 juta keluarga, daripada kelompok, jika sehari rata-rata 10, kelompok keluarga miskin mempunyai, kepala rumah tangganya adalah, low income family, mereka telah membelanjakan rp, miskin di indonesia 63, pendapatan keluarga kaya, perokok, prevalensi merokok lebih tinggi, smoking},
	pages = {105--110},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/3CEVGWMW/jupromkes17f9558da7full.pdf:application/pdf},
}

@misc{noauthor_infografis:_nodate,
	title = {{INFOGRAFIS}: {Fakta} seputar konsumsi rokok dan tembakau di dunia},
	url = {https://www.rappler.com/indonesia/gaya-hidup/203786-infografis-fakta-seputar-konsumsi-rokok-dan-tembakau-di-dunia},
}

@article{tirtosastro_kandungan_2019,
	title = {Kandungan {Kimia} {Tembakau} dan {Rokok}},
	author = {Tirtosastro, Samsuri and Murdiyati, Dan A S and Penelitian, Balai and Tembakau, Tanaman and Serat, Dan and Raya, Jl and Km, Karangploso and Pos, Kotak},
	year = {2019},
	keywords = {cigarettes smoke, nicotine, tar, tobacco},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/ICLVJRK8/document.pdf:application/pdf},
}

@article{iryanto_optimasi_2017,
	title = {Optimasi {Pemilihan} {Barang} {Dagangan} bagi {Pedagang} {Keliling} dengan {Algoritma} {Genetika}},
	volume = {3},
	issn = {2477-3506},
	doi = {10.31884/jtt.v3i1.2},
	abstract = {Existence of constraints increases difficulty in choosing the right goods for a seller. Indeed, the seller wants to optimize the profit gained. Due to limitation of capital and maximum capacity, the seller needs a certain strategy to do the selection. Moreover the fact that each goods has its own probability to sell makes the problem becomes more complex. In this paper, the problem is solved using genetic algorithm. The result of simulation is in a good agreement with analytical solution. The simulation of N-goods selection is also given in the paper.},
	number = {1},
	journal = {JTT (Jurnal Teknologi Terapan)},
	author = {Iryanto, Iryanto and Ismantohadi, Eka},
	year = {2017},
	keywords = {genetic algorithm, knapsack problem, optimization of goods selection},
	pages = {24--28},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/4CWNWF53/669-1080-1-SM.pdf:application/pdf},
}

@misc{noauthor_menteri_nodate,
	title = {Menteri {Kesehatan}: {Sepertiga} {Penduduk} {Indonesia} {Perokok}},
	url = {https://nasional.tempo.co/read/875384/menteri-kesehatan-sepertiga-penduduk-indonesia-perokok/full&view=ok},
}

@book{negnevitsky_artificial_2002,
	title = {Artificial {Intelligence} - {A} {Guide} to {Intelligent} {Systems}},
	volume = {110},
	isbn = {0-321-20466-2},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/4462},
	abstract = {Two unusual cases of ruptured acute amebic liver abcess are presented one with inferior vena caval compression. Surgical drainage was followed by the development of colonic complications (haemorrhage and perforation) although the patients were under specific therapy. After a new surgical operation both cases were cured. The relation with amebiasis is discussed. The possibility of such an association must always be kept in mind. The value of immunofluorescence test in the diagnosis is emphasised.},
	author = {Negnevitsky, Michael},
	year = {2002},
	pmid = {4462},
	note = {Publication Title: Journal de chirurgie
Issue: 5
ISSN: 0021-7697},
}

@book{sheppard_genetic_2016,
	title = {Genetic {Algorithm} with {Python}},
	abstract = {This is a preview},
	author = {Sheppard, Clinton},
	year = {2016},
}

@article{hosseinzadeh_empirical_2017,
	title = {Empirical propagation performance evaluation of {LoRa} for indoor environment},
	doi = {10.1109/INDIN.2017.8104741},
	abstract = {Wireless sensors are increasingly being used for smart Buildings. LoRa is a chirp spread spectrum (CSS) technology. Its CSS modulation provides wide bandwidth, increased processing gain and higher receiver sensitivity. Propagation analysis of this long-range low power wireless platform is essential to make it a prevailing technology of choice for IoT. This paper empirically evaluates the indoor propagation performance of LoRa. The practical measurements were critically analyzed against four propagation models; ITU site generic, log-distance, multi-wall and 3D ray tracing. Data was collected in the Hanover building at Glasgow Caledonian University using the LoRa transceivers. The aims of this research were (1) to assess the indoor propagation performance of LoRa technology and (2) to identify the model that best describes the indoor propagation of LoRa. The study concluded that multi-wall has the best overall performance amongst the models. This research work will facilitate the link budget design, network implementation and coverage diagnosis in similar indoor scenarios.},
	journal = {Proceedings - 2017 IEEE 15th International Conference on Industrial Informatics, INDIN 2017},
	author = {Hosseinzadeh, Salaheddin and Larijani, Hadi and Curtis, Krystyna and Wixted, Andrew and Amini, Amin},
	year = {2017},
	note = {ISBN: 9781538608371},
	keywords = {LPWAN, 3D ray-tracing model, COST231 model, indoor propagation estimation, Internet of Things (loT), ITU model, log-distance model, LoRa propagation, Motley-Keenan model},
	pages = {26--31},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/H7B3QCV8/hosseinzadeh2017.pdf:application/pdf},
}

@article{ameloot_lora_2019,
	title = {{LoRa} {Indoor} {Performance}: {An} {Office} {Environment} {Case} {Study}},
	doi = {10.23919/ACESS.2018.8669294},
	abstract = {When deploying wireless sensor networks in smart buildings, low-power, long-range communication technologies such as LoRa may offer a reliable, low data-rate alternative to existing wireless technologies. For this contribution, custom-built LoRa nodes were used to measure LoRa propagation characteristics for both the 434 MHz and 868 MHz ISM-bands. These measurements show that the presence of people has a negative impact on the quality of the LoRa link and confirm the superiority of the 434 MHz band for indoor LoRa communication.},
	journal = {2018 International Applied Computational Electromagnetics Society Symposium in China, ACES-China 2018},
	author = {Ameloot, Thomas and Van Torre, Patrick and Rogier, Hendrik},
	year = {2019},
	note = {Publisher: ACES
ISBN: 9780996007849},
	pages = {1--2},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/5E6J8NFI/ameloot2018.pdf:application/pdf},
}

@phdthesis{santoso_aplikasi_nodate,
	title = {{APLIKASI} {TEKNIK} {FINGERPRINTING} {UNTUK} {PENENTUAN} {POSISI} {PADA} {RUANGAN} {TERTUTUP} {MENGGUNAKAN} {BLUETOOTH} {LOW} {ENERGY} ({BLE})},
	school = {Universitas Gadjah Mada},
	author = {Santoso, Budy},
}

@phdthesis{chairani_machine_2012,
	title = {Machine {Learning} {Untuk} {Localization} {Dalam} {Gedung} {Berbasis} {Rss} {Fingerprint}},
	school = {Universitas Gadjah Mada},
	author = {{CHAIRANI}},
	year = {2012},
}

@article{jati_cyberspace_2016,
	title = {Cyberspace, {Internet}, {Dan} {Ruang} {Publik} {Baru}: {Aktivisme} {Online} {Politik} {Kelas} {Menengah} {Indonesia}},
	volume = {3},
	issn = {2252-570X},
	doi = {10.22146/jps.v3i1.23524},
	abstract = {Artikel ini bertujuan untuk menganalisis mengenai cyberspace sebagai ruang publik baru bagi kelas menengah Indonesia. Konsep lama ruang publik besasal dari Habermas yang menilai ruang tersebut merupakan bagian dari proses komunikasi dan advokasi publik. Ruang tersebut dipahami sebagai ruang inklusif, deliberatif, dan juga parsipatif yang mendorong publik untuk berdiskusi satu sama lain. Kemunculan cyberspace melalui sosial media ini menarik untuk dicermati karena mampu mentrasnformasi ruang publik dalam bentuk digital. Dibandingkan dengan ruang publik, cyberspace berinteraksi kapanpun dan dimanapun. Dari situlah kemudian proses kesadaran politik kelas menengah kemudian tercipta. Artikel ini akan mengelaborasi lebih lanjut mengenai aktivisme politik onlone di Indonesia},
	number = {1},
	journal = {Jurnal Pemikiran Sosiologi},
	author = {Jati, Wasisto Raharjo},
	year = {2016},
	keywords = {indonesian middle class, online activism, political awareness},
	pages = {25},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/VE6Y5665/Wasisto Raharjo.pdf:application/pdf},
}

@article{sutrisno_penegakan_2019,
	title = {Penegakan {Hukum} {Terhadap} {Tindak} {Pidana} {Pencemaran} {Nama} {Baik} {Menurut} {Pasal} 27 {Ayat} (3) {Undang}-{Undang} {Nomor} 11 {Tahun} 2008 {Tentang} {Informasi} {Dan} {Transaksi} {Elektronik} ({Uu} {Ite})},
	volume = {8},
	issn = {2301-7295},
	doi = {10.32503/mizan.v8i1.495},
	abstract = {Penggunaan teknologi internet juga tidak dapat dipungkiri membawa dampak negatif yang tidak kalah banyak dengan manfaat positif yang ada. Internet dapat menimbulkan kejahatan seperti pengancaman, pencurian, pencemaran nama baik, pornografi, perjudian, penipuan hingga tindak pidana terorisme. Melalui media internet beberapa jenis tindak pidana tersebut dapat dilakukan secara online oleh individu maupun kelompok dengan resiko tertangkap yang sangat kecil dengan akibat kerugian yang lebih besar baik untuk masyarakat  maupun negara. Fenomena tindak pidana teknologi informasi merupakan bentuk kejahatan yang relatif baru apabila dibandingkan dengan bentuk-bentuk kejahatan lain yang sifatnya konvensional.  Hasil penelitian menunjukkan bahwa Modus operandi yang dilakukan oleh pelaku tindak pencemaran nama baik melalui media sosial, merupakan salah satu cerminan bahwa masyarakat Indonesia belum memahami makna penggunaan media sosial secara baik dan bertanggung jawab. Selain mempunyai hak kita juga harus mengetahui kewajiban apa saja yang harus kita laksanakan sebelum mendapatkan hak tersebut, sama halnya dengan menggunakan media sosial, penggunaan media sosial merupakan hak tiap-tiap masyarakat pada saat ini, namun sebagai penggunanya tentu kita juga harus mengetahui kewajiban untuk mengharagai orang lain. Banyaknya modus operandi yang digunaan oleh pelaku cyber crime, maka perlunya kehati-hatian dalam menggunakan media sosial agar kita tidak menjadi salah satu dari pelaku yang dapat merugikan orang banyak. Dalam Undang-Undang Nomor 11 Tahun 2008 tentang Informasi dan Transaksi Elektronik, tidak diatur secara jelas memahami batasan dalam kebebasan berpendapat. Jika kita melihat impelementasinya seakan-akan diatur, maka jelas bahwa kita benar-benar membutuhkan aturan yang baru tentang tindak pidana pencemaran nama baik dalam undang-undang Informasi dan Transaksi Elektronik. Bagi masyarakat harus lebih mehami arti kebebasan berpendapat yang diberikan oleh negara, dan menggunakan kebebasan tersebut dengan bertanggung jawab. Bukan untuk membatasi kebebasan tersebut melainkan untuk memberi peringatan atau tindakan Preventif bagi masyarakat agar lebih berhati-hati dalam menggunakan media sosial dalam berkomunikasi dan memberikan tindakan Represif bagi pelaku tindak pidana pencemaran nama baik melalui media sosial.},
	number = {1},
	journal = {MIZAN, Jurnal Ilmu Hukum},
	author = {Sutrisno, Bambang and Paksa, FX Bhirawa Braja},
	year = {2019},
	pages = {20},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/CM8S42PY/Bambang Sutrisno.pdf:application/pdf},
}

@article{raza_low_2017,
	title = {Low {Power} {Wide} {Area} {Networks}: {An} {Overview}},
	volume = {19},
	issn = {1553877X},
	doi = {10.1109/COMST.2017.2652320},
	abstract = {Low power wide area (LPWA) networks are attracting a lot of attention primarily because of their ability to offer affordable connectivity to the low-power devices distributed over very large geographical areas. In realizing the vision of the Internet of Things, LPWA technologies complement and sometimes supersede the conventional cellular and short range wireless technologies in performance for various emerging smart city and machine-to-machine applications. This review paper presents the design goals and the techniques, which different LPWA technologies exploit to offer wide-area coverage to low-power devices at the expense of low data rates. We survey several emerging LPWA technologies and the standardization activities carried out by different standards development organizations (e.g., IEEE, IETF, 3GPP, ETSI) as well as the industrial consortia built around individual LPWA technologies (e.g., LoRa Alliance, Weightless-SIG, and Dash7 alliance). We further note that LPWA technologies adopt similar approaches, thus sharing similar limitations and challenges. This paper expands on these research challenges and identifies potential directions to address them. While the proprietary LPWA technologies are already hitting the market with large nationwide roll-outs, this paper encourages an active engagement of the research community in solving problems that will shape the connectivity of tens of billions of devices in the next decade.},
	number = {2},
	journal = {IEEE Communications Surveys and Tutorials},
	author = {Raza, Usman and Kulkarni, Parag and Sooriyabandara, Mahesh},
	year = {2017},
	keywords = {IoT, Internet of Things, LPWAN, low power wide area, cellular, LPWA, machine-to-machine communication},
	pages = {855--873},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/KQAQEQKM/1606.07360.pdf:application/pdf},
}

@article{mekki_overview_2018,
	title = {Overview of {Cellular} {LPWAN} {Technologies} for {IoT} {Deployment}: {Sigfox}, {LoRaWAN}, and {NB}-{IoT}},
	doi = {10.1109/PERCOMW.2018.8480255},
	abstract = {LPWAN are actually the most popular low cost, long battery lifetime, and long range communication technology for IoT applications. This paper presents a comprehensive and comparative study on three actually leading LPWAN technologies called Sigfox, LoRaWAN, and NB-IoT. We show that Sigfox and LoRaWAN excel on network capacity, devices lifetime, and cost. Whereas, NB-IoT excels on quality of service and latency. In addition, we consider application scenarios and explain which technology fits best to guide future researchers and industrials.},
	journal = {2018 IEEE International Conference on Pervasive Computing and Communications Workshops, PerCom Workshops 2018},
	author = {Mekki, Kais and Bajic, Eddy and Chaxel, Frederic and Meyer, Fernand},
	year = {2018},
	note = {ISBN: 9781538632277},
	keywords = {Internet of Things, LoRaWAN, Sigfox, NB-IoT, Low Power Wide Area Networks},
	pages = {197--202},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/XIEYV8CV/mekki2018.pdf:application/pdf},
}

@article{chen_narrow_2017,
	title = {Narrow {Band} {Internet} of {Things}},
	volume = {5},
	issn = {21693536},
	doi = {10.1109/ACCESS.2017.2751586},
	abstract = {In this paper, we review the background and state-of-the-art of the narrow-band Internet of Things (NB-IoT). We first introduce NB-IoT general background, development history, and standardization. Then, we present NB-IoT features through the review of current national and international studies on NB-IoT technology, where we focus on basic theories and key technologies, i.e., connection count analysis theory, delay analysis theory, coverage enhancement mechanism, ultra-low power consumption technology, and coupling relationship between signaling and data. Subsequently, we compare several performances of NB-IoT and other wireless and mobile communication technologies in aspects of latency, security, availability, data transmission rate, energy consumption, spectral efficiency, and coverage area. Moreover, we analyze five intelligent applications of NB-IoT, including smart cities, smart buildings, intelligent environment monitoring, intelligent user services, and smart metering. Finally, we summarize security requirements of NB-IoT, which need to be solved urgently. These discussions aim to provide a comprehensive overview of NB-IoT, which can help readers to understand clearly the scientific problems and future research directions of NB-IoT.},
	journal = {IEEE Access},
	author = {Chen, Min and Miao, Yiming and Hao, Yixue and Hwang, Kai},
	year = {2017},
	keywords = {Internet of Things, LPWAN, NB-IoT, Intelligent application, LTE},
	pages = {20557--20577},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/RYNH4AWX/08038776.pdf:application/pdf},
}

@article{singh_using_2018,
	title = {Using data mining tools for breast cancer prediction and analysis},
	doi = {10.1109/CCAA.2018.8777713},
	abstract = {Breast Cancer is one of the most common disease that is responsible for high number of women's deaths every year. Despite the fact that cancer is treatable and healable in earliest stages, the huge number of patients are examined with cancer very late. Data mining process and classification are an efficient way to categorise the data particularly in medical fields, where those approaches are broadly used in diagnosis to make decision. This paper presents a performance comparison among the classifiers: Decision tree classifier (J4.8, Simple CART), Bayes classifier (NaiveBayes, Bayesian LogisticRegression). The Wisconsin Breast Cancer(original) dataset is used here and is taken from UCI Machine learning Repository. The main goal is to classify data of both the algorithms in terms of accuracy. Our experimental result shows that among all the classifiers, decision tree classifier i.e. Simple CART (98.13\%) gives higher accuracy.},
	journal = {2018 4th International Conference on Computing Communication and Automation, ICCCA 2018},
	author = {Singh, S. N. and Thakral, Shivani},
	year = {2018},
	note = {Publisher: IEEE
ISBN: 9781538669471},
	keywords = {Bayesian Logistic Regression, Breast Cancer, Data mining, J48, Naive Bayes, Simple CART, Wisconsin breast cancer(WBCO)},
	pages = {1--4},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/8DE689PA/08777713.pdf:application/pdf},
}

@article{amrane_breast_2018,
	title = {Breast cancer classification using machine learning},
	doi = {10.1109/EBBT.2018.8391453},
	abstract = {During their life, among 8\% of women are diagnosed with Breast cancer (BC), after lung cancer, BC is the second popular cause of death in both developed and undeveloped worlds. BC is characterized by the mutation of genes, constant pain, changes in the size, color(redness), skin texture of breasts. Classification of breast cancer leads pathologists to find a systematic and objective prognostic, generally the most frequent classification is binary (benign cancer/malign cancer). Today, Machine Learning (ML) techniques are being broadly used in the breast cancer classification problem. They provide high classification accuracy and effective diagnostic capabilities. In this paper, we present two different classifiers: Naive Bayes (NB) classifier and knearest neighbor (KNN) for breast cancer classification. We propose a comparison between the two new implementations and evaluate their accuracy using cross validation. Results show that KNN gives the highest accuracy (97.51\%) with lowest error rate then NB classifier (96.19 \%).},
	journal = {2018 Electric Electronics, Computer Science, Biomedical Engineerings' Meeting, EBBT 2018},
	author = {Amrane, Meriem and Oukid, Saliha and Gagaoua, Ikram and Ensari, Tolga},
	year = {2018},
	note = {Publisher: IEEE
ISBN: 9781538651353},
	keywords = {Bayesian classifier component, Breast cancer classification, K-nearest neibhor},
	pages = {1--4},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/9XZGNJ5A/08391453.pdf:application/pdf},
}

@article{chauhan_breast_2018,
	title = {Breast {Cancer} {Prediction} {Using} {Genetic} {Algorithm} {Based} {Ensemble} {Approach}},
	doi = {10.1109/ICCCNT.2018.8493927},
	abstract = {Breast cancer prediction is an open area of research. Breast cancer is a classification problem which can be solved by machine learning models like a decision tree, random forest, support vector machine, and many more models. Each machine learning model has its own merits and demerits. In breast cancer prediction we need to improve the accuracy of models, so we use here ensemble method which combines predictions of multiple models. An ensemble is a method to increase the prediction accuracy of breast cancer. In this study, a new technique is introduced to GA based weighted average ensemble method of classification dataset which overcame the limitations of the classical weighted average method. Genetic algorithm based weighted average method is used for the prediction of multiple models. The comparison between Particle swarm optimization(PSO), Differential evolution(DE) and Genetic algorithm(GA) and it is concluded that the genetic algorithm outperforms for weighted average methods. One more comparison between classical ensemble method and GA based weighted average method and it is concluded that GA based weighted average method outperforms.},
	journal = {2018 9th International Conference on Computing, Communication and Networking Technologies, ICCCNT 2018},
	author = {Chauhan, Pragya and Swami, Amit},
	year = {2018},
	note = {Publisher: IEEE
ISBN: 9781538644300},
	keywords = {Classification, Ensemble, Genetic Algorithm, Machine Learning, Weighted Average},
	pages = {1--8},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/HU8DNMWF/08493927.pdf:application/pdf},
}

@article{rawan_real_2019,
	title = {Real time data analysis and visualization for the breast cancer disease},
	volume = {7},
	issn = {23034521},
	doi = {10.21533/pen.v7i1.421},
	abstract = {Today, the amount of data that are digitally collected in the healthcare sector is tremendous and expanding rapidly, these data are inherently geospatial and temporal ranging from individual families to whole states and from minutes to decades. Therefore, they need sophisticated data management and analysis to be transformed into valuable knowledge. Healthcare professionals are faced with several challenges regarding extracting knowledge from this massive amount of data in order to support the decision-making process. To gain advantage of health care big data, big data analytics need to be exploited to utilize and understand patterns associations within these data thus make the right decision. In this research, an interactive data analysis and visualization tool is proposed to visually compare the performance of three machine learning algorithms on Wisconsin Diagnostic Breast Cancer (WDBC) dataset. The proposed model consists of two phases: input phase and analysis/visualization phase. It aims to allow the user to interactively compare the performance of three different ML algorithms (KNN, SVM and NB) in terms of accuracy, sensitivity and error rate in a user-friendly way. Here, SVM classifier has proven its efficiency and it is concluded as the best classifier with the highest accuracy as compared to the other two classifiers.},
	number = {1},
	journal = {Periodicals of Engineering and Natural Sciences},
	author = {Rawan, Sanyour and Manal, Abdullah},
	year = {2019},
	keywords = {Classification, Breast cancer prediction, Data visualization, Interactive data visualization, Shiny app},
	pages = {395--407},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/V5B29UGS/421-1180-2-PB.pdf:application/pdf},
}

@article{bayrak_comparison_2019,
	title = {Comparison of machine learning methods for breast cancer diagnosis},
	doi = {10.1109/EBBT.2019.8741990},
	abstract = {Cancer is the common problem for all people in the world with all types. Particularly, Breast Cancer is the most frequent disease as a cancer type for women. Therefore, any development for diagnosis and prediction of cancer disease is capital important for a healthy life. Machine learning techniques can make a huge contribute on the process of early diagnosis and prediction of cancer. In this paper, two of the most popular machine learning techniques have been used for classification of Wisconsin Breast Cancer (Original) dataset and the classification performance of these techniques have been compared with each other using the values of accuracy, precision, recall and ROC Area. The best performance has been obtained by Support Vector Machine technique with the highest accuracy.},
	journal = {2019 Scientific Meeting on Electrical-Electronics and Biomedical Engineering and Computer Science, EBBT 2019},
	author = {Bayrak, Ebru Aydindag and Kirci, Pinar and Ensari, Tolga},
	year = {2019},
	note = {ISBN: 9781728110134},
	keywords = {Classification, Breast cancer, Early diagnosis, Machine learning},
	pages = {4--6},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/IUXDMWG6/08741990.pdf:application/pdf},
}

@article{chandrashekar_survey_2014,
	title = {A survey on feature selection methods},
	volume = {40},
	issn = {00457906},
	url = {http://dx.doi.org/10.1016/j.compeleceng.2013.11.024},
	doi = {10.1016/j.compeleceng.2013.11.024},
	abstract = {Plenty of feature selection methods are available in literature due to the availability of data with hundreds of variables leading to data with very high dimension. Feature selection methods provides us a way of reducing computation time, improving prediction performance, and a better understanding of the data in machine learning or pattern recognition applications. In this paper we provide an overview of some of the methods present in literature. The objective is to provide a generic introduction to variable elimination which can be applied to a wide array of machine learning problems. We focus on Filter, Wrapper and Embedded methods. We also apply some of the feature selection techniques on standard datasets to demonstrate the applicability of feature selection techniques. © 2013 Elsevier Ltd. All rights reserved.},
	number = {1},
	journal = {Computers and Electrical Engineering},
	author = {Chandrashekar, Girish and Sahin, Ferat},
	year = {2014},
	note = {Publisher: Elsevier Ltd},
	pages = {16--28},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/NDYKLUQ7/1-s2.0-S0045790613003066-main.pdf:application/pdf},
}

@article{derisma_optimization_2019,
	title = {Optimization of {Neural} {Network} with {Genetic} {Algorithm} for {Breast} {Cancer} {Classification}},
	doi = {10.1109/ICITSI.2018.8696014},
	abstract = {Proper diagnosis of breast cancer is one of the main issues in a medical sector. The neural network could overcome the issue, but weak in determining parameter value, therefore it requires optimization. A genetic algorithm is one of the optimization methods, due to that matter, attribute parameter value of neural network will be optimized by using Genetic Algorithm to acquire the best predictor attributes. Genetic-based Neural Network algorithm has higher accuracy compared to the application of Neural Network algorithm alone. This notion is proven through the increasing rate of accuracy value for Neural Network algorithm which amounted to 96.57 \% and 97.24 \% for Genetic-Based Neural Network Algorithm as well as the decreasing rate of error classification of Neural Network algorithm model from 3.43 \% rate to 2.86 \% due to the application of Genetic-Based Neural Network Algorithm. Therefore, it can be concluded that the application of the optimization technique of Genetic Algorithm can enhance the accuracy value and decrease the error value of the Neural Network algorithm on breast cancer classification.},
	journal = {2018 International Conference on Information Technology Systems and Innovation, ICITSI 2018 - Proceedings},
	author = {{Derisma} and Silvana, Meza and {Imelda}},
	year = {2019},
	note = {Publisher: IEEE
ISBN: 9781538656938},
	keywords = {Genetic Algorithm, Breast cancer, Neural network},
	pages = {398--403},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/GY6LND47/08696014.pdf:application/pdf},
}

@article{asri_using_2016,
	title = {Using {Machine} {Learning} {Algorithms} for {Breast} {Cancer} {Risk} {Prediction} and {Diagnosis}},
	volume = {83},
	issn = {18770509},
	url = {http://dx.doi.org/10.1016/j.procs.2016.04.224},
	doi = {10.1016/j.procs.2016.04.224},
	abstract = {Breast cancer represents one of the diseases that make a high number of deaths every year. It is the most common type of all cancers and the main cause of women's deaths worldwide. Classification and data mining methods are an effective way to classify data. Especially in medical field, where those methods are widely used in diagnosis and analysis to make decisions. In this paper, a performance comparison between different machine learning algorithms: Support Vector Machine (SVM), Decision Tree (C4.5), Naive Bayes (NB) and k Nearest Neighbors (k-NN) on the Wisconsin Breast Cancer (original) datasets is conducted. The main objective is to assess the correctness in classifying data with respect to efficiency and effectiveness of each algorithm in terms of accuracy, precision, sensitivity and specificity. Experimental results show that SVM gives the highest accuracy (97.13\%) with lowest error rate. All experiments are executed within a simulation environment and conducted in WEKA data mining tool.},
	number = {Fams},
	journal = {Procedia Computer Science},
	author = {Asri, Hiba and Mousannif, Hajar and Al Moatassime, Hassan and Noel, Thomas},
	year = {2016},
	note = {Publisher: Elsevier Masson SAS
ISBN: 9781538684870},
	keywords = {Classification, Breast cancer, C4.5, Effectiveness, Efficiency, k-NN, NB, SVM},
	pages = {1064--1069},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/79U2B3BB/1-s2.0-S1877050916302575-main.pdf:application/pdf},
}

@article{abdar_cwv-bann-svm_2019,
	title = {{CWV}-{BANN}-{SVM} ensemble learning classifier for an accurate diagnosis of breast cancer},
	volume = {146},
	issn = {02632241},
	url = {https://doi.org/10.1016/j.measurement.2019.05.022},
	doi = {10.1016/j.measurement.2019.05.022},
	abstract = {This paper presents a new data mining technique for an accurate prediction of breast cancer (BC), which is one of the major mortality causes among women around the globe. The main objective of our study is to expand an automatic expert system (ES) to provide an accurate diagnosis of BC. Both, Support Vector Machines (SVMs) and Artificial Neural Networks (ANNs) were applied to analyze BC data. The well-known Wisconsin Breast Cancer Dataset (WBCD), available in the UCI repository, was examined in our study. We first tested the SVM algorithm using various values of the C, ɛ and γ parameters. As a result of the first experiment, we were able to observe that the adjustment of these regularization parameters can greatly improve the performance of the traditional SVM algorithm applied for BC detection. The highest obtained accuracy at the first step was 99.71\%. Then, we performed a new BC detection approach based on two ensemble learning techniques: the confidence-weighted voting method and the boosting ensemble technique. Our model, called CWV-BANNSVM, combines boosting ANNs (BANN) and two SVMs, using optimal parameters selected during the first experiment. The performance of the applied methods was evaluated using several popular metrics, such as specificity, sensitivity, precision, FPR, FNR, F1 score, AUC, Gini and accuracy. The proposed CWV-BANNSVM model was able to improve the performance of the traditional machine learning algorithms applied to BC detection, reaching the accuracy of 100\%. To overcome the overfitting issue, we determined and used some appropriate parameter values of polynomial SVM. Our comparison with the existing studies dedicated to BC prediction suggests that the proposed CWV-BANN-SVM model provides one of the best prediction performances overall.},
	journal = {Measurement: Journal of the International Measurement Confederation},
	author = {Abdar, Moloud and Makarenkov, Vladimir},
	year = {2019},
	note = {Publisher: Elsevier Ltd},
	keywords = {Data mining, Breast cancer, Machine learning, Artificial neural network, Ensemble technique, Support vector machine},
	pages = {557--570},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/XK54EIFL/1-s2.0-S0263224119304385-main.pdf:application/pdf},
}

@article{cai_breast_2018,
	title = {Breast {Cancer} {Diagnosis} {Using} {Imbalanced} {Learning} and {Ensemble} {Method}},
	volume = {7},
	issn = {2328-5605},
	doi = {10.11648/j.acm.20180703.20},
	abstract = {Worldwide, breast cancer is one of the most threatening killers to mid-aged women. The diagnosis of breast cancer aims to classify spotted breast tumor to be Benign or Malignant. With recent developments in data mining technique, new model structures and algorithms are helping medical workers greatly in improving classification accuracy. In this study, a model is proposed combining ensemble method and imbalanced learning technique for the classification of breast cancer data. First, Synthetic Minority Over-Sampling Technique (SMOTE), an imbalanced learning algorithm is applied to selected datasets and second, multiple baseline classifiers are tuned by Bayesian Optimization. Finally, a stacking ensemble method combines the optimized classifiers for final decision. Comparative analysis shows the proposed model can achieve better performance and adaptivity than conventional methods, in terms of classification accuracy, specificity and AuROC on two mostly-used breast cancer datasets, validating the clinical value of this model.},
	number = {3},
	journal = {Applied and Computational Mathematics},
	author = {Cai, Tongan},
	year = {2018},
	keywords = {breast cancer, data mining, ensemble method, imbalanced learning},
	pages = {146},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/9KKNZQHF/T_CAI_Breast_Cancer.pdf:application/pdf},
}

@article{nilashi_knowledge-based_2017,
	title = {A knowledge-based system for breast cancer classification using fuzzy logic method},
	volume = {34},
	issn = {07365853},
	url = {http://dx.doi.org/10.1016/j.tele.2017.01.007},
	doi = {10.1016/j.tele.2017.01.007},
	abstract = {Breast cancer has become a common disease around the world. Expert systems are valuable tools that have been successful for the disease diagnosis. In this research, we accordingly develop a new knowledge-based system for classification of breast cancer disease using clustering, noise removal, and classification techniques. Expectation Maximization (EM) is used as a clustering method to cluster the data in similar groups. We then use Classification and Regression Trees (CART) to generate the fuzzy rules to be used for the classification of breast cancer disease in the knowledge-based system of fuzzy rule-based reasoning method. To overcome the multi-collinearity issue, we incorporate Principal Component Analysis (PCA) in the proposed knowledge-based system. Experimental results on Wisconsin Diagnostic Breast Cancer and Mammographic mass datasets show that proposed methods remarkably improves the prediction accuracy of breast cancer. The proposed knowledge-based system can be used as a clinical decision support system to assist medical practitioners in the healthcare practice.},
	number = {4},
	journal = {Telematics and Informatics},
	author = {Nilashi, Mehrbakhsh and Ibrahim, Othman and Ahmadi, Hossein and Shahmoradi, Leila},
	year = {2017},
	note = {Publisher: Elsevier Ltd},
	keywords = {Classification, Breast cancer, CART, Fuzzy logic, Mammographic mass, Wisconsin Diagnostic Breast Cancer},
	pages = {133--144},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/MJHMYU8N/1-s2.0-S0736585316306542-main.pdf:application/pdf},
}

@article{purwaningsih_application_2019,
	title = {Application of the {Support} {Vector} {Machine} and {Neural} {Network} {Model} {Based} on {Particle} {Swarm} {Optimization} for {Breast} {Cancer} {Prediction}},
	volume = {4},
	issn = {2541-044X},
	doi = {10.33395/sinkron.v4i1.10195},
	abstract = {There are several studies in the medical field that classify data to diagnose and analyze decisions. To predict breast cancer, this study compares two methods, the Support Vector Machine method and the Neural Network method based on Particle Swarm Optimization (PSO) which is intended to determine the highest accuracy value in the Coimbra dataset data. To implement the Support Vector Machine and Neural Network method based on PSO, RapidMiner software is used. Then the application results are compared using Confusion Matrix and ROC Curve. Based on the accuracy of the two models, it is known that the PSO-based Neural Network model has a higher accuracy value of 84.55\% than the results of the PSO-based Vector Support Machine with an accuracy value of 80.08\%. The calculation results, the accuracy of the AUC performance obtained by the results of the study are, the two methods are PSO-based Neural Network with AUC value of 0.885 and PSO-based Support Vector Machine with a value of 0.819 included in the category of Good Classification.},
	number = {1},
	journal = {SinkrOn},
	author = {Purwaningsih, Esty},
	year = {2019},
	keywords = {optimization, breast cancer, neural network, particle swarm, rapid miner, support vector machine},
	pages = {66},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/BKC9ERTL/document(4).pdf:application/pdf},
}

@article{nallamala_breast_2019,
	title = {Breast cancer detection using machine learning way},
	volume = {8},
	issn = {22773878},
	doi = {10.35940/ijrte.B1260.0782S319},
	abstract = {Affording in the direction of Breast Cancer Organization, Breast Cancer is solitary and one and only of the most perilous sorts of viruses that is located operative for females in the biosphere. By way of experimental professional distinguishing this cancer in her initial phase aids in abiding breathes. Based on cancer.net proposal individualized funnels for additional 120 kinds of cancer and correlated to genetic diseases. Aimed At discovering breast cancer fundamentally AI rehearses are utilized. We have foreseen adaptive ensemble voting scheme for broke down breast cancer with WBC (Wisconsin Breast Cancer) record. Intention of our effort is to associate \& describe in what way CNN and logistic algorithm afford used for detecting breast cancer yet the variables are condensed. Here remain 2 categories of tumours be situated. Benign tumour and malignant tumours, where benign tumour is non-cancer and malignant is cancer tumour.},
	number = {2 Special Issue 3},
	journal = {International Journal of Recent Technology and Engineering},
	author = {Nallamala, Sri Hari and Mishra, Pragnyaban and Koneru, Suvarna Vani},
	year = {2019},
	note = {Publisher: IEEE
ISBN: 9781538677094},
	keywords = {Data mining, Breast cancer, Machine learning, Fuzzy networks, Neural networks, WBCD},
	pages = {1402--1405},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/WVTQYM34/08769187.pdf:application/pdf},
}

@article{gbenga_performance_2017,
	title = {Performance {Comparison} of {Machine} {Learning} {Techniques} for {Breast} {Cancer} {Detection}},
	volume = {6},
	url = {www.novaexplore.com},
	doi = {10.20286/nova-jeas-060105},
	abstract = {è},
	number = {1},
	journal = {Nova Journal of Engineering and Applied Sciences},
	author = {Gbenga, Dada Emmanuel and Christopher, Ngene and Yetunde, Daramola Comfort},
	year = {2017},
	keywords = {breast cancer, adaboost, j48, knn, nb, rbf, svm},
	pages = {1--8},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/XRQK5PTI/Performance_Comparison_of_Machine_Learni.pdf:application/pdf},
}

@article{kumar_machine_2019,
	title = {Machine {Learning} {Based} {Approaches} for {Cancer} {Prediction}: {A} {Survey}},
	doi = {10.2139/ssrn.3350294},
	journal = {SSRN Electronic Journal},
	author = {Kumar, Ajay and Sushil, Rama and Tiwari, Arvind Kumar},
	year = {2019},
	keywords = {machine learning, knn, nb, svm, ann, cancer},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/8GYSLPAA/SSRN-id3350294.pdf:application/pdf},
}

@article{sinha_optimized_2019,
	title = {An {Optimized} {Model} for {Breast} {Cancer} {Prediction} {Using} {Frequent} {Itemsets} {Mining}},
	doi = {10.5815/ijieeb.2019.05.02},
	number = {September},
	author = {Sinha, Ankita},
	year = {2019},
	pages = {11--18},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/NGCWWXPC/out.pdf:application/pdf},
}

@article{liu_comparison_2019,
	title = {Comparison of {Machine} {Learning} {Classifiers} for {Breast} {Cancer} {Diagnosis} {Based} on {Feature} {Selection}},
	doi = {10.1109/SMC.2018.00743},
	abstract = {The diagnosis of breast cancer in the middle and early period is conducive to later treatment, but the current diagnosis rate is not very desirable. Using machine learning to predict the benign and malignant of breast cancer can provide some assist to doctors' treatment in clinical practice. In this paper, we have collected data from digitized images of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei presented in the image. This work adopts several feature selection methods to select the most related features for breast cancer diagnosis. Based on the selected features, four machine learning models, Support Vector Machine (SVM), Decision Tree (DT), AdaBoost and Random Forest (RF) are built and their performance are evaluated. The experimental results show that the accuracy of RF is higher than the other three methods.},
	journal = {Proceedings - 2018 IEEE International Conference on Systems, Man, and Cybernetics, SMC 2018},
	author = {Liu, Bo and Li, Xingrui and Li, Jianqiang and Li, Yong and Lang, Jianlei and Gu, Rentao and Wang, Fei},
	year = {2019},
	note = {ISBN: 9781538666500},
	keywords = {Classification, breast cancer, feature selection, prediction model},
	pages = {4399--4404},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/5D55MJSB/08616740.pdf:application/pdf},
}

@article{hesser_ipads_2013,
	title = {{iPads} in the {Science} {Laboratory} : {Experience} in {Designing} and {Implementing} a {Paperless} {Chemistry} {Laboratory} {Course}},
	volume = {14},
	issn = {1557-5284},
	abstract = {In the Fall of 2012, twenty General Chemistry Honors students at the\_\_\_\_\_\_\_\_\_were issued the new iPad 3 to incorporate the devices both in the classroom and the laboratory.   This paper will focus on the integration of the iPad into the laboratory curriculum  while creating a paperless experience, an environment where no paper would enter or be used for the laboratory over the course of the year. Specific apps were chosen that would allow for an easy transition of course materials into an electronic format.  After a transition period for the students and instructor, the overall experience has been a positive one and can easily be implemented into any teaching laboratory.},
	number = {2},
	journal = {Journal of STEM Education},
	author = {Hesser, Tiffany L and Schwartz, Pauline M},
	year = {2013},
	pmid = {89166355},
	note = {ISBN: 15575276},
	pages = {5--9},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/26WB892B/iPads in the Science Laboratory_ Experience in Designing and Impl(1).pdf:application/pdf},
}

@article{fei_wang_creating_2009,
	title = {Creating a paperless classroom with the best of two worlds},
	volume = {2},
	issn = {1941-3394},
	abstract = {The information age has presented unprecedented opportunities for educators to digitize traditional classrooms, an evolution that can empower instructors to extend the channels of knowledge dissemination and unleash the learning power of students from the manacles of physical classrooms. Since the early adoption of the Internet technology by educational institutions, various studies have been done to explore the conceptualization of the paperless classroom, focusing on its theoretical framework and impact on traditional learning environment. This paper aims to present a hands-on developmental framework that brings together the best of two worlds - online academic course management and industry-class collaboration into a state-of-the-art paperless classroom.},
	journal = {Journal of Instructional Pedagogies},
	author = {Fei Wang, Jeremy},
	year = {2009},
	note = {ISBN: 1941-3394},
	keywords = {creating a paperless, domino web access, e-learning, page, paperless classroom, virtual classroom, webct},
	pages = {1 -- 22},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/H4JQLUM2/m-api-06ce1469-2d47-3fe5-5b38-7a0e5c45a438.pdf:application/pdf},
}

@article{isaeva_paperless_2016,
	title = {Paperless university -{How} we can make it work?},
	doi = {10.1109/ITHET.2016.7760717},
	abstract = {At present time all administration processes in many universities of Uzbekistan are mainly paper based. It requires the usage of huge amount of paper, leads information lose and overlapping, creates bureaucracy barriers for students and teachers. One of examples is the administration system of Tashkent University of IT (TUIT): all documents starting from admission until graduation process are mainly paper based. The digitalization of documents is easy, but how to go further? How to control the volume of e-documents, how to properly share it with colleges? How we can avoid the repetition and duplication of documents? Main purpose of this paper is to find the answer for these questions. This is not single case, paperless campus is remaining to be dream not for only TUIT, but for many other universities too. Many universities all over the world tried to switch from paper-based admissions to a completely paperless system. Universities are looking for software technologies, which can help them to eliminate the huge amount of mail received/sent, easily present student records and documentation, and can share files between multiple administration staffs. Going to paperless is important for current ecological situation -universities can help to save natural resources. But the most important thing is that, it is the way of improve the university management and make administration process much easier and faster. In this paper we are trying to find the ways of making university paperless by using information system of University Management. This information system should avoid repetition of documents and help share important data between all departments. This system can be seen like a combination of mobile and web application and services. Classification of documents helps to control, for this reason we divide all the types of documents in university to groups and identify the owners (who is responsible for creating and making changes) and users (who can see, print or copy) of these documents. Current and suggested models of university management are presented and the possibility of creating new mobile applications for providing new services is highlighted. Our suggested model of paperless university is built in case of Tashkent University of IT (TUIT) but can be implemented to other universities too. This paper considers the paperless university as one of the constituent elements of 'E-government' system. Developing of a complex information system 'Education' is a part of Master plan of developing E-government in Uzbekistan. This system will be used to control all educational processes within universities and in the level of Ministry of Higher and Secondary Special Education of the Republic of Uzbekistan. The reasons of going paperless, the benefits which can be reached by going paperless are listed here, also some successful examples of ongoing projects in different countries and universities all over the world are also presented. In future this model can be improved by adding new IT solutions which will appear in market.},
	journal = {2016 15th International Conference on Information Technology Based Higher Education and Training, ITHET 2016},
	author = {Isaeva, Masuda and Yoon, Hyen Young},
	year = {2016},
	note = {ISBN: 9781509007783},
	keywords = {e-documents, e-forms, Information system, learning management, university administration},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/SXT36A4M/isaeva2016.pdf:application/pdf},
}

@article{oborne_reading_1988,
	title = {Reading from screen versus paper: there is no difference},
	volume = {28},
	issn = {00207373},
	doi = {10.1016/S0020-7373(88)80049-X},
	abstract = {This paper considers the effect of presentation medium on reading speed and comprehension. By directly comparing performance using screen and paper presentations, it examines the argument that it takes longer to read from a screen-based display than from paper, and that comprehension will be lower. The hypothesis is also tested that it takes longer to read light characters on a dark background compared with dark characters on a light background, and that comprehension will be lower with light-character displays. Altogether four conditions were used, with two passages read in each condition: screen with dark characters, screen with light characters, paper with dark characters, and paper with light characters. Subjects also ranked the four conditions for preference. No significant difference was found in either reading speed or comprehension between screen and paper, or between dark and light character displays. Some preference differences were found, however. Reasons for the lack of reading and comprehension differences are discussed, and it is argued that this reflects the close attention to experimental detail paid in the present experiment, which has often been missing in past studies. © 1988, Academic Press Limited. All rights reserved.},
	number = {1},
	journal = {International Journal of Man-Machine Studies},
	author = {Oborne, David J. and Holton, Doreen},
	year = {1988},
	pages = {1--9},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/DM5L4XXV/oborne1988.pdf:application/pdf},
}

@article{kong_comparison_2018,
	title = {Comparison of reading performance on screen and on paper: {A} meta-analysis},
	volume = {123},
	issn = {03601315},
	url = {https://doi.org/10.1016/j.compedu.2018.05.005},
	doi = {10.1016/j.compedu.2018.05.005},
	abstract = {This meta-analysis looked at 17 studies which focused on the comparison of reading on screen and reading on paper in terms of reading comprehension and reading speed. The robust variance estimation (RVE)- based meta-analysis models were employed, followed by four different RVE meta-regression models to examine the potential effects of some of the covariates (moderators) on the mean differences in comprehension and reading speed between reading on screen and reading on paper. The RVE meta-analysis showed that reading on paper was better than reading on screen in terms of reading comprehension, and there were no significant differences between reading on paper and reading on screen in terms of reading speed. None of the moderators were significant at the 0.05 level. In the meanwhile, albeit not significant, examination of the p-values for the difference tests prior to 2013 and after 2013 respectively (not shown here) indicated that the magnitude of the difference in reading comprehension between paper and screen followed a diminishing trajectory. It was suggested that future meta-analyses include latest studies, and other potential moderators such as fonts, spacing, age and gender.},
	journal = {Computers and Education},
	author = {Kong, Yiren and Seo, Young Sik and Zhai, Ling},
	year = {2018},
	note = {Publisher: Elsevier Ltd},
	keywords = {Digital reading, Meta-analysis, Paper, Reading performance, Screen},
	pages = {138--149},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/8Z9JC2MQ/kong2018.pdf:application/pdf},
}

@article{wright_proof-reading_1983,
	title = {Proof-reading texts on screen and paper},
	volume = {2},
	issn = {13623001},
	doi = {10.1080/01449298308914479},
	abstract = {This study examined the speed and accuracy of proof-reading a text presented on a CRT, relative to performance with print on paper. Two groups of 16 people each proof-read four published texts, roughly 1500 words per text For all readers, half the texts were presented as print on paper and half were presented on a 12 in. CRT screen. The two groups differed in whether the errors found in the screened text were recorded on the screen or on paper. The results suggested that the method of recording errors on the screen was quickly learned, but that both speed and accuracy were impaired when the text was presented on the screen. The implications of this for refereeing electronic journals is discussed. © 1983 Taylor \& Francis Group, LLC.},
	number = {3},
	journal = {Behaviour and Information Technology},
	author = {Wright, P.},
	year = {1983},
	pages = {227--235},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/ITQ7JI5E/wright1983.pdf:application/pdf},
}

@article{joenk_toward_2013,
	title = {Toward paperless information systems — {F}. {W}. {Lancaster}},
	volume = {PC-22},
	issn = {0361-1434},
	doi = {10.1109/tpc.1979.6500187},
	number = {1},
	journal = {IEEE Transactions on Professional Communication},
	author = {Joenk, R. J.},
	year = {2013},
	pages = {41--41},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/H2Y6KRVR/06500187.pdf:application/pdf},
}

@article{uther_digital_2019,
	title = {Digital vs. {Hard} {Copy}? {A} {Preliminary} {Study} of {Reading} {Style} in {Children} {Using} {Touch} {Screen} and {Paper} {Book}},
	volume = {11585},
	url = {http://link.springer.com/10.1007/978-3-030-23538-3},
	doi = {10.1007/978-3-030-23538-3},
	author = {Uther, Maria and Ross, Kirsty and Randell, Jordan and Pye, Rachel},
	year = {2019},
	note = {Publisher: Springer International Publishing
ISBN: 978-3-030-23537-6},
	keywords = {á developing readers á, Developing readers, E-books, Emotional engagement, emotional engagement á e-books, Reading, reading á touch screen, Touch screen},
	pages = {495--502},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/AJ6RESRM/10.1007@978-3-030-23538-338.pdf:application/pdf},
}

@article{ranieri_paper_2018,
	title = {on {Paper} or on {Screen}? a {Study} on the {Perceptions} of {Digital} {Tests} in {Higher} {Education}‏},
	url = {https://www.learntechlib.org/p/195245/},
	doi = {10.17471/2499-4324/1011},
	journal = {Learntechlib.Org‏},
	author = {Ranieri, M and Technology, A Nardi - Italian Journal of Educational and 2018, undefined},
	year = {2018},
	keywords = {abstract this paper explores, an, and to what extent, bring your own device, byod, cbt, compared to traditional paper-based, of computer-based testing, pbt, percezioni, studenti universitari, testing, the aim is to, the potentialities and limitations, verifiche cartacee, verifiche computerizzate, verify whether},
	pages = {56--70},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/NX7V2AGY/article_195245.pdf:application/pdf},
}

@article{ackerman_taking_2012,
	title = {Taking reading comprehension exams on screen or on paper? {A} metacognitive analysis of learning texts under time pressure},
	volume = {28},
	issn = {07475632},
	url = {http://dx.doi.org/10.1016/j.chb.2012.04.023},
	doi = {10.1016/j.chb.2012.04.023},
	abstract = {People often attribute their reluctance to study texts on screen to technology-related factors rooted in hardware or software. However, previous studies have pointed to screen inferiority in the metacognitive regulation of learning. The study examined the effects of time pressure on learning texts on screen relative to paper among undergraduates who report only moderate paper preference. In Experiment 1, test scores on screen were lower than on paper under time pressure, with no difference under free regulation. In Experiment 2 the time condition was manipulated within participants to include time pressure, free regulation, and an interrupted condition where study was unexpectedly stopped after the time allotted under time pressure. No media effects were found under the interrupted study condition, although technology-related barriers should have taken their effect also in this condition. Paper learners who preferred this learning medium improved their scores when the time constraints were known in advance. No such adaptation was found on screen regardless of the medium preference. Beyond that, paper learning was more efficient and self-assessments of knowledge were better calibrated under most conditions. The results reinforce the inferiority of self-regulation of learning on screen and argue against technology-related factors as the main reason for this. © 2012 Elsevier Ltd. All rights reserved.},
	number = {5},
	journal = {Computers in Human Behavior},
	author = {Ackerman, Rakefet and Lauterman, Tirza},
	year = {2012},
	note = {Publisher: Elsevier Ltd},
	keywords = {Digital literacy, Metacognitive monitoring and control, Metacomprehension, Self-regulated learning, Study-time allocation, Time constraints},
	pages = {1816--1828},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/JBPXIXMV/ackerman2012.pdf:application/pdf},
}

@article{muramatsu_construction_1992,
	title = {Construction of the paperless system in {Japan} patent office},
	doi = {10.1109/icsi.1992.217293},
	abstract = {The Paperless system of Japan Patent Office aims to electronize all kinds of documents of the Patent Office. This system, to guarantee free access to external users, has been developed as an open system which is based on OSI. This paper gives detailed explanation about the protocol configuration and document format. The upper layer protocol (which is called 'Pp protocol') of the application layer is originated for the Paperless System to ensure realtime interactive communications of patent documents between host computers and terminals. Patent application information, which is a mixture of code data and image data, is described as a content of Pp protocol.},
	journal = {Proceedings of the Second International Conference on Systems Integration},
	author = {Muramatsu, M. and Takabayashi, O. and Kosuge, K.},
	year = {1992},
	note = {ISBN: 0818626976},
	pages = {278--287},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/74CMNJQN/the-construction-of-the-paperless-system-in-japan-patent-office.pdf:application/pdf},
}

@article{de_bonis_going_2011,
	title = {Going {Green}: {Managing} a {Paperless} {Classroom}.},
	volume = {1},
	issn = {1548-6613},
	abstract = {The LMS (learning management system) at many schools for delivering, tracking and managing education relies on TEL (technology-enhanced learning), what Nichols called " pedagogy empowered by digital technology " (Nichols, 2008). It includes the " paperless classroom " in traditional (not online) classes in which faculty and students exchange information and assignments electronically. The paperless non-online classroom pedagogy is designed to improve the efficiency of the learning experience, to contribute to asynchronous learning and to help students develop the electronic skills and competencies they will need in the post-graduate private sector while contributing to the sustainability efforts of the university. The main objective of this paper is to provide a framework for managing a paperless classroom, including best practices, pedagogical issues and the " how-do-I " suggestions.},
	journal = {Online Submission},
	author = {De Bonis, Susan and De Bonis, Nick},
	year = {2011},
	keywords = {Asynchronous Communication, Blended Learning, Colleges, Computer Literacy, Computer Mediated Communication, Computer Uses in Education, Conservation (Environment), Conventional Instruction, Educational Technology, Management Systems, Teaching Methods, Web Sites},
	pages = {83--87},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/QYNPC4EX/ED522208.pdf:application/pdf},
}

@article{sharan_b._merriam_andragogy_2001,
	title = {Andragogy and {Self}-{Directed} {Learning}: {Pillars} of {Adult} {Learning} {Theory} - {Merriam} - 2002 - {New} {Directions} for {Adult} and {Continuing} {Education} - {Wiley} {Online} {Library}},
	volume = {2001},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/ace.3/abstract;jsessionid=840D35437776B768F8550CF5510E8277.f03t04},
	doi = {10.1002/ace.3},
	abstract = {Andragogy and self-directed learning continue to be important to our present-day understanding of adult learning.},
	number = {89},
	journal = {Androgogy and Self-Directed Learning},
	author = {{Sharan B. Merriam}},
	year = {2001},
	pages = {3--14},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/B6IMPMTA/merriam2001.pdf:application/pdf},
}

@article{meishar-tal_students_2019,
	title = {Students’ writing and reading preferences in a paperless classroom},
	volume = {27},
	issn = {17445191},
	url = {https://doi.org/10.1080/10494820.2018.1504306},
	doi = {10.1080/10494820.2018.1504306},
	abstract = {This study took place in a school which adopted a “paperless classroom” policy. The purpose of the study was to examine whether students who learn in a paperless classroom really prefer reading and writing on computers rather than on paper and whether their preferences differ according to contextual conditions and personal differences. The findings show that students’ reading and writing preferences depended on the context in which the reading or writing was performed. The boys preferred to read and write on the computer significantly more than girls. Conversely, the girls’ handwriting skills and preference for handwriting were higher than the boys’. Reading and writing on computer was found to be favored among strong students, while weak students tended to prefer using paper. This research also revealed a rapid decrease in favoring computer over paper in both reading and writing over time. Students who had experienced the paperless classroom policy in this school for three years were less supportive of the use of computers for reading and writing than younger students.},
	number = {7},
	journal = {Interactive Learning Environments},
	author = {Meishar-Tal, Hagit and Shonfeld, Miri},
	year = {2019},
	note = {Publisher: Taylor \& Francis},
	keywords = {paperless classroom, Reading, BYOD, handwriting, print vs. digital, writing},
	pages = {908--918},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/HCR8FELP/meishar-tal2018(1).pdf:application/pdf},
}

@article{smart_paperless_1995,
	title = {Paperless office: facts and fictions},
	abstract = {With the advent of computers, many have anticipated the realization of the 'paperless' office. Despite the technology that makes an electronic office feasible, the proliferation of paper continues. This paper suggests a 'less' paper office serves as a more realistic goal than the 'paperless' office. Case examples show two organizations attempts to use technology to reduce paper: one successfully, one unsuccessfully. The author suggests a three-phase implementation strategy to help organizations use technology to reduce paper and costs and increase productivity.},
	journal = {IEEE International Professional Communication Conference},
	author = {Smart, Karl L.},
	year = {1995},
	note = {ISBN: 0780329570},
	pages = {141},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/7FVAXLBK/the-paperless-office-facts-and-fictions.pdf:application/pdf},
}

@book{geron_hands-machine_nodate,
	title = {Hands-{On} {Machine} {Learning} with {Scikit}-{Learn} and {TensorFlow}},
	isbn = {978-1-4919-6229-9},
	abstract = {Through a series of recent breakthroughs, deep learning has boosted the entire field of machine learning. Now, even programmers who know close to nothing about this technology can use simple, efficient tools to implement programs capable of learning from data. This practical book shows you how. Using concrete examples, minimal theory, and two production-ready Python frameworks—scikit-learn and TensorFlow—author Aurélien Géron helps you gain an intuitive understanding of the concepts and tools for building intelligent systems. You’ll learn a range of techniques, starting with simple linear regression and progressing to deep neural networks.},
	author = {Géron, Aurélien},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/6VH4SI6J/[Aur_lien_G_ron]_Hands-On_Machine_Learning_with_Sc(z-lib.org).pdf:application/pdf},
}

@article{prensky_digital_2001,
	title = {Digital {Natives}, {Digital} {Immigrants}, {Part} {II}: {Do} {They} {Really} {Think} {Differently}?},
	issn = {0011135X},
	number = {9},
	journal = {On the Horizon},
	author = {Prensky, Marc},
	year = {2001},
	pages = {687--691},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/N43BRT64/Prensky - Digital Natives, Digital Immigrants - Part2.pdf:application/pdf},
}

@article{prensky_digital_2001-1,
	title = {Digital {Natives}, {Digital} {Immigrants} {Part} 1},
	volume = {9},
	issn = {20541708},
	doi = {10.1108/10748120110424816},
	abstract = {Part one of this paper highlights how students today think and process information fundamentally differently from their predecessors, as a result of being surrounded by new technology. The author compares these “digital natives” with the older generation who are learning and adopting new technology naming them “digital immigrants”. © 2001, MCB UP Limited},
	number = {5},
	journal = {On the Horizon},
	author = {Prensky, Marc},
	year = {2001},
	keywords = {Culture, Education, Language, Students, Technology},
	pages = {1--6},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/2ZEX57XI/Prensky - Digital Natives, Digital Immigrants - Part1.pdf:application/pdf},
}

@book{zadeh_tensorflow_2018,
	title = {Tensorflow for {Deep} {Learning}},
	isbn = {978-1-4919-8045-3},
	abstract = {Learn how to solve challenging machine learning problems with Tensorflow, Google’s revolutionary new system for deep learning. If you have some background with basic linear algebra and calculus, this practical book shows you how to build—and when to use—deep learning architectures. You’ll learn how to design systems capable of detecting objects in images, understanding human speech, analyzing video, and predicting the properties of potential medicines. TensorFlow for Deep Learning teaches concepts through practical examples and builds understanding of deep learning foundations from the ground up.},
	author = {Zadeh, Reza and Ramsundar, Bharath},
	year = {2018},
	doi = {http://dx.doi.org/10.1016/S1386-6532(02)00032-X},
	note = {ISSN: 0100-736X},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/C2IMFWQZ/TensorFlow for Deep Learning.pdf:application/pdf},
}

@misc{noauthor_for_nodate,
	title = {({For} {Dummies}) {John} {Paul} {Mueller}, {Luca} {Massaron} - {Python} for {Data} {Science}, 2nd {Edition}-{Wiley} (2019)},
	file = {(For Dummies) John Paul Mueller, Luca Massaron - Python for Data Science, 2nd Edition-Wiley (2019).epub:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/9TUEGN4K/(For Dummies) John Paul Mueller, Luca Massaron - Python for Data Science, 2nd Edition-Wiley (2019).epub:application/epub+zip;Arafah_2017_IOP_Conf._Ser. _Earth_Environ._Sci._70_012065.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/LEN3FF7L/Arafah_2017_IOP_Conf._Ser. _Earth_Environ._Sci._70_012065.pdf:application/pdf},
}

@book{consoli_preface_2019,
	title = {Preface},
	isbn = {978-3-030-05249-2},
	author = {Consoli, Sergio and Recupero, Diego Reforgiato and Petković, Milan},
	year = {2019},
	doi = {10.1007/978-3-030-05249-2},
	note = {Publication Title: Data Science for Healthcare: Methodologies and Applications},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/22PV4L47/Sergio Consoli, Diego Reforgiato Recupero, Milan Petković - Data Science for Healthcare_ Methodologies and Applications-Springer International Publishing (2019).pdf:application/pdf},
}

@article{abbas_predicting_2019,
	title = {Predicting diabetes in healthy population through machine learning},
	volume = {2019-June},
	issn = {10637125},
	doi = {10.1109/CBMS.2019.00117},
	abstract = {In this paper, we revisit the data of the San Antonio Heart Study, and employ machine learning to predict the future development of type-2 diabetes. To build the prediction model, we use the support vector machines and ten features that are wellknown in the literature as strong predictors of future diabetes. Due to the unbalanced nature of the dataset in terms of the class labels, we use 10-fold cross-validation to train the model and a hold-out set to validate it. The results of this study show a validation accuracy of 84.1\% with a recall rate of 81.1\% averaged over 100 iterations. The outcomes of this study can help in identifying the population that is at high risk of developing type-2 diabetes in the future.},
	journal = {Proceedings - IEEE Symposium on Computer-Based Medical Systems},
	author = {Abbas, Hasan and Alic, Lejla and Rios, Marelyn and Abdul-Ghani, Muhammad and Qaraqe, Khalid},
	year = {2019},
	note = {ISBN: 9781728122861},
	keywords = {Support vector machine, Disease Prediction, Type 2 diabetes},
	pages = {567--570},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/XV58PNC3/abbas2019.pdf:application/pdf},
}

@article{benbelkacem_random_2019,
	title = {Random forests for diabetes diagnosis},
	doi = {10.1109/ICCISci.2019.8716405},
	abstract = {Random forest is one of the most recent successful research findings for decision tree learning. It is widely used in the medical field, particularly for diabetes diagnosis. Diabetes is reaching epidemic proportions in many developing and newly industrialized countries. Thus, random forest should be exploited to treat diabetes diagnosis. In this paper, we exploit the principle of random forests for the implementation of a powerful model for the diagnosis of diabetes. The experiments were carried out on the Pima Indians Diabetes data set selected from the UCI repository. First, several random forests have been developed with different numbers of trees in order to define the optimum size of the forest. Then, random forests were compared with other machine learning methods. The results of the experiments show that our approach based on random forest has proved to be more efficient in comparison with other methods of machine learning.},
	journal = {2019 International Conference on Computer and Information Sciences, ICCIS 2019},
	author = {Benbelkacem, Sofia and Atmani, Baghdad},
	year = {2019},
	note = {Publisher: IEEE
ISBN: 9781538681251},
	keywords = {Classification, Machine learning, Decision tree, Diabetes, Diagnosis, Random forest},
	pages = {1--4},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/I2V35283/benbelkacem2019.pdf:application/pdf},
}

@article{guha_cochannel_2010,
	title = {Cochannel interference minimization using {Wilcoxon} multilayer perceptron neural network},
	doi = {10.1109/ITC.2010.50},
	abstract = {This paper presents the application of wilcoxon machines learning technique for artificial neural network in channel equalization application. The equalizer mitigates the effect of co-channel interference, inter-symbol interference in the presence of additive white Gaussian noise (AWGN). The performance of this proposed Multilayer Perceptron Network equalizer trained with wilcoxon learning has been compared with Linear equalizer trained with recursive-least-squares algorithm and MLP equalizer with back-propagation algorithm. The Performance shows superiority of Wilcoxon Learning Multilayer Perceptron Network equalizer over back-propagation Multilayer Perceptron Network equalizer. © 2010 IEEE.},
	journal = {ITC 2010 - 2010 International Conference on Recent Trends in Information, Telecommunication, and Computing},
	author = {Guha, Devi Rani and Patra, Sarat Kumar},
	year = {2010},
	note = {ISBN: 9780769539751},
	keywords = {Artificial neural network, Back propagation, Channel equalizer, Least mean square, Multilayer perceptron neural network, Recursive least squares, Wilcoxon multilayer perceptron neural network},
	pages = {145--149},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/WAFX463A/guha2010.pdf:application/pdf},
}

@article{kala_comparative_2009,
	title = {Comparative analysis of intelligent hybrid systems for detection of {PIMA} {Indian} diabetes},
	doi = {10.1109/NABIC.2009.5393877},
	abstract = {The past few years have seen a lot of applications of Hybrid Soft Computing approaches that seem to have completely replaced the traditional uni-system approaches. The added abilities that come from the hybrid approaches motivate their use in every system. Bio-Medical Engineering is yet another field which has seen a major change in he past few years. We find various new approaches being applied to this field as well as many new models being proposed. At this juncture, we study the effectiveness of various new hybrid approaches in the field of Bio-medicals in this paper. PIMA Indian database has been used for this purpose from the UCI Machine Learning Repository. The basic aim is to compare the various hybrid approaches from the recent literature and compare their performances. We have chosen 3 major Hybrid Systems and standard Back Propagation Algorithm for this purpose. These are Adaptive Neuro Fuzzy Inference Systems, Ensembles and Evolutionary Artificial Neural Networks. We also try to explain the results from our theoretical understanding of the individual Hybrid Systems. ©2009 IEEE.},
	journal = {2009 World Congress on Nature and Biologically Inspired Computing, NABIC 2009 - Proceedings},
	author = {Kala, Rahul and Shukla, Anupam and Tiwari, Ritu},
	year = {2009},
	note = {ISBN: 9781424456123},
	keywords = {Classification, Ensemble, ANFIS, Bio-medicals, Evolutionary ANN, Modular neural network, PIMA Indian diabetes},
	pages = {947--952},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/RVL8BCYP/kala2009.pdf:application/pdf},
}

@article{karatsiolis_region_2012,
	title = {Region based {Support} {Vector} {Machine} algorithm for medical diagnosis on {Pima} {Indian} {Diabetes} dataset},
	doi = {10.1109/BIBE.2012.6399663},
	abstract = {The problem of diagnosing Pima Indian Diabetes from data obtained from the UCI Repository of Machine Learning Databases[6] is handled with a modified Support Vector Machine strategy. Performance comparison with previous studies is presented in order to demonstrate the proposed algorithm's advantages over various classification methods. The goal of the paper is to provide the grasp of a methodology that can be efficiently used to raise classification success rates obtained by the use of conventional approaches such as Neural Networks, RBF networks and K-nearest neighbors. The suggested algorithm divides the training set into two subsets: one that arises from the joining of coherent data regions and one that comprises of the data portion that is difficult to be clustered. Consequently, the first subset is used to train a Support Vector Machine with a RBF kernel and the second subset is used to train another Support Vector Machine with a polynomial kernel. During classification the algorithm is capable of identifying which of the two Support Vector Machine models to use. The intuition behind the suggested algorithm relies on the expectation that the RBF Support Vector Machine model is more appropriate to use on data sets of different characteristics than the polynomial kernel. In the specific study case the suggested algorithm raised average classification success rate to 82.2\% while the best performance obtained by previous studies was 81\% given by a fine tuned highly complex ARTMAP-IC model. © 2012 IEEE.},
	number = {November},
	journal = {IEEE 12th International Conference on BioInformatics and BioEngineering, BIBE 2012},
	author = {Karatsiolis, Savvas and Schizas, Christos N.},
	year = {2012},
	note = {ISBN: 9781467343589},
	keywords = {Clustering, Pima Indian Diabetes, Support Vector Machine, Support Vector Machine Kernel},
	pages = {139--144},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/Y65GU63P/karatsiolis2012.pdf:application/pdf},
}

@article{vijiyakumar_random_2019,
	title = {Random forest algorithm for the prediction of diabetes},
	doi = {10.1109/ICSCAN.2019.8878802},
	abstract = {Diabetes is taken into account together of the deadliest and chronic disease that causes a rise in glucose. Polygenic disease is that the kind wherever the exocrine gland doesn't manufacture hypoglycaemic agent in line with International polygenic disease Federation 382 million individuals live with polygenic disease across the world. By 2035, this will be doubled as 592 million. Diabetes mellitus or just sickness may be a disease caused due to the rise of blood glucose level. Many difficulties might occur if the diabetes remains untreated and unidentified by the doctor. The complications are excretory organ injury, typically resulting in chemical analysis, eye damage that may end in visual impairment, or associate degree enhanced risk for cardiopathy or stroke. The tedious identifying methodology ends up in visiting of a patient to a diagnostic center and consulting the doctor for more treatment. Rise in machine learning approaches solves this essential draw back. The objective of this paper is to develop a system which can perform early prediction of diabetes for a patient with a higher accuracy by using Random Forest algorithm in machine learning technique. Random Forest algorithms are often used for each classification and regression tasks and also it is a type of ensemble learning method. The accuracy level is greater when compared to other algorithms. The proposed model gives the best results for diabetic prediction and the result showed that the prediction system is capable of predicting the diabetes disease effectively, efficiently and most importantly, instantly.},
	journal = {2019 IEEE International Conference on System, Computation, Automation and Networking, ICSCAN 2019},
	author = {Vijiyakumar, K. and Lavanya, B. and Nirmala, I. and Sofia Caroline, S.},
	year = {2019},
	note = {Publisher: IEEE
ISBN: 9781728115252},
	keywords = {Diabetes, Machine learning technique, Random Forest algorithm},
	pages = {1--5},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/JWXBDKGU/10.1109@ICSCAN.2019.8878802.pdf:application/pdf},
}

@article{faruque_performance_2019,
	title = {Performance {Analysis} of {Machine} {Learning} {Techniques} to {Predict} {Diabetes} {Mellitus}},
	doi = {10.1109/ECACE.2019.8679365},
	abstract = {Diabetes mellitus is a common disease of human body caused by a group of metabolic disorders where the sugar levels over a prolonged period is very high. It affects different organs of the human body which thus harm a large number of the body's system, in particular the blood veins and nerves. Early prediction in such disease can be controlled and save human life. To achieve the goal, this research work mainly explores various risk factors related to this disease using machine learning techniques. Machine learning techniques provide efficient result to extract knowledge by constructing predicting models from diagnostic medical datasets collected from the diabetic patients. Extracting knowledge from such data can be useful to predict diabetic patients. In this work, we employ four popular machine learning algorithms, namely Support Vector Machine (SVM), Naive Bayes (NB), K-Nearest Neighbor (KNN) and C4.5 Decision Tree (DT), on adult population data to predict diabetic mellitus. Our experimental results show that C4.5 decision tree achieved higher accuracy compared to other machine learning techniques.},
	journal = {2nd International Conference on Electrical, Computer and Communication Engineering, ECCE 2019},
	author = {Faruque, Md Faisal and {Asaduzzaman} and Sarker, Iqbal H.},
	year = {2019},
	note = {Publisher: IEEE
ISBN: 9781538691113},
	keywords = {machine learning, diabetes, eHealth, prediction},
	pages = {1--4},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/5MVEZT5Y/faruque2019.pdf:application/pdf},
}

@book{suyanto_machine_2018,
	address = {Bandung},
	title = {Machine {Learning} {Tingkat} {Dasar} dan {Lanjut}},
	isbn = {978-602-623-278-6},
	publisher = {Informatika Bandung},
	author = {{Suyanto}},
	year = {2018},
}

@misc{noauthor_sklearnneural_networkmlpclassifier_nodate,
	title = {sklearn.neural\_network.{MLPClassifier}},
	url = {https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html},
}

@misc{noauthor_pima_nodate,
	title = {Pima {Indians} {Diabetes} {Database}},
	url = {https://www.kaggle.com/uciml/pima-indians-diabetes-database/activity},
}

@article{li_user_2016,
	title = {User behavior analysis and research based on big data in large-scale gathering scene},
	doi = {10.1109/ISCIT.2016.7751651},
	abstract = {On the mobile communication guarantee project for important activities, the analysis of mass data based on user behavior is conducive to precision operation, including the network layout and optimization, resource investment, etc. A multi-dimensional analysis method is proposed, by combining the network data and the market development operation data, which has been verified in the operation of mobile network and achieved good results.},
	journal = {2016 16th International Symposium on Communications and Information Technologies, ISCIT 2016},
	author = {Li, Mingxin and Yin, Jinsong and Tan, Juanjuan},
	year = {2016},
	note = {ISBN: 9781509040995},
	keywords = {mobile, big data, communication support, gathering scene, user behavior},
	pages = {362--366},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/32M5Z5YE/li2016.pdf:application/pdf},
}

@article{cardone_crowdsensing_2014,
	title = {Crowdsensing in {Urban} areas for city-scale mass gathering management: {Geofencing} and activity recognition},
	volume = {14},
	issn = {1530437X},
	doi = {10.1109/JSEN.2014.2344023},
	abstract = {The widespread availability of smartphones today equipped with several physical and virtual sensors allows to directly collect various information about surrounding physical and logical context for different purposes that range from detecting user's current physical activity and also user presence in a designated area, often referred to as geofencing, to determining current social pulse of individuals and entire communities. Mobile crowdsensing seems a promising solution for enabling the design/development and deployment of a wide range of advanced applications in various fields. In particular, public safety, transportation, and energy monitoring and management in urban environments can benefit from mobile crowdsensing in terms of advanced provisioned applications as well as savings of investments in the urban sensing infrastructure. However, enabling those advanced smart urban applications requires complex signal processing, machine learning, and resource management algorithms that are often beyond the skills of many mobile app developers. This paper describes the pivotal relevance of these facilities for mobile crowdsensing applications and presents our open-source solution, called Mobile Sensing Technology (MoST), for activity detection and geofencing, comparing it with the reference implementations provided by Google as part of the Google Play Services library. Experimental results within the testbed framework of a crowd-management application scenario validate MoST design guidelines and demonstrate the general-purpose, unintrusive, and power-efficient characteristics of MoST sensing capabilities.},
	number = {12},
	journal = {IEEE Sensors Journal},
	author = {Cardone, Giuseppe and Cirri, Andrea and Corradi, Antonio and Foschini, Luca and Ianniello, Raffaele and Montanari, Rebecca},
	year = {2014},
	keywords = {machine learning, activity recognition, geofencing, geographic information systems, Mobile computing, mobile crowdsensing (MCS)},
	pages = {4185--4195},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/BXC49FBD/cardone2014.pdf:application/pdf},
}

@article{weiser_computer_1991,
	title = {The {Computer} for the 21st {Century} - {Specialized} elements of hardware and software, connected by wires, radio waves and infrared, will be so ubiquitous that no one will notice their presence},
	volume = {265},
	abstract = {Specialized elements of hardware and software, connected by wires, radio waves and infrared, will be so ubiquitous that no one will notice their presence},
	number = {3},
	journal = {Scientific American},
	author = {Weiser, Mark},
	year = {1991},
	pages = {94--104},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/MDLI2GU6/Weiser-SciAm.pdf:application/pdf},
}

@article{nagy_crowdsensing_2016,
	title = {A crowdsensing platform for mass surveillance},
	volume = {2016-Novem},
	issn = {13342630},
	doi = {10.1109/ELMAR.2016.7731784},
	abstract = {Nowadays festivals and city events attract huge number of visitors and unfortunately in large masses a minor panic could have incalculable consequences despite of the organizers' efforts to do everything for participants' safety. Therefore we have developed an integrated mass surveillance system based on crowdsensing data, where the system helps authorities and organizers in information gathering about the actual dynamics of the crowd. Based on real time and representative information, they are able to perform fast and targeted interventions.},
	number = {September},
	journal = {Proceedings Elmar - International Symposium Electronics in Marine},
	author = {Nagy, Attila Mátyás and Simon, Vilmos},
	year = {2016},
	note = {ISBN: 9789531842211},
	keywords = {Smart Cities, Mass Surveillance, Mobile Crowd Sensing},
	pages = {189--194},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/QZWAH3NT/nagy2016.pdf:application/pdf},
}

@article{el-moukaddem_maximizing_2010,
	title = {Maximizing data gathering capacity of wireless sensor networks using mobile relays},
	doi = {10.1109/MASS.2010.5664019},
	abstract = {Recently, the availability of numerous low-cost robotic units (e.g., Packbot, Robomote, and Khepera) has made it possible to massively deploy mobile sensors in a network and use them in a disposable manner. It has been shown that the controlled mobility offered by sensors can be exploited to improve the energy efficiency of a network. In this paper, we study a new problem called max-data mobile relay configuration (MMRC) that finds the positions of a set of mobile sensors, referred to as relays, that maximize the total amount of data gathered by the network during its lifetime. Different from previous controlled mobility approaches, we account for several characteristics of existing practical mobile sensing platforms including limited mobility and the high energy consumption of locomotion. We show that the MMRC problem is surprisingly complex even for a trivial network topology due to the joint consideration of the energy consumption of both wireless communication and mechanical locomotion. We present optimal MMRC algorithms and practical distributed implementations for several important network topologies. Our extensive simulations based on realistic energy models of existing mobile sensing platforms show that our approach can increase the data gathering capacity by a factor of at least 2 in most scenarios. Moreover, our distributed algorithms converge quickly and incur low messaging overhead. ©2010 IEEE.},
	journal = {2010 IEEE 7th International Conference on Mobile Adhoc and Sensor Systems, MASS 2010},
	author = {El-Moukaddem, Fatme and Torng, Eric and Xing, Guoliang},
	year = {2010},
	note = {ISBN: 9781424474882},
	pages = {312--321},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/R578HQCB/el-moukaddem2010.pdf:application/pdf},
}

@article{bonne_wifipi_2013,
	title = {{WiFiPi}: {Involuntary} tracking of visitors at mass events},
	doi = {10.1109/WoWMoM.2013.6583443},
	abstract = {To simulate crowds at mass events, realistic movement data of people is required. Despite their limited capacity for approximating real human mobility, synthetic movement models are traditionally used for this purpose. More realistic simulations can be achieved by using real-life movement data, gathered by observing people in the desired context. This paper presents a method for tracking people at mass events without the need for active cooperation by the subjects. The mechanism works by scanning at multiple locations for packets sent out by the Wi-Fi interface on visitors' smartphones, and correlating the data captured at these different locations. The proposed method can be implemented at very low cost on Raspberry Pi computers. This implementation was trialed in two different contexts: a popular music festival and a university campus. The method allows for tracking thousands of people simultaneously, and achieves a higher coverage rate than similar methods for involuntary crowd tracking. Moreover, the coverage rate is expected to increase even further as more people will start using smartphones. The proposed method has many applications in different domains. It also entails privacy implications that must be considered when deploying a similar system. © 2013 IEEE.},
	journal = {2013 IEEE 14th International Symposium on a World of Wireless, Mobile and Multimedia Networks, WoWMoM 2013},
	author = {Bonne, Bram and Barzan, Arno and Quax, Peter and Lamotte, Wim},
	year = {2013},
	note = {ISBN: 9781467358279},
	keywords = {Mobile ad hoc networks, mobile communication, privacy, simulation, wireless lan, wireless networks},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/5NEIT7IW/bonne2013.pdf:application/pdf},
}

@article{liu_research_2017,
	title = {Research on the {Impact} of {Crowd} {Flow} on {Crowd} {Risk} in {Large} {Gathering} {Spots}},
	doi = {10.1109/ICIICII.2016.0094},
	abstract = {In order to assess crowd risk involved with mass of people gathering in large gathering spots, four common crowd flows including two-way flow, heterogeneous crowd flow, circular flow and arching phenomenon were specifically analyzed on the basis of investigation of crowd's route selection. The formation mechanism of crowd risk consists of four stages namely free movement, retention, congestion and stampede, and by using the method of event tree, the important impact of crowd flow on crowd risk was found out. Combined with crowd risk model, the thinking of computer simulation on crowd risk was proposed to provide a reference for crowd security management in large gathering spots.},
	journal = {Proceedings - 2016 International Conference on Industrial Informatics - Computing Technology, Intelligent Technology, Industrial Information Integration, ICIICII 2016},
	author = {Liu, Zimei and Chen, Yun and Xie, Kefan},
	year = {2017},
	note = {ISBN: 9781509035755},
	keywords = {Computer simulation, crowd flow, crowd risk},
	pages = {368--371},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/BSCYZ9Q3/liu2016.pdf:application/pdf},
}

@article{lamba_large_2018,
	title = {A large scale crowd density classification using spatio-temporal local binary pattern},
	volume = {2018-Janua},
	doi = {10.1109/SITIS.2017.57},
	abstract = {Increasing world wide population is leading to dense crowd gathering at public places. Due to mass gathering at large scale, crowd related disaster has been frequently occurred. In order to prevent crowd calamities, automated crowd scene analysis has been a topic of great interest. Density is the status of crowd which is essential to classify in visual surveillance system primarily for security aspects. Most of the existing techniques work on detection and tracking of individuals. Due to fewer pixels per target, multiple occlusion and perspective effects etc., detection and tracking of individuals is a complex task in dense crowd scenarios. This paper presents a novel strategy for large scale crowd density classification powered by dynamic texture analysis. This approach consists of an interest points detection followed by spatio-temporal feature extraction. A rotation invariant spatio-temporal local binary (RIST-LBP) pattern is proposed to extract dynamic texture of the moving crowd. Further, a multi-class support vector regression is adopted for density classification. We also include a tracking step which tracks the selected interest points over the video frames for crow flow estimation. We validate our proposed approach on three different datasets such as PETS, UCF and CUHK which vary in density ranging from low to very dense. The performance of our proposed approach is compared with most commonly used pixel based statistics. Our approach has the advantage of low computational complexity with high efficiency in real world applications of video surveillance.},
	journal = {Proceedings - 13th International Conference on Signal-Image Technology and Internet-Based Systems, SITIS 2017},
	author = {Lamba, Sonu and Nain, Neeta},
	year = {2018},
	note = {ISBN: 9781538642832},
	keywords = {Crowd density classification, Crowd flow estimation, RIST-LBP},
	pages = {296--302},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/P2SHC7VX/lamba2017.pdf:application/pdf},
}

@article{guangbao_grid_2004,
	title = {Grid view: {A} dynamic and visual grid monitoring system},
	doi = {10.1109/hpcasia.2004.1324020},
	abstract = {Computational and Data Grids consist of the coordinated utilization of large sets of diverse, geographically distributed resources for high performance computation. In order to make better use of these computing entities, a substantial amount of monitoring data is collected for a variety of tasks. The large number of heterogeneous resources available in Grids makes the task challenging. The processing of mass data is another problem with large amounts of monitoring data increasing. In this paper, a monitoring system in Grid environment called GridView is presented. It gathers much important information from a large computing facility. For giving more efficient performance evaluation, comprehensive computation capacity (C3) model is set up. GridView also gives mass data management mechanism and mass data visualization technique. Due to the Grid environment, GridView must consider dynamic changes and heterogeneous characteristic of different platforms.},
	number = {2002},
	journal = {Proceedings - Seventh International Conference on High Performance Computing and Grid in Asia Pacific Region, HPCAsia 2004},
	author = {Guangbao, Ni and Jie, Ma and Bo, Li},
	year = {2004},
	note = {ISBN: 076952138X},
	pages = {89--92},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/YRLNBIUR/gridview-a-dynamic-and-visual-grid-monitoring-system.pdf:application/pdf},
}

@article{hideg_data_2017,
	title = {Data collection for widely distributed mass of sensors},
	doi = {10.1109/CogInfoCom.2016.7804548},
	abstract = {Due to the increasing computational capacity of embedded systems, it has now become possible to monitor a given area efficiently by using a mass of low-cost sensors. However, the collection and analysis of such big data is still an open question from the perspective of energy efficiency. In this article will show a concept which covers the whole lifecycle of such huge scale sensor networks. We introduce a deployment and maintenance solution for uncharted areas. We present a method for gathering the measured data of each sensor and we will show a system for analyzing and visualizing the collected data.},
	number = {CogInfoCom},
	journal = {7th IEEE International Conference on Cognitive Infocommunications, CogInfoCom 2016 - Proceedings},
	author = {Hideg, Attila and Blazovics, Laszlo and Csorba, Kristof and Gotzy, Marton},
	year = {2017},
	note = {ISBN: 9781509026456},
	pages = {193--198},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/2YI5M9YA/hideg2016.pdf:application/pdf},
}

@article{patil_wifipi-tracking_2015,
	title = {{WiFiPi}-{Tracking} at mass events},
	volume = {00},
	doi = {10.1109/PERVASIVE.2015.7087170},
	abstract = {To track the crowd at mass events, real time data of people is required. By observing people and gathering the data in the desired context, more realistic tracking can be achieved. This paper presents a method of tracking the people without active cooperation of the object. Here this method works by scanning at different locations with the help of WiFi interface on visitors object. This method can be implemented using a low cost Raspberry Pi device. Raspberry Pi is recently become very popular. This method allows tracking of number of peoples and has many applications in different areas.},
	number = {c},
	journal = {2015 International Conference on Pervasive Computing: Advance Communication Technology and Application for Society, ICPC 2015},
	author = {Patil, P. H. and Kokil, A. A.},
	year = {2015},
	note = {ISBN: 9781479962723},
	keywords = {Hotspot, Raspberry Pi, Tracking, WiFi, WiFi enabled device},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/A6MLHF2X/patil2015.pdf:application/pdf},
}

@article{nascimento_modeling_2014,
	title = {Modeling and analyzing the video game live-streaming community},
	doi = {10.1109/LAWeb.2014.9},
	abstract = {In parallel to the exponential growth of the gaming industry, video game live-streaming is rising as a major form of online entertainment. Gathering a heterogeneous community, the popularity of this new media led to the creation of web services just for streaming video games, such as Twitch. TV. In this paper, we propose a model to characterize how streamers and spectators behave, based on their possible actions in Twitch and, using it, we perform a case study on the Star craft II streamers and spectators. In the case study we analyze a large amount of data collected in Twitch. TV's chat in order to better understand how streamers behave, and how this new form of online entertainment is different from previous ones. Based on this analysis, we were able to better understand channel switching, channel surfing, and to create a model for predicting the number of chat messages based on the number of spectators. We were also able to describe behavioral patterns, such as the mass evasion of spectators before the end of a streaming section in a channel.},
	journal = {Proceedings - 9th Latin American Web Congress, LA-WEB 2014},
	author = {Nascimento, Gustavo and Ribeiro, Manoel and Cerf, Loiclcerf and Cesario, Natalia and Kaytoue, Mehdi and Raissi, Chedy and Vasconcelos, Thiago and Meira, Wagner},
	year = {2014},
	note = {ISBN: 9781479969531},
	keywords = {starcraft, streaming, Tv, twitch, video game},
	pages = {1--9},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/FWSP7RPP/nascimento2014.pdf:application/pdf},
}

@article{kadar_human_2019,
	title = {Human {Activity} {Recognition} {Using} {Smartphone} {Sensors} : {A} {Dense} {Neural} {Network} {Approach}},
	volume = {2019},
	number = {Icasert},
	journal = {2019 1st International Conference on Advances in Science, Engineering and Robotics Technology (ICASERT)},
	author = {Kadar, Abdul and Masum, Muhammad},
	year = {2019},
	note = {Publisher: IEEE
ISBN: 9781728134451},
	keywords = {accelerometer, dense neural, gyroscope sensor, human activity recognition, sensor, smartphone sensor},
	pages = {1--6},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/NUNF8AEZ/muhammadmasum2019.pdf:application/pdf},
}

@article{alam_orchestration_2018,
	title = {Orchestration of {Microservices} for {IoT} {Using} {Docker} and {Edge} {Computing}},
	volume = {56},
	issn = {15581896},
	doi = {10.1109/MCOM.2018.1701233},
	abstract = {The world of connected devices has led to the rise of the Internet of Things paradigm, where applications rely on multiple devices, gathering and sharing data across highly heterogeneous networks. The variety of possible mechanisms, protocols, and hardware has become a hindrance in the development of architectures capable of addressing the most common IoT use cases, while abstracting services from the underlying communication subsystem. Moreover, the world is moving toward new strict requirements in terms of timeliness and low latency in combination with ultra-high availability and reliability. Thus, future IoT architectures will also have to support the requirements of these cyber-physical applications. In this regard, edge computing has been presented as one of the most promising solutions, relying on the cooperation of nodes by moving services directly to end devices and caching information locally. Therefore, in this article, we propose a modular and scalable architecture based on lightweight virtualization. The provided modularity, combined with the orchestration supplied by Docker, simplifies management and enables distributed deployments, creating a highly dynamic system. Moreover, characteristics such as fault tolerance and system availability are achieved by distributing the application logic across different layers, where failures of devices and micro-services can be masked by this natively redundant architecture, with minimal impact on the overall system performance. Experimental results have validated the implementation of the proposed architecture for on-demand services deployment across different architecture layers.},
	number = {9},
	journal = {IEEE Communications Magazine},
	author = {Alam, Muhammad and Rufino, Joao and Ferreira, Joaquim and Ahmed, Syed Hassan and Shah, Nadir and Chen, Yuanfang},
	year = {2018},
	pages = {118--123},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/4X248HRX/alam2018.pdf:application/pdf},
}

@article{islam_docker_2019,
	title = {Docker {Enabled} {Virtualized} {Nanoservices} for {Local} {IoT} {Edge} {Networks}},
	doi = {10.1109/CSCN.2019.8931321},
	abstract = {Edge computing is a novel computing paradigm moving server resources closer to end-devices. It helps unleashing the full potential of high-performance access networks with respect to ultra-low latency and transfer rate and improve resilience to problems at core networks and data centers. Multi-access Edge Computing (MEC), is a standard solution by European Telecommunications Standards Institute (ETSI) for access network-level edge computing. MEC, operating at access network level, is an ideal solution for the most cases. However, there are still some challenges to address: first is related to the vulnerability to access network problems and the second is about the high load inflicted to access networks and MEC servers. This is a particular issue in massive-scale Internet of Things (IoT) use cases, where numerous sensors may produce high amounts of data, or where critical system functionalities must be ensured also during access network problems. In this paper, we study the feasibility of bringing some edge functions to the local level as virtualized and dynamically deployable components utilizing local hardware capacity. For the study, we have implemented a local edge networking prototype based on local microservices, called nanoservices, implemented using Docker containers and deployed using Docker Swarm-based orchestration. Since IoT networks typically consist of constrained-capacity devices, our focus is in optimizing the resources of the proposed nanoservices.},
	journal = {2019 IEEE Conference on Standards for Communications and Networking, CSCN 2019},
	author = {Islam, Johirul and Harjula, Erkki and Kumar, Tanesh and Karhula, Pekka and Ylianttila, Mika},
	year = {2019},
	note = {Publisher: IEEE
ISBN: 9781728108643},
	keywords = {Microservices, IoT, Virtualization, Edge Computing, Nanoservices, Orchestration},
	pages = {1--7},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/K5KWTJYR/islam2019.pdf:application/pdf},
}

@article{kankanhalli_iot_2019,
	title = {{IoT} and {AI} for {Smart} {Government}: {A} {Research} {Agenda}},
	volume = {36},
	issn = {0740624X},
	doi = {10.1016/j.giq.2019.02.003},
	abstract = {The Internet of things (IoT) is the network of objects/things that contain electronics, software, sensors, and actuators, which allows these things to connect, interact, and exchange data. The users, sensors, and networks generate huge amounts of data from which governments can develop applications and gain knowledge using Artificial Intelligence (AI) techniques. Thus, IoT and AI can enable the development of valuable services for citizens, businesses, and public agencies, in multiple domains, such as transportation, energy, healthcare, education, and public safety. This guest editorial for the special issue on IoT and AI for Smart Government, identifies the challenges involved in implementing and adopting these technologies in the public sector, and proposes a comprehensive research framework, which includes both IoT and AI elements for smart government transformation. Subsequently, the editorial provides a brief introduction of the six papers in this special issue. Finally, an agenda for future research on IoT and AI for smart government is presented, based on the proposed framework and gaps in existing literature, supported by the papers that were submitted to this special issue. The agenda comprises four directions i.e., conducting domain-specific studies, going beyond adoption studies to examine implementation and evaluation of these technologies, focusing on specific challenges and thus quick wins, and expanding the existing set of research methods and theoretical foundations used.},
	number = {2},
	journal = {Government Information Quarterly},
	author = {Kankanhalli, Atreyi and Charalabidis, Yannis and Mellouli, Sehl},
	year = {2019},
	pages = {304--309},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/27FG7QD2/kankanhalli2019.pdf:application/pdf},
}

@article{buzachis_towards_2018,
	title = {Towards {Osmotic} {Computing}: {Analyzing} {Overlay} {Network} {Solutions} to {Optimize} the {Deployment} of {Container}-{Based} {Microservices} in {Fog}, {Edge} and {IoT} {Environments}},
	doi = {10.1109/CFEC.2018.8358729},
	abstract = {In recent years, the rapid growth of new Cloud technologies acted as an enabling factor for the adoption of microservices based architecture that leverages container virtualization in order to build modular and robust systems. As the number of containers running on hosts increases, it becomes essential to have tools to manage them in a simple, straightforward manner and with a high level of abstraction. Osmotic Computing is an emerging research field that studies the migration, deployment and optimization of microservices from the Cloud to Fog, Edge, and Internet of Things (IoT) environments. However, in order to achieve Osmotic Computing environments, connectivity issues have to be addressed. This paper investigates these connectivity issues leveraging different network overlays. In particular, we analyze the performance of four network overlays that are OVN, Calico, Weave, and Flannel. Our results give a concrete overview in terms of overhead and performances for each proposed overlay solution, helping us to understand which the best overlay solution is. Specifically, we deployed CoAP and FTP microservices which helped us to carry out these benchmarks and collect the results in terms of transfer times.},
	journal = {2018 IEEE 2nd International Conference on Fog and Edge Computing, ICFEC 2018 - In conjunction with 18th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing, IEEE/ACM CCGrid 2018},
	author = {Buzachis, Alina and Galletta, Antonino and Carnevale, Lorenzo and Celesti, Antonio and Fazio, Maria and Villari, Massimo},
	year = {2018},
	note = {ISBN: 9781538664889},
	keywords = {Fog computing, IoT, Virtualization, Edge Computing, Orchestration, Cloud Computing, Container, Microservice, Network overlay, Osmotic Computing},
	pages = {1--10},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/S97PXWNX/buzachis2018.pdf:application/pdf},
}

@article{krivic_microservices_2018,
	title = {Microservices as agents in {IoT} systems},
	volume = {74},
	issn = {21903026},
	doi = {10.1007/978-3-319-59394-4_3},
	abstract = {Developing robust monolith systems has achieved its limitations, since the implementation of changes in today’s large, complex, and fast evolving systems would be too slow and inefficient. As a response to these problems, microservice architecture emerged, and quickly became a widely used solution. Such modular architecture is appropriate for distributed environment of Internet of Things (IoT) solutions. In this paper we present a solution for service management on Machine-to-Machine (M2M) devices within IoT system by using collaborative microservices. Collaboration of distributed modules highly reminds of multi-agent systems where autonomous agents also cooperate to provide services to the end-user. Because of these similarities we consider microservices as modern agents that could improve systems in distributed environments, such as IoT.},
	journal = {Smart Innovation, Systems and Technologies},
	author = {Krivic, Petar and Skocir, Pavle and Kusek, Mario and Jezic, Gordan},
	year = {2018},
	note = {ISBN: 9783319593937},
	keywords = {Microservices, IoT, Agents, M2M, Service management},
	pages = {22--31},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/BKKTSJFX/krivic2017.pdf:application/pdf},
}

@article{chen_cognitive-lpwan_2019,
	title = {Cognitive-{LPWAN}: {Towards} {Intelligent} {Wireless} {Services} in {Hybrid} {Low} {Power} {Wide} {Area} {Networks}},
	volume = {3},
	issn = {24732400},
	doi = {10.1109/TGCN.2018.2873783},
	abstract = {The relentless development of the Internet of Things (IoT) communication technologies and the gradual maturity of artificial intelligence (AI) have led to a powerful cognitive computing ability. Users can now access efficient and convenient smart services in smart-city, green-IoT, and heterogeneous networks. AI has been applied in various areas, including the intelligent household, advanced health-care, automatic driving, and emotional interactions. This paper focuses on current wireless-communication technologies, including cellular-communication technologies (4G, 5G), low-power wide-area (LPWA) technologies with an unlicensed spectrum (LoRa, SigFox), and other LPWA technologies supported by 3GPP working with an authorized spectrum (EC-GSM, LTE-M, NB-IoT). We put forward a cognitive LPWA-network (Cognitive-LPWAN) architecture to safeguard stable and efficient communications in a heterogeneous IoT. To ensure that the user can employ the AI efficiently and conveniently, we realize a variety of LPWA technologies to safeguard the network layer. In addition, to balance the demand for heterogeneous IoT devices with the communication delay and energy consumption, we put forward the AI-enabled LPWA hybrid method, starting from the perspective of traffic control. The AI algorithm provides the smart control of wireless-communication technology, intelligent applications and services for the choice of different wireless-communication technologies. As an example, we consider the AIWAC emotion interaction system, build the Cognitive-LPWAN and test the proposed AI-enabled LPWA hybrid method. The experimental results show that our scheme can meet the demands of communication-delay applications. Cognitive-LPWAN selects appropriate communication technologies to achieve a better interaction experience.},
	number = {2},
	journal = {IEEE Transactions on Green Communications and Networking},
	author = {Chen, Min and Miao, Yiming and Jian, Xin and Wang, Xiaofei and Humar, Iztok},
	year = {2019},
	note = {Publisher: IEEE},
	keywords = {Artificial intelligence, LoRa, NB-IoT, LTE, low-power wide-area network},
	pages = {409--417},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/22P27ZZI/chen2018.pdf:application/pdf},
}

@article{ferrari_use_2017,
	title = {On the use of {LPWAN} for {EVehicle} to grid communication},
	volume = {2017-Janua},
	doi = {10.23919/AEIT.2017.8240531},
	abstract = {The expected diffusion of EVehicles (EVs) to limit the impact of fossil fuel on mobility is going to cause severe issues to the management of electric grid. A large number of charging stations is going to be installed on the power grid to support EVs. Each of the charging station could require more than 100 kW from the grid. The grid consumption is unpredictable and it depends from the need of EVs in the neighborhood. The impact of the EV on the power grid can be limited by the proper exploitation of Vehicle to Grid communication (V2G). The advent of Low Power Wide Area Network (LPWAN) promoted by Internet Of Things applications offers new opportunity for wireless communications. In this work, an example of such a technology (the LoRaWAN solution) is tested in a real-world scenario as a candidate for EV to grid communications. The experimental results highlight as LoRaWAN technology can be used to cover an area with a radius under 2 km, in an urban environment. At this distance, the Received Signal Strength Indicator (RSSI) is about-117 dBm. Such a result demonstrates the feasibility of the proposed approach.},
	journal = {2017 AEIT International Annual Conference: Infrastructures for Energy and ICT: Opportunities for Fostering Innovation, AEIT 2017},
	author = {Ferrari, Paolo and Flammini, Alessandra and Rinaldi, Stefano and Rizzi, Mattia and Sisinni, Emiliano},
	year = {2017},
	note = {ISBN: 9788887237375},
	keywords = {LPWAN, charging station, eVehicle, Internet of Thing, LoRa-WAN, Smart City, Smart Grid, v2g communication},
	pages = {1--6},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/UMQTFSZH/ferrari2017.pdf:application/pdf},
}

@article{morabito_legiot_2018,
	title = {{LEGIoT}: {A} {Lightweight} {Edge} {Gateway} for the {Internet} of {Things}},
	volume = {81},
	issn = {0167739X},
	url = {https://doi.org/10.1016/j.future.2017.10.011},
	doi = {10.1016/j.future.2017.10.011},
	abstract = {The stringent latency together with the higher bandwidth requirements of current Internet of Things (IoT) applications, are leading to the definition of new network-infrastructures, such as Multi-access Edge Computing (MEC). This emerging paradigm encompasses the execution of many network tasks at the edge and in particular on constrained gateways that have also to deal with the plethora of disparate technologies available in the IoT landscape. To cope with these issues, we introduce a Lightweight Edge Gateway for the Internet of Things (LEGIoT) architecture. It relies on the modular characteristic of microservices and the flexibility of lightweight virtualization technologies to guarantee an extensible and flexible solution. In particular, by combining the implementation of specific frameworks and the benefits of container-based virtualization, our proposal enhances the suitability of edge gateways towards a wide variety of IoT protocols/applications (for both downlink and uplink) enabling an optimized resource management and taking into account requirements such as energy efficiency, multi-tenancy, and interoperability. LEGIoT is designed to be hardware agnostic and its implementation has been tested within a real sensor network. Achieved results demonstrate its scalability and suitability to host different applications meant to provide a wide range of IoT services.},
	journal = {Future Generation Computer Systems},
	author = {Morabito, Roberto and Petrolo, Riccardo and Loscrì, Valeria and Mitton, Nathalie},
	year = {2018},
	note = {Publisher: Elsevier B.V.},
	keywords = {Edge computing, Internet of Things, Virtualization, Container, Gateway, Sensor network},
	pages = {1--15},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/KZ93FQSB/morabito2018.pdf:application/pdf},
}

@article{leppanen_edge-based_2019,
	title = {Edge-based microservices architecture for internet of things: {Mobility} analysis case study},
	doi = {10.1109/GLOBECOM38437.2019.9014273},
	abstract = {In this paper, we describe how the microservices paradigm can be used to design and implement distributed edge services for Internet of Things applications. As a case study, traditionally monolithic user mobility analysis service is developed, with distributed and extendable microservices, for the standardized ETSI MEC system reference architecture. In each of the edge system three tiers, microservices implement the service logic with components for movement trace analysis, movement prediction and visualization of the results. The distributed service is implemented with Docker containers and evaluated on real-world settings with low capacity edge servers and real user mobility data. The results show that the edge promise of low latency can be met in such as implementation. The integration of a software development technology with a standardized edge system provides solid background for further development.},
	journal = {2019 IEEE Global Communications Conference, GLOBECOM 2019 - Proceedings},
	author = {Leppanen, Teemu and Savaglio, Claudio and Loven, Lauri and Jarvenpaa, Tommi and Ehsani, Rouhollah and Peltonen, Ella and Fortino, Giancarlo and Riekki, Jukka},
	year = {2019},
	note = {ISBN: 9781728109626},
	keywords = {5G, Container, Mobility, Multi-access Edge Computing, Service computing},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/BXRVARYF/leppanen2019.pdf:application/pdf},
}

@article{filip_microservices_2018,
	title = {Microservices scheduling model over heterogeneous cloud-edge environments as support for {IoT} applications},
	volume = {5},
	issn = {23274662},
	doi = {10.1109/JIOT.2018.2792940},
	abstract = {Motivated by the high-interest in increasing the utilization of nongeneral purpose devices in reaching computational objectives with a reduced cost, we propose a new model for scheduling microservices over heterogeneous cloud-edge environments. Our model uses a particular mathematical formulation for describing an architecture that includes heterogeneous machines that can handle different microservices. Since any new model asks for an early risk-analysis of the solution, we improved the CloudSim simulation framework to be suitable for an experiment that includes that kind of systems. In this paper, we discuss two examples of real-life utilizations of our proposed scheduling architecture. For an objective appreciation of the first example, we also include some experimental results based on the developed simulation tool. As a result of our interpretation of the experimental results we find out that some very simple scheduling algorithms may outperform some others in given situations that are frequently present in cloud-edge environments when we are using a microservice-oriented approach.},
	number = {4},
	journal = {IEEE Internet of Things Journal},
	author = {Filip, Ion Dorinel and Pop, Florin and Serbanescu, Cristina and Choi, Chang},
	year = {2018},
	keywords = {Edge computing, Cloud computing, Energy efficiency, Heterogeneous systems, Microservice scheduling},
	pages = {2672--2681},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/DGG8PVZX/filip2018.pdf:application/pdf},
}

@article{rabah_convergence_2018,
	title = {Convergence of {AI}, {IoT}, {Big} {Data} and {Blockchain}: {A} {Review}},
	volume = {1},
	url = {www.thelakeinstitute.org},
	abstract = {Data is the lifeblood of any business. Today, big data has applications in just about every industry-retail, healthcare, financial services, government, agriculture, customer service among others. Any organization that can assimilate data to answer nagging questions about their operations can benefit from big data. In overall, the demand for big data transcend across all sectors and business. Those who work to understand their customers' business and their problems will be able to proactively identify big data solutions appropriate to their needs, and thus gain competitive advantage over their competitors. Job demand for people with big data skill-set is also in the rise especially professional, scientific and technical services; information technology; manufacturing; and finance and insurance; and retail. DevOps is baseless without the cloud. IoT needs cloud to operate efficiently, for computing is required by the cloud operate efficiently. AI remained only as model up until the advent of big data. Blockchain and related distributed ledger technologies are disrupting the technology sector as we know it. The confluence of technologies is just inevitable and often they are beneficial especially today when usher in the 4th industrial revolution (Rabah, 2017a) and the forth coming machine economy (Rabah, 2018). More-so, data is a key ingredient of approaches to developing AI and machine learning, which are now being applied to a wide variety of uses, from stock trading to chatbots to self-driving cars. There is barely a business or human activity today that is not considered as a target for AI in future years and decades.},
	number = {1},
	journal = {The Lake Institute Journal},
	author = {Rabah, Kefa},
	year = {2018},
	keywords = {Agriculture, Big data, Business modelling, Data infrastructure, Governance, Healthcare, Manufacturing indu},
	pages = {1--18},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/NHUH2U53/Fardapaper-Convergence-of-AI-IoT-Big-Data-and-Blockchain-A-Review.pdf:application/pdf},
}

@article{familiar_iot_2015,
	title = {{IoT} and {Microservices}},
	volume = {m},
	doi = {10.1007/978-1-4842-1275-2_7},
	journal = {Microservices, IoT, and Azure},
	author = {Familiar, Bob and Familiar, Bob},
	year = {2015},
	pages = {133--163},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/C5KX2X8S/familiar2015.pdf:application/pdf},
}

@article{samanta_dyme_2020,
	title = {Dyme: {Dynamic} {Microservice} {Scheduling} in {Edge} {Computing} {Enabled} {IoT}},
	volume = {4662},
	doi = {10.1109/jiot.2020.2981958},
	abstract = {In recent years, the rapid development of Mobile Edge Computing (MEC) provides an efficient execution platform at the edge for Internet-of-Things (IoT) applications. Nevertheless, the MEC also provides optimal resources to different microservices, however, underlying network conditions and infrastructures inherently affect the execution process in MEC. Therefore, in the presence of varying network conditions, it is necessary to optimally execute the available task of end-users while maximizing the energy efficiency in edge platform and we also need to provide fair Quality-of-Service (QoS). On the other hand, it is necessary to schedule the microservices dynamically to minimize the total network delay and network price. Thus in this paper, unlike most of the existing works, we propose a dynamic microservice scheduling scheme for MEC. We design the microservice scheduling framework mathematically and also discuss the computational complexity of the scheduling algorithm. Extensive simulation results show that the microservice scheduling framework significantly improves the performance metrics in terms of total network delay, average price, satisfaction level, energy consumption rate (ECR), failure rate and network throughput over other existing baselines.},
	number = {c},
	journal = {IEEE Internet of Things Journal},
	author = {Samanta, Amit and Tang, Jianhua},
	year = {2020},
	note = {Publisher: IEEE},
	pages = {1--1},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/X4YNC39W/samanta2020.pdf:application/pdf},
}

@article{shah_multi-agent_2018,
	title = {Multi-agent cognitive architecture-enabled {IoT} applications of mobile edge computing},
	volume = {73},
	issn = {19589395},
	doi = {10.1007/s12243-018-0648-1},
	abstract = {Mobile edge computing (MEC) offers cloud capabilities and service environment for Internet-of-Things (IoT) applications at the edge of the mobile network. New services for a specific set of IoT application programming interfaces (APIs) of diversified industry verticals can efficiently be deployed. As the set of APIs based on the IoT continues to thrive, reliance on the underlying cloud computing to deliver real-time and context-based services is also prominent in MEC. Due to the increased level of mutual interference of IoT APIs, the complexities are also multiplied. The set of IoT APIs competes for available resources within heterogeneous clouds (HCs). It is further aggravated by the unprecedented number of connected devices. We are presenting a cognitive agent (CA)-oriented approach to proactively subordinate IoT APIs with HCs. This paper contributes to establish an empirical multi-agent cognitive architecture framework (MCAF) for continuous transition of IoT APIs. We identified an adaptable composition method and a classification technique for CAs during this research effort. It introduces rationalization of CA creation, migration, and control. The approach achieves transparency in the heterogeneity and distribution of IoT APIs. It provides dynamism of cloud computing environments. The paper also illustrates the architecture impact analysis with the indicative capabilities of auto-scaling, predictability in HCs’ resource use, and responsiveness and attainment of IoT APIs.},
	number = {7-8},
	journal = {Annales des Telecommunications/Annals of Telecommunications},
	author = {Shah, Vikas S.},
	year = {2018},
	note = {Publisher: Annals of Telecommunications},
	keywords = {Microservices, Internet of Things (IoT), Application programming interfaces (APIs), Cognitive agents (CAs), Heterogeneous cloud services (HCSs)},
	pages = {487--497},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/AKVNREDZ/shah2018.pdf:application/pdf},
}

@article{hao_smart-edge-cocaco_2019,
	title = {Smart-{Edge}-{CoCaCo}: {AI}-{Enabled} {Smart} {Edge} with {Joint} {Computation}, {Caching}, and {Communication} in {Heterogeneous} {IoT}},
	volume = {33},
	issn = {1558156X},
	doi = {10.1109/MNET.2019.1800235},
	abstract = {The development of mobile communication technology, hardware, distributed computing, and artificial intelligence (AI) technology has promoted the application of edge computing in the field of heterogeneous IoT in order to overcome the defects of the traditional cloud computing model in the era of big data. In this article, we first propose a new AI-enabled smart edge with heterogeneous IoT architecture that combines edge computing, caching, and communication. Then we propose the Smart-Edge-CoCaCo algorithm. To minimize total delay and confirm the computation offloading decision, Smart-Edge-CoCaCo uses joint optimization of the wireless communication model, the collaborative filter caching model in edge cloud, and the computation offloading model. Finally, we built an emotion interaction testbed to perform computational delay experiments in real environments. The experiment results show that the computation delay of the Smart-Edge-CoCaCo algorithm is lower than that of the traditional cloud computing model with the increase of computing task data and the number of concurrent users.},
	number = {2},
	journal = {IEEE Network},
	author = {Hao, Yixue and Miao, Yiming and Hu, Long and Hossain, M. Shamim and Muhammad, Ghulam and Amin, Syed Umar},
	year = {2019},
	note = {Publisher: IEEE},
	pages = {58--64},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/8BAJQI9R/hao2019.pdf:application/pdf},
}

@article{colakovic_internet_2018,
	title = {Internet of {Things} ({IoT}): {A} review of enabling technologies, challenges, and open research issues},
	volume = {144},
	issn = {13891286},
	url = {https://doi.org/10.1016/j.comnet.2018.07.017},
	doi = {10.1016/j.comnet.2018.07.017},
	abstract = {IoT (Internet of Things) is a new paradigm which provides a set of new services for the next wave of technological innovations. IoT applications are nearly limitless while enabling seamless integration of the cyber-world with the physical world. However, despite the enormous efforts of standardization bodies, alliances, industries, researchers and others, there are still numerous problems to deal with in order to reach the full potential of IoT. These issues should be considered from various aspects such as enabling technologies, applications, business models, social and environmental impacts. In focus of this paper are open issues and challenges considered from the technological perspective. Just for clarification, we put in light different visions that stand behind this paradigm in order to facilitate a better understanding of the IoT's features. Furthermore, this exhaustive survey provides insights into the state-of-the-art of IoT enabling and emerging technologies. The most relevant among them are addressed with some details. The main scope is to deliver a comprehensive overview of open issues and challenges to be tackled by future research. We provide some insights into specific emerging ideas in order to facilitate future research. Also, this paper brings order in the existing literature by classifying contributions according to different research topics.},
	journal = {Computer Networks},
	author = {Čolaković, Alem and Hadžialić, Mesud},
	year = {2018},
	note = {Publisher: Elsevier B.V.},
	keywords = {Future research direction, IoT (Internet of Things), IoT enabling technologies, IoT features, IoT vision, Open issues and challenges},
	pages = {17--39},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/PWBAAPWB/10.1016@j.comnet.2018.07.017.pdf:application/pdf},
}

@article{khazaei_savi-iot_2017,
	title = {{SAVI}-{IoT}: {A} self-managing containerized {IoT} platform},
	volume = {2017-Janua},
	doi = {10.1109/FiCloud.2017.27},
	abstract = {Internet of Things (IoT) as a service is the ultimate goal of employing cloud computing paradigm for initiating IoT application scenarios. Due to the nature of IoT ecosystems, an IoT application should be distributed, programmable and autonomic; also, it requires to support heterogeneity, security and privacy by following design patterns involved in creating IoT systems. A multi-layer cloud architecture comprising of a high-capacity core center that is connected, through high speed links, to geographically distributed smart edges seem appropriate for highly distributed and heterogeneous IoT applications. Building upon our previous initiatives and inspired by the Infrastructure as Code (IoC) paradigm, in this paper, we propose and evaluate a hierarchical, programmable and autonomic IoT platform based on the microservice models. Our platform supports big data, local/edge data processing, high level of programmability and runtime autonomic management. The autonomic management system ensures the service availability, quality of service and optimized resource utilization in the whole IoT application components autonomously. The primary results affirm a promising future of our platform toward realization of IoT as a service.},
	journal = {Proceedings - 2017 IEEE 5th International Conference on Future Internet of Things and Cloud, FiCloud 2017},
	author = {Khazaei, Hamzeh and Bannazadeh, Hadi and Leon-Garcia, Alberto},
	year = {2017},
	note = {ISBN: 9781538620748},
	keywords = {Internet of Things, Auto-Scalability, Autonomic Management System, Multi-tier cloud},
	pages = {227--234},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/LPQWCVTA/khazaei2017.pdf:application/pdf},
}

@article{khaled_iot-ddl-device_2018,
	title = {{IoT}-{DDL}-{Device} {Description} {Language} for the '{T}' in {IoT}},
	volume = {6},
	issn = {21693536},
	doi = {10.1109/ACCESS.2018.2825295},
	abstract = {We argue that the success of the Internet of Things (IoT) vision will greatly depend on how its main ingredient-the 'thing'-is architected and prepared to engage. The IoT's fragmented and wide-varying nature introduces the need for additional effort to homogenize these things so they may blend together with the surrounding space to create opportunities for powerful and unprecedented IoT applications. We introduce the IoT Device Description Language (IoT-DDL), a machine-and human-readable descriptive language for things, seeking to achieve such integration and homogenization. IoT-DDL explicitly tools things to self-discover and securely share their own capabilities, entities, and services, including the various cloud-based accessories that may be attached to them. We also present the Atlas thing architecture-a lightweight architecture for things that fully exploits IoT-DDL and its specifications. Our architecture provides new OS layers, services, and capabilities we believe a thing must have in order to be prepared to engage in IoT scenarios and applications. The architecture and IoT-DDL enable things to generate their offered services and self-formulate APIs for such services, on the fly, at power-on or whenever a thing description changes. The architecture takes advantage of widely used device management, micro-services, security, and communication standards and protocols. We present details of IoT-DDL and corresponding parts of the thing architecture. We demonstrate some features of IoT-DDL and the architecture through proof-of-concept implementations. Finally, we present a benchmarking study to measure and assess time performance and energy consumption characteristics of our architecture and IoT-DDL on real hardware platforms.},
	number = {c},
	journal = {IEEE Access},
	author = {Khaled, Ahmed E. and Helal, Abdelsalam and Lindquist, Wyatt and Lee, Choonhwa},
	year = {2018},
	keywords = {microservices, CoAP, Internet of Things architecture, IPSO, MQTT, OMA, thing description},
	pages = {24048--24063},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/JBAD5F3E/iotddldevice-description-language-for-the-t-in-iot-2018.pdf:application/pdf},
}

@article{wang_enorm_2017,
	title = {{ENORM}: {A} {Framework} {For} {Edge} {NOde} {Resource} {Management}},
	volume = {X},
	issn = {19391374},
	doi = {10.1109/TSC.2017.2753775},
	abstract = {Current computing techniques using the cloud as a centralised server will become untenable as billions of devices get connected to the Internet. This raises the need for fog computing, which leverages computing at the edge of the network on nodes, such as routers, base stations and switches, along with the cloud. However, to realise fog computing the challenge of managing edge nodes will need to be addressed. This paper is motivated to address the resource management challenge. We develop the first framework to manage edge nodes, namely the Edge NOde Resource Management (ENORM) framework. Mechanisms for provisioning and auto-scaling edge node resources are proposed. The feasibility of the framework is demonstrated on a Pok\&\#x00E9;Mon Go-like online game use-case. The benefits of using ENORM are observed by reduced application latency between 20\%-80\% and reduced data transfer and communication frequency between the edge node and the cloud by up to 95\%. These results highlight the potential of fog computing for improving the quality of service and experience.},
	number = {JANUARY},
	journal = {IEEE Transactions on Services Computing},
	author = {Wang, Nan and Varghese, Blesson and Matthaiou, Michail and Nikolopoulos, Dimitrios S.},
	year = {2017},
	keywords = {Edge computing, Resource management, Cloud computing, fog computing, Computational modeling, edge nodes, provisioning, Quality of service, resource management, scaling resources, Servers},
	pages = {1--14},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/J2D88QVC/wang2017.pdf:application/pdf},
}

@article{du_computation_2018,
	title = {Computation {Offloading} and {Resource} {Allocation} in {Mixed} {Fog}/{Cloud} {Computing} {Systems} with {Min}-{Max} {Fairness} {Guarantee}},
	volume = {66},
	issn = {00906778},
	doi = {10.1109/TCOMM.2017.2787700},
	abstract = {Cooperation between the fog and the cloud in mobile cloud computing environments could offer improved offloading services to smart mobile user equipment (UE) with computation intensive tasks. In this paper, we tackle the computation offloading problem in a mixed fog/cloud system by jointly optimizing the offloading decisions and the allocation of computation resource, transmit power, and radio bandwidth while guaranteeing user fairness and maximum tolerable delay. This optimization problem is formulated to minimize the maximal weighted cost of delay and energy consumption (EC) among all UEs, which is a mixed-integer non-linear programming problem. Due to the NP-hardness of the problem, we propose a low-complexity suboptimal algorithm to solve it, where the offloading decisions are obtained via semidefinite relaxation and randomization, and the resource allocation is obtained using fractional programming theory and Lagrangian dual decomposition. Simulation results are presented to verify the convergence performance of our proposed algorithms and their achieved fairness among UEs, and the performance gains in terms of delay, EC, and the number of beneficial UEs over existing algorithms.},
	number = {4},
	journal = {IEEE Transactions on Communications},
	author = {Du, Jianbo and Zhao, Liqiang and Feng, Jie and Chu, Xiaoli},
	year = {2018},
	note = {Publisher: IEEE},
	keywords = {fog computing, cloud computing, Computation offloading, min-max fairness, resource allocation},
	pages = {1594--1608},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/5CR4G49Q/08240666(1).pdf:application/pdf},
}

@article{hong_resource_2018,
	title = {Resource management in fog/edge computing: {A} survey},
	doi = {10.1145/3326066},
	abstract = {Contrary to using distant and centralized cloud data center resources, employing decentralized resources at the edge of a network for processing data closer to user devices, such as smartphones and tablets, is an upcoming computing paradigm, referred to as fog/edge computing. Fog/edge resources are typically resource-constrained, heterogeneous, and dynamic compared to the cloud, thereby making resource management an important challenge that needs to be addressed. This article reviews publications as early as 1991, with 85\% of the publications between 2013-2018, to identify and classify the architectures, infrastructure, and underlying algorithms for managing resources in fog/edge computing.},
	number = {September},
	journal = {arXiv},
	author = {Hong, Cheol Ho and Varghese, Blesson},
	year = {2018},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/6EWTAP4E/acm_csur_resource (1)(1).pdf:application/pdf},
}

@article{aazam_offloading_2018,
	title = {Offloading in fog computing for {IoT}: {Review}, enabling technologies, and research opportunities},
	volume = {87},
	issn = {0167739X},
	url = {https://doi.org/10.1016/j.future.2018.04.057},
	doi = {10.1016/j.future.2018.04.057},
	abstract = {The digital world is expanding rapidly and advances in networking technologies such as 4G long-term evolution (LTE), wireless broadband (WiBro), low-power wide area networks (LPWAN), 5G, LiFi, and so on, all of which are paving the way for the emergence of sophisticated services. The number of online applications is increasing along with more computation, communication, and intelligent capabilities. Although current devices in use today are also getting more powerful in terms of features and capabilities, but they are still incapable of executing smart, autonomous, and intelligent tasks such as those often required for smart healthcare, ambient assisted living (AAL), virtual reality, augmented reality, intelligent vehicular communication, as well as in many services related to smart cities, Internet of Things (IoT), Tactile Internet, Internet of Vehicles (IoV), and so on. For many of these applications, we need another entity to execute tasks on behalf of the user's device and return the results - a technique often called offloading, where tasks are outsourced and the involved entities work in tandem to achieve the ultimate goal of the application. Task offloading is attractive for emerging IoT and cloud computing applications. It can occur between IoT nodes, sensors, edge devices, or fog nodes. Offloading can be performed based on different factors that include computational requirements of an application, load balancing, energy management, latency management, and so on. We present a taxonomy of recent offloading schemes that have been proposed for domains such as fog, cloud computing, and IoT. We also discuss the middleware technologies that enable offloading in a cloud-IoT cases and the factors that are important for offloading in a particular scenario. We also present research opportunities concerning offloading in fog and edge computing.},
	journal = {Future Generation Computer Systems},
	author = {Aazam, Mohammad and Zeadally, Sherali and Harras, Khaled A.},
	year = {2018},
	note = {Publisher: Elsevier B.V.},
	keywords = {Edge computing, Fog computing, Cloud computing, Internet of things (IoT), Middleware, Offloading},
	pages = {278--289},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/EET8QLI6/aazam2018(1).pdf:application/pdf},
}

@article{de_prado_smart_2020,
	title = {Smart containers schedulers for microservices provision in cloud-fog-{IoT} networks. challenges and opportunities},
	volume = {20},
	issn = {14248220},
	doi = {10.3390/s20061714},
	abstract = {Docker containers are the lightweight-virtualization technology prevailing today for the provision of microservices. This work raises and discusses two main challenges in Docker containers’ scheduling in cloud-fog-internet of things (IoT) networks. First, the convenience to integrate intelligent containers’ schedulers based on soft-computing in the dominant open-source containers’ management platforms: Docker Swarm, Google Kubernetes and Apache Mesos. Secondly, the need for specific intelligent containers’ schedulers for the different interfaces in cloud-fog-IoT networks: cloud-to-fog, fog-to-IoT and cloud-to-fog. The goal of this work is to support the optimal allocation of microservices provided by the main cloud service providers today and used by millions of users worldwide in applications such as smart health, content delivery networks, smart health, etc. Particularly, the improvement is studied in terms of quality of service (QoS) parameters such as latency, load balance, energy consumption and runtime, based on the analysis of previous works and implementations. Moreover, the scientific-technical impact of smart containers’ scheduling in the market is also discussed, showing the possible repercussion of the raised opportunities in the research line.},
	number = {6},
	journal = {Sensors (Switzerland)},
	author = {De Prado, Rocío Pérez and García-Galán, Sebastián and Muñoz-Expósito, José Enrique and Marchewka, Adam and Ruiz-Reyes, Nicolás},
	year = {2020},
	pmid = {32204390},
	keywords = {Microservices, Fog computing, Cloud computing, Machine learning, Cloud service providers, Containers, Docker, Intelligent scheduling, Iot, Soft-computing},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/79GKPM6Z/Smart_Containers_Schedulers_for_Microservices_Prov.pdf:application/pdf},
}

@article{zahoor_resource_2018,
	title = {Resource management in pervasive {Internet} of {Things}: {A} survey},
	issn = {22131248},
	url = {https://doi.org/10.1016/j.jksuci.2018.08.014},
	doi = {10.1016/j.jksuci.2018.08.014},
	abstract = {Internet of Things (IoT) embodies a vision of merging heterogeneous objects to establish seamless interaction among physical and virtual entities. IoT has given the Internet a shift from connecting networks to interconnecting the physical world. The IoT devices are capable of sensing, processing, communicating and storing the data acquired from the physical world. Most of the applications of IoT are pervasive in nature, the pervasive IoT environment poses many challenges due to constrained resources in these miniature and unattended IoT devices. This paper presents a survey of physical and virtual resource management in IoT systems. The main focus of the paper is on resource management in pervasive IoT environment with limited resources. This paper also presents a use case of IoT based Body Area Network and proposes a model for resource management in personal and community healthcare.},
	journal = {Journal of King Saud University - Computer and Information Sciences},
	author = {Zahoor, Saniya and Mir, Roohie Naaz},
	year = {2018},
	note = {Publisher: The Authors},
	keywords = {Fog computing, Internet of Things, Resource management, Body Area Networks, Data aggregation},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/H76TT2XB/1-s2.0-S1319157818305858-main(1).pdf:application/pdf},
}

@article{dubey_computation_2020,
	title = {Computation {Offloading} {Techniques} in {Mobile} {Edge} {Computing} {Environment}: {A} {Review}},
	doi = {10.1109/ICCSP48568.2020.9182210},
	abstract = {With the rapid increase in communication, correspondence and intuiting abilities of mobile devices, applications in such devices are getting highly diversified. Wireless mobile devices have various constraints like size, battery, and computational capabilities. As a solution to such restrictions technologies like mobile edge computing (MEC) came into existence. Computation offloading is a major attribute of mobile edge computing. Offloading of computationally exhaustive applications from mobile devices to the edge servers improves the battery life of mobile devices and enhances the functioning of applications. This paper introduces the existing computation offloading techniques. Secondly, comparing the performance of these techniques based on certain paradigms like power consumption and delay minimization. Thirdly, reviews some well-known simulator tools for the evaluation of new computation offloading approaches. Finally, highlights the issues faced and future work that is required to be accomplished to utilize the features of offloading in MEC in the best possible way.},
	journal = {Proceedings of the 2020 IEEE International Conference on Communication and Signal Processing, ICCSP 2020},
	author = {Dubey, Sakshi and Meena, Jasraj},
	year = {2020},
	note = {ISBN: 9781728149882},
	keywords = {Mobile edge computing, computation offloading, offloading techniques},
	pages = {1217--1223},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/6XBKKPWN/dubey2020(1).pdf:application/pdf},
}

@article{wang_survey_2020,
	title = {A {Survey} and {Taxonomy} on {Task} {Offloading} for {Edge}-{Cloud} {Computing}},
	volume = {8},
	issn = {2169-3536},
	doi = {10.1109/access.2020.3029649},
	journal = {IEEE Access},
	author = {Wang, Bo and Wang, Changhai and Huang, Wanwei and Song, Ying and Qin, Xiaoyun},
	year = {2020},
	pages = {186080--186101},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/NQAFP2BI/09217600(1).pdf:application/pdf},
}

@article{bonomi_fog_2012,
	title = {Fog computing and its role in the internet of things},
	doi = {10.1145/2342509.2342513},
	abstract = {Fog Computing extends the Cloud Computing paradigm to the edge of the network, thus enabling a new breed of applications and services. Defining characteristics of the Fog are: a) Low latency and location awareness; b) Wide-spread geographical distribution; c) Mobility; d) Very large number of nodes, e) Predominant role of wireless access, f) Strong presence of streaming and real time applications, g) Heterogeneity. In this paper we argue that the above characteristics make the Fog the appropriate platform for a number of critical Internet of Things (IoT) services and applications, namely, Connected Vehicle, Smart Grid, Smart Cities, and, in general, Wireless Sensors and Actuators Networks (WSANs). © 2012 ACM.},
	journal = {MCC'12 - Proceedings of the 1st ACM Mobile Cloud Computing Workshop},
	author = {Bonomi, Flavio and Milito, Rodolfo and Zhu, Jiang and Addepalli, Sateesh},
	year = {2012},
	keywords = {fog computing, iot, cloud computing, analytics, real time systems, software defined networks, wsan},
	pages = {13--15},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/LU8AF783/p13(2).pdf:application/pdf},
}

@article{habibi_fog_2020,
	title = {Fog {Computing}: {A} {Comprehensive} {Architectural} {Survey}},
	volume = {8},
	issn = {21693536},
	doi = {10.1109/ACCESS.2020.2983253},
	abstract = {Fog computing is an emerging technology to address computing and networking bottlenecks in large scale deployment of IoT applications. It is a promising complementary computing paradigm to cloud computing where computational, networking, storage and acceleration elements are deployed at the edge and network layers in a multi-tier, distributed and possibly cooperative manner. These elements may be virtualized computing functions placed at edge devices or network elements on demand, realizing the 'computing everywhere' concept. To put the current research in perspective, this paper provides an inclusive taxonomy for architectural, algorithmic and technologic aspects of fog computing. The computing paradigms and their architectural distinctions, including cloud, edge, mobile edge and fog computing are subsequently reviewed. Practical deployment of fog computing includes a number of different aspects such as system design, application design, software implementation, security, computing resource management and networking. A comprehensive survey of all these aspects from the architectural point of view is covered. Current reference architectures and major application-specific architectures describing their salient features and distinctions in the context of fog computing are explored. Base architectures for application, software, security, computing resource management and networking are presented and are evaluated using a proposed maturity model.},
	journal = {IEEE Access},
	author = {Habibi, Pooyan and Farhoudi, Mohammad and Kazemian, Sepehr and Khorsandi, Siavash and Leon-Garcia, Alberto},
	year = {2020},
	keywords = {Internet of Things (IoT), edge computing, fog computing, Cloud Computing, advanced internet architecture},
	pages = {69105--69133},
}

@article{alizadeh_task_2020,
	title = {Task scheduling approaches in fog computing: {A} systematic review},
	volume = {33},
	issn = {10991131},
	doi = {10.1002/dac.4583},
	abstract = {The Internet of Things (IoT) interconnects billions of physical objects to collect and exchange information and makes available various applications. Despite all the advantages of the IoT, some of its applications are not feasible because of the existing restrictions in the IoT sensors. To overcome these restrictions, cloud computing has been developed in recent years. Although cloud computing has removed some of these restrictions, the cloud itself has faced some other challenges. One of these challenges is the distance between the cloud and the end-devices, which is not ideal for delay-sensitive applications and also leads to high communication costs and security problems. To handle these challenges, the fog computing has been introduced in literature, which places the resources and services at the edge of the network, close to the end-devices. On the other hand, fog nodes suffer from heterogeneity, uncertainty, and dispersion of resources, and also processing, storage, and memory limitations. Thus, there is need for a proper task scheduling approach to use these resources optimally. In this study, the task scheduling algorithms proposed by different researchers for the cloud-fog environment, their advantages and disadvantages, and also various tools and issues regarding the scheduling methods and their restrictions were discussed. The results indicated that about 58\% of the scheduling algorithms use static scheduling and that the other 42\% use dynamic scheduling, and the delay metric is the most noteworthy parameter considered in most studies with a share of nearly 17\%. Finally, we identified the open issues related to the task scheduling based on cloud-fog computing and provided some directions for future works.},
	number = {16},
	journal = {International Journal of Communication Systems},
	author = {Alizadeh, Mohammad Reza and Khajehvand, Vahid and Rahmani, Amir Masoud and Akbari, Ebrahim},
	year = {2020},
	keywords = {Internet of Things, fog computing, cloud computing, task scheduling},
	pages = {1--36},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/DFX2Y25B/10.1002@dac.4583(1).pdf:application/pdf},
}

@article{wang_convergence_2020,
	title = {Convergence of {Edge} {Computing} and {Deep} {Learning}: {A} {Comprehensive} {Survey}},
	volume = {22},
	issn = {1553877X},
	doi = {10.1109/COMST.2020.2970550},
	abstract = {Ubiquitous sensors and smart devices from factories and communities are generating massive amounts of data, and ever-increasing computing power is driving the core of computation and services from the cloud to the edge of the network. As an important enabler broadly changing people's lives, from face recognition to ambitious smart factories and cities, developments of artificial intelligence (especially deep learning, DL) based applications and services are thriving. However, due to efficiency and latency issues, the current cloud computing service architecture hinders the vision of 'providing artificial intelligence for every person and every organization at everywhere'. Thus, unleashing DL services using resources at the network edge near the data sources has emerged as a desirable solution. Therefore, edge intelligence, aiming to facilitate the deployment of DL services by edge computing, has received significant attention. In addition, DL, as the representative technique of artificial intelligence, can be integrated into edge computing frameworks to build intelligent edge for dynamic, adaptive edge maintenance and management. With regard to mutually beneficial edge intelligence and intelligent edge, this paper introduces and discusses: 1) the application scenarios of both; 2) the practical implementation methods and enabling technologies, namely DL training and inference in the customized edge computing framework; 3) challenges and future trends of more pervasive and fine-grained intelligence. We believe that by consolidating information scattered across the communication, networking, and DL areas, this survey can help readers to understand the connections between enabling technologies while promoting further discussions on the fusion of edge intelligence and intelligent edge, i.e., Edge DL.},
	number = {2},
	journal = {IEEE Communications Surveys and Tutorials},
	author = {Wang, Xiaofei and Han, Yiwen and Leung, Victor C.M. and Niyato, Dusit and Yan, Xueqiang and Chen, Xu},
	year = {2020},
	note = {Publisher: IEEE},
	keywords = {Edge computing, deep learning, computation offloading, artificial intelligence, wireless communication},
	pages = {869--904},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/7QLBW47Z/xwang2020(1).pdf:application/pdf},
}

@article{wu_efficient_2019,
	title = {An {Efficient} {Application} {Partitioning} {Algorithm} in {Mobile} {Environments}},
	volume = {30},
	issn = {15582183},
	doi = {10.1109/TPDS.2019.2891695},
	abstract = {Application partitioning that splits the executions into local and remote parts, plays a critical role in high-performance mobile offloading systems. Optimal partitioning will allow mobile devices to obtain the highest benefit from Mobile Cloud Computing (MCC) or Mobile Edge Computing (MEC). Due to unstable resources in the wireless network (network disconnection, bandwidth fluctuation, network latency, etc.) and at the service nodes (different speeds of mobile devices and cloud/edge servers, memory, etc.), static partitioning solutions with fixed bandwidth and speed assumptions are unsuitable for offloading systems. In this paper, we study how to dynamically partition a given application effectively into local and remote parts while reducing the total cost to the degree possible. For general tasks (represented in arbitrary topological consumption graphs), we propose a Min-Cost Offloading Partitioning (MCOP) algorithm that aims at finding the optimal partitioning plan (i.e., to determine which portions of the application must run on the mobile device and which portions on cloud/edge servers) under different cost models and mobile environments. Simulation results show that the MCOP algorithm provides a stable method with low time complexity which significantly reduces execution time and energy consumption by optimally distributing tasks between mobile devices and servers, besides it adapts well to mobile environmental changes.},
	number = {7},
	journal = {IEEE Transactions on Parallel and Distributed Systems},
	author = {Wu, Huaming and Knottenbelt, William J. and Wolter, Katinka},
	year = {2019},
	keywords = {offloading, application partitioning, communication networks, Mobile cloud computing, mobile edge computing},
	pages = {1464--1480},
}

@article{tuli_fogbus_2019,
	title = {{FogBus}: {A} {Blockchain}-based {Lightweight} {Framework} for {Edge} and {Fog} {Computing}},
	volume = {154},
	issn = {01641212},
	url = {https://doi.org/10.1016/j.jss.2019.04.050},
	doi = {10.1016/j.jss.2019.04.050},
	abstract = {Recently much emphasize is given on integrating Edge, Fog and Cloud infrastructures to support the execution of various latency sensitive and computing intensive Internet of Things (IoT) applications. Although different real-world frameworks attempt to assist such integration, they have limitations in respect of platform independence, security, resource management and multi-application execution. To address these limitations, we propose a framework, named FogBus that facilitates end-to-end IoT-Fog(Edge)-Cloud integration. FogBus offers platform independent interfaces to IoT applications and computing instances for execution and interaction. It not only assists developers to build applications but also helps users to run multiple applications at a time and service providers to manage their resources. Moreover, FogBus applies Blockchain, authentication and encryption techniques to secure operations on sensitive data. Due to its simplified and cross platform software systems, it is easy to deploy, scalable and cost efficient. We demonstrate the effectiveness of FogBus by creating a computing environment with it that integrates finger pulse oximeters as IoT devices with Smartphone-based gateway and Raspberry Pi-based Fog nodes for Sleep Apnea analysis. We also evaluate the characteristics of FogBus in respect of other existing frameworks and the impact of various FogBus settings on system parameters through deployment of a real-world IoT application. The experimental results show that FogBus is comparatively lightweight and responsive, and different FogBus settings can tune the computing environment as per the situation demands.},
	journal = {Journal of Systems and Software},
	author = {Tuli, Shreshth and Mahmud, Redowan and Tuli, Shikhar and Buyya, Rajkumar},
	year = {2019},
	note = {Publisher: Elsevier Inc.},
	keywords = {Edge computing, Fog computing, Cloud computing, Blockchain, Internet of Things(IoT)},
	pages = {22--36},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/KULIT32M/1-s2.0-S0164121219300822-main.pdf:application/pdf},
}

@article{shi_emergence_2016,
	title = {The {Emergence} of {Edge} {Computing}},
	number = {0018},
	journal = {Ieee Computer Society},
	author = {Shi, Weisong and Computing, Edge},
	year = {2016},
	note = {Publisher: IEEE},
	pages = {17--20},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/7UFQU9TI/07807196.pdf:application/pdf},
}

@article{satyanarayanan_emergence_2017,
	title = {The emergence of edge computing},
	volume = {50},
	issn = {00189162},
	doi = {10.1109/MC.2017.9},
	abstract = {Industry investment and research interest in edge computing, in which computing and storage nodes are placed at the Internet's edge in close proximity to mobile devices or sensors, have grown dramatically in recent years. This emerging technology promises to deliver highly responsive cloud services for mobile computing, scalability and privacy-policy enforcement for the Internet of Things, and the ability to mask transient cloud outages. The web extra at www.youtube.com/playlist?list=PLmrZVvFtthdP3fwHPy-4d61oDvQY-RBgS includes a five-video playlist demonstrating proof-of-concept implementations for three tasks: assembling 2D Lego models, freehand sketching, and playing Ping-Pong.},
	number = {1},
	journal = {Computer},
	author = {Satyanarayanan, Mahadev},
	year = {2017},
	pages = {30--39},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/8YBTD3YI/07807196.pdf:application/pdf},
}

@article{vaquero_break_2008,
	title = {A break in the clouds: towards a cloud definition},
	volume = {39},
	issn = {0146-4833},
	doi = {10.1145/1496091.1496100},
	abstract = {This paper discusses the concept of Cloud Computing to achieve a complete definition of what a Cloud is, using the main characteristics typically associated with this paradigm in the literature. More than 20 definitions have been studied allowing for the extraction of a consensus definition as well as a minimum definition containing the essential characteristics. This paper pays much attention to the Grid paradigm, as it is often confused with Cloud technologies. We also describe the relationships and distinctions between the Grid and Cloud approaches.},
	number = {1},
	journal = {ACM SIGCOMM Computer Communication Review},
	author = {Vaquero, Luis and Rodero-Merino, Luis and Caceres, Juan and Lindner, Maik},
	year = {2008},
	keywords = {cloud computing, c, computer science, distributed computing, grid},
	pages = {50--55},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/6X2Y42XK/1496091.1496100.pdf:application/pdf},
}

@article{wen_fog_2017,
	title = {Fog orchestration for internet of things services},
	volume = {21},
	issn = {10897801},
	doi = {10.1109/MIC.2017.36},
	abstract = {Large-scale Internet of Things (IoT) services such as healthcare, smart cities, and marine monitoring are pervasive in cyber-physical environments strongly supported by Internet technologies and fog computing. Complex IoT services are increasingly composed of sensors, devices, and compute resources within fog computing infrastructures. The orchestration of such applications can be leveraged to alleviate the difficulties of maintenance and enhance data security and system reliability. However, efficiently dealing with dynamic variations and transient operational behavior is a crucial challenge within the context of choreographing complex services. Furthermore, with the rapid increase of the scale of IoT deployments, the heterogeneity, dynamicity, and uncertainty within fog environments and increased computational complexity further aggravate this challenge. This article gives an overview of the core issues, challenges, and future research directions in fog-enabled orchestration for IoT services. Additionally, it presents early experiences of an orchestration scenario, demonstrating the feasibility and initial results of using a distributed genetic algorithm in this context.},
	number = {2},
	journal = {IEEE Internet Computing},
	author = {Wen, Zhenyu and Yang, Renyu and Garraghan, Peter and Lin, Tao and Xu, Jie and Rovatsos, Michael},
	year = {2017},
	keywords = {IoT, Internet of Things, fog computing, distributed systems, fog orchestration, Internet/Web technologies},
	pages = {16--24},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/XDD5AUUZ/IC_ICSI-2016-06-0082.R2_Yang(1).pdf:application/pdf},
}

@article{scalia_break_2006,
	title = {A {Break} in the {Clouds}},
	volume = {59},
	issn = {0043-1672},
	doi = {10.3200/wewi.59.1.42-47},
	abstract = {ABSTRACT This paper discusses the concept of Cloud Computing to achieve a complete definition of what a Cloud is, using the main characteristics typically associated with this paradigm in the literature. More than 20 definitions have been studied allowing for the extraction of a ...},
	number = {1},
	journal = {Weatherwise},
	author = {Scalia, Sarah},
	year = {2006},
	keywords = {cloud computing, grid, cloud definition},
	pages = {42--47},
}

@article{mell_nist_2012,
	title = {The {NIST} definition of cloud computing: {Recommendations} of the {National} {Institute} of {Standards} and {Technology}},
	journal = {Public Cloud Computing: Security and Privacy Guidelines},
	author = {Mell, Peter and Grance, Timothy},
	year = {2012},
	note = {ISBN: 9781620819821},
	pages = {97--101},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/WSEMK3L5/2206223.pdf:application/pdf},
}

@article{vaquero_finding_2014,
	title = {Finding your way in the fog: {Towards} a comprehensive definition of fog computing},
	volume = {44},
	issn = {19435819},
	doi = {10.1145/2677046.2677052},
	abstract = {The cloud is migrating to the edge of the network, where routers themselves may become the virtualisation infrastructure, in an evolution labelled as "the fog". However, many other complementary technologies are reaching a high level of maturity. Their interplay may dramatically shift the information and communication technology landscape in the following years, bringing separate technologies into a common ground. This paper offers a comprehensive definition of the fog, comprehending technologies as diverse as cloud, sensor networks, peer-to-peer networks, network virtualisation functions or configuration management techniques. We highlight the main challenges faced by this potentially breakthrough technology amalgamation.},
	number = {5},
	journal = {Computer Communication Review},
	author = {Vaquero, Luis M. and Rodero-Merino, Luis},
	year = {2014},
	keywords = {Fog computing, Internet of Things (IoT), Cloud computing, Configuration management, Network Function Virtualisation (NFV), Peer-to-peer (P2P), Sensor networks},
	pages = {27--32},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/5WKCXUXR/vaquero2014.pdf:application/pdf},
}

@article{chiang_clarifying_2017,
	title = {Clarifying {Fog} {Computing} and {Networking}: 10 {Questions} and {Answers}},
	volume = {55},
	issn = {01636804},
	doi = {10.1109/MCOM.2017.7901470},
	number = {4},
	journal = {IEEE Communications Magazine},
	author = {Chiang, Mung and Ha, Sangtae and Chih-Lin, I. and Risso, Fulvio and Zhang, Tao},
	year = {2017},
	pages = {18--20},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/V8HLLFEB/07901470.pdf:application/pdf},
}

@article{atzori_understanding_2017,
	title = {Understanding the {Internet} of {Things}: definition, potentials, and societal role of a fast evolving paradigm},
	issn = {15708705},
	doi = {10.1016/j.adhoc.2016.12.004},
	abstract = {The high penetration rate of new technologies in all the activities of everyday life is fostering the belief that for any new societal challenge there is always an ICT solution able to successfully deal with it. Recently, the solution that is proposed almost anytime is the “Internet of Things” (IoT). This apparent panacea of the ICT world takes different aspects on and, actually, is identified with different (often very different) technological solutions. As a result, many think that IoT is just RFIDs, others think that it is sensor networks, and yet others that it is machine-to-machine communications. In the meanwhile, industrial players are taking advantage of the popularity of IoT to use it as a very trendy brand for technology solutions oriented to the consumer market. The scientific literature sometimes does not help much in clarifying, as it is rich in definitions of IoT often discordant between them. Objective of this paper is to present the evolutionary stages, i.e., generations, that have characterized the development of IoT, along with the motivations of their triggering. Besides, it analyzes the role that IoT can play in addressing the main societal challenges and the set of features expected from the relevant solutions. The final objective is to give a modern definition of the phenomenon, which de facto shows a strong pervasive nature, and, if not well understood in its theories, technologies, methodologies, and real potentials, then runs the risk of being regarded with suspicion and, thus, rejected by users.},
	journal = {Ad Hoc Networks},
	author = {Atzori, Luigi and Iera, Antonio and Morabito, Giacomo},
	year = {2017},
	keywords = {Internet of Things, Cloud of things, Web of things},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/BJYE7AEM/paper6.pdf:application/pdf},
}

@article{sobecki_deep_2019,
	title = {Deep learning in the fog},
	volume = {15},
	issn = {15501477},
	doi = {10.1177/1550147719867072},
	abstract = {In the era of a ubiquitous Internet of Things and fast artificial intelligence advance, especially thanks to deep learning networks and hardware acceleration, we face rapid growth of highly decentralized and intelligent solutions that offer functionality of data processing closer to the end user. Internet of Things usually produces a huge amount of data that to be effectively analyzed, especially with neural networks, demands high computing capabilities. Processing all the data in the cloud may not be sufficient in cases when we need privacy and low latency, and when we have limited Internet bandwidth, or it is simply too expensive. It poses a challenge for creating a new generation of fog computing that supports artificial intelligence and selects the architecture appropriate for an intelligent solution. In this article, we show from four perspectives, namely, hardware, software libraries, platforms, and current applications, the landscape of components used for developing intelligent Internet of Things solutions located near where the data are generated. This way, we pinpoint the odds and risks of artificial intelligence fog computing and help in the process of selecting suitable architecture and components that will satisfy all requirements defined by the complex Internet of Things systems.},
	number = {8},
	journal = {International Journal of Distributed Sensor Networks},
	author = {Sobecki, Andrzej and Szymański, Julian and Gil, David and Mora, Higinio},
	year = {2019},
	keywords = {Internet of Things, edge computing, fog computing, deep neural networks},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/4K3KGTKS/1550147719867072(1)(2).pdf:application/pdf},
}

@article{santana_microservices_2018,
	title = {Microservices: {A} mapping study for internet of things solutions},
	doi = {10.1109/NCA.2018.8548331},
	abstract = {The Internet of Things (IoT) involves the connectivity of a number of different physical and virtual devices, allowing the development of new services and applications. These intelligent objects, along with their tasks, constitute domain-specific applications (vertical markets), while ubiquitous and analytical services form domain-independent services (horizontal markets). The development of these applications and services in these markets brings challenges such as deployment, scalability, integration, interoperability, mobility and performance. Recent researches indicates that Microservices have been adopted in several domains such as IoT. This paper provides an overview of the current state of the art (studies selected by May 2018) regarding the adoption of Microservices in the development of IoT applications by means of the mapping study methodology. In this context, we present the eighteen selected studies, the existing contributions and the future research perspectives.},
	journal = {NCA 2018 - 2018 IEEE 17th International Symposium on Network Computing and Applications},
	author = {Santana, Cleber and Alencar, Brenno and Prazeres, Cassio},
	year = {2018},
	note = {ISBN: 9781538676592},
	keywords = {Microservices, Internet of Things, Cloud Computing, Fog Computing, Reactive Microservices, systematic mapping study},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/GXYAZSUM/08548331(2).pdf:application/pdf},
}

@book{sunyaev_internet_2020,
	title = {Internet {Computing}},
	author = {Sunyaev, Ali},
	year = {2020},
	doi = {10.1007/978-3-030-34957-8},
	note = {Publication Title: Internet Computing},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/9RNI66Q4/Internet Computing E-book.pdf:application/pdf},
}

@book{data_ieee_2018,
	title = {{IEEE} 1934-2018 - {IEEE} {Standard} for {Adoption} of {OpenFog} {Reference} {Architecture} for {Fog} {Computing}},
	isbn = {978-1-5044-5017-1},
	url = {https://standards.ieee.org/standard/1934-2018.html},
	author = {Data, Big and Committee, Standards},
	year = {2018},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/EP6CDRTJ/1934-2018.pdf:application/pdf},
}

@article{consortium_openfog_2017,
	title = {{OpenFog} {Reference} {Architecture} for {Fog} {Copmuting}},
	number = {February},
	author = {Consortium, OpenFog},
	year = {2017},
	pages = {1--162},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/AZZFPXM5/07_OpenFog.pdf:application/pdf},
}

@article{sadri_fog_2021,
	title = {Fog data management: {A} vision, challenges, and future directions},
	volume = {174},
	issn = {10958592},
	doi = {10.1016/j.jnca.2020.102882},
	abstract = {Cloud computing with its key facets and its inherent advantages still faces several challenges in the Internet of Things (IoT) ecosystem. The distance among the IoT end devices and cloud computing might be a problem for latency-sensitive applications such as catastrophe management and content transference applications. Fog computing is a novel paradigm to address such issues that playacts a significant role in massive and real-time data management systems in an IoT environment. Particularly IoT data management by fog computing is one important phase for latency reduction in latency-sensitive applications and necessary to generate more skilled knowledge and intelligent decisions. In this study, we used the SLR (systematic literature review) method to survey fog data management to understand the various topics and main contexts in this domain that have been newly offered. The target of this article is classifying and analyzing the researches about the fog data management domain which has been released from 2014 to 2019. A context-based taxonomy is offered for fog data management including data processing, data storage and data security based on the context of papers that are elected with the SLR method in our study. Based on presented technical taxonomy, the grouped papers in any context are compared with each other pursuant to some metrics of fog data management reference model. Then, for any selected research, the new findings, advantages, and weaknesses are debated. Finally, based on studies the open issues in fog data management and their related challenges for future researches are highlighted.},
	journal = {Journal of Network and Computer Applications},
	author = {Sadri, Ali Akbar and Rahmani, Amir Masoud and Saberikamarposhti, Morteza and Hosseinzadeh, Mehdi},
	year = {2021},
	keywords = {Systematic literature review, Fog computing, Internet of things, Data analytics, Data management, Data processing, Data security, Data storage},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/4LAA2I3E/1-s2.0-S1084804520303465-main(1).pdf:application/pdf},
}

@article{soldani_pains_2018,
	title = {The pains and gains of microservices: {A} {Systematic} grey literature review},
	volume = {146},
	issn = {01641212},
	url = {https://doi.org/10.1016/j.jss.2018.09.082},
	doi = {10.1016/j.jss.2018.09.082},
	abstract = {The design, development, and operation of microservices are picking up more and more momentum in the IT industry. At the same time, academic work on the topic is at an early stage, and still on the way to distilling the actual “Pains \& Gains” of microservices as an architectural style. Having witnessed this gap, we set forth to systematically analyze the industrial grey literature on microservices, to identify the technical/operational pains and gains of the microservice-based architectural style. We conclude by discussing research directions stemming out from our analysis.},
	journal = {Journal of Systems and Software},
	author = {Soldani, Jacopo and Tamburri, Damian Andrew and Van Den Heuvel, Willem Jan},
	year = {2018},
	note = {Publisher: Elsevier Inc.},
	keywords = {Microservices, Systematic literature review, Microservices design, Microservices development, Microservices operation, Systematic grey literature review},
	pages = {215--232},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/Z4MGX3I5/1-s2.0-S0164121218302139-main.pdf:application/pdf},
}

@article{luan_fog_2015,
	title = {Fog {Computing}: {Focusing} on {Mobile} {Users} at the {Edge}},
	url = {http://arxiv.org/abs/1502.01815},
	abstract = {With smart devices, particular smartphones, becoming our everyday companions, the ubiquitous mobile Internet and computing applications pervade people daily lives. With the surge demand on high-quality mobile services at anywhere, how to address the ubiquitous user demand and accommodate the explosive growth of mobile traffics is the key issue of the next generation mobile networks. The Fog computing is a promising solution towards this goal. Fog computing extends cloud computing by providing virtualized resources and engaged location-based services to the edge of the mobile networks so as to better serve mobile traffics. Therefore, Fog computing is a lubricant of the combination of cloud computing and mobile applications. In this article, we outline the main features of Fog computing and describe its concept, architecture and design goals. Lastly, we discuss some of the future research issues from the networking perspective.},
	author = {Luan, Tom H. and Gao, Longxiang and Li, Zhi and Xiang, Yang and Wei, Guiyi and Sun, Limin},
	year = {2015},
}

@article{dai_choreography_2020,
	title = {A {Choreography} {Analysis} {Approach} for {Microservice} {Composition} in {Cyber}-{Physical}-{Social} {Systems}},
	volume = {8},
	issn = {21693536},
	doi = {10.1109/ACCESS.2020.2980891},
	abstract = {Choreography-driven microservice composition has provided a better way to integrate components in the Cyber-physical-Social System (CPSS). Choreography is a global contract that specifies interactions among microservices participating in a composite service. After modeling a choreography, a problem arises here is whether the choreography specification at design time can be implemented correctly by generated microservices that interact with each other via exchanging messages. In this paper, we propose a novel approach for choreography analysis. Specifically, a choreography is specified using a Labeled Transition Systems (LTSs); then, the microservices participating in a composite service can be generated from the given choreography via projection and \${\textbackslash}varepsilon \$ -remove; finally, the analysis of the choreography can be checked for both synchronous and asynchronous compositions using refinement checking. Our approach is completely automated under the support of our developed tool and the Process Analysis Toolkit (PAT) tool.},
	journal = {IEEE Access},
	author = {Dai, Fei and Mo, Qi and Qiang, Zhenping and Huang, Bi and Kou, Weili and Yang, Hongji},
	year = {2020},
	keywords = {choreography, cyber-physical-social system, microservice, peer to peer communication, Service composition},
	pages = {53215--53222},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/7E9CWUDP/09036947(2).pdf:application/pdf},
}

@article{harjula_decentralized_2019,
	title = {Decentralized {Iot} edge nanoservice architecture for future gadget-free computing},
	volume = {7},
	issn = {21693536},
	doi = {10.1109/ACCESS.2019.2936714},
	abstract = {In the envisioned ubiquitous world, services will follow users as they move across smart surroundings. Services are instantiated to users through the environment, appearing and disappearing as they move, which reduces the need for personal communication devices such as smartphones or tablets. To facilitate this development, service architectures need to support virtualized, on-demand service composition based on the hardware and software resources available at the current user location. The technical context for this type of user interaction with digital services through smart surroundings is called Internet of Everything (IoE). Today's service architectures will be too inflexible in this highly decentralized and dynamic environment. Hence, in this article we propose a novel service model called nanoEdge, where nodes collaboratively provide needed functions for virtual services that need to be deployed locally due to performance, efficiency or reliability requirements, for example. The main contributions of this article are the nanoEdge conceptual model and its proof-of-concept (PoC) implementation to show that the model is feasible with regard to performance and resource-efficiency. The successful demonstration of PoC implementation exemplifies future IoE service scenarios with today's hardware components.},
	journal = {IEEE Access},
	author = {Harjula, Erkki and Karhula, Pekka and Islam, Johirul and Leppänen, Teemu and Manzoor, Ahsan and Liyanage, Madhusanka and Chauhan, Jagmohan and Kumar, Tanesh and Ahmad, Ijaz and Ylianttila, Mika},
	year = {2019},
	keywords = {Microservices, Edge computing, Fog computing, IoT, Virtualization, Nanoservices, Gadget-free computing, IoE},
	pages = {119856--119872},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/BVHALEAX/08808867(1).pdf:application/pdf},
}

@article{qiao_thingnet_2018,
	title = {{ThingNet}: {A} micro-service based {IoT} macro-programming platform over edges and cloud},
	doi = {10.1109/ICIN.2018.8401626},
	abstract = {The enormous number of things connected to the Internet requires a flexible macro-programming platform to efficiently organize functions and process data. Fog or Edge computing is an emerging architecture to fill the gaps between things and cloud through providing computing, storage and forwarding services close to the end devices. This paper presents ThingNet- A micro-service based macro-programming platform to enable distributed data routing and processing across IoT devices, edges and central cloud. Application providers can deploy, modify, migrate and scale application logic over underlying infrastructures. An application level service function chaining is designed to enable data flow programming. The service functions can be shared by multiple data flows to reduce resource utilisation. The platform is implemented based on open source platforms including Kubernetes and MiNifi. ThingNet has been verified through a proof of concept testbed including Raspberry Pis, Intel NUCs, and Openstack VMs.},
	journal = {21st Conference on Innovation in Clouds, Internet and Networks, ICIN 2018},
	author = {Qiao, Yuansong and Nolani, Robert and Gill, Saul and Fang, Guiming and Lee, Brian},
	year = {2018},
	note = {ISBN: 9781538634585},
	keywords = {IoT, Edge Computing, Fog Computing, Macro-programming, Micro-service},
	pages = {1--4},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/68F3YPMZ/qiao2018.pdf:application/pdf},
}

@article{mostafa_application_2019,
	title = {Application in {Fog} {Computing} {Using} {Microservices} {Case} {Study} : {Traffic} {Management} {System}},
	abstract = {Fog computing is a new computational paradigm proposed by Cisco that subdues the shortcomings of cloud computing in Internet of Things (IoT) by transferring some of the core functions of cloud computing towards the edge of the network to provide low latency, real-time, and location-aware services required for billions of edge devices. But in case of high load on some fog layer, its fog nodes do vertical offloading to a higher layer or to the cloud faraway again from the edge which in turn increases the latency while in this case the need for low latency is highly required to handle the load quickly. The main goal of this research is to develop a cognitive and context-aware horizontal offloading mechanism for IoT applications in fog computing to keep the computations as much as possible in the same fog layer in case of high load using the same available resources instead of offloading to a higher layer or to the cloud depending on three main technologies, Virtualization, Containerization and Microservices. By nature, while moving towards the edge the capabilities of the fog nodes decrease but at the same time their number increases, therefore, if it's possible to well utilize the larger number of fog nodes in lower fog layers near to the edge by offloading the computations from the loaded fog nodes to less loaded ones in the same fog layer then high load can be horizontally handled in the same fog layer using the same available resources, also the number and nature of functions that can be carried out in the fog will increase. But IoT is very dynamic so that the mechanism must be cognitive and contextaware to select (in a real-time fashion) the most appropriate fog nodes for offloading without affecting their performance in serving their main functions and geographic areas, also it's very important to efficiently decide when to consider horizontal or vertical offloading in order not to waste time trying to handle the load horizontally while vertical offloading is the appropriate decision. The mechanism depends on dividing the IoT application into a set of microservices which is the most appropriate architecture for the nature of fog computing with multiple geographically distributed fog nodes with limited capabilities such that each microservice is responsible for only one function and isolated in containers hosted in the fog nodes, the offloading is performed at the level of the microservices by watching, analyzing and considering their load patterns and their availability for offloading (Offloading Map). By simulating the mechanism on the traffic management system, each fog node can horizontally handle extra requests over its maximum capacity up to 30\% for each hosted microservice by offloading to 2 microservices, and up to 100\% in case there are 7 available offloading microservices.},
	journal = {2019 IEEE Jordan International Joint Conference on Electrical Engineering and Information Technology (JEEIT)},
	author = {Mostafa, Mostafa Abd Al Azim and Khater, Ahmad Mohammad and Mostafa, Prof and Mostafa, Abd Al-azim},
	year = {2019},
	note = {Publisher: IEEE
ISBN: 9781538679425},
	keywords = {Microservices, IoT, microservices, offloading, fog computing, iot, cloud computing, Cloud Computing, Offloading, Fog Computing, containerization, Containerization},
	pages = {640--647},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/NJQS3MHY/08717462(2).pdf:application/pdf},
}

@article{al-masri_enhancing_2019,
	title = {Enhancing the {Microservices} {Architecture} for the {Internet} of {Things}},
	doi = {10.1109/BigData.2018.8622557},
	abstract = {Collecting data from smart Internet of Things (IoT) devices is becoming an increasingly essential part of many of the existing industrial applications. The importance of this data collection relies on the fact that it can uncover valuable insights and enable smarter, faster decision making. This enables organizations to quickly adapt to changes in the workflows, reduce downtime and expand the production capacity and enhance the overall operating efficiency. The problem, however, is that many of these Industrial IoT (IIoT) applications can considerably be influenced by the composition of RESTFul APIs and the microservices architecture they integrate. In addition, IIoT applications do not take into consideration the dynamism of service-based environments and requirements. To overcome these challenges, it is essential to consider the Quality of Service (QoS) characteristics of RESTful APIs and microservices particularly that these properties may fluctuate during their lifecycle. In this paper, we introduce a quality-aware microservices' architecture that continuously monitors the behavior of these services in delivering the required functionality. This paper presents experimental validation results and analysis of the presented ideas.},
	journal = {Proceedings - 2018 IEEE International Conference on Big Data, Big Data 2018},
	author = {Al-Masri, Eyhab},
	year = {2019},
	note = {Publisher: IEEE
ISBN: 9781538650356},
	keywords = {microservices, fog computing, APIs, IoT devices, IoT discovery, IoT gateways, REST, RESTful},
	pages = {5119--5125},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/PNWTUDPM/08622557(1).pdf:application/pdf},
}

@article{taherizadeh_capillary_2018,
	title = {A capillary computing architecture for dynamic internet of things: {Orchestration} of microservices from edge devices to fog and cloud providers},
	volume = {18},
	issn = {14248220},
	doi = {10.3390/s18092938},
	abstract = {The adoption of advanced Internet of Things (IoT) technologies has impressively improved in recent years by placing such services at the extreme Edge of the network. There are, however, specific Quality of Service (QoS) trade-offs that must be considered, particularly in situations when workloads vary over time or when IoT devices are dynamically changing their geographic position. This article proposes an innovative capillary computing architecture, which benefits from mainstream Fog and Cloud computing approaches and relies on a set of new services, including an Edge/Fog/Cloud Monitoring System and a Capillary Container Orchestrator. All necessary Microservices are implemented as Docker containers, and their orchestration is performed from the Edge computing nodes up to Fog and Cloud servers in the geographic vicinity of moving IoT devices. A car equipped with a Motorhome Artificial Intelligence Communication Hardware (MACH) system as an Edge node connected to several Fog and Cloud computing servers was used for testing. Compared to using a fixed centralized Cloud provider, the service response time provided by our proposed capillary computing architecture was almost four times faster according to the 99th percentile value along with a significantly smaller standard deviation, which represents a high QoS.},
	number = {9},
	journal = {Sensors (Switzerland)},
	author = {Taherizadeh, Salman and Stankovski, Vlado and Grobelnik, Marko},
	year = {2018},
	pmid = {30181454},
	keywords = {Microservices, Edge computing, Fog computing, Internet of things, Container-based virtualization, On/offloading},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/AA6HBCX6/091f1cbe1e7456cd15e037155c2a0323.pdf:application/pdf},
}

@article{butzin_microservices_2016,
	title = {Microservices approach for the internet of things},
	volume = {2016-Novem},
	issn = {19460759},
	doi = {10.1109/ETFA.2016.7733707},
	abstract = {The microservice approach has created a hype in the domain of cloud and enterprise application business. Before, grown, monolithic, software has been pushed to the limits of maintainability and scalability. The microservice architecture approach utilizes the service oriented architecture together with best practices and recent developments in software virtualization to overcome those issues. One monolithic application is split up into a set of distributed services. Those are strongly decoupled to enable high maintainability and scalability. In this case an application is split up in a top down manner.},
	number = {September},
	journal = {IEEE International Conference on Emerging Technologies and Factory Automation, ETFA},
	author = {Butzin, Bjorn and Golatowski, Frank and Timmermann, Dirk},
	year = {2016},
	note = {ISBN: 9781509013142},
	keywords = {microservices, internet of things, best practices, distributed services, patterns, service oriented architecture},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/JR3GZXD7/MicroservicesApproachfortheInternetofThings.pdf:application/pdf},
}

@article{taneja_fog_2018,
	title = {Fog assisted application support for animal behaviour analysis and health monitoring in dairy farming},
	volume = {2018-Janua},
	doi = {10.1109/WF-IoT.2018.8355141},
	abstract = {With the exponential growth rate of technology, the future of all activities, including dairy farming involves an omnipresence of widely connected devices. Internet of things (IoT), fog computing, cloud computing and data analytics together offer a great opportunity to increase productivity in the dairy industry. In this paper, we present a fog computing assisted application system for animal behaviour analysis and health monitoring in a dairy farming scenario. The sensed data from sensors is sent to a fog based platform for data classification and analysis, which includes decision making capabilities. The solution aims towards keeping track of the animals' well-being by delivering early warning alerts generated through behavioural analytics, thus aiding the farmer to monitor the health of their livestock and the capability to identify potential diseases at an early stage, thereby also helping in increasing milk yield and productivity. The proposed system follows a service based model, avoids vendor lock-in, and is also scalable to add new features such as the detection of calving, heat, and issues like lameness.},
	journal = {IEEE World Forum on Internet of Things, WF-IoT 2018 - Proceedings},
	author = {Taneja, Mohit and Byabazaire, John and Davy, Alan and Olariu, Cristian},
	year = {2018},
	note = {ISBN: 9781467399449},
	keywords = {Microservices, Internet of Things (IoT), Cloud Computing, Fog Computing, Dairy Farming, Data Analytics, Real-time, Smart Farm},
	pages = {819--824},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/JCZHI4S8/taneja2018.pdf:application/pdf},
}

@article{xu_blendmas_2019,
	title = {{BlendMAS}: {A} blockchain-enabled decentralized microservices architecture for smart public safety},
	doi = {10.1109/Blockchain.2019.00082},
	abstract = {Thanks to rapid technological advances in the Internet of Things (IoT), a smart public safety (SPS) system has become feasible by integrating heterogeneous computing devices to collaboratively provide public protection services. While service-oriented architecture (SOA) has been adopted by IoT and cyber-physical systems (CPS), it is difficult for a monolithic architecture to provide scalable and extensible services for a distributed IoT based SPS system. Furthermore, traditional security solutions rely on a centralized authority, which can be a performance bottleneck or single point failure. Inspired by microservices architecture and blockchain technology, this paper proposes a BLockchain-ENabled Decentralized Microservices Architecture for Smart public safety (BlendMAS). Within a permissioned blockchain network, a microservices based security mechanism is introduced to secure data access control in an SPS system. The functionality of security services is decoupled into separate containerized microservices that are built using a smart contract and deployed on edge and fog computing nodes. An extensive experimental study verified that the proposed BlendMAS is able to offer a decentralized, scalable and secured data sharing and access control to distributed IoT based SPS system.},
	journal = {Proceedings - 2019 2nd IEEE International Conference on Blockchain, Blockchain 2019},
	author = {Xu, Ronghua and Nikouei, Seyed Yahya and Chen, Yu and Blasch, Erik and Aved, Alexander},
	year = {2019},
	note = {Publisher: IEEE
ISBN: 9781728146935},
	keywords = {Internet of Things (IoT), Blockchain, Microservices Architecture, Smart Contract, Smart Public Safety (SPS)},
	pages = {564--571},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/LZUEG5VC/10.1109@Blockchain.2019.00082.pdf:application/pdf},
}

@article{baresi_unified_2019,
	title = {A unified model for the mobile-edge-cloud continuum},
	volume = {19},
	issn = {15576051},
	doi = {10.1145/3226644},
	abstract = {Technologies such as mobile, edge, and cloud computing have the potential to form a computing continuum for new, disruptive applications. At runtime, applications can choose to execute parts of their logic on different infrastructures that constitute the continuum, with the goal of minimizing latency and battery consumption and maximizing availability. In this article, we propose A3-E, a unified model for managing the life cycle of continuum applications. In particular, A3-E exploits the Functions-as-a-Service model to bring computation to the continuum in the form of microservices. Furthermore, A3-E selects where to execute a certain function based on the specific context and user requirements. The article also presents a prototype framework that implements the concepts behind A3-E. Results show that A3-E is capable of dynamically deploying microservices and routing the application's requests, reducing latency by up to 90\% when using edge instead of cloud resources, and battery consumption by 74\% when computation has been offloaded.},
	number = {2},
	journal = {ACM Transactions on Internet Technology},
	author = {Baresi, L. and Mendonça, D. F. and Garriga, M. and Guinea, S. and Quattrocchi, G.},
	year = {2019},
	keywords = {Edge computing, Fog computing, Mobile computing, Computing continuum, Functions-as-a-Service, Ops automation, Real-time systems},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/VMBWIMRR/3226644.pdf:application/pdf},
}

@article{pallewatta_microservices-based_2019,
	title = {Microservices-based {IoT} application placement within heterogeneous and resource constrained fog computing environments},
	doi = {10.1145/3344341.3368800},
	abstract = {Fog computing paradigm has created innovation opportunities within Internet of Things (IoT) domain by extending cloud services to the edge of the network. Due to the distributed, heterogeneous and resource constrained nature of the Fog computing nodes, Fog applications need to be developed as a collection of interdependent, lightweight modules. Since this concept aligns with the goals of microservices architecture, efficient placement of microservices-based IoT applications within Fog environments has the potential to fully leverage capabilities of Fog devices. In this paper, we propose a decentralized microservices-based IoT application placement policy for heterogeneous and resource constrained Fog environments. The proposed policy utilizes the independently deployable and scalable nature of microservices to place them as close as possible to the data source to minimize latency and network usage. Moreover, it aims to handle service discovery and load balancing related challenges of the microservices architecture. We implement and evaluate our policy using iFogSim simulated Fog environment. Results of the simulations show around 85\% improvement in latency and network usage for the proposed microservice placement policy when compared with Cloud-only placement approach and around 40\% improvement over an alternative Fog application placement method known as Edge-ward placement policy. Moreover, the decentralized placement approach proposed in this paper demonstrates significant reduction in microservice placement delay over centralized placement.},
	journal = {UCC 2019 - Proceedings of the 12th IEEE/ACM International Conference on Utility and Cloud Computing},
	author = {Pallewatta, Samodha and Kostakos, Vassilis and Buyya, Rajkumar},
	year = {2019},
	note = {ISBN: 9781450368940},
	keywords = {Fog computing, Application placement, Internet of things (IoT), Application deployment, Microservices architecture},
	pages = {71--81},
	file = {Pallewatta et al_2019_Microservices-based IoT application placement within heterogeneous and resource.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/AJHKD3UZ/Pallewatta et al_2019_Microservices-based IoT application placement within heterogeneous and resource.pdf:application/pdf;PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/56RNEAA6/MicroServiceFog-UCC2019(1).pdf:application/pdf},
}

@article{shih_nfv-based_2019,
	title = {An {NFV}-{Based} {Service} {Framework} for {IoT} {Applications} in {Edge} {Computing} {Environments}},
	volume = {16},
	issn = {19324537},
	doi = {10.1109/TNSM.2019.2948764},
	abstract = {Emerging Internet of Things (IoT) applications share the same characteristics of involving multiple processing components (i.e., function modules) and requiring a massive amount of data to be processed with low latency. To meet these needs, edge/fog computing has been proposed for next-generation mobile networks to migrate the computing from the cloud to the edge of the network. Thanks to the development of Network Functions Virtualization (NFV), with which edge computing platform can virtualize function modules and deploy them on any edge devices to provide flexible services on the edge networks. However, such platform would need to deal with complicated function module calling relationship (i.e., call graph) of applications and user mobility, and both are not thoroughly considered by existing works of NFV and edge computing. In this paper, based on our previous idea of virtual local-hub (VLH), we propose a complete design of edge computing framework, which applies NFV technology on edge computing environment for IoT applications. To handle the complicated call graphs of IoT applications with better resource utilization, the VLH framework adapts the technologies of container-based virtualization and microservice architecture, which enables remote function module sharing on the edge computing environment. The framework includes the heuristic algorithm for function module allocation with the objective of minimizing total bandwidth consumption. We also present a design of protocols for system operations and mobility handling in the framework. Then we implement the framework on commodity hardware as a testbed. Via simulations under a large-scale environment with practical settings and experiments on the testbed under real-world scenarios, we demonstrate and verify the effectiveness and practicability of the proposed VLH framework for IoT application service provision.},
	number = {4},
	journal = {IEEE Transactions on Network and Service Management},
	author = {Shih, Yuan Yao and Lin, Hsin Peng and Pang, Ai Chun and Chuang, Ching Chih and Chou, Chun Ting},
	year = {2019},
	note = {Publisher: IEEE},
	keywords = {microservices, Internet of Things, edge computing, fog computing, container-based virtualization, Network functions virtualization, wearable device},
	pages = {1419--1434},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/H4WIKA3J/08880517(1).pdf:application/pdf},
}

@article{diaz-sanchez_dnsdane_2019,
	title = {{DNS}/{DANE} collision-based distributed and dynamic authentication for microservices in {IoT}},
	volume = {19},
	issn = {14248220},
	doi = {10.3390/s19153292},
	abstract = {IoT devices provide real-time data to a rich ecosystem of services and applications. The volume of data and the involved subscribe/notify signaling will likely become a challenge also for access and core networks. To alleviate the core of the network, other technologies like fog computing can be used. On the security side, designers of IoT low-cost devices and applications often reuse old versions of development frameworks and software components that contain vulnerabilities. Many server applications today are designed using microservice architectures where components are easier to update. Thus, IoT can benefit from deploying microservices in the fog as it offers the required flexibility for the main players of ubiquitous computing: nomadic users. In such deployments, IoT devices need the dynamic instantiation of microservices. IoT microservices require certificates so they can be accessed securely. Thus, every microservice instance may require a newly-created domain name and a certificate. The DNS-based Authentication of Named Entities (DANE) extension to Domain Name System Security Extensions (DNSSEC) allows linking a certificate to a given domain name. Thus, the combination of DNSSEC and DANE provides microservices’ clients with secure information regarding the domain name, IP address, and server certificate of a given microservice. However, IoT microservices may be short-lived since devices can move from one local fog to another, forcing DNSSEC servers to sign zones whenever new changes occur. Considering DNSSEC and DANE were designed to cope with static services, coping with IoT dynamic microservice instantiation can throttle the scalability in the fog. To overcome this limitation, this article proposes a solution that modifies the DNSSEC/DANE signature mechanism using chameleon signatures and defining a new soft delegation scheme. Chameleon signatures are signatures computed over a chameleon hash, which have a property: a secret trapdoor function can be used to compute collisions to the hash. Since the hash is maintained, the signature does not have to be computed again. In the soft delegation schema, DNS servers obtain a trapdoor that allows performing changes in a constrained zone without affecting normal DNS operation. In this way, a server can receive this soft delegation and modify the DNS zone to cope with frequent changes such as microservice dynamic instantiation. Changes in the soft delegated zone are much faster and do not require the intervention of the DNS primary servers of the zone.},
	number = {15},
	journal = {Sensors (Switzerland)},
	author = {Díaz-Sánchez, Daniel and Marín-Lopez, Andrés and Mendoza, Florina Almenárez and Cabarcos, Patricia Arias},
	year = {2019},
	pmid = {31357487},
	keywords = {Microservices, IoT, Chameleon signatures, DANE, DNSSEC},
	pages = {1--23},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/MX6M3A7J/10.3390@s19153292.pdf:application/pdf},
}

@article{taneja_smartherd_2019,
	title = {{SmartHerd} management: {A} microservices-based fog computing–assisted {IoT} platform towards data-driven smart dairy farming},
	volume = {49},
	issn = {1097024X},
	doi = {10.1002/spe.2704},
	abstract = {Internet of Things (IoT), fog computing, cloud computing, and data-driven techniques together offer a great opportunity for verticals such as dairy industry to increase productivity by getting actionable insights to improve farming practices, thereby increasing efficiency and yield. In this paper, we present SmartHerd, a fog computing–assisted end-to-end IoT platform for animal behavior analysis and health monitoring in a dairy farming scenario. The platform follows a microservices-oriented design to assist the distributed computing paradigm and addresses the major issue of constrained Internet connectivity in remote farm locations. We present the implementation of the designed software system in a 6-month mature real-world deployment, wherein the data from wearables on cows is sent to a fog-based platform for data classification and analysis, which includes decision-making capabilities and provides actionable insights to farmer towards the welfare of animals. With fog-based computational assistance in the SmartHerd setup, we see an 84\% reduction in amount of data transferred to the cloud as compared with the conventional cloud-based approach.},
	number = {7},
	journal = {Software - Practice and Experience},
	author = {Taneja, Mohit and Jalodia, Nikita and Byabazaire, John and Davy, Alan and Olariu, Cristian},
	year = {2019},
	keywords = {Internet of Things (IoT), microservices, fog computing, cloud computing, dairy farming, data analytics, data-driven, smart farm},
	pages = {1055--1078},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/3DUWA9D6/taneja2019(1).pdf:application/pdf},
}

@article{kayal_autonomic_2019,
	title = {Autonomic service placement in fog computing},
	doi = {10.1109/WoWMoM.2019.8792989},
	abstract = {Fog computing recently emerged as novel distributed virtualized computing paradigm, where cloud services are extended to the edge of the network, thereby increasing network capacity and reducing latencies. In fog computing, applications are composed of building blocks, called microservices, that are mapped to edge computing and communication devices, referred to as fog nodes. A crucial component in fog computing are placement algorithms that assign microservices to fog nodes, since they determine the overall system performance in terms of energy consumption, communication costs, load balancing, and others. Placement strategies for virtual machines in cloud computing abound, but are generally centralized and therefore not well suited for decentralized fog systems. In this paper, we develop a fully distributed placement strategy that jointly optimizes energy consumption of fog nodes and communication costs of applications. We follow a Markov approximation approach for the design of a fully distributed autonomic service placement strategy without central coordination or global state information. Using numerical examples, we show that our placement algorithm finds solutions that are comparable to existing centralized solutions.},
	number = {August},
	journal = {20th IEEE International Symposium on A World of Wireless, Mobile and Multimedia Networks, WoWMoM 2019},
	author = {Kayal, Paridhika and Liebeherr, Jorg},
	year = {2019},
	note = {ISBN: 9781728102702},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/NRLWGS85/WoWMoM(1).pdf:application/pdf},
}

@article{mendes_vitasenior-mt_2019,
	title = {{VITASENIOR}-{MT}: {A} distributed and scalable cloud-based telehealth solution},
	doi = {10.1109/WF-IoT.2019.8767184},
	abstract = {VITASENIOR-MT is a telehealth platform that allows to remotely monitor biometric and environmental data in a domestic environment, designed specifically to the elderly population. This paper proposes a highly scalable and efficient architecture to transport, process, store and visualize the data collected by devices of an Internet of Things (IoT) scenario. The cloud infrastructure follows a microservices architecture to provide computational scalability, better fault isolation, easy integration and automatic deployment. This solution is complemented with a pre-processing and validation of the collected data at the edge of the Internet by using the Fog Computing concept, allowing a better computing distribution. The presented approach provides personal data security and a simplified way to collect and present the data to the different actors, allowing a dynamic and intuitive management of patients and equipment to caregivers. The presented load tests proved that this solution is more efficient than a monolithic approach, promoting better access and control in the data flowing from heterogeneous equipment.},
	number = {April},
	journal = {IEEE 5th World Forum on Internet of Things, WF-IoT 2019 - Conference Proceedings},
	author = {Mendes, Diogo and Jorge, Dario and Pires, Gabriel and Panda, Renato and Antonio, Ricardo and Dias, Pedro and Oliveira, Luis},
	year = {2019},
	note = {ISBN: 9781538649800},
	keywords = {Microservices, IoT, Cloud Computing, Fog Computing, Telehealth},
	pages = {767--772},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/UGMLJCF4/preprint-paperWFIOT2019.pdf:application/pdf},
}

@article{kayal_kubernetes_2020,
	title = {Kubernetes in {Fog} {Computing}: {Feasibility} {Demonstration}, {Limitations} and {Improvement} {Scope} : r},
	doi = {10.1109/WF-IoT48130.2020.9221340},
	abstract = {Fog computing (also known as edge computing) is a decentralized computing architecture that seeks to minimize service latency and average response time in IoT applications by providing compute and network services physically close to end-users. Fog environment consists of a network of fog nodes and IoT applications are composed of containerized microservices communicating with each other. Due to limited resources of fog nodes, it is often not possible to deploy all the containers of an application on a single fog node. Therefore, communicating containers need to be distributed on multiple fog nodes. Distribution and management of containerized IoT applications is always a critical issue to the system performance in a fog environment. Kubernetes, an open-source system, has grown into a container orchestration standard by simplifying the deployment and management of containerized applications. Despite the progress made by the academia and industry with respect to container management and the wide-scale acceptance of Kubernetes in cloud environments, container management in fog environment is still in the early stage in terms of research and practical deployment. This article aims to fill this gap by analyzing the expediency of Kubernetes container orchestration tool in the fog computing model. The paper also highlights limitations with the current Kubernetes approach and provide ideas for further research to adapt to the needs of the fog environment. Lastly, we provide experiments that demonstrate the feasibility and industrial practicality of deploying and managing containerized IoT applications in the fog computing environment.},
	journal = {IEEE World Forum on Internet of Things, WF-IoT 2020 - Symposium Proceedings},
	author = {Kayal, Paridhika},
	year = {2020},
	note = {ISBN: 9781728155036},
	keywords = {Fog computing, microservices, Docker, fog nodes, Kubernetes},
	pages = {1--6},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/9WPYFZBP/09221340.pdf:application/pdf},
}

@article{li_fast_2020,
	title = {A fast and scalable authentication scheme in {IoT} for smart living},
	issn = {23318422},
	abstract = {Numerous resource-limited smart objects (SOs) such as sensors and actuators have been widely deployed in smart environments, opening new attack surfaces to intruders. The severe security flaw discourages the adoption of the Internet of things in smart living. In this paper, we leverage fog computing and microservice to push certificate authority (CA) functions to the proximity of data sources. Through which, we can minimize attack surfaces and authentication latency, and result in a fast and scalable scheme in authenticating a large volume of resource-limited devices. Then, we design lightweight protocols to implement the scheme, where both a high level of security and low computation workloads on SO (no bilinear pairing requirement on the client-side) is accomplished. Evaluations demonstrate the efficiency and effectiveness of our scheme in handling authentication and registration for a large number of nodes, meanwhile protecting them against various threats to smart living. Finally, we showcase the success of computing intelligence movement towards data sources in handling complicated services.},
	journal = {arXiv},
	author = {Li, Jianhua Jack and Jin, Jiong and Lyu, Lingjuan and Yuan, Dong and Yang, Yingying and Gao, Longxiang and Shen, Chao},
	year = {2020},
	keywords = {Fog computing, Internet of Things (IoT), Virtualization, Microservice, Certificate authority (CA), Device-to-Device authenticatio},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/S86X3V72/2011.06325.pdf:application/pdf},
}

@article{vetoshkin_towards_2020,
	title = {Towards the {Fog} {Computing} {PaaS} {Solution}},
	doi = {10.1109/USBEREIT48449.2020.9117791},
	abstract = {Nowadays, the cloud computing approach is used to solve a wide variety of tasks. It provides access to virtually infinite amount of computing resources. However, a number of issues arise when it is necessary to provide computational services requiring low latency. The growing demand for services with low latency motivates to place computing resources at the edge of the network. This study suggests the architecture of a PaaS platform providing computational resources based on the concept of fog computing which is intended to solve this problem. This platform should control, conFigure and provide fog computing resources in automatic mode. During the process of computer system design, the main tasks were detected and tools for their solution were found. The most important tasks are the following: the communication pattern of the internal services, container orchestration and user data storage. The system deployment will be based on heterogeneous computing resources including the resources of SUSU supercomputer center.},
	journal = {Proceedings - 2020 Ural Symposium on Biomedical Engineering, Radioelectronics and Information Technology, USBEREIT 2020},
	author = {Vetoshkin, Nikita and Radchenko, Gleb},
	year = {2020},
	note = {ISBN: 9781728131658},
	keywords = {microservices, fog computing, containerization, computing system},
	pages = {516--519},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/JZI74CI5/09117791.pdf:application/pdf},
}

@article{zhao_microservice_2020,
	title = {Microservice {Based} {Computational} {Offloading} {Framework} and {Cost} {Efficient} {Task} {Scheduling} {Algorithm} in {Heterogeneous} {Fog} {Cloud} {Network}},
	volume = {8},
	issn = {21693536},
	doi = {10.1109/ACCESS.2020.2981860},
	abstract = {Nowadays, the usage of the fog cloud-based Internet of Things (IoT) applications among users has been growing progressively. These applications may be E-Transport, E-Healthcare, Augmented Reality, and 3D-Game. Generally, contemporary cloud frameworks offer services based on virtual machines. These frameworks incurred with following issues such as long boot-Time, overhead and unnecessary cost to run the IoT applications. We propose a new Microservice container fog system (MSCFS) based framework to run the mobility and delay-sensitive applications with minimum cost. The study the cost-efficient task scheduling problem in the heterogeneous fog servers. Furthermore, the study introduces the Cost Aware Computational Offloading and task scheduling (CACOTS)framework, which solves the task scheduling into multiple steps. Such as task sequencing step, resource matching step and scheduling step. The experimental results prove that the proposed MSCFS and CACOTS schemes can enhance server utilization. As decrease the services latency and average services bootup time more effectively, and minimize costs.},
	journal = {IEEE Access},
	author = {Zhao, Xuehua and Huang, Changcheng},
	year = {2020},
	keywords = {microservices, Task scheduling, boot-up time, container, fog servers},
	pages = {56680--56694},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/VARSIFHA/09042334(2).pdf:application/pdf},
}

@article{abdullah_predictive_2020,
	title = {Predictive {Autoscaling} of {Microservices} {Hosted} in {Fog} {Microdata} {Center}},
	issn = {1932-8184},
	doi = {10.1109/jsyst.2020.2997518},
	abstract = {Fog computing provides micro data center (MDC) facilities closer to the users and applications, which help to overcome the application latency and response time concerns. However, to guarantee specific service level objectives (SLO) for the applications running on MDC required automatic scaling of allocated resources by efficiently utilizing the available infrastructure capacity. In this paper, we propose a novel predictive autoscaling method for microservices running on Fog MDC to satisfy the application response time SLO. Initially, our proposed approach uses a reactive rule-based autoscaling method to gather the training dataset for building the predictive autoscaling model. The proposed approach is efficient as it can learn the predictive autoscaling model using an increasing synthetic workload. The learned predictive autoscaling model is used to manage the application resources serving different realistic workloads effectively. Our experimental evaluation using two synthetic and three realistic workloads for two benchmark microservice applications on a real MDC shows excellent performance compared to the existing state-of-the-art baseline rule-based autoscaling method. The proposed autoscaling method yields 75.51\% reduction of rejected requests and 77.53\% fewer number of SLO violations compared to the baseline autoscaling methods by using only 9.20\% additional data center resources at the Fog layer.},
	journal = {IEEE Systems Journal},
	author = {Abdullah, Muhammad and Iqbal, Waheed and Mahmood, Arif and Bukhari, Faisal and Erradi, Abdelkarim},
	year = {2020},
	pages = {1--12},
}

@article{xavier_time_2016,
	title = {Time {Provisioning} {Evaluation} of {KVM}, {Docker} and {Unikernels} in a {Cloud} {Platform}},
	doi = {10.1109/CCGrid.2016.86},
	abstract = {Unikernels are a promising alternative for application deployment in cloud platforms. They comprise a very small footprint, providing better deployment agility and portability among virtualization platforms. Similar to Linux containers, they are a lightweight alternative for deploying distributed applications based on microservices. However, the comparison of unikernels with other virtualization options regarding the concurrent provisioning of instances, as in the case of microservices-based applications, is still lacking. This paper provides an evaluation of KVM (Virtual Machines), Docker (Containers), and OSv (Unikernel), when provisioning multiple instances concurrently in an OpenStack cloud platform. We confirmed that OSv outperforms the other options and also identified opportunities for optimization.},
	journal = {Proceedings - 2016 16th IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing, CCGrid 2016},
	author = {Xavier, Bruno and Ferreto, Tiago and Jersak, Luis},
	year = {2016},
	note = {ISBN: 9781509024520},
	keywords = {cloud computing, hypervisor, linux containers, unikernels},
	pages = {277--280},
}

@article{santos_towards_2020,
	title = {Towards delay-aware container-based {Service} {Function} {Chaining} in {Fog} {Computing}},
	doi = {10.1109/NOMS47738.2020.9110376},
	abstract = {Recently, the fifth-generation mobile network (5G) is getting significant attention. Empowered by Network Function Virtualization (NFV), 5G networks aim to support diverse services coming from different business verticals (e.g. Smart Cities, Automotive, etc). To fully leverage on NFV, services must be connected in a specific order forming a Service Function Chain (SFC). SFCs allow mobile operators to benefit from the high flexibility and low operational costs introduced by network softwarization. Additionally, Cloud computing is evolving towards a distributed paradigm called Fog Computing, which aims to provide a distributed cloud infrastructure by placing computational resources close to end-users. However, most SFC research only focuses on Multi-access Edge Computing (MEC) use cases where mobile operators aim to deploy services close to end-users. Bi-directional communication between Edges and Cloud are not considered in MEC, which in contrast is highly important in a Fog environment as in distributed anomaly detection services. Therefore, in this paper, we propose an SFC controller to optimize the placement of service chains in Fog environments, specifically tailored for Smart City use cases. Our approach has been validated on the Kubernetes platform, an open-source orchestrator for the automatic deployment of micro-services. Our SFC controller has been implemented as an extension to the scheduling features available in Kubernetes, enabling the efficient provisioning of container-based SFCs while optimizing resource allocation and reducing the end-to-end (E2E) latency. Results show that the proposed approach can lower the network latency up to 18\% for the studied use case while conserving bandwidth when compared to the default scheduling mechanism.},
	journal = {Proceedings of IEEE/IFIP Network Operations and Management Symposium 2020: Management in the Age of Softwarization and Artificial Intelligence, NOMS 2020},
	author = {Santos, Jose and Wauters, Tim and Volckaert, Bruno and De Turck, Filip},
	year = {2020},
	note = {ISBN: 9781728149738},
	keywords = {IoT, Fog Computing, Kubernetes, Resource Provisioning, Service Function Chain},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/FRF2LEFM/Towards delay-aware container-based Service Function Chaining in Fog.pdf:application/pdf},
}

@article{gedeon_microservice_2019,
	title = {A microservice store for efficient edge offloading},
	doi = {10.1109/GLOBECOM38437.2019.9014114},
	abstract = {Current edge computing frameworks require tight coupling between mobile clients and surrogates, i.e., the offloaded code has been preconfigured with its required execution environment. In many cases, this includes prior transfers of code blocks or execution environments from mobile devices to the offloading infrastructure. This approach incurs additional latency and is detrimental for the energy consumption of the mobile devices. In this paper, we propose the concept of a microservice store. Using the microservice abstraction common in software development and following the serverless paradigm, we envision a repository through which said services are made accessible to developers and can be re-used across applications. We implement a proof-of-concept edge computing system based on a microservice repository and demonstrate its benefits with real-world applications on mobile devices. Our results show that we were able to reduce latencies by up to 14x and save up to 94\% of battery life.},
	journal = {2019 IEEE Global Communications Conference, GLOBECOM 2019 - Proceedings},
	author = {Gedeon, Julien and Wagner, Martin and Heuschkel, Jens and Wang, Lin and Muhlhauser, Max},
	year = {2019},
	note = {ISBN: 9781728109626},
	keywords = {Microservices, Edge computing, Fog computing, Computation offloading, Cyber foraging, Serverless},
}

@article{goethals_fledge_2020,
	title = {{FLEDGE}: {Kubernetes} {Compatible} {Container} {Orchestration} on {Low}-{Resource} {Edge} {Devices}},
	volume = {11894 LNCS},
	issn = {16113349},
	doi = {10.1007/978-3-030-38651-1_16},
	abstract = {In recent years, containers have quickly gained popularity in the cloud, mostly thanks to their scalable, ethereal and isolated nature. Simultaneously, edge devices have become powerful enough to run containerized microservices, while remaining small and low-powered. These evolutions have triggered a wave of research into container placement strategies on clusters including edge devices, leading to concepts such as fog computing. These container placement strategies can optimize workload placement across cloud and edge clusters, but current container orchestrators are very resource intensive and are not designed to run on edge devices. This paper presents FLEDGE as a Kubernetes compatible edge container orchestrator. A number of aspects of how to achieve low-resource container orchestration are examined, for example the choice of container runtime and how to implement container networking. Finally, a number of evaluations are performed, comparing FLEDGE to K3S and Kubernetes, to show that it is a viable alternative to existing container orchestrators.},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Goethals, Tom and De Turck, Filip and Volckaert, Bruno},
	year = {2020},
	note = {ISBN: 9783030386504},
	keywords = {Edge computing, Containers, Container orchestration, Edge networks, VPN},
	pages = {174--189},
}

@article{sami_dynamic_2020,
	title = {Dynamic {On}-{Demand} {Fog} {Formation} {Offering} {On}-the-{Fly} {IoT} {Service} {Deployment}},
	volume = {17},
	issn = {19324537},
	doi = {10.1109/TNSM.2019.2963643},
	abstract = {With the increasing number of IoT devices, fog computing has emerged, providing processing resources at the edge for the tremendous amount of sensed data and IoT computation. The advantage of the fog gets eliminated if it is not present near IoT devices. Fogs nowadays are pre-configured in specific locations with pre-defined services, which limit their diverse availabilities and dynamic service update. In this paper, we address the aforementioned problem by benefiting from the containerization and micro-service technologies to build our on-demand fog framework with the help of the volunteering devices. Our approach overcomes the current limitations by providing available fog devices with the ability to have services deployed on the fly. Volunteering devices form a resource capacity for building the fog computing infrastructure. Moreover, our framework leverages intelligent container placement scheme that produces efficient volunteers' selection and distribution of services. An Evolutionary Memetic Algorithm (MA) is elaborated to solve our multi-objective container placement optimization problem. Real life and simulated experiments demonstrate various improvements over existing approaches interpreted by the relevance and efficiency of (1) forming volunteering fog devices near users with maximum time availability and shortest distance, and (2) deploying services on the fly on selected fogs with improved QoS.},
	number = {2},
	journal = {IEEE Transactions on Network and Service Management},
	author = {Sami, Hani and Mourad, Azzam},
	year = {2020},
	keywords = {IoT, edge computing, fog computing, Kubernetes, container placement, docker, evolutionary memetic algorithm, Kubeadm, micro-services, on-demand fog formation},
	pages = {1026--1039},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/5BPDH6M9/Dynamic On-Demand Fog Formation Offering.pdf:application/pdf},
}

@article{sami_vehicular-obus-as--demand-fogs_2020,
	title = {Vehicular-{OBUs}-{As}-{On}-{Demand}-{Fogs}: {Resource} and {Context} {Aware} {Deployment} of {Containerized} {Micro}-{Services}},
	volume = {28},
	issn = {15582566},
	doi = {10.1109/TNET.2020.2973800},
	abstract = {Observing the headway in vehicular industry, new applications are developed demanding more resources. For instance, real-time vehicular applications require fast processing of the vast amount of generated data by vehicles in order to maintain service availability and reachability while driving. Fog devices are capable of bringing cloud intelligence near the edge, making them a suitable candidate to process vehicular requests. However, their location, processing power, and technology used to host and update services affect their availability and performance while considering the mobility patterns of vehicles. In this paper, we overcome the aforementioned limitations by taking advantage of the evolvement of On-Board Units, Kubeadm Clustering, Docker Containerization, and micro-services technologies. In this context, we propose an efficient resource and context aware approach for deploying containerized micro-services on on-demand fogs called Vehicular-OBUs-As-On-Demand-Fogs. Our proposed scheme embeds (1) a Kubeadm based approach for clustering OBUs and enabling on-demand micro-services deployment with the least costs and time using Docker containerization technology, (2) a hybrid multi-layered networking architecture to maintain reachability between the requesting user and available vehicular fog cluster, and (3) a vehicular multi-objective container placement model for producing efficient vehicles selection and services distribution. An Evolutionary Memetic Algorithm is elaborated to solve our vehicular container placement problem. Experiments and simulations demonstrate the relevance and efficiency of our approach compared to other recent techniques in the literature.},
	number = {2},
	journal = {IEEE/ACM Transactions on Networking},
	author = {Sami, Hani and Mourad, Azzam and El-Hajj, Wassim},
	year = {2020},
	keywords = {Docker, container, Kubeadm, micro-services, memetic algorithm, on-demand fog placement, orchestration, vehicular clustering, vehicular edge computing, vehicular fog computing, Vehicular on-boarding units (OBUs)},
	pages = {778--790},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/IGJPZTF9/Vehicular-OBUs-As-On-Demand-Fogs Resource.pdf:application/pdf},
}

@book{newman_building_2015,
	title = {Building {Microservices}},
	isbn = {978-1-4919-5035-7},
	url = {https://www.google.hr/books?hl=en&lr=&id=jjl4BgAAQBAJ&pgis=1%5Cnhttp:// oreilly.com/catalog/errata.csp?isbn=9781491950357},
	abstract = {Distributed systems have become more fine-grained in the past 10 years, shifting from code-heavy monolithic applications to smaller, self-contained microservices. But developing these systems brings its own set of headaches. With lots of examples and practical advice, this book takes a holistic view of the topics that system architects and administrators must consider when building, managing, and evolving microservice architectures.Microservice technologies are moving quickly. Author Sam Newman provides you with a firm grounding in the concepts while diving into current solutions for modeling, integrating, testing, deploying, and monitoring your own autonomous services. You’ll follow a fictional company throughout the book to learn how building a microservice architecture affects a single domain.Discover how microservices allow you to align your system design with your organization’s goalsLearn options for integrating a service with the rest of your systemTake an incremental approach when splitting monolithic codebasesDeploy individual microservices through continuous integrationExamine the complexities of testing and monitoring distributed servicesManage security with user-to-service and service-to-service modelsUnderstand the challenges of scaling microservice architectures},
	author = {Newman, Sam},
	year = {2015},
	note = {Publication Title: O'Reilly},
	keywords = {www.it-ebooks.info},
}

@article{taneja_machine_2020,
	title = {Machine learning based fog computing assisted data-driven approach for early lameness detection in dairy cattle},
	volume = {171},
	issn = {01681699},
	doi = {10.1016/j.compag.2020.105286},
	abstract = {Timely lameness detection is one of the major and costliest health problems in dairy cattle that farmers and practitioners haven't yet solved adequately. The primary reason behind this is the high initial setup costs, complex equipment and lack of multi-vendor interoperability in currently available solutions. On the other hand, human observation based solutions relying on visual inspections are prone to late detection with possible human error, and are not scalable. This poses a concern with increasing herd sizes, as prolonged or undetected lameness severely compromises cows' health and welfare, and ultimately affects the milk productivity of the farm. To tackle this, we have developed an end-to-end IoT application that leverages advanced machine learning and data analytics techniques to monitor the cattle in real-time and identify lame cattle at an early stage. The proposed approach has been validated on a real world smart dairy farm setup consisting of a dairy herd of 150 cows in Waterford, Ireland. Using long-range pedometers specifically designed for use in dairy cattle, we monitor the activity of each cow in the herd. The accelerometric data from these sensors is aggregated at the fog node to form a time series of behavioral activities, which are further analyzed in the cloud. Our hybrid clustering and classification model identifies each cow as either Active, Normal or Dormant, and further, Lame or Non-Lame. The detected lameness anomalies are further sent to farmer's mobile device by way of push notifications. The results indicate that we can detect lameness 3 days before it can be visually captured by the farmer with an overall accuracy of 87\%. This means that the animal can either be isolated or treated immediately to avoid any further effects of lameness. Moreover, with fog based computational assistance in the setup, we see an 84\% reduction in amount of data transferred to the cloud as compared to the conventional cloud based approach.},
	journal = {Computers and Electronics in Agriculture},
	author = {Taneja, Mohit and Byabazaire, John and Jalodia, Nikita and Davy, Alan and Olariu, Cristian and Malone, Paul},
	year = {2020},
	keywords = {Microservices, Fog computing, Internet of Things (IoT), Cloud computing, Classification, Machine learning, Clustering, Data analytics, Data-driven, Smart dairy farming, Smart farm},
}

@article{paul_martin_crew_2020,
	title = {{CREW}: {Cost} and {Reliability} aware {Eagle}-{Whale} optimiser for service placement in {Fog}},
	volume = {50},
	issn = {1097024X},
	doi = {10.1002/spe.2896},
	abstract = {Integration of Internet of Things (IoT) with industries revamps the traditional ways in which industries work. Fog computing extends Cloud services to the vicinity of end users. Fog reduces delays induced by communication with the distant clouds in IoT environments. The resource constrained nature of Fog computing nodes demands an efficient placement policy for deploying applications, or their services. The distributed and heterogeneous features of Fog environments deem it imperative to consider the reliability performance parameter in placement decisions to provide services without interruptions. Increasing reliability leads to an increase in the cost. In this article, we propose a service placement policy which addresses the conflicting criteria of service reliability and monetary cost. A multiobjective optimisation problem is formulated and a novel placement policy, Cost and Reliability-aware Eagle-Whale (CREW), is proposed to provide placement decisions ensuring timely service responses. Considering the exponentially large solution space, CREW adopts Eagle strategy based multi-Whale optimisation for taking placement decisions. We have considered real time microservice applications for validating our approaches, and CREW has been experimentally shown to outperform the existing popular multiobjective meta-heuristics such as NSGA-II and MOWOA based placement strategies.},
	number = {12},
	journal = {Software - Practice and Experience},
	author = {Paul Martin, John and Kandasamy, A. and Chandrasekaran, K.},
	year = {2020},
	keywords = {Fog computing, Cloud computing, service placement, resource management, Fogonomics, monetary cost, multi-Whale optimisation algorithm, NSGA-II, reliability},
	pages = {2337--2360},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/XM5CLZLY/10.1002@spe.2896(1)(1).pdf:application/pdf},
}

@article{faticanti_deployment_2020,
	title = {Deployment of {Application} {Microservices} in {Multi}-{Domain} {Federated} {Fog} {Environments}},
	doi = {10.1109/COINS49042.2020.9191379},
	abstract = {In this paper we consider the problem of initial resource selection for a single-domain fog provider lacking sufficient resources for the complete deployment of a batch of IoT applications. To overcome resources shortage, it is possible to lease assets from other domains across a federation of cloud-fog infrastructures to meet the requirements of those applications: The fog provider seeks to minimise the number of external resources to be rented in order to successfully deploy the applications' demands exceeding own infrastructure capacity. To this aim, we introduce a general framework for the deployment of applications across multiple domains of cloud-fog providers while guaranteeing resources locality constraints. The resource allocation problem is presented in the form of an integer linear program, and we provide a heuristic method that explores the resource assignment space in a breadth-first fashion. Extensive numerical results demonstrate the efficiency of the proposed approach in terms of deployment cost and feasibility with respect to standard approaches adopted in the literature.},
	journal = {2020 International Conference on Omni-Layer Intelligent Systems, COINS 2020},
	author = {Faticanti, Francescomaria and Savi, Marco and Pellegrini, Francesco De and Kochovski, Petar and Stankovski, Vlado and Siracusa, Domenico},
	year = {2020},
	note = {ISBN: 9781728163710},
	keywords = {Microservices, Fog Computing, Federation, Locality Constraints, Resources Allocation, Virtual Network Embedding},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/SS7YKFLE/faticanti2020.pdf:application/pdf},
}

@article{chemodanov_policy-based_2019,
	title = {Policy-based function-centric computation offloading for real-time drone video analytics},
	volume = {2019-July},
	issn = {19440375},
	doi = {10.1109/LANMAN.2019.8847112},
	abstract = {Computer vision applications are increasingly used on mobile Internet-of-Things (IoT) devices such as drones. They provide real-time support in disaster/incident response or crowd protest management scenarios by e.g., counting human/vehicles, or recognizing faces/objects. However, deployment of such applications for real-time video analytics at geo-distributed areas presents new challenges in processing intensive media-rich data to meet users' Quality of Experience (QoE) expectations, due to limited computing power on the devices. In this paper, we present a novel policy-based decision computation offloading scheme that not only facilitates trade-offs in performance vs. cost, but also aids in offloading decision to either an Edge, Cloud or Function-Centric Computing resource architecture for real-time video analytics. To evaluate our offloading scheme, we decompose an existing computer vision pipeline for object/motion detection and object classification into a chain of container-based micro-service functions that communicate via a RESTful API. We evaluate the performance of our scheme on a realistic geo-distributed edge/core cloud testbed using different policies and computing architectures. Results show how our scheme utilizes state-of-the-art computation offloading techniques to Pareto-optimally trade-off performance (i.e., frames-per-second) vs. cost factors (using Amazon Web Services Lambda pricing) during real-time drone video analytics, and thus fosters effective environmental situational awareness.},
	journal = {IEEE Workshop on Local and Metropolitan Area Networks},
	author = {Chemodanov, Dmitrii and Qu, Chengyi and Opeoluwa, Osunkoya and Wang, Songjie and Calyam, Prasad},
	year = {2019},
	note = {Publisher: IEEE
ISBN: 9781728114347},
	keywords = {Cloud/fog Computing, Computation offloading policies, Drone video analytics, Function-centric computing},
	pages = {1--6},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/NZLRI8ZR/Policy-Based Function-Centric Computation Offloading for Real-Time Drone Video Analytics.pdf:application/pdf},
}

@article{faticanti_throughput-aware_2020,
	title = {Throughput-{Aware} {Partitioning} and {Placement} of {Applications} in {Fog} {Computing}},
	volume = {17},
	issn = {19324537},
	doi = {10.1109/TNSM.2020.3023011},
	abstract = {Fog computing promises to extend cloud computing to match emerging demands for low latency, location-awareness and dynamic computation. It thus brings data processing close to the edge of the network by leveraging on devices with different computational characteristics. However, the heterogeneity, the geographical distribution, and the data-intensive profiles of IoT deployments render the placement of fog applications a fundamental problem to guarantee target performance figures. This is a core challenge for fog computing providers to offer fog infrastructure as a service, while satisfying the requirements of this new class of microservices-based applications. In this article we root our analysis on the throughput requirements of the applications while exploiting offloading towards different regions. The resulting resource allocation problem is developed for a fog-native application architecture based on containerised microservice modules. An algorithmic solution is designed to optimise the placement of applications modules either in cloud or in fog. Finally, the overall solution consists of two cascaded algorithms. The first one performs a throughput-oriented partitioning of fog application modules. The second one rules the orchestration of applications over a region-based infrastructure. Extensive numerical experiments validate the performance of the overall scheme and confirm that it outperforms state-of-the-art solutions adapted to our context.},
	number = {4},
	journal = {IEEE Transactions on Network and Service Management},
	author = {Faticanti, Francescomaria and De Pellegrini, Francesco and Siracusa, Domenico and Santoro, Daniele and Cretti, Silvio},
	year = {2020},
	keywords = {Fog computing, IoT, microservices, resource allocation, applications partitioning},
	pages = {2436--2450},
	file = {Faticanti et al_2020_Throughput-aware partitioning and placement of applications in fog computing.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/7L4GYZ8J/Faticanti et al_2020_Throughput-aware partitioning and placement of applications in fog computing.pdf:application/pdf;PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/NKBN2JFL/09189841(1).pdf:application/pdf},
}

@book{newman_building_2015-1,
	title = {Building microservices : designing fine-grained systems},
	isbn = {1-4919-5035-8},
	abstract = {First edition. Includes index.},
	author = {Newman, Sam and Newman, Sam},
	year = {2015},
}

@article{rossi_geo-distributed_2020,
	title = {Geo-distributed efficient deployment of containers with {Kubernetes}},
	volume = {159},
	issn = {1873703X},
	url = {https://doi.org/10.1016/j.comcom.2020.04.061},
	doi = {10.1016/j.comcom.2020.04.061},
	abstract = {Software containers are changing the way applications are designed and executed. Moreover, in the last few years, we see the increasing adoption of container orchestration tools, such as Kubernetes, to simplify the management of multi-container applications. Kubernetes includes simple deployment policies that spread containers on computing resources located in the cluster and automatically scale them out or in based on some cluster-level metrics. As such, Kubernetes is not well-suited for deploying containers in a geo-distributed computing environment and dealing with the dynamism of application workload and computing resources. To tackle the problem, in this paper we present ge-kube (Geo-distributed and Elastic deployment of containers in Kubernetes), an orchestration tool that relies on Kubernetes and extends it with self-adaptation and network-aware placement capabilities. Ge-kube introduces flexible and decentralized control loops that can be easily equipped with different deployment policies. Specifically, we propose a two-step control loop, in which a model-based reinforcement learning approach dynamically controls the number of replicas of individual containers on the basis of the application response time, and a network-aware placement policy allocates containers on geo-distributed computing resources. To address the placement issue, we propose an optimization problem formulation and a network-aware heuristic, which explicitly take into account the non-negligible network delays among computing resources so to satisfy Quality of Service requirements of latency-sensitive applications. Using a surrogate CPU-intensive application and a real application (i.e., Redis), we conducted an extensive set of experiments, which show the benefits arising from the combination of elasticity and placement policies, as well as the advantages of using network-aware placement solutions.},
	number = {March},
	journal = {Computer Communications},
	author = {Rossi, Fabiana and Cardellini, Valeria and Lo Presti, Francesco and Nardelli, Matteo},
	year = {2020},
	note = {Publisher: Elsevier B.V.},
	keywords = {Containers, Kubernetes, Elasticity, Geographically distributed resources, Placement, Self-management},
	pages = {161--174},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/GL36DU4C/rossi2020.pdf:application/pdf},
}

@article{gogouvitis_seamless_2020,
	title = {Seamless computing in industrial systems using container orchestration},
	volume = {109},
	issn = {0167739X},
	url = {https://doi.org/10.1016/j.future.2018.07.033},
	doi = {10.1016/j.future.2018.07.033},
	abstract = {Industrial systems are increasingly dominated by software. In addition, this software is distributed across several compute domains, from decentralized edge to centralized datacenters and clouds. While software lifecycle management has tremendously improved in the area of cloud computing, there is no homogeneous and seamless environment to build, deploy and operate software across these domains. This leads to a separation, inefficient processes, and increased efforts in providing software that runs across the different layers. This paper introduces the concept of seamless computing, which provides a homogeneous computing environment for multi-domain applications, supporting the mobility of workloads between cloud and edge. The approach is based on transferring established, de-facto standard cloud computing technologies to resource-constrained compute environments in the edge. After defining high-level requirements for seamless computing, a functional reference model is proposed, and existing cloud technologies are discussed. Finally, a concept and results of an implementation of seamless computing using container orchestration are presented and discussed.},
	journal = {Future Generation Computer Systems},
	author = {Gogouvitis, Spyridon V. and Mueller, Harald and Premnadh, Sreenath and Seitz, Andreas and Bruegge, Bernd},
	year = {2020},
	note = {Publisher: Elsevier B.V.},
	keywords = {Edge computing, Fog computing, Cloud computing, Container orchestration, Seamless computing, Workload mobility},
	pages = {678--688},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/V4B92LN2/1-s2.0-S0167739X17330236-main.pdf:application/pdf},
}

@article{chegini_framework_2019,
	title = {A framework of automation on context-aware internet of things ({IoT}) systems},
	doi = {10.1145/3368235.3368848},
	abstract = {An ever-increasing number of different types of objects are connecting to the Internet, and this phenomenon is called the Internet of Things(IoT). Processing the IoT generated data by Cloud Computing causes high latency. Fog Computing is a new motivation for resolving the latency issue, which is a hosting environment between the IoT and the Cloud layers. IoT applications are faced with three significant challenges: big data, device heterogeneity, and Fog resiliency. With the motivation of resolving the challenges, this proposal introduces a Microservice software framework for implementing automatic functions in the IoT-Fog-Cloud ecosystem. The proposed Microservice framework will also enable the development of IoT-based context-aware intelligent decision-making systems. We describe the functionality and contribution of each automatic function in the paper.},
	journal = {UCC 2019 Companion - Proceedings of the 12th IEEE/ACM International Conference on Utility and Cloud Computing},
	author = {Chegini, Hossein and Mahanti, Aniket},
	year = {2019},
	note = {ISBN: 9781450370448},
	keywords = {IoT, Cloud Computing, Microservice, Fog Computing, Automation, Complex Event Processing, Context-aware system, Machine-to-Machine(M2M)},
	pages = {157--162},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/HMI53ZTC/10.1145@3368235.3368848(1).pdf:application/pdf},
}

@article{jimenez_hydra_2020,
	title = {{HYDRA}: {Decentralized} {Location}-aware {Orchestration} of {Containerized} {Applications}},
	volume = {7161},
	issn = {21687161},
	doi = {10.1109/TCC.2020.3041465},
	abstract = {The edge computing paradigm, spurred by the Internet-of-Things, poses new requirements and challenges for distributed application deployment. There is a need for an orchestrator design that leverages characteristics that enable this new paradigm. We present HYDRA, a decentralized and distributed orchestrator for containerized microservice applications. This orchestrator focuses on scalability and resiliency to enable the global manageability of cloud and edge environments. It can manage heterogeneous resources across geographical locations and provide robust application control. Further, HYDRA enables the location-aware deployment of microservice applications via containerization. Thus, an application's services may be deployed to separate locations according to expected needs. In this paper, the experiments show the orchestrator scaling to 20 000 nodes and simultaneously deploying 30 000 applications. Further, empirical results show that location-aware application deployment does not hinder HYDRA's performance, and the random resource search algorithm currently being employed may be used as a baseline to find resources in this decentralized orchestrator. Therefore, we conclude that HYDRA is a viable orchestrator design for the new computing paradigm.},
	number = {c},
	journal = {IEEE Transactions on Cloud Computing},
	author = {Jimenez, Lara Lorna and Schelen, Olov},
	year = {2020},
	keywords = {Edge computing, microservices, Cloud computing, edge computing, fog computing, Scalability, Virtualization, Containers, Docker, Kubernetes, orchestration, containers, decentralized networks, deployment, Peer-to-peer computing, scalability, Voting},
	pages = {1--16},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/8N9QIF7Y/09274526.pdf:application/pdf},
}

@article{stefanic_quality_2020,
	title = {Quality of {Service}-aware matchmaking for adaptive microservice-based applications},
	issn = {15320634},
	doi = {10.1002/cpe.6120},
	abstract = {Applications that make use of Internet of Things (IoT) can capture an enormous amount of raw data from sensors and actuators, which is frequently transmitted to cloud data centers for processing and analysis. However, due to varying and unpredictable data generation rates and network latency, this can lead to a performance bottleneck for data processing. With the emergence of fog and edge computing hosted microservices, data processing could be moved towards the network edge. We propose a new method for continuous deployment and adaptation of multi-tier applications along edge, fog, and cloud tiers by considering resource properties and non-functional requirements (e.g., operational cost, response time and latency etc.). The proposed approach supports matchmaking of application and Cloud-To-Things infrastructure based on a subgraph pattern matching (P-Match) technique. Results show that the proposed approach improves resource utilization and overall application Quality of Service. The approach can also be integrated into software engineering workbenches for the creation and deployment of cloud-native applications, enabling partitioning of an application across the multiple infrastructure tiers outlined above.},
	number = {November},
	journal = {Concurrency Computation},
	author = {Štefanič, Polona and Kochovski, Petar and Rana, Omer F. and Stankovski, Vlado},
	year = {2020},
	keywords = {microservices, fog computing, cloud computing, provisioning, deployment, adaptation, matchmaking},
	pages = {1--14},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/EIIVMTJ5/10.1002@cpe.6120.pdf:application/pdf},
}

@article{ahmed_docker_2020,
	title = {Docker {Container} {Deployment} in {Distributed} {Fog} {Infrastructures} with {Checkpoint}/{Restart}},
	doi = {10.1109/MobileCloud48802.2020.00016},
	abstract = {n fog computing environments container deployment is a frequent operation which often lies in the critical path of services being delivered to an end user. Although creating a container can be very fast, the container's application needs to start before the container starts producing useful work. Depending on the application this startup process can be arbitrarily long. To speed up the application startup times we propose to snapshot the state of fully-deployed containers and restart future container instances from a pre-started application state. In our evaluations based on 14 real micro-service containers, this technique effectively reduces the startup phase with speedups between 1x (no speedup) and 60x.},
	journal = {Proceedings - 2020 8th IEEE International Conference on Mobile Cloud Computing, Services, and Engineering, MobileCloud 2020},
	author = {Ahmed, Arif and Mohan, Apoorve and Cooperman, Gene and Pierre, Guillaume},
	year = {2020},
	note = {ISBN: 9781728110356},
	keywords = {Fog computing, Docker, containers, checkpoint/restart},
	pages = {55--62},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/YCBRTXLY/09126743(1).pdf:application/pdf},
}

@article{ahmed_docker_2019,
	title = {Docker image sharing in distributed fog infrastructures},
	volume = {2019-Decem},
	issn = {23302186},
	doi = {10.1109/CloudCom.2019.00030},
	abstract = {Fog computing platforms offer virtualized resources located in the vicinity of their end users. Their broad geographical distribution force them to split physical resources in large numbers of relatively weak machines. The limited available disk space per fog node however creates problems for Docker-based systems which locally cache a copy of every container image they execute: first, caches may fill very quickly, whereas standard Docker never automatically evicts any image from its cache. This motivates us to implement automatic cache replacement in Docker. Second, splitting cache space in multiple disjoint partitions negatively impacts the hit rates. This motivates us to propose allowing multiple co-located Docker servers to share their caches. Our trace-based evaluations show that the proposed design achieves significant cache hit improvements, leading to reductions of average container deployment times between 37\% and 78\% depending on the scenarios.},
	journal = {Proceedings of the International Conference on Cloud Computing Technology and Science, CloudCom},
	author = {Ahmed, Arif and Pierre, Guillaume},
	year = {2019},
	note = {ISBN: 9781728150116},
	keywords = {Fog computing, Containers, Docker},
	pages = {135--142},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/8A7TR8KE/08968919.pdf:application/pdf},
}

@article{aazam_fog_2015,
	title = {Fog computing micro datacenter based dynamic resource estimation and pricing model for {IoT}},
	volume = {2015-April},
	issn = {1550445X},
	doi = {10.1109/AINA.2015.254},
	abstract = {Pervasive and ubiquitous computing services have recently been under focus of not only the research community, but developers as well. Prevailing wireless sensor networks (WSNs), Internet of Things (IoT), and healthcare related services have made it difficult to handle all the data in an efficient and effective way and create more useful services. Different devices generate different types of data with different frequencies. Therefore, amalgamation of cloud computing with IoTs, termed as Cloud of Things (CoT) has recently been under discussion in research arena. CoT provides ease of management for the growing media content and other data. Besides this, features like: ubiquitous access, service creation, service discovery, and resource provisioning play a significant role, which comes with CoT. Emergency, healthcare, and latency sensitive services require real-time response. Also, it is necessary to decide what type of data is to be uploaded in the cloud, without burdening the core network and the cloud. For this purpose, Fog computing plays an important role. Fog resides between underlying IoTs and the cloud. Its purpose is to manage resources, perform data filtration, preprocessing, and security measures. For this purpose, Fog requires an effective and efficient resource management framework for IoTs, which we provide in this paper. Our model covers the issues of resource prediction, customer type based resource estimation and reservation, advance reservation, and pricing for new and existing IoT customers, on the basis of their characteristics. The implementation was done using Java, while the model was evaluated using CloudSim toolkit. The results and discussion show the validity and performance of our system.},
	journal = {Proceedings - International Conference on Advanced Information Networking and Applications, AINA},
	author = {Aazam, Mohammad and Huh, Eui Nam},
	year = {2015},
	note = {ISBN: 9781479979042},
	keywords = {Edge computing, Fog computing, IoT, Resource management, Cloud of Things, Micro Data Center},
	pages = {687--694},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/UXUN7TJ7/aazam2015.pdf:application/pdf},
}

@article{mostafa_fog_2018,
	title = {Fog resource selection using historical executions},
	doi = {10.1109/FMEC.2018.8364078},
	abstract = {As an emergent technology, IoT promises to harness the computational and storage resources distributed across different remote clouds. Fog computing extends cloud computing by bringing the network and cloud resources closer to the network edge. Those resources are typically heterogeneous in nature requiring careful management. As the number of resources contributing to a cloud grows, so the problems associated with efficient and effective resource selection and allocation increase. In this paper, we introduce a fog resource selection algorithm (FResS) that enables automated fog selection and allocation for IoT systems. The proposed model collects and maintains a repository of fog performance data in the form of execution logs stored in standard formats. When a new task needs to be executed, prediction for its run-time is made by using these logs, which results in a realistic run-time estimate as well as best fog selection for task placement. Simulation results show a decrease in the overall end-to-end (e2e) latency of the system.},
	journal = {2018 3rd International Conference on Fog and Mobile Edge Computing, FMEC 2018},
	author = {Mostafa, Nour and Ridhawi, Ismaeel Al and Aloqaily, Moayad},
	year = {2018},
	note = {ISBN: 9781538658963},
	keywords = {cloud, e2e delay, fog, fog-to-cloud, fog-to-fog},
	pages = {272--276},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/7FUHKC8A/mostafa2018.pdf:application/pdf},
}

@article{gao_pora_2020,
	title = {{PORA}: {Predictive} offloading and resource allocation in dynamic fog computing systems},
	issn = {23318422},
	abstract = {In multi-tiered fog computing systems, to accelerate the processing of computation-intensive tasks for real-time IoT applications, resource-limited IoT devices can offload part of their workloads to nearby fog nodes, whereafter such workloads may be offloaded to upper-tier fog nodes with greater computation capacities. Such hierarchical offloading, though promising to shorten processing latencies, may also induce excessive power consumptions and latencies for wireless transmissions. With the temporal variation of various system dynamics, such a tradeoff makes it rather challenging to conduct effective and online offloading decision making. Meanwhile, the fundamental benefits of predictive offloading to fog computing systems still remain unexplored. In this paper, we focus on the problem of dynamic offloading and resource allocation with traffic prediction in multi-tiered fog computing systems. By formulating the problem as a stochastic network optimization problem, we aim to minimize the time-average power consumptions with stability guarantee for all queues in the system. We exploit unique problem structures and propose PORA, an efficient and distributed predictive offloading and resource allocation scheme for multi-tiered fog computing systems. Our theoretical analysis and simulation results show that PORA incurs near-optimal power consumptions with queue stability guarantee. Furthermore, PORA requires only mild-value of predictive information to achieve a notable latency reduction, even with prediction errors.},
	journal = {arXiv},
	author = {Gao, Xin and Huang, Xi and Bian, Simeng and Shao, Ziyu and Yang, Yang},
	year = {2020},
	note = {Publisher: IEEE
ISBN: 9781538680889},
	keywords = {Fog computing, Internet of Things, Resource allocation, Lyapunov optimization, Predictive offloading, Workload offloading},
	pages = {1--6},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/JCFKRMJH/gao2019.pdf:application/pdf},
}

@article{patman_predictive_2018,
	title = {Predictive analytics for fog computing using machine learning and {GENI}},
	doi = {10.1109/INFCOMW.2018.8407027},
	abstract = {Fog computing is a rapidly emerging paradigm concerned with providing energy- and latency-aware solutions to users by moving computing and storage capabilities closer to end users via fog networks. A major challenge associated with such a goal is ensuring that forecasts about network quality are not only accurate but also have small operational overhead. Machine Learning is a popular approach that has been used to model network parameters of interest. However, due to the small amount of public datasets and testbeds available, designing reproducible models becomes cumbersome and more likely to under-perform during deployment. For these reasons, we seek to design an exploratory testbed for benchmarking the forecasting strength of a suite of supervised learning models aimed at inferring network quality estimates. To create a realistic fog computing sandbox, we deployed an image processing ensemble of services in the GENI infrastructure. The nodes in GENI have varying hardware specifications for the purpose of generating compute-intensive workloads on heterogeneous systems. Our experimental results suggest that machine learning can be used to accurately model important network quality parameters and outperforms traditional techniques. Moreover, our results indicate that the training and prediction times for each model is suitable for deployment in latency-sensitive environments.},
	journal = {INFOCOM 2018 - IEEE Conference on Computer Communications Workshops},
	author = {Patman, Jon and Alfarhood, Meshal and Islam, Soliman and Lemus, Mauro and Calyam, Prasad and Palaniappan, Kannappan},
	year = {2018},
	note = {Publisher: IEEE
ISBN: 9781538659793},
	pages = {790--795},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/L5VG8X52/patman2018.pdf:application/pdf},
}

@misc{noauthor_09187676pdf_nodate,
	title = {09187676.pdf},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/VVVJCLSM/09187676.pdf:application/pdf},
}

@article{siasi_deep_2020,
	title = {Deep {Learning} for {Service} {Function} {Chain} {Provisioning} in {Fog} {Computing}},
	volume = {8},
	issn = {2169-3536},
	doi = {10.1109/access.2020.3021355},
	journal = {IEEE Access},
	author = {Siasi, Nazli and Jasim, Mohammed and Aldalbahi, Adel and Ghani, Nasir},
	year = {2020},
	pages = {167665--167683},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/6WJUIV4X/09187676(1).pdf:application/pdf},
}

@article{fei_cps_2019,
	title = {{CPS} data streams analytics based on machine learning for {Cloud} and {Fog} {Computing}: {A} survey},
	volume = {90},
	issn = {0167739X},
	url = {https://doi.org/10.1016/j.future.2018.06.042},
	doi = {10.1016/j.future.2018.06.042},
	abstract = {Cloud and Fog computing has emerged as a promising paradigm for the Internet of things (IoT) and cyber–physical systems (CPS). One characteristic of CPS is the reciprocal feedback loops between physical processes and cyber elements (computation, software and networking), which implies that data stream analytics is one of the core components of CPS. The reasons for this are: (i) it extracts the insights and the knowledge from the data streams generated by various sensors and other monitoring components embedded in the physical systems; (ii) it supports informed decision making; (iii) it enables feedback from the physical processes to the cyber counterparts; (iv) it eventually facilitates the integration of cyber and physical systems. There have been many successful applications of data streams analytics, powered by machine learning techniques, to CPS systems. Thus, it is necessary to have a survey on the particularities of the application of machine learning techniques to the CPS domain. In particular, we explore how machine learning methods should be deployed and integrated in Cloud and Fog architectures for better fulfilment of the requirements of mission criticality and time criticality arising in CPS domains. To the best of our knowledge, this paper is the first to systematically study machine learning techniques for CPS data stream analytics from various perspectives, especially from a perspective that leads to the discussion and guidance of how the CPS machine learning methods should be deployed in a Cloud and Fog architecture.},
	journal = {Future Generation Computer Systems},
	author = {Fei, Xiang and Shah, Nazaraf and Verba, Nandor and Chao, Kuo Ming and Sanchez-Anguix, Victor and Lewandowski, Jacek and James, Anne and Usman, Zahid},
	year = {2019},
	note = {Publisher: Elsevier B.V.},
	keywords = {Edge computing, Fog computing, Cloud computing, Machine learning, Analytics, Cyber–physical systems (CPS)},
	pages = {435--450},
	file = {Full Text:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/L6L9XPG9/Fei et al. - 2019 - CPS data streams analytics based on machine learni.pdf:application/pdf;PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/ILIQFN25/1-s2.0-S0167739X17330613-main.pdf:application/pdf},
}

@article{guevara_classification_2020,
	title = {On the classification of fog computing applications: {A} machine learning perspective},
	volume = {159},
	issn = {10958592},
	url = {https://doi.org/10.1016/j.jnca.2020.102596},
	doi = {10.1016/j.jnca.2020.102596},
	abstract = {Currently, Internet applications running on mobile devices generate a massive amount of data that can be transmitted to a Cloud for processing. However, one fundamental limitation of a Cloud is the connectivity with end devices. Fog computing overcomes this limitation and supports the requirements of time-sensitive applications by distributing computation, communication, and storage services along the Cloud to Things (C2T) continuum, empowering potential new applications, such as smart cities, augmented reality (AR), and virtual reality (VR). However, the adoption of Fog-based computational resources and their integration with the Cloud introduces new challenges in resource management, which requires the implementation of new strategies to guarantee compliance with the quality of service (QoS) requirements of applications. In this context, one major question is how to map the QoS requirements of applications on Fog and Cloud resources. One possible approach is to discriminate the applications arriving at the Fog into Classes of Service (CoS). This paper thus introduces a set of CoS for Fog applications which includes, the QoS requirements that best characterize these Fog applications. Moreover, this paper proposes the implementation of a typical machine learning classification methodology to discriminate Fog computing applications as a function of their QoS requirements. Furthermore, the application of this methodology is illustrated in the assessment of classifiers in terms of efficiency, accuracy, and robustness to noise. The adoption of a methodology for machine learning-based classification constitutes a first step towards the definition of QoS provisioning mechanisms in Fog computing. Moreover, classifying Fog computing applications can facilitate the decision-making process for Fog scheduler.},
	number = {March},
	journal = {Journal of Network and Computer Applications},
	author = {Guevara, Judy C. and Torres, Ricardo da S. and da Fonseca, Nelson L.S.},
	year = {2020},
	note = {Publisher: Elsevier Ltd},
	keywords = {Edge computing, Fog computing, Cloud computing, Internet of things, Machine learning, Quality of service, Attribute noise, Classes of service, Classification algorithms, Feature selection, Scheduling},
	pages = {102596},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/JKEWKUM6/1-s2.0-S1084804520300709-main.pdf:application/pdf},
}

@article{puliafito_companion_2018,
	title = {Companion fog computing: supporting things mobility through container migration at the edge},
	doi = {10.1109/SMARTCOMP.2018.00079},
	abstract = {Due to their intrinsic resource constraints, the mobile Internet of Things (IoT) devices are not able to provide intensive services by just relying on their own facilities. Fog Computing effectively helps overcome this hurdle. Indeed, it extends the Cloud toward the network edge, distributing resources and services of computing, storage, and networking close to the end devices. This topological proximity is the key enabler of several advantages that are essential in many emerging ICT domains. Nonetheless, the mobility of an IoT device compromises such benefits as it increases the topological distance to the serving Fog node. Therefore, the Fog service has to be migrated in order to be always close enough to the served IoT device. We name this Companion Fog Computing (CFC), since the Fog service behaves as a 'companion' of the correspondent application on the mobile device. In this paper, we present a Fog Computing Platform that performs stateful container (i.e., Fog service) migrations in order to enable CFC. Specifically, we introduce a CFC model from which we derive a reference architecture comprising all the functionalities required in a platform to make migration decisions and carry them out. Moreover, we demonstrate the soundness of the proposed reference architecture by discussing a proof-of-concept implementation based on the Stack4Things (S4T) platform, and we report a set of conducted experiments to show the feasibility of stateful container migrations.},
	journal = {Proceedings - 2018 IEEE International Conference on Smart Computing, SMARTCOMP 2018},
	author = {Puliafito, Carlo and Mingozzi, Enzo and Vallati, Carlo and Longo, Francesco and Merlino, Giovanni},
	year = {2018},
	note = {Publisher: IEEE
ISBN: 9781538647059},
	keywords = {Internet of Things, Mobility, Containers, Docker, Fog Computing, Migration, Topological proximity},
	pages = {97--105},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/GJSQVJTC/SMARTCOMP.2018.00079.pdf:application/pdf},
}

@article{li_sslb_2018,
	title = {{SSLB}: {Self}-{Similarity}-{Based} {Load} {Balancing} for {Large}-{Scale} {Fog} {Computing}},
	volume = {43},
	issn = {21914281},
	url = {https://doi.org/10.1007/s13369-018-3169-3},
	doi = {10.1007/s13369-018-3169-3},
	abstract = {As a novelty approach to achieve Internet of things and an important supplement of cloud, fog computing has been widely studied in recent years. The research in this domain is still in infancy, so an efficient resource management is seriously required. Existing solutions are mostly ported from cloud domain straightforward, which performed well in many cases, but cannot keep excellent when the fog scale increased. In this paper, we examine the runtime characteristics of fog infrastructure and propose SSLB, a self-similarity-based load balancing mechanism for large-scale fog computing. As far as we know, this is the first work try to address the load balancing challenges caused by fog’s ‘large-scale’ characteristic. Furthermore, we propose an adaptive threshold policy and corresponding scheduling algorithm, which successfully guarantees the efficiency of SSLB. Experimental results show that SSLB outperforms existing schemes in fog scenario. Specifically, the resources utilization of SSLB is 1.7× and 1.2× of traditional centralized and decentralized schemes under 1000 nodes.},
	number = {12},
	journal = {Arabian Journal for Science and Engineering},
	author = {Li, Changlong and Zhuang, Hang and Wang, Qingfeng and Zhou, Xuehai},
	year = {2018},
	note = {Publisher: Springer Berlin Heidelberg},
	keywords = {Fog computing, Internet of things, Dynamic load balancing, Self-similarity},
	pages = {7487--7498},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/FLR3P2H2/s13369-018-3169-3.pdf:application/pdf},
}

@article{bellavista_feasibility_2017,
	title = {Feasibility of fog computing deployment based on docker containerization over {RaspberryPi}},
	doi = {10.1145/3007748.3007777},
	abstract = {Fog computing is strongly emerging as a relevant and interest-attracting paradigm+technology for both the academic and industrial communities. However, architecture and methodological approaches are still prevalent in the literature, while few research activities have specifically targeted so far the issues of practical feasibility, cost-effectiveness, and efficiency of fog solutions over easily-deployable environments. In this perspective, this paper originally presents i) our fog-oriented framework for Internet-of-Things applications based on innovative scalability extensions of the open-source Kura gateway and ii) its Docker-based containerization over challenging and resource-limited fog nodes, i.e., RaspberryPi devices. Our practical experience and experimental work show the feasibility of using even extremely constrained nodes as fog gateways; the reported results demonstrate that good scalability and limited overhead can be coupled, via proper configuration tuning and implementation optimizations, with the significant advantages of containerization in terms of flexibility and easy deployment, also when working on top of existing, off-the-shelf, and limited-cost gateway nodes.},
	journal = {ACM International Conference Proceeding Series},
	author = {Bellavista, Paolo and Zanni, Alessandro},
	year = {2017},
	note = {ISBN: 9781450348393},
	keywords = {Fog computing, Resource management, Internet of things, Container, Docker, Gateways, Kura framework, RaspberryPi},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/NXEV2WIP/3007748.3007777.pdf:application/pdf},
}

@book{benamer_latency-aware_2018,
	title = {Latency-aware placement heuristic in fog computing environment},
	volume = {11230 LNCS},
	isbn = {978-3-030-02670-7},
	url = {http://dx.doi.org/10.1007/978-3-030-02671-4_14},
	abstract = {With the rise of IoT applications popularity, a new paradigm has emerged so-called Fog Computing. To facilitate their deployment on fog nodes, IoT applications are decomposed into a set of modules. These modules interact with each other in order to achieve a global goal. Placing these modules without a prior strategy may affect the overall performance of the application. Moreover, the restricted capacity of the fog nodes vis-a-vis the modules’ requirements arises the problem of placement. In this paper, we focus on minimizing the overall latency of the application while placing modules on fog nodes. In order to address the module placement problem, we propose both exact and approximate solutions. Experiments were conducted using CPLEX and iFogSim-simulated Fog environment respectively. The results show the effectiveness of our final approach.},
	publisher = {Springer International Publishing},
	author = {Benamer, Amira Rayane and Teyeb, Hana and ben Hadj-Alouane, Nejib},
	year = {2018},
	doi = {10.1007/978-3-030-02671-4_14},
	note = {Publication Title: Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
ISSN: 16113349},
	keywords = {Fog computing, Internet of things, Cloud, Latency, Placement decision},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/7X6IE9F6/978-3-030-02671-4_14.pdf:application/pdf},
}

@article{fadahunsi_locality_2019,
	title = {Locality sensitive request distribution for fog and cloud servers},
	volume = {13},
	issn = {18632394},
	url = {https://doi.org/10.1007/s11761-019-00260-2},
	doi = {10.1007/s11761-019-00260-2},
	abstract = {Fog computing is meant to bring the cloud resource closer to the edge of the Internet so that devices can access the back end services much faster. Additionally, the services hosted at the fogs can be customized to fit the local needs. Because fogs are dispersed throughout the network, each installation will have limited resources. This makes resource management a very critical issue. In this paper, we present a two-step resource management approach for fog computing. The first step decides the allocation of the devices to the fogs. The fogs are allocated in a two-tiered manner. That is, for each device, a home fog and a pool of backup fogs are allocated. In the second step, the requests from the devices are distributed to the allocated fogs or the cloud. Using simulation studies, we compared the performance of the proposed request distribution algorithm against existing ones. The results indicate that our request distribution algorithm outperforms existing ones.},
	number = {2},
	journal = {Service Oriented Computing and Applications},
	author = {Fadahunsi, Olamilekan and Maheswaran, Muthucumaru},
	year = {2019},
	note = {Publisher: Springer London
ISBN: 1176101900},
	keywords = {Fog computing, IoT, Resource management, Cloud computing, Algorithms, Fault tolerance, Request distribution},
	pages = {127--140},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/JT4VN6CG/fadahunsi2019.pdf:application/pdf},
}

@article{afrin_multi-objective_2019,
	title = {Multi-objective resource allocation for {Edge} {Cloud} based robotic workflow in smart factory},
	volume = {97},
	issn = {0167739X},
	url = {https://doi.org/10.1016/j.future.2019.02.062},
	doi = {10.1016/j.future.2019.02.062},
	abstract = {Multi-robotic services are widely used to enhance the efficiency of Industry 4.0 applications including emergency management in smart factory. The workflow of these robotic services consists of data hungry, delay sensitive and compute intensive tasks. Generally, robots are not enriched in computational power and storage capabilities. It is thus beneficial to leverage the available Cloud resources to complement robots for executing robotic workflows. When multiple robots and Cloud instances work in a collaborative manner, optimal resource allocation for the tasks of a robotic workflow becomes a challenging problem. The diverse energy consumption rate of both robot and Cloud instances, and the cost of executing robotic workflow in such a distributed manner further intensify the resource allocation problem. Since the tasks are inter-dependent, inconvenience in data exchange between local robots and remote Cloud also degrade the service quality. Therefore, in this paper, we address simultaneous optimization of makespan, energy consumption and cost while allocating resources for the tasks of a robotic workflow. As a use case, we consider resource allocation for the robotic workflow of emergency management service in smart factory. We design an Edge Cloud based multi-robot system to overcome the limitations of remote Cloud based system in exchanging delay sensitive data. The resource allocation for robotic workflow is modelled as a constrained multi-objective optimization problem and it is solved through a multi-objective evolutionary approach, namely, NSGA-II algorithm. We have redesigned the NSGA-II algorithm by defining a new chromosome structure, pre-sorted initial population and mutation operator. It is further augmented by selecting the minimum distant solution from the non-dominated front to the origin while crossing over the chromosomes. The experimental results based on synthetic workload demonstrate that our augmented NSGA-II algorithm outperforms the state-of-the-art works by at least 18\% in optimizing makespan, energy and cost attributes on various scenarios.},
	journal = {Future Generation Computer Systems},
	author = {Afrin, Mahbuba and Jin, Jiong and Rahman, Ashfaqur and Tian, Yu Chu and Kulkarni, Ambarish},
	year = {2019},
	note = {Publisher: Elsevier B.V.},
	keywords = {Resource allocation, Edge cloud, Multi-objective evolutionary algorithm, Multi-robot system, Smart factory, Workflow management},
	pages = {119--130},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/EEHTTEY3/1-s2.0-S0167739X18326785-main.pdf:application/pdf},
}

@article{alrawais_attribute-based_2017,
	title = {An {Attribute}-{Based} {Encryption} {Scheme} to {Secure} {Fog} {Communications}},
	volume = {5},
	issn = {21693536},
	doi = {10.1109/ACCESS.2017.2705076},
	abstract = {Fog computing is deemed as a highly virtualized paradigm that can enable computing at the Internet of Things devices, residing in the edge of the network, for the purpose of delivering services and applications more efficiently and effectively. Since fog computing originates from and is a non-trivial extension of cloud computing, it inherits many security and privacy challenges of cloud computing, causing the extensive concerns in the research community. To enable authentic and confidential communications among a group of fog nodes, in this paper, we propose an efficient key exchange protocol based on ciphertext-policy attribute-based encryption (CP-ABE) to establish secure communications among the participants. To achieve confidentiality, authentication, verifiability, and access control, we combine CP-ABE and digital signature techniques. We analyze the efficiency of our protocol in terms of security and performance. We also implement our protocol and compare it with the certificate-based scheme to illustrate its feasibility.},
	number = {c},
	journal = {IEEE Access},
	author = {Alrawais, Arwa and Alhothaily, Abdulrahman and Hu, Chunqiang and Xing, Xiaoshuang and Cheng, Xiuzhen},
	year = {2017},
	keywords = {Fog computing, cloud computing, ciphertext-policy attribute based encryption (CP-A, communications security, security},
	pages = {9131--9138},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/QQAVJD42/ACCESS.2017.2705076.pdf:application/pdf},
}

@article{adhikari_energy_2019,
	title = {Energy efficient offloading strategy in fog-cloud environment for {IoT} applications},
	volume = {6},
	issn = {25426605},
	url = {https://doi.org/10.1016/j.iot.2019.100053},
	doi = {10.1016/j.iot.2019.100053},
	abstract = {Nowadays, cloud computing leverages the capability of Internet-of-Things (IoT) applications by providing computing resources as a form of virtual machine (VM) instances. However, the Cloud data center consumes a large amount of energy while transmitting and computing the IoT applications which lead to a high carbon footprint. On the other hand, the Fog nodes provide various cloud services at the edge of the network which can run the IoT applications locally with minimum energy consumption and delay. Due to the limited resource capacity, the Fog nodes are not suitable for processing the resource-intensive IoT applications. To address these challenges, in this paper, we build sustainable infrastructure in Fog-Cloud environment for processing delay-intensive and resource-intensive applications with an optimal task offloading strategy. The proposed offloading strategy uses Firefly algorithm for finding an optimal computing device based on two Quality-of-Service (QoS) parameters such as energy consumption and computational time. The main objectives of this strategy are to minimize the computational time and the energy consumption of the IoT applications with minimum delay. The effect of the control parameters of the Firefly technique is investigated thoroughly. Through comparisons, we show that the proposed method performs better than the existing ones in terms of various performance metrics including computational time, energy consumption, CO2 emission, and Temperature emission.},
	journal = {Internet of Things},
	author = {Adhikari, Mainak and Gianey, Hemant},
	year = {2019},
	note = {Publisher: Elsevier B.V.},
	keywords = {IoT application,Multi-objective optimization,Fog c},
	pages = {100053},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/AGG8JFF9/adhikari2019.pdf:application/pdf},
}

@article{alnoman_dynamic_2018,
	title = {A {Dynamic} {Priority} {Service} {Provision} {Scheme} for {Delay}-{Sensitive} {Applications} in {Fog} {Computing}},
	doi = {10.1109/BSC.2018.8494691},
	abstract = {The massive numbers of connected devices in the IoT era impose a real challenge in the management of both communication and computing resources. Moreover, the competition of those devices on the limited resources will inherently raise the delay experienced by users. To this end, we propose a priority service provision scheme to reduce the latency experienced by delay-sensitive services. Here, incoming tasks are classified into delay-sensitive and delay-insensitive whereby priority classes are assigned using a matching theory approach. Then, the queue delay experienced by each class is investigated at the computing node i.e., the edge device, and the communication node i.e., the small base station (SBS). To maintain high quality of experience (QoE) in regard with time delay for all tasks, a dynamic priority scheme is proposed and controlled using a heuristic algorithm. The goal of the dynamic priority scheme is to minimize the delay at the communication node (SBS) for users requesting non-computing tasks (e.g., regular phone calls) by promoting their class when the delay exceeds a threshold value. The combined delay experienced at both communication and computing nodes is compared using the prioritized, non-prioritized, and the dynamic priority schemes. Results show that undertaking a dynamic priority service provision can achieve significant reduction in the amount of delay experienced by users.},
	number = {Bsc},
	journal = {29th Biennial Symposium on Communications, BSC 2018},
	author = {Alnoman, Ali and Anpalagan, Alagan},
	year = {2018},
	note = {Publisher: IEEE
ISBN: 9781538657355},
	keywords = {Fog computing, IoT, delay-sensitive, edge device, H-CRAN, priority queue, small base stations},
	pages = {1--5},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/MGRK76V8/bsc.2018.8494691.pdf:application/pdf},
}

@article{avgeris_adaptive_2019,
	title = {Adaptive resource allocation for computation offloading: {A} control-theoretic approach},
	volume = {19},
	issn = {15576051},
	doi = {10.1145/3284553},
	abstract = {Although mobile devices today have powerful hardware and networking capabilities, they fall short when it comes to executing compute-intensive applications. Computation offloading (i.e., delegating resource-consuming tasks to servers located at the edge of the network) contributes toward moving to a mobile cloud computing paradigm. In this work, a two-level resource allocation and admission control mechanism for a cluster of edge servers offers an alternative choice to mobile users for executing their tasks. At the lower level, the behavior of edge servers is modeled by a set of linear systems, and linear controllers are designed to meet the system's constraints and quality of service metrics, whereas at the upper level, an optimizer tackles the problems of load balancing and application placement toward the maximization of the number the offloaded requests. The evaluation illustrates the effectiveness of the proposed offloading mechanism regarding the performance indicators, such as application average response time, and the optimal utilization of the computational resources of edge servers.},
	number = {2},
	journal = {ACM Transactions on Internet Technology},
	author = {Avgeris, Marios and Dechouniotis, Dimitrios and Athanasopoulos, Nikolaos and Papavassiliou, Symeon},
	year = {2019},
	keywords = {Edge computing, Feedback control, Linear modeling},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/S743ZVFS/acm_latest_without_copyrights_v2.pdf:application/pdf},
}

@article{fahs_proximity-aware_2019,
	title = {Proximity-aware traffic routing in distributed fog computing platforms},
	doi = {10.1109/CCGRID.2019.00062},
	abstract = {Container orchestration engines such as Kubernetes do not take into account the geographical location of application replicas when deciding which replica should handle which request. This makes them ill-suited to act as a general-purpose fog computing platforms where the proximity between end users and the replica serving them is essential. We present proxy-mity, a proximity-aware traffic routing system for distributed fog computing platforms. It seamlessly integrates in Kubernetes, and provides very simple control mechanisms to allow system administrators to address the necessary trade-off between reducing the user-to-replica latencies and balancing the load equally across replicas. proxy-mity is very lightweight and it can reduce average user-to-replica latencies by as much as 90\% while allowing the system administrators to control the level of load imbalance in their system.},
	journal = {Proceedings - 19th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing, CCGrid 2019},
	author = {Fahs, Ali J. and Pierre, Guillaume},
	year = {2019},
	note = {Publisher: IEEE
ISBN: 9781728109121},
	keywords = {Fog Computing, Kubernetes, Load-Balancing, Proximity-Awareness},
	pages = {478--487},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/4NHXBAVP/08752909.pdf:application/pdf},
}

@article{benblidia_ranking_2019,
	title = {Ranking fog nodes for tasks scheduling in fog-cloud environments: {A} fuzzy logic approach},
	doi = {10.1109/IWCMC.2019.8766437},
	abstract = {Fog computing has becoming an attractive solution to face the low responsiveness existing in cloud-based networks. With the rapid emerging of Internet of Things (IoT), more and more terminal nodes are offloading their tasks to nearby fog nodes, located at the network edge, in order to reduce the processing delay. However, this tasks offloading requires an efficient scheduling mechanism that considers both user preferences and fog-cloud requirements. Existing research works for task scheduling in fog-cloud computing networks have mainly focused on reducing task delay and the overall energy consumption, without considering user preferences regarding the fog nodes' constraints. In this work, we present a ranking based task scheduling method that aggregates both user preferences and fog nodes features using linguistic and fuzzy quantified proposition to rank fog nodes from the most to the least satisfactory one. Moreover, we used two parameters called least satisfactory proportion (lsp) and greatest satisfactory proportion (gsp) in order to distinguish the similarities. Experimental results show that our approach satisfies the user preferences, and provides a compromising solution between the average user satisfaction, execution delay and energy consumption.},
	journal = {2019 15th International Wireless Communications and Mobile Computing Conference, IWCMC 2019},
	author = {Benblidia, Mohammed Anis and Brik, Bouziane and Merghem-Boulahia, Leila and Esseghir, Moez},
	year = {2019},
	note = {Publisher: IEEE
ISBN: 9781538677476},
	keywords = {Task scheduling, Fuzzy logic, Fog-Cloud networks},
	pages = {1451--1457},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/CB8PAX7V/IWCMC.2019.8766437.pdf:application/pdf},
}

@article{he_multitier_2018,
	title = {Multitier {Fog} {Computing} {With} {Large}-{Scale} {IoT} {Data} {Analytics} for {Smart} {Cities}},
	volume = {5},
	issn = {23274662},
	doi = {10.1109/JIOT.2017.2724845},
	abstract = {Analysis of Internet of Things (IoT) sensor data is a key for achieving city smartness. In this paper a multitier fog computing model with large-scale data analytics service is proposed for smart cities applications. The multitier fog is consisted of ad-hoc fogs and dedicated fogs with opportunistic and dedicated computing resources, respectively. The proposed new fog computing model with clear functional modules is able to mitigate the potential problems of dedicated computing infrastructure and slow response in cloud computing. We run analytics benchmark experiments over fogs formed by Rapsberry Pi computers with a distributed computing engine to measure computing performance of various analytics tasks, and create easy-to-use workload models. Quality of services (QoS) aware admission control, offloading, and resource allocation schemes are designed to support data analytics services, and maximize analytics service utilities. Availability and cost models of networking and computing resources are taken into account in QoS scheme design. A scalable system level simulator is developed to evaluate the fog-based analytics service and the QoS management schemes. Experiment results demonstrate the efficiency of analytics services over multitier fogs and the effectiveness of the proposed QoS schemes. Fogs can largely improve the performance of smart city analytics services than cloud only model in terms of job blocking probability and service utility.},
	number = {2},
	journal = {IEEE Internet of Things Journal},
	author = {He, Jianhua and Wei, Jian and Chen, Kai and Tang, Zuoyin and Zhou, Yi and Zhang, Yan},
	year = {2018},
	keywords = {Internet of Things (IoT), fog computing, Raspberry Pi, Data analytics, quality of services (QoS), smart cities, Spark},
	pages = {677--686},
	file = {Full Text:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/X5WCZ7ME/He et al. - 2018 - Multitier fog computing with large-scale IoT data .pdf:application/pdf;PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/3DI5XSFD/JIOT.2017.2724845.pdf:application/pdf},
}

@article{xu_dynamic_2020,
	title = {Dynamic resource provisioning for cyber-physical systems in cloud-fog-edge computing},
	volume = {9},
	issn = {2192113X},
	doi = {10.1186/s13677-020-00181-y},
	abstract = {Cyber-Physical Systems(CPS) serves as an interdisciplinary effort that incorporates cyber vector as well as physical vector. The latter can generate exponentially growing amounts of data. How to process CPS big data systematically and efficiently is the key to the breakthrough of offering prospective and personalized services for each individual user and entity involved. In recent years, much research has been proactively conducted on advancing specific scenario or algorithm. However, few surveys value their integration. For good measure, the synthesis remains a fundamental challenge. Subsequently, we fill the gap in the literature by constructing cloud computing, fog computing and edge computing as a whole to inspire on new architectures and cross utilizations. Moreover, bringing the enthusiasm of traditionally solitude entities into play is crucial. In this exploratory study, we examine definitions of CPS as well as the three aforementioned computing paradigms and then shed new light on comprehensively established frameworks. We also survey on the application level of Cloud-Fog-Edge Computing in CPS respectively and dive into diversified algorithms and strategies to embed big data applications into a more intelligent and convenient society with current deficiencies and future research directions followed.},
	number = {1},
	journal = {Journal of Cloud Computing},
	author = {Xu, Zhanyang and Zhang, Yanqi and Li, Haoyuan and Yang, Weijing and Qi, Quan},
	year = {2020},
	keywords = {Edge computing, Cyber-physical system, Dynamic resource Provisioning},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/EVU9T2LA/Xu2020_Article_DynamicResourceProvisioningFor.pdf:application/pdf},
}

@article{carvalho_computation_2020,
	title = {Computation offloading in {Edge} {Computing} environments using {Artificial} {Intelligence} techniques},
	volume = {95},
	issn = {09521976},
	url = {https://doi.org/10.1016/j.engappai.2020.103840},
	doi = {10.1016/j.engappai.2020.103840},
	abstract = {Edge Computing (EC) is a recent architectural paradigm that brings computation close to end-users with the aim of reducing latency and bandwidth bottlenecks, which 5G technologies are committed to further reduce, while also achieving higher reliability. EC enables computation offloading from end devices to edge nodes. Deciding whether a task should be offloaded, or not, is not trivial. Moreover, deciding when and where to offload a task makes things even harder and making inadequate or off-time decisions can undermine the EC approach. Recently, Artificial Intelligence (AI) techniques, such as Machine Learning (ML), have been used to help EC systems cope with this problem. AI promises accurate decisions, higher adaptability and portability, thus diminishing the cost of decision-making and the probability of error. In this work, we perform a literature review on computation offloading in EC systems with and without AI techniques. We analyze several AI techniques, especially ML-based, that display promising results, overcoming the shortcomings of current approaches for computing offloading coordination We sorted the ML algorithms into classes for better analysis and provide an in-depth analysis on the use of AI for offloading, in particular, in the use case of offloading in Vehicular Edge Computing Networks, actually one technology that gained more relevance in the last years, enabling a vast amount of solutions for computation and data offloading. We also discuss the main advantages and limitations of offloading, with and without the use of AI techniques.},
	number = {July},
	journal = {Engineering Applications of Artificial Intelligence},
	author = {Carvalho, Gonçalo and Cabral, Bruno and Pereira, Vasco and Bernardino, Jorge},
	year = {2020},
	note = {Publisher: Elsevier Ltd},
	keywords = {Machine Learning, Edge Computing, Computation offloading, Artificial Intelligence},
	pages = {103840},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/3L4MVZTX/j.engappai.2020.103840.pdf:application/pdf},
}

@article{losing_incremental_2018,
	title = {Incremental on-line learning: {A} review and comparison of state of the art algorithms},
	volume = {275},
	issn = {18728286},
	url = {https://doi.org/10.1016/j.neucom.2017.06.084},
	doi = {10.1016/j.neucom.2017.06.084},
	abstract = {Recently, incremental and on-line learning gained more attention especially in the context of big data and learning from data streams, conflicting with the traditional assumption of complete data availability. Even though a variety of different methods are available, it often remains unclear which of them is suitable for a specific task and how they perform in comparison to each other. We analyze the key properties of eight popular incremental methods representing different algorithm classes. Thereby, we evaluate them with regards to their on-line classification error as well as to their behavior in the limit. Further, we discuss the often neglected issue of hyperparameter optimization specifically for each method and test how robustly it can be done based on a small set of examples. Our extensive evaluation on data sets with different characteristics gives an overview of the performance with respect to accuracy, convergence speed as well as model complexity, facilitating the choice of the best method for a given application.},
	journal = {Neurocomputing},
	author = {Losing, Viktor and Hammer, Barbara and Wersing, Heiko},
	year = {2018},
	note = {Publisher: Elsevier B.V.},
	keywords = {Data streams, Hyperparameter optimization, Incremental learning, Model selection, On-line learning},
	pages = {1261--1274},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/3WADTKXJ/1-s2.0-S0925231217315928-main.pdf:application/pdf},
}

@article{cisco_cisco_2018,
	title = {Cisco visual networking index: {Forecast} and trends, 2017–2022},
	volume = {1},
	abstract = {This forecast is part of the Cisco® Visual Networking Index™ (Cisco VNI™), an ongoing initiative to track and forecast the impact of visual networking applications. This document presents the details of the Cisco VNI global IP traffic forecast and the methodology behind it. For a more analytical look at the implications of the data presented in this paper, refer to the companion document The Zettabyte Era—Trends and Analysis or the VNI Forecast Highlights tool. Annual global IP traffic will surpass the zettabyte (ZB; 1000 exabytes [EB]) threshold in 2016, and will reach 2.3 ZB by 2020. Global IP traffic will reach 1.1 ZB per year or 88.7 EB (one billion gigabytes [GB]) per month in 2016. By 2020, global IP traffic will reach 2.3 ZB per year, or 194 EB per month. Global IP traffic will increase nearly threefold over the next 5 years, and will have increased nearly a hundredfold from 2005 to 2020. Overall, IP traffic will grow at a compound annual growth rate (CAGR) of 22 percent from 2015 to 2020.},
	journal = {White Paper},
	author = {{Cisco}},
	year = {2018},
	note = {ISBN: c11-481360},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/D9V37KHP/cisco-vni-feb2019.pdf:application/pdf},
}

@article{filiposka_community-based_2018,
	title = {Community-based allocation and migration strategies for fog computing},
	volume = {2018-April},
	issn = {15253511},
	doi = {10.1109/WCNC.2018.8377095},
	abstract = {When moving cloud computing towards the edge in order to provide low latency and location-based Internet services, there are additional considerations that need to be introduced in the traditional cloud approaches to adapt them to fog computing. This paper discusses a proposal for resource allocation and migration strategies adapted specifically to fog computing. The proposal is based on the concept of virtual and physical communities and it has already shown its efficiency when applied to cloud computing. Simulation-based scenarios provide the performance of our community-based proposal following the geographical trajectory of mobile users.},
	journal = {IEEE Wireless Communications and Networking Conference, WCNC},
	author = {Filiposka, Sonja and Mishev, Anastas and Gilly, Katja},
	year = {2018},
	note = {Publisher: IEEE
ISBN: 9781538617342},
	keywords = {Fog computing, Resource management, Node mobility, Wireless access},
	pages = {1--6},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/8AJVLZUZ/08377095.pdf:application/pdf},
}

@article{lera_availability-aware_2019,
	title = {Availability-aware service placement policy in fog computing based on graph partitions},
	volume = {6},
	issn = {23274662},
	doi = {10.1109/JIOT.2018.2889511},
	abstract = {Fog computing extends the cloud to where things are by placing applications closer to the users and Internet of Things devices. The placement of those applications, or their services, has an important influence on the performance of the fog architecture. Improving the availability and the latency of the applications is a challenging task due to the complexity of this type of distributed system. In this paper, we propose a service placement policy inspired by complex networks. We are able to increase the service availability and the quality of service (QoS) satisfaction rate by first mapping applications to communities of fog devices and then transitively placing the services of the applications on the fog devices of the community. The underlying idea is to place as many interrelated services as possible in the devices closest to the users. We compare our solution with an integer linear programming approach, and the simulation results show that our proposal obtains improved QoS satisfaction and service availability.},
	number = {2},
	journal = {IEEE Internet of Things Journal},
	author = {Lera, Isaac and Guerrero, Carlos and Juiz, Carlos},
	year = {2019},
	note = {Publisher: IEEE},
	keywords = {fog computing, service placement, Complex network communities, graph transitive closures, performance optimization, service availability, notion},
	pages = {3641--3651},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/WLA9J8H9/08588297.pdf:application/pdf},
}

@article{gravalos_efficient_2018,
	title = {Efficient {Network} {Planning} for {Internet} of {Things} with {QoS} {Constraints}},
	volume = {5},
	issn = {23274662},
	doi = {10.1109/JIOT.2018.2849327},
	abstract = {In the Internet of Things (IoT) era, a vast number of (smart) end devices forward their traffic to the Internet, either by direct communication to LTE networks, or by multihop transmissions to a specific gateway. Acquiring both types of communication capabilities for IoT end devices would be unnecessarily costly. Instead, for a cost effective IoT infrastructure, only devices performing as gateways could be fully equipped with such capabilities, while the remaining devices could have simple low cost wireless transceivers, of differing transmission specifications, to forward/relay the traffic toward a gateway. Furthermore, the IoT devices network should comply with specific quality of service (QoS) requirements, specified for each IoT device. In this context, the IoT network planning problem, where we have to select the number of gateways and their locations along with respective transceivers for IoT devices, is key to provide a low cost and QoS aware IoT infrastructure. We formulate the planning problem as an integer linear program (ILP) that minimizes the total cost of the devices deployed in the network, while achieving the mandatory QoS requirements. We also present a heuristic algorithm of lower complexity that was observed to provide solutions near the optimal ones, in scenarios that we tracked optimal solutions with the ILP. A variety of performance evaluation results exhibits the effectiveness of the proposed algorithms in terms of network cost and efficiency.},
	number = {5},
	journal = {IEEE Internet of Things Journal},
	author = {Gravalos, Ilias and Makris, Prodromos and Christodoulopoulos, Kostas and Varvarigos, Emmanouel A.},
	year = {2018},
	note = {Publisher: IEEE},
	keywords = {Internet of Things (IoT), fog computing, Cost optimization, gateway placement, sensor network, smart city},
	pages = {3823--3836},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/8LGYFUT2/08390913.pdf:application/pdf},
}

@article{nashaat_iot_2020,
	title = {{IoT} {Application} {Placement} {Algorithm} {Based} on {Multi}-{Dimensional} {QoE} {Prioritization} {Model} in {Fog} {Computing} {Environment}},
	volume = {8},
	issn = {21693536},
	doi = {10.1109/ACCESS.2020.3003249},
	abstract = {With the increasing popularity of Internet of Things (IoT) applications in many different areas, the round-trip delay of data processing in the cloud affect the user's quality perception. But fortunately, fog computing aims to service users at the network edge similar to cloud services, which helps in supporting IoT in processing the data near to the end-user, especially for time-sensitive applications. It makes the resource allocation of application placement requests in a fog environment more necessary to satisfy the Quality of Experience (QoE) Influence Factors (IFs). In this paper, an IoT application placement algorithm based on the Multi-Dimensional QoE (MD-QoE) model is proposed in a fog computing environment. The algorithm is composed of two main phases. The first phase is to prioritize different IoT application placement requests depending on three main domains of IFs which are: Environment runtime context, application usage, and user expectations considering the Quality of Service (QoS) violation as a feedback. The second phase is to map and place the request to the appropriate fog node instance, depending on its proximity, computing capabilities, and expected response time. The proposed algorithm is evaluated by simulating a fog environment using iFogSim. Experimental results indicate that the proposed algorithm significantly improves the QoE in respect of application placement time, application delay, network usage, and power consumption. Therefore, the proposed algorithm can improve the overall system performance with a slight increasing in power consumption in fog control nodes.},
	journal = {IEEE Access},
	author = {Nashaat, Heba and Ahmed, Eman and Rizk, Rawya},
	year = {2020},
	keywords = {IoT, fog computing, cloud computing, Application placement algorithm, QoE},
	pages = {111253--111264},
	file = {Nashaat et al. - 2020 - IoT Application Placement Algorithm Based on Multi.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/I5XDF8XX/Nashaat et al. - 2020 - IoT Application Placement Algorithm Based on Multi.pdf:application/pdf;PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/SCBBU8A7/09119416(2).pdf:application/pdf},
}

@article{josilo_decentralized_2019,
	title = {Decentralized {Algorithm} for {Randomized} {Task} {Allocation} in {Fog} {Computing} {Systems}},
	volume = {27},
	issn = {10636692},
	doi = {10.1109/TNET.2018.2880874},
	abstract = {Fog computing is identified as a key enabler for using various emerging applications by battery powered and computationally constrained devices. In this paper, we consider devices that aim at improving their performance by choosing to offload their computational tasks to nearby devices or to an edge cloud. We develop a game theoretical model of the problem and use a variational inequality theory to compute an equilibrium task allocation in static mixed strategies. Based on the computed equilibrium strategy, we develop a decentralized algorithm for allocating the computational tasks among nearby devices and the edge cloud. We use the extensive simulations to provide insight into the performance of the proposed algorithm and compare its performance with the performance of a myopic best response algorithm that requires global knowledge of the system state. Despite the fact that the proposed algorithm relies on average system parameters only, our results show that it provides a good system performance close to that of the myopic best response algorithm.},
	number = {1},
	journal = {IEEE/ACM Transactions on Networking},
	author = {Jošilo, Sladana and Dán, György},
	year = {2019},
	keywords = {fog computing, Computation offloading, decentralized resource management, game theory, task placement},
	pages = {85--97},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/ZXDW278K/08571179.pdf:application/pdf;PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/42U57EWL/08571179.pdf:application/pdf;Submitted Version:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/2FR477TD/Josilo and Dan - 2019 - Decentralized algorithm for randomized task alloca.pdf:application/pdf},
}

@article{mseddi_joint_2019,
	title = {Joint {Container} {Placement} and {Task} {Provisioning} in {Dynamic} {Fog} {Computing}},
	volume = {6},
	issn = {23274662},
	doi = {10.1109/JIOT.2019.2935056},
	abstract = {Fog computing has emerged as a promising technology that can bring cloud applications closer to the devices at the network edge. The fog infrastructure contains mainly distributed and heterogeneous fog devices such as in the context of the Internet of Things. Unlike traditional data centers, those devices are characterized by sporadic resources availability, mobility, and increased flexibility. However, resource allocation mechanisms proposed currently for fog computing still lack the support of dynamic behavior. In this article, we propose novel resource management algorithms capable of flexible service provisioning in a dynamic fog computing environment. Specifically, the joint problem of container placement and task provisioning is formulated with integer linear programming. Due to its NP-hardness, we propose a low-complex particle-swarm-optimization-based metaheuristic and a greedy heuristic. Our solutions aim to optimize the number of served end-users with a predefined delay-threshold while considering dynamic fog nodes behavior/mobility and resources availability of fog nodes. Using real-world mobility data sets and different resources' availability models, conducted simulations demonstrate that the PSO-based algorithm achieves near-optimal results. Whereas, the greedy algorithm realizes only 10\%-30\% less success ratio than the optimal solution with negligible execution time.},
	number = {6},
	journal = {IEEE Internet of Things Journal},
	author = {Mseddi, Amina and Jaafar, Wael and Elbiaze, Halima and Ajib, Wessam},
	year = {2019},
	note = {Publisher: IEEE},
	keywords = {fog computing, optimization, resource management, Container placement, mobility, particle swarm optimization (PSO), task provisioning, ⛔ No INSPIRE recid found},
	pages = {10028--10040},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/J7NU3ZEZ/08796375.pdf:application/pdf},
}

@article{tun_resource_2020,
	title = {Resource {Aware} {Placement} of {IoT} {Devices} in {Fog} {Computing}},
	doi = {10.1109/ICAIT51105.2020.9261787},
	abstract = {Fog computing is the new favorable technology that can support real-Time cloud application services near to the physical IoT device at the network edge rather than the cloud. It is the decentralized internet-based computing and a layer between the cloud and IoT devices. For real time analytics and critical services, it must process the data as fast as possible. Fog computing can process and manipulate the data at the network edge devices in near real time. However, there is a resource limitation because the services are performed by the fog devices at network edge. So, it needs to utilize the resources of the fog devices. As a result, the placement of IoT (edge) devices on what fog devices is considered to get the efficient resource utilization of the fog devices in this paper. In order to get efficient resource utilization of the fog devices and reduce application delay, network usage and cost of execution in cloud, Fog Node Placement algorithm that finds the fog devices which is minimum distance and enough resource for the IoT (edge) devices is proposed. In addition, the effectiveness of the algorithm will be showed by comparing with traditional cloud placement and fog cloud placement with nearest distance.},
	journal = {Proceedings of the 4th International Conference on Advanced Information Technologies, ICAIT 2020},
	author = {Tun, Khin Nandar and Myat Paing, Aye Myat},
	year = {2020},
	note = {ISBN: 9781728183640},
	keywords = {Fog computing, Cloud computing, IoT (Internet-of-Things)},
	pages = {176--181},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/4NQTB4T6/09261787.pdf:application/pdf},
}

@article{brogi_qos-aware_2017,
	title = {{QoS}-aware deployment of {IoT} applications through the fog},
	volume = {4},
	issn = {23274662},
	doi = {10.1109/JIOT.2017.2701408},
	abstract = {Fog computing aims at extending the Cloud by bringing computational power, storage and communication capabilities to the edge of the network, in support of the IoT. Segmentation, distribution and adaptive deployment of functionalities over the continuum from Things to Cloud are challenging tasks, due to the intrinsic heterogeneity, hierarchical structure and very large scale infrastructure they will have to exploit. In this paper, we propose a simple, yet general, model to support the QoS-aware deployment of multi-component IoT applications to Fog infrastructures. The model describes operational systemic qualities of the available infrastructure (latency and bandwidth), interactions among software components and Things, and business policies. Algorithms to determine eligible deployments for an application to a Fog infrastructure are presented. A Java tool, FogTorch, based on the proposed model has been prototyped.},
	number = {5},
	journal = {IEEE Internet of Things Journal},
	author = {Brogi, Antonio and Forti, Stefano},
	year = {2017},
	pages = {1185--1192},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/84JT4M8P/07919155(1).pdf:application/pdf},
}

@article{brogi_how_2017,
	title = {How to {Best} {Deploy} {Your} {Fog} {Applications}, {Probably}},
	doi = {10.1109/ICFEC.2017.8},
	abstract = {Deploying composite applications to Fog nodes in a QoS-and context-aware manner is challenging due to the heterogeneity and scale of Fog infrastructures. Application components must be provided with the software and hardware capabilities they need. Communication links that support interactions between components must meet certain QoS (latency and bandwidth). On the other hand, different Fog and Cloud nodes provide different software and hardware capabilities, and actual communication links support different QoS over time. In this paper we present a prototype (FogTorchII) capable of determining deployments of composite applications to Fog infrastructures, which fulfil software, hardware and QoS requirements. FogTorchII exploits Monte Carlo simulations to take into account possible variations of the QoS of communication links. It classifies eligible deployments both in terms of QoS-assurance and of Fog resource consumption. We illustrate the utility of FogTorchII over a motivating example where we compare different possible deployments for a smart agriculture application.},
	journal = {Proceedings - 2017 IEEE 1st International Conference on Fog and Edge Computing, ICFEC 2017},
	author = {Brogi, Antonio and Forti, Stefano and Ibrahim, Ahmad},
	year = {2017},
	note = {ISBN: 9781509030477},
	keywords = {QoS, Fog applications, Monte Carlo simulations},
	pages = {105--114},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/YC74HNNB/08014366.pdf:application/pdf},
}

@article{brogi_deploying_2018,
	title = {Deploying fog applications: {How} much does it cost, by the way?},
	volume = {2018-Janua},
	doi = {10.5220/0006676100680077},
	abstract = {Deploying IoT applications through the Fog in a QoS-, context-, and cost-aware manner is challenging due to the heterogeneity, scale and dynamicity of Fog infrastructures. To decide how to allocate app functionalities over the continuum from the IoT to the Cloud, app administrators need to find a trade-off among QoS, resource consumption and cost. In this paper, we present a novel cost model for estimating the cost of deploying IoT applications to Fog infrastructures. We show how the inclusion of the cost model in the FogTorchΠ open-source prototype permits to determine eligible deployments of multi-component applications to Fog infrastructures and to rank them according to their QoS-assurance, Fog resource consumption and cost. We run the extended prototype on a motivating scenario, showing how it can support IT experts in choosing the deployments that best suit their desiderata.},
	number = {Closer 2018},
	journal = {CLOSER 2018 - Proceedings of the 8th International Conference on Cloud Computing and Services Science},
	author = {Brogi, Antonio and Forti, Stefano and Ibrahim, Ahmad},
	year = {2018},
	note = {ISBN: 9789897582950},
	keywords = {Fog computing, QoS, Application deployment, Cost models, Resource consumption},
	pages = {68--77},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/FMQM5P97/66761.pdf:application/pdf},
}

@article{skarlat_optimized_2017,
	title = {Optimized {IoT} service placement in the fog},
	volume = {11},
	issn = {18632394},
	doi = {10.1007/s11761-017-0219-8},
	abstract = {The Internet of Things (IoT) leads to an ever-growing presence of ubiquitous networked computing devices in public, business, and private spaces. These devices do not simply act as sensors, but feature computational, storage, and networking resources. Being located at the edge of the network, these resources can be exploited to execute IoT applications in a distributed manner. This concept is known as fog computing. While the theoretical foundations of fog computing are already established, there is a lack of resource provisioning approaches to enable the exploitation of fog-based computational resources. To resolve this shortcoming, we present a conceptual fog computing framework. Then, we model the service placement problem for IoT applications over fog resources as an optimization problem, which explicitly considers the heterogeneity of applications and resources in terms of Quality of Service attributes. Finally, we propose a genetic algorithm as a problem resolution heuristic and show, through experiments, that the service execution can achieve a reduction of network communication delays when the genetic algorithm is used, and a better utilization of fog resources when the exact optimization method is applied.},
	number = {4},
	journal = {Service Oriented Computing and Applications},
	author = {Skarlat, Olena and Nardelli, Matteo and Schulte, Stefan and Borkowski, Michael and Leitner, Philipp},
	year = {2017},
	note = {Publisher: Springer London},
	keywords = {Fog computing, Internet of Things, Service placement, Resource provisioning, Quality of service, notion},
	pages = {427--443},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/Y7HYJXQS/Skarlat2017_Article_OptimizedIoTServicePlacementIn.pdf:application/pdf},
}

@article{gadhavi_adaptive_2019,
	title = {Adaptive cloud resource management through workload prediction},
	issn = {18683975},
	doi = {10.1007/s12667-019-00368-6},
	abstract = {Resource management strategy in adaptive cloud provisions the needed resources dynamically to the end-users. To improve the runtime performance of adaptive cloud for service-based applications, two aspects of technical issues are required to be addressed. The first one is the balancing of a large amount of data on existing resources and the second is resource provisioning which can adjust the number of resources optimally to adapt the time-varying workload. As the growth of data is increasing tremendously, efficient resource management is the need in cloud computing. We build a cloud framework to process data in automation with adaptive resource and workload management strategy. Numbers of approaches are reviewed and applied for workload prediction. We developed the model Auto-Regressive Integrated Moving Average-workload Prediction for Efficient Resource Provisioning (ARIMA-PERP) and evaluated the results that can satisfy the on-demand need of end-users for efficient resource utilization. To serve the maximum number of user requests, performance metrics of the proposed approach are evaluated. It is observed that our evaluated results achieved an accurate prediction by 91.11\%, which meets the efficient resource utilization for the demanded workload. As compared with the exiting approach, we achieved better performance by 0.11\% for accurate prediction. The proposed architecture is intended to provide the resources dynamically and efficiently satisfying the demands of the user. To achieve this objective of efficient resource provisioning, algorithms are developed for workload prediction which helps in deciding optimum resource provisioning. Our system uses proactive approach resource management and deployment of the adaptive cloud system. In traditional systems, resources are managed based on demand, availability and the strategy of scheduling which results in delayed response time at large. We configured the ARIMA model to predict the future workload for provisioning the resources dynamically and remove the problem of over-provisioning and under-provisioning in a cloud environment.},
	journal = {Energy Systems},
	author = {Gadhavi, Lata J. and Bhavsar, Madhuri D.},
	year = {2019},
	keywords = {Resource provisioning, Adaptive cloud, Prediction model, Quality of services, Resource exploitation, Workload prediction},
}

@article{venticinque_methodology_2019,
	title = {A methodology for deployment of {IoT} application in fog},
	volume = {10},
	issn = {18685145},
	url = {http://dx.doi.org/10.1007/s12652-018-0785-4},
	doi = {10.1007/s12652-018-0785-4},
	abstract = {The foreseen increase of IoT connected to the Internet is worrying the ICT community because of its impact on network Infrastructure when the number of requesters become larger and larger. Moreover also reliability of network connection and real-time constraints can affect the effectiveness of the Cloud Computing paradigm for developing IoT solutions. The necessity of an intermediate layer in the whole IoT architecture that works as a middle ground between the local physical memories and Cloud is proposed by the Fog paradigm. In this paper we define and use a methodology that supports the developer to address the Fog Service Placement Problem, which consists of finding the optimal mapping between IoT applications and computational resources. We exploited and extended a Fog Application model from the related work to apply the proposed methodology in order to investigate the optimal deployment of IoT application. The case study is an IoT application in the Smart Energy domain. In particular, we extended a software platform, which was developed, and released open source by the CoSSMic European project, with advanced functionalities. The new functionalities provide capabilities for automatic learning of energy profiles and lighten the platform utilization by users, but they introduce new requirements, also in terms of computational resources. Experimental results are presented to demonstrate the usage and the effectiveness of the proposed methodology at deployment stage.},
	number = {5},
	journal = {Journal of Ambient Intelligence and Humanized Computing},
	author = {Venticinque, Salvatore and Amato, Alba},
	year = {2019},
	note = {Publisher: Springer Berlin Heidelberg
ISBN: 0123456789},
	keywords = {Fog computing, Cloud computing, Internet of things, Smart grid},
	pages = {1955--1976},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/F7FJN4L7/Venticinque-Amato2019_Article_AMethodologyForDeploymentOfIoT.pdf:application/pdf},
}

@article{brogi_predictive_2019,
	title = {Predictive {Analysis} to {Support} {Fog} {Application} {Deployment}},
	doi = {10.1002/9781119525080.ch9},
	abstract = {In this chapter, we first recapitulate on the challenges related to segmenting application functionalities all through the Cloud-to-Things continuum. A detailed life-like example is then used to further motivate the readers. We then describe the model and algorithms that constitute our prototype tool, FogTorchΠ, which permits (1) to find candidate deployments that meet (functional and non-functional) requirements of an application to a given infrastructure, and (2) to perform what-if analysis based on predicted metrics. Applicability of FogTorchΠ to the given motivating example is shown, comparing candidate deployments with respect to their QoS-assurance, Fog resource consumption and cost. Later, we describe the state-of-the-art related to our work. Particularly, a VR game application example is used to compare the results obtained by FogTorchΠ with those obtained by one of the most promising tools available for simulating Fog scenarios (iFogSim). Finally, after highlighting future research directions in this area, we draw some concluding remarks.},
	journal = {Fog and Edge Computing},
	author = {Brogi, Antonio and Forti, Stefano and Ibrahim, Ahmad},
	year = {2019},
	pages = {191--221},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/6CXMMSGF/9781119525080.ch9.pdf:application/pdf},
}

@article{zhang_hierarchical_2017,
	title = {A {Hierarchical} {Game} {Framework} for {Resource} {Management} in {Fog} {Computing}},
	volume = {55},
	issn = {15581896},
	doi = {10.1109/MCOM.2017.1600896},
	abstract = {Supporting real-Time and mobile data services, fog computing has been considered as a promising technology to overcome long and unpredicted delay in cloud computing. However, as resources in FNs are owned by independent users or infrastructure providers, the ADSSs cannot connect and access data services from the FNs directly, but can only request data service from the DSOs in the cloud. Accordingly, in fog computing, the DSOs are required to communicate with FNs and allocate resources from the FNs to the ADSSs. The DSOs provide virtualized data services to the ADSSs, and the FNs, motivated by the DSOs, provide data services in the physical network. Nevertheless, with fog computing added as the intermediate layer between the cloud and users, there are challenges such as the resource allocation in the virtualized network between the DSOs and ADSSs, the asymmetric information problem between DSOs and ADSSs, and the resource matching from the FNs to the ADSSs in the physical network. In this article, we propose a three-layer hierarchical game framework to solve the challenges in fog computing networks. In the proposed framework, we apply the Stackelberg sub-game for the interaction between DSOs and ADSSs, moral hazard modeling for the interaction between DSOs and FNs, and the student project allocation matching sub-game for the interaction between FNs and ADSSs. The purpose is to obtain stable and optimal utilities for each DSO, FN, and ADSS in a distributed fashion.},
	number = {8},
	journal = {IEEE Communications Magazine},
	author = {Zhang, Huaqing and Zhang, Yanru and Gu, Yunan and Niyato, Dusit and Han, Zhu},
	year = {2017},
	note = {Publisher: IEEE},
	pages = {52--57},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/J482QPI4/08004153.pdf:application/pdf},
}

@article{wang_dynamic_2017,
	title = {Dynamic {Service} {Placement} for {Mobile} {Micro}-{Clouds} with {Predicted} {Future} {Costs}},
	volume = {28},
	issn = {10459219},
	doi = {10.1109/TPDS.2016.2604814},
	abstract = {Mobile micro-clouds are promising for enabling performance-critical cloud applications. However, one challenge therein is the dynamics at the network edge. In this paper, we study how to place service instances to cope with these dynamics, where multiple users and service instances coexist in the system. Our goal is to find the optimal placement (configuration) of instances to minimize the average cost overtime, leveraging the ability of predicting future cost parameters with known accuracy. We first propose an offline algorithm that solves for the optimal configuration in a specific look-ahead time-window. Then, we propose an online approximation algorithm with polynomial time-complexity to find the placement in real-time whenever an instance arrives. We analytically show that the online algorithm is 0(1)-competitive for a broad family of cost functions. Afterwards, the impact of prediction errors is considered and a method for finding the optimal look-ahead window size is proposed, which minimizes an upper bound of the average actual cost. The effectiveness of the proposed approach is evaluated by simulations with both synthetic and real-world (San Francisco taxi) usermobility traces. The theoretical methodology used in this paper can potentially be applied to a larger class of dynamic resource allocation problems.},
	number = {4},
	journal = {IEEE Transactions on Parallel and Distributed Systems},
	author = {Wang, Shiqiang and Urgaonkar, Rahul and He, Ting and Chan, Kevin and Zafer, Murtaza and Leung, Kin K.},
	year = {2017},
	keywords = {Cloud computing, optimization, wireless networks, resource allocation, fog/edge computing, online approximation algorithm},
	pages = {1002--1016},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/MD2X87JR/07557016.pdf:application/pdf},
}

@article{mahmud_quality_2018,
	title = {Quality of {Experience} ({QoE})-aware placement of applications in {Fog} computing environments},
	volume = {132},
	issn = {07437315},
	doi = {10.1016/j.jpdc.2018.03.004},
	abstract = {Fog computing aims at offering Cloud like services at the network edge for supporting Internet of Things (IoT) applications with low latency response requirements. Hierarchical, distributed and heterogeneous nature of computational instances make application placement in Fog a challenging task. Diversified user expectations and different features of IoT devices also intensify the application placement problem. Placement of applications to compatible Fog instances based on user expectations can enhance Quality of Experience (QoE) regarding the system services. In this paper, we propose a QoE-aware application placement policy that prioritizes different application placement requests according to user expectations and calculates the capabilities of Fog instances considering their current status. In Fog computing environment, it also facilitates placement of applications to suitable Fog instances so that user QoE is maximized in respect of utility access, resource consumption and service delivery. The proposed policy is evaluated by simulating a Fog environment using iFogSim. Experimental results indicate that the policy significantly improves data processing time, network congestion, resource affordability and service quality.},
	number = {March 2018},
	journal = {Journal of Parallel and Distributed Computing},
	author = {Mahmud, Redowan and Srirama, Satish Narayana and Ramamohanarao, Kotagiri and Buyya, Rajkumar},
	year = {2018},
	keywords = {Fog computing, Application placement, Fuzzy logic, Quality of experience, User expectation},
	pages = {190--203},
	file = {Mahmud et al_2019_Quality of Experience (QoE)-Aware placement of applications in Fog computing.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/635X96GV/Mahmud et al_2019_Quality of Experience (QoE)-Aware placement of applications in Fog computing.pdf:application/pdf;PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/YCGEIB2U/MainDocument_JPDC-17-402R1.pdf:application/pdf},
}

@article{mahmud_latency-aware_2018,
	title = {Latency-aware application module management for fog computing environments},
	volume = {19},
	issn = {15576051},
	doi = {10.1145/3186592},
	abstract = {The fog computing paradigm has drawn significant research interest as it focuses on bringing cloud-based services closer to Internet of Things (IoT) users in an efficient and timelymanner. Most of the physical devices in the fog computing environment, commonly named fog nodes, are geographically distributed, resource constrained, and heterogeneous. To fully leverage the capabilities of the fog nodes, large-scale applications that are decomposed into interdependent Application Modules can be deployed in an orderly way over the nodes based on their latency sensitivity. In this article,we propose a latency-aware ApplicationModule management policy for the fog environment that meets the diverse service delivery latency and amount of data signals to be processed in per unit of time for different applications. The policy aims to ensure applications' Quality of Service (QoS) in satisfying service delivery deadlines and to optimize resource usage in the fog environment. We model and evaluate our proposed policy in an iFogSim-simulated fog environment. Results of the simulation studies demonstrate significant improvement in performance over alternative latency-aware strategies.},
	number = {1},
	journal = {ACM Transactions on Internet Technology},
	author = {Mahmud, Redowan and Ramamohanarao, Kotagiri and Buyya, Rajkumar},
	year = {2018},
	keywords = {Fog computing, Application placement, Internet of things, Application management, Application QoS, Latency awareness, Resource optimization},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/ZKLVZKXC/MainDocument_TOIT-2017-0032.R1.pdf:application/pdf},
}

@article{rosvall_map_2009,
	title = {The map equation},
	volume = {178},
	issn = {19516355},
	doi = {10.1140/epjst/e2010-01179-1},
	abstract = {Many real-world networks are so large that we must simplify their structure before we can extract useful information about the systems they represent. As the tools for doing these simplifications proliferate within the network literature, researchers would benefit from some guidelines about which of the so-called community detection algorithms are most appropriate for the structures they are studying and the questions they are asking. Here we show that different methods highlight different aspects of a network's structure and that the the sort of information that we seek to extract about the system must guide us in our decision. For example, many community detection algorithms, including the popular modularity maximization approach, infer module assignments from an underlying model of the network formation process. However, we are not always as interested in how a system's network structure was formed, as we are in how a network's extant structure influences the system's behavior. To see how structure influences current behavior, we will recognize that links in a network induce movement across the network and result in system-wide interdependence. In doing so, we explicitly acknowledge that most networks carry flow. To highlight and simplify the network structure with respect to this flow, we use the map equation. We present an intuitive derivation of this flow-based and information-theoretic method and provide an interactive on-line application that anyone can use to explore the mechanics of the map equation. The differences between the map equation and the modularity maximization approach are not merely conceptual. Because the map equation attends to patterns of flow on the network and the modularity maximization approach does not, the two methods can yield dramatically different results for some network structures. To illustrate this and build our understanding of each method, we partition several sample networks. We also describe an algorithm and provide source code to efficiently decompose large weighted and directed networks based on the map equation. © 2009 EDP Sciences and Springer.},
	number = {1},
	journal = {European Physical Journal: Special Topics},
	author = {Rosvall, M. and Axelsson, D. and Bergstrom, C. T.},
	year = {2009},
	pages = {13--23},
}

@article{rossi_hierarchical_2020,
	title = {Hierarchical scaling of microservices in {Kubernetes}},
	doi = {10.1109/ACSOS49614.2020.00023},
	abstract = {In the last years, we have seen the increasing adoption of the microservice architectural style where applications satisfy user requests by invoking a set of independently deployable services. Software containers and orchestration tools, such as Kubernetes, have simplified the development and management of microservices. To manage containers' horizontal elasticity, Kubernetes uses a decentralized threshold-based policy that requires to set thresholds on system-oriented metrics (i.e., CPU utilization). This might not be well-suited to scale latency-sensitive applications, which need to express requirements in terms of response time. Moreover, being a fully decentralized solution, it may lead to frequent and uncoordinated application reconfigurations.In this paper, we present me-kube (Multi-level Elastic Kubernetes), a Kubernetes extension that introduces a hierarchical architecture for controlling the elasticity of microservice-based applications. At higher level, a centralized per-application component coordinates the run-time adaptation of subordinated distributed components, which, in turn, locally control the adaptation of each microservice. Then, we propose novel proactive and reactive hierarchical control policies, based on queuing theory. To show that me-kube provides general mechanisms, we also integrate reinforcement learning-based scaling policies. Using me-kube, we perform a large set of experiments, aimed to show the advantages of a hierarchical control over the default Kubernetes autoscaler.},
	journal = {Proceedings - 2020 IEEE International Conference on Autonomic Computing and Self-Organizing Systems, ACSOS 2020},
	author = {Rossi, Fabiana and Cardellini, Valeria and Presti, Francesco Lo},
	year = {2020},
	note = {ISBN: 9781728172774},
	keywords = {Microservices, Container, Kubernetes, Elasticity, Hierarchical control, Self-adaptation},
	pages = {28--37},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/5LTMCQJC/09196461(1).pdf:application/pdf},
}

@article{rossi_elastic_2019,
	title = {Elastic {Deployment} of {Software} {Containers} in {Geo}-{Distributed} {Computing} {Environments}},
	volume = {2019-June},
	issn = {15301346},
	doi = {10.1109/ISCC47284.2019.8969607},
	abstract = {Software containers are ever more adopted to manage and execute distributed applications. Indeed, they enable to quickly scale the amount of computing resources by means of horizontal and vertical elasticity. Most of the existing works consider the deployment of containers in centralized data centers. However, to exploit the diffused presence of edge/fog computing resources, we need new solutions that deploy containers while also considering their placement on decentralized resources. In this paper, we present a two-step approach that manages the run-time adaptation of container-based applications deployed over geo-distributed virtual machines. In the first step, our approach exploits Reinforcement Learning (RL) solutions to control the horizontal and vertical elasticity of the containers. In the second step, it addresses the container placement by solving a suitable integer linear programming problem or using a network-aware heuristic. A wide set of simulation results shows the benefits and flexibility of the proposed approach, which can satisfy stringent application requirements expressed in terms of response time percentiles.},
	journal = {Proceedings - International Symposium on Computers and Communications},
	author = {Rossi, Fabiana and Cardellini, Valeria and Presti, Francesco Lo},
	year = {2019},
	note = {ISBN: 9781728129990},
	keywords = {Containers, Elasticity, Geographically distributed resources, Placement, Self-adaptation},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/8S44UM62/08969607.pdf:application/pdf},
}

@article{mahmud_context-aware_2020,
	title = {Context-{Aware} {Placement} of {Industry} 4.0 {Applications} in {Fog} {Computing} {Environments}},
	volume = {16},
	issn = {19410050},
	doi = {10.1109/TII.2019.2952412},
	abstract = {The fourth industrial revolution, widely known as Industry 4.0, is realizable through widespread deployment of Internet of Things (IoT) devices across the industrial ambiance. Due to communication latency and geographical distribution, Cloud-centric IoT models often fail to satisfy the Quality of Service requirements of different IoT applications assisting Industry 4.0 in real time. Therefore, Fog computing focuses on harnessing edge resources to place and execute these applications in the proximity of data sources. Since most of the Fog nodes are heterogeneous, distributed, and resource-constrained, it is challenging to place Industry 4.0-oriented applications (I4OAs) over them ensuring time-optimized service delivery. Diversified data sensing frequency of different industrial IoT devices and their data size further intensify the application placement problem. To address this issue, in this article we propose a context-aware application placement policy for Fog environments. Our policy coordinates the IoT device-level contexts with the capacity of Fog nodes and minimizes the service delivery time of various I4OAs such as image processing and robot navigation applications. It also ensures that the streams of input data flowing toward the placed applications neither congest the network nor increase the computing overhead of host Fog nodes significantly. Performance of the proposed policy is evaluated in both real-world and simulated Fog environments and compared with the existing placement policies. The experiment results show that our policy offers overall 16\% improvement in service latency, network relaxation, and computing overhead management compared to other placement policies.},
	number = {11},
	journal = {IEEE Transactions on Industrial Informatics},
	author = {Mahmud, Redowan and Toosi, Adel N. and Ramamohanarao, Kotagiri and Buyya, Rajkumar},
	year = {2020},
	keywords = {Fog computing, Internet of Things, Application placement, context-aware-ness, Industry 4.0},
	pages = {7004--7013},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/ZQ6QNQME/08894519.pdf:application/pdf},
}

@article{skarlat_framework_2019,
	title = {A framework for optimization, service placement, and runtime operation in the fog},
	doi = {10.1109/UCC.2018.00025},
	abstract = {Fog computing provides a paradigm for executing Internet of Things services. Enabling the coordinated cooperation among computational, storage, and networking resources in the fog can be challenging due to the volatility of resources. For this reason, we design an architecture and implement a representative framework called FogFrame that defines the necessary communication mechanisms for instantiating and maintaining service execution in the fog. To evaluate our approach, we conduct a series of experiments that show how service placement, deployment, and execution is performed by the framework, and how the framework operates at runtime, i.e., adapts to changes in the available resources, balances the workload and recovers from resource failures and overloads.},
	number = {October},
	journal = {Proceedings - 11th IEEE/ACM International Conference on Utility and Cloud Computing, UCC 2018},
	author = {Skarlat, Olena and Karagiannis, Vasileios and Rausch, Thomas and Bachmann, Kevin and Schulte, Stefan},
	year = {2019},
	note = {ISBN: 9781538655047},
	keywords = {Fog computing, Service placement, Internet of things, Fog computing framework, Service deployment},
	pages = {164--173},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/AHR8SNSF/A_Framework_for_Optimization_Service_Placement_and(1).pdf:application/pdf},
}

@article{santos_towards_2019,
	title = {Towards network-{Aware} resource provisioning in kubernetes for fog computing applications},
	doi = {10.1109/NETSOFT.2019.8806671},
	abstract = {Nowadays, the Internet of Things (IoT) continues to expand at enormous rates. Smart Cities powered by connected sensors promise to transform public services from transportation to environmental monitoring and healthcare to improve citizen welfare. Furthermore, over the last few years, Fog Computing has been introduced to provide an answer to the massive growth of heterogeneous devices connected to the network. Nevertheless, providing a proper resource scheduling for delay-sensitive and data-intensive services in Fog Computing environments is still a key research domain. Therefore, in this paper, a network-Aware scheduling approach for container-based applications in Smart City deployments is proposed. Our proposal has been validated on the Kubernetes platform, an open source orchestrator for the automatic management and deployment of micro-services. Our approach has been implemented as an extension to the default scheduling mechanism available in Kubernetes, enabling Kubernetes to make resource provisioning decisions based on the current status of the network infrastructure. Evaluations based on Smart City container-based applications have been carried out to compare the performance of the proposed scheduling approach with the standard scheduling feature available in Kubernetes. Results show that the proposed approach achieves reductions of 80\% in terms of network latency when compared to the default scheduling mechanism.},
	journal = {Proceedings of the 2019 IEEE Conference on Network Softwarization: Unleashing the Power of Network Softwarization, NetSoft 2019},
	author = {Santos, Jose and Wauters, Tim and Volckaert, Bruno and De Turck, Filip},
	year = {2019},
	note = {ISBN: 9781538693766},
	keywords = {IoT, Smart Cities, Fog Computing, Kubernetes, Resource Provisioning},
	pages = {351--359},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/HRSVTVQZ/NETSOFT.2019.8806671.pdf:application/pdf},
}

@article{ahmed_fog_2019,
	title = {Fog {Computing} {Applications}: {Taxonomy} and {Requirements}},
	issn = {23318422},
	abstract = {Fog computing was designed to support the specific needs of latency-critical applications such as augmented reality, and IoT applications which produce massive volumes of data that are impractical to send to faraway cloud data centers for analysis. However this also created new opportunities for a wider range of applications which in turn impose their own requirements on future fog computing platforms. This article presents a study of a representative set of 30 fog computing applications and the requirements that a general-purpose fog computing platform should support.},
	journal = {arXiv},
	author = {Ahmed, Arif and Arkian, Hamid Reza and Battulga, Davaadorj and Fahs, Ali J. and Farhadi, Mozhdeh and Giouroukis, Dimitrios and Gougeon, Adrien and Gutierrez, Felipe Oliveira and Pierre, Guillaume and Souza, Paulo R. and Tamiru, Mulugeta Ayalew and Wu, Li},
	year = {2019},
	pages = {1--16},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/CR8ZWTM9/1907.11621(1).pdf:application/pdf},
}

@article{guevara_task_2021,
	title = {Task scheduling in cloud-fog computing systems},
	issn = {19366450},
	doi = {10.1007/s12083-020-01051-9},
	abstract = {Fog computing extends cloud services to the edge of the network. In such scenario, it is necessary to decide where applications should be executed so that their quality of service requirements can be supported. Thus, a cloud-fog system requires an efficient task scheduler to decide the locality where applications should run. This paper presents two schedulers based on integer linear programming, that schedule tasks either in the cloud or on fog resources. The schedulers differ from existing ones by the use of class of services to select the processing elements on which the tasks should be executed. Numerical results evince that the proposed schedulers outperform traditional ones, e.g., Random and Round Robin algorithms without causing violation of QoS requirements.},
	journal = {Peer-to-Peer Networking and Applications},
	author = {Guevara, Judy C. and da Fonseca, Nelson L.S.},
	year = {2021},
	note = {Publisher: Peer-to-Peer Networking and Applications},
	keywords = {Edge computing, Fog computing, Cloud computing, Quality of service, Scheduling, Class of service},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/YEXB72V3/Guevara-Fonseca2021_Article_TaskSchedulingInCloud-fogCompu(1).pdf:application/pdf},
}

@article{guevara_class_2017,
	title = {Class of service in fog computing},
	volume = {2017-Janua},
	doi = {10.1109/LATINCOM.2017.8240187},
	abstract = {Although Fog computing specifies a scalable architecture for computation, communication and storage, there is still a demand for better Quality of Service (QoS), especially for agile mobile services. Both industry and academia have been working on novel and efficient mechanisms for QoS provisioning in Fog computing. This paper presents a classification of services according to their QoS requirements as well as Class of Service for fog applications. This will facilitate the decision-making process for fog scheduler, and specifically to identify the timescale and location of resources, helping to make scalable the deployment of new applications. Moreover, this paper introduces a mapping between the proposed classes of service and the processing layers of the Fog computing reference architecture. The paper also discusses use cases in which the proposed classification of services would be helpful.},
	journal = {2017 IEEE 9th Latin-American Conference on Communications, LATINCOM 2017},
	author = {Guevara, Judy C. and Bittencourt, Luiz F. and Da Fonseca, Nelson L.S.},
	year = {2017},
	note = {ISBN: 9781538620984},
	keywords = {Edge computing, Fog computing, Resource management, Cloud computing, Internet of things (IoT), Classes of service, Mobile cloud, Quality of service (QoS)},
	pages = {1--6},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/KQDUWFVS/Class of Service in Fog Computing(1).pdf:application/pdf},
}

@article{guerrero_lightweight_2019,
	title = {A lightweight decentralized service placement policy for performance optimization in fog computing},
	volume = {10},
	issn = {18685145},
	url = {http://dx.doi.org/10.1007/s12652-018-0914-0},
	doi = {10.1007/s12652-018-0914-0},
	abstract = {A decentralized optimization policy for service placement in fog computing is presented. The optimization is addressed to place most popular services as closer to the userAs as possible. The experimental validation is done in the iFogSim simulator and by comparing our algorithm with the simulator’s built-in policy. The simulation is characterized by modeling a microservice-based application for different experiment sizes. Results showed that our decentralized algorithm places most popular services closer to users, improving network usage and service latency of the most requested applications, at the expense of a latency increment for the less requested services and a greater number of service migrations.},
	number = {6},
	journal = {Journal of Ambient Intelligence and Humanized Computing},
	author = {Guerrero, Carlos and Lera, Isaac and Juiz, Carlos},
	year = {2019},
	note = {Publisher: Springer Berlin Heidelberg
ISBN: 0123456789},
	keywords = {Fog computing, Service placement, Performance optimization, notion},
	pages = {2435--2452},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/WXXQU6WH/guerrero2018(2).pdf:application/pdf},
}

@article{zhang_dots_2019,
	title = {{DOTS}: {Delay}-optimal task scheduling among voluntary nodes in fog networks},
	volume = {6},
	issn = {23274662},
	doi = {10.1109/JIOT.2018.2887264},
	abstract = {Through offloading the computing tasks of the task nodes (TNs) to the fog nodes (FNs) located at the network edge, the fog network is expected to address the unacceptable processing delay and heavy link burden existed in current cloud-based networks. Unlike most existing researches based on the command-mode offloading and full capability report, this paper develops a general analytical model of the task scheduling among voluntary nodes (VNs) in fog networks, wherein the VNs voluntarily contribute their capabilities for serving their neighboring TNs. A novel delay-optimal task scheduling (DOTS) algorithm is proposed to obtain the delay-optimal offloading solution according to the reported capabilities of the VNs. Extensive simulations are carried out in a fog network, and the numerical results indicate that the proposed DOTS algorithm can effectively provide the optimal set of the helper nodes, subtask sizes, and the TN transmission power to minimize the overall task processing delay. Moreover, compared with the command-mode offloading, the voluntary-mode achieves more balanced offloading and a higher fairness level among the FNs.},
	number = {2},
	journal = {IEEE Internet of Things Journal},
	author = {Zhang, Guowei and Shen, Fei and Chen, Nanxi and Zhu, Pengcheng and Dai, Xuewu and Yang, Yang},
	year = {2019},
	note = {Publisher: IEEE},
	keywords = {Delay minimization, fairness, fog network, voluntary capability report},
	pages = {3533--3544},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/L8DW46D6/08580377.pdf:application/pdf},
}

@article{zhang_femto_2019,
	title = {{FEMTO}: {Fair} and energy-minimized task offloading for fog-enabled {IoT} networks},
	volume = {6},
	issn = {23274662},
	doi = {10.1109/JIOT.2018.2887229},
	abstract = {Future Internet of Things (IoT) networks enabled with fog computing is promising to achieve lower processing delay and lighter link burden, by effectively offloading the computing tasks of the terminal nodes (TNs) to nearby fog nodes (FNs) at the network edge. Existing researches for the energy consumption in fog-enabled networks mostly focused on the minimization of the overall energy consumed by the task offloading services. However, fair offloading among multiple FNs while maintaining a satisfactory energy efficiency is of great significance for the sustainability of the fog-enabled IoT networks, especially in the scenarios with battery-powered FNs. In this paper, we propose a fair and energy-minimized task offloading (FEMTO) algorithm based on a fairness scheduling metric, taking three important characteristics into consideration, which include the task offloading energy consumption, the FN's historical average energy and the FN priority. The analytical results of the optimal target FN, the optimal TN transmission power, and the optimal subtask size are obtained in a fair and energy-minimized manner. Extensive simulations are carried out for the heterogeneous fog-enabled IoT network, and the numerical results indicate that the proposed FEMTO algorithm effectively determines the FN feasibility and the minimum energy consumption for the task offloading services. Moreover, a high and robust fairness level for the FNs' energy consumptions is obtained by the proposed FEMTO algorithm.},
	number = {3},
	journal = {IEEE Internet of Things Journal},
	author = {Zhang, Guowei and Shen, Fei and Liu, Zening and Yang, Yang and Wang, Kunlun and Zhou, Ming Tuo},
	year = {2019},
	note = {Publisher: IEEE},
	keywords = {Fog computing, Internet of Things (IoT), Task offloading, Energy minimization, Fairness},
	pages = {4388--4400},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/3M7HLTKV/08580383.pdf:application/pdf},
}

@book{abbasi_load_2019,
	title = {Load {Stabilizing} in {Fog} {Computing} {Environment} {Using} {Load} {Balancing} {Algorithm}},
	volume = {25},
	isbn = {978-3-030-02613-4},
	url = {http://dx.doi.org/10.1007/978-3-030-02613-4_66},
	abstract = {The paper concentrates on the Fog Computing (FC) application to a Smart Grid (SG), that comprises of a Distribution Generation System recognized as a Microgrid (MG). FC acts as an additional layer of computation and communication. It decreases the load on the Cloud and provides same facilities as Cloud. The main concern in FC environment is Load Balancing. Fog contains many software and hardware resources and handling these will play a significant role in completing a client’s request. Today, from different regions of the world clients are requesting for the numerous services in a continuous frequency. The Fog manages the load by assigning the Virtual Machines (VMs) to clients’ requests. In this regard, the techniques that should be employed to stabilize the load on the Fog should be very effective in assigning the VM to user requests. In the proposed work, for load balancing we have used four different load balancing algorithms: Round Robin (RR), Throttled, Particle Swarm Optimization (PSO) and Active VM Load Balancing Algorithm (AVMLB). Further, the Cloud Analyst simulator is used to analyze and compare the performances of the algorithms.},
	publisher = {Springer International Publishing},
	author = {Abbasi, Sadam Hussain and Javaid, Nadeem and Ashraf, Muhammad Hassaan and Mehmood, Mubashar and Naeem, Maria and Rehman, Mubariz},
	year = {2019},
	doi = {10.1007/978-3-030-02613-4_66},
	note = {Publication Title: Lecture Notes on Data Engineering and Communications Technologies
ISSN: 23674520},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/BAHQP3DF/978-3-030-02613-4_66.pdf:application/pdf},
}

@article{shurman_collaborative_2017,
	title = {Collaborative execution of distributed mobile and {IoT} applications running at the edge},
	volume = {2018-Janua},
	doi = {10.1109/ICECTA.2017.8252057},
	abstract = {The use of mobile and IoT applications is growing rapidly and gaining huge interests in research and commercial investment to meet future visions, these applications have common demands to support their needs of low latency, geographically distributed services and location based awareness. These demands contrast with services provided by the centralized distant cloud datacenters. Edge computing paradigm has emerged as a more applicable solution for these applications providing an extension of cloud computing storage and network resources placed in a geographically distributed manner at the edge of the network closer to mobiles and IoT devices. In this paper, we focus on exploiting edge resources to the maximum using a collaborative approach of distributing modules of pre-partitioned applications between edge resources, aiming to reduce amount of traffic travelling through the core network to the cloud and reduce amount of delays in order to provide an efficient services delivery and a better user experience. We tested our approach using iFogSim toolkit, the obtained results show reduction in network usage and total delays compared to the baseline approach of placement, yielding in a better throughput and better utilization of edge resources.},
	journal = {2017 International Conference on Electrical and Computing Technologies and Applications, ICECTA 2017},
	author = {Shurman, Mohammad M. and Aljarah, Maha K.},
	year = {2017},
	note = {ISBN: 9781538608722},
	keywords = {IoT, Resource management, Edge Computing, Fog Computing, Mobile Edge Computing (MEC)},
	pages = {1--5},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/DV7VG4HQ/08252057.pdf:application/pdf},
}

@article{liu_dependent_2019,
	title = {Dependent task placement and scheduling with function configuration in edge computing},
	doi = {10.1145/3326285.3329055},
	abstract = {In Mobile Edge Computing (MEC), each edge server can be configured with only a small number of functions due to the limited capacity of various resources. Meanwhile, mobile applications become more complicated, consisting of multiple dependent tasks which are typically modeled as a Directed Acyclic Graph (DAG). In edge computing, when an application arrives, we need to place and schedule its tasks onto edge servers and/or the remote cloud, where the functions to execute the tasks are configured. In this work, we jointly consider the problem of dependent task placement and scheduling with on-demand function configuration on servers. Our objective is to minimize the application completion time. Specifically, for the special case when the configuration on each edge server is fixed, we derive an algorithm to find the optimal task placement and scheduling efficiently. When the on-demand function configuration is allowed, we propose a novel approximation algorithm, named GenDoc, and analyze theoretically its additive error from the optimal solution. Our extensive experiments on the cluster trace from Alibaba (including 20365 unique applications with DAG information) show that GenDoc outperforms state-ofthe- art baselines in processing 86.14\% of these unique applications, and reduces their average completion time by at least 24\% (and up to 54\%). Moreover, GenDoc consistently performs well on various settings of key parameters.},
	journal = {Proceedings of the International Symposium on Quality of Service, IWQoS 2019},
	author = {Liu, Liuyan and Tan, Haisheng and Jiang, Shaofeng H.C. and Han, Zhenhua and Li, Xiang Yang and Huang, Hong},
	year = {2019},
	note = {ISBN: 9781450367783},
	keywords = {Edge Computing, Function Configuration, Task Scheduling},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/TWCAQWM9/09068608.pdf:application/pdf},
}

@article{nezami_decentralized_2020,
	title = {Decentralized edge-to-cloud load-balancing: {Service} placement for the internet of things},
	issn = {23318422},
	abstract = {The Internet of Things (IoT) has revolutionized everyday life and expanded the scope of smart services to a broad range of domains. In ubiquitous environments, fog computing has emerged leveraging the resources in the edge-to-cloud continuum to improve the quality of service, while reducing the traffic on cloud infrastructure and networks. In such a distributed ecosystem with heterogeneous resources of various sizes and inherent dynamics such as varying service demand over time, managing resources and services is a major challenge. This paper studies two optimization objectives and formulates a decentralized load-balancing problem for IoT service placement: (global) IoT workload balance and (local) quality of service, in terms of minimizing the cost of deadline violation, service deployment, and unhosted services. The proposed solution, EPOS Fog, introduces a decentralized multi-agent system for collective learning that utilizes edge-to-cloud nodes to jointly balance the input workload across the network and minimize the costs involved in service execution. The agents locally generate possible assignments of requests to resources and then cooperatively select an assignment such that their combination maximizes edge utilization while minimizes service execution cost. Extensive experimental evaluation with realistic Google cluster workloads on various networks demonstrates the superior performance of EPOS Fog in terms of workload balance and quality of service, compared to approaches such as First Fit and exclusively Cloud-based. The findings demonstrate how distributed computational resources on the edge can be utilized more cost-effectively by harvesting collective intelligence.},
	journal = {arXiv},
	author = {Nezami, Zeinab and Zamanifar, Kamran and Djemame, Karim and Pournaras, Evangelos},
	year = {2020},
	keywords = {Edge computing, Fog computing, Internet of Things, Service placement, Cloud computing, Agent, Collective learning, Distributed optimization, Edge-to-cloud, Load-balancing},
	pages = {1--16},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/FHZBY4Y6/2005.00270.pdf:application/pdf},
}

@article{aslanpour_performance_2020,
	title = {Performance evaluation metrics for cloud, fog and edge computing: {A} review, taxonomy, benchmarks and standards for future research},
	volume = {12},
	issn = {25426605},
	url = {https://doi.org/10.1016/j.iot.2020.100273},
	doi = {10.1016/j.iot.2020.100273},
	abstract = {Optimization is an inseparable part of Cloud computing, particularly with the emergence of Fog and Edge paradigms. Not only these emerging paradigms demand reevaluating cloud-native optimizations and exploring Fog and Edge-based solutions, but also the objectives require significant shift from considering only latency to energy, security, reliability and cost. Hence, it is apparent that optimization objectives have become diverse and lately Internet of Things (IoT)-specific born objectives must come into play. This is critical as incorrect selection of metrics can mislead the developer about the real performance. For instance, a latency-aware auto-scaler must be evaluated through latency-related metrics as response time or tail latency; otherwise the resource manager is not carefully evaluated even if it can reduce the cost. Given such challenges, researchers and developers are struggling to explore and utilize the right metrics to evaluate the performance of optimization techniques such as task scheduling, resource provisioning, resource allocation, resource scheduling and resource execution. This is challenging due to (1) novel and multi-layered computing paradigm, e.g., Cloud, Fog and Edge, (2) IoT applications with different requirements, e.g., latency or privacy, and (3) not having a benchmark and standard for the evaluation metrics. In this paper, by exploring the literature, (1) we present a taxonomy of the various real-world metrics to evaluate the performance of cloud, fog, and edge computing; (2) we survey the literature to recognize common metrics and their applications; and (3) outline open issues for future research. This comprehensive benchmark study can significantly assist developers and researchers to evaluate performance under realistic metrics and standards to ensure their objectives will be achieved in the production environments.},
	journal = {Internet of Things},
	author = {Aslanpour, Mohammad S. and Gill, Sukhpal Singh and Toosi, Adel N.},
	year = {2020},
	note = {Publisher: Elsevier B.V.},
	keywords = {Cloud computing, Internet of, Performance evaluation, Cloud computing,Performance evaluation,Internet of},
	pages = {100273},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/NQKQD6ZJ/aslanpour2020(1).pdf:application/pdf},
}

@article{natesha_adopting_2021,
	title = {Adopting elitism-based {Genetic} {Algorithm} for minimizing multi-objective problems of {IoT} service placement in fog computing environment},
	volume = {178},
	issn = {10958592},
	url = {https://doi.org/10.1016/j.jnca.2020.102972},
	doi = {10.1016/j.jnca.2020.102972},
	abstract = {Fog computing is an emerging computation technology for handling and processing the data from IoT devices. The devices such as the router, smart gateways, or micro-data centers are used as the fog nodes to host and service the IoT applications. However, the primary challenge in fog computing is to find the suitable nodes to deploy and run the IoT application services as these devices are geographically distributed and have limited computational resources. In this paper, we design the two-level resource provisioning fog framework using docker and containers and formulate the service placement problem in fog computing environment as a multi-objective optimization problem for minimizing the service time, cost, energy consumption and thus ensuring the QoS of IoT applications. We solved the said multi-objective problem using the Elitism-based Genetic Algorithm (EGA). The proposed approach is evaluated on fog computing testbed developed using docker and containers on 1.4 GHz 64-bit quad-core processor devices. The experimental results demonstrate that the proposed method outperforms other state-of-the-art service placement strategies considered for performance evaluation in terms of service cost, energy consumption, and service time.},
	number = {December 2020},
	journal = {Journal of Network and Computer Applications},
	author = {Natesha, B. V. and Guddeti, Ram Mohana Reddy},
	year = {2021},
	note = {Publisher: Elsevier Ltd},
	keywords = {Fog computing, IoT, Service placement, Resource provisioning, Containers, Multi-objective},
	pages = {102972},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/72UPY79R/1-s2.0-S1084804520304239-main(2).pdf:application/pdf},
}

@article{islam_context-aware_2021,
	title = {Context-aware scheduling in {Fog} computing: {A} survey, taxonomy, challenges and future directions},
	volume = {180},
	issn = {10848045},
	url = {https://doi.org/10.1016/j.jnca.2021.103008},
	doi = {10.1016/j.jnca.2021.103008},
	abstract = {Fog computing extends Cloud-based facilities and stays in the vicinity of the end-users to provide an attractive solution to a diverse range of latency-sensitive applications. The applications are becoming more sophisticated, context-aware, and computation-intensive due to varying situational and environmental conditions in order to meet the ever-increasing users’ demands. Further, resource heterogeneity, dynamic nature, resource limitations, and unpredictability of the Fog environment make scheduling of application tasks while satisfying Quality of Service (QoS) requirements a challenging job. To overcome these issues various scheduling strategies have been proposed considering contextual information of different entities involved in Fog computing. This survey rep- resents a comprehensive literature analysis pertaining to context-aware scheduling in Fog computing. It provides detailed comparison of existing scheduling approaches based on important factors such as context-aware pa- rameters, case studies, performance metrics, and evaluation tools along with advantages and limitations. It also presents detailed taxonomy, performance metrics, and context-aware parameter analysis. Further, it list several issues and challenges. This study will aid the research community in exploring future research directions and essential aspects of scheduling approaches using different types of contextual information},
	number = {December 2020},
	journal = {Journal of Network and Computer Applications},
	author = {Islam, Mir Salim Ul and Kumar, Ashok and Hu, Yu-Chen},
	year = {2021},
	note = {Publisher: Elsevier Ltd},
	keywords = {Fog computing, Resource management, Resource provisioning, Context-awareness, Scheduling, Contextual information, Resource estimation},
	pages = {103008},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/RIBLRMWK/1-s2.0-S1084804521000357-main(1).pdf:application/pdf},
}

@article{srirama_akka_2021,
	title = {Akka framework based on the {Actor} model for executing distributed {Fog} {Computing} applications},
	volume = {117},
	issn = {0167739X},
	url = {https://doi.org/10.1016/j.future.2020.12.011},
	doi = {10.1016/j.future.2020.12.011},
	abstract = {Future Internet of Things (IoT)-driven applications will move from the cloud-centric IoT model to the hybrid distributed processing model, known as Fog computing, where some of the involved computational tasks (e.g. real-time data analytics) are partially moved to the edge of the network to reduce latency and improve the network efficiency. In recent times, Fog computing has generated significant research interest for IoT applications, however, there is still a lack of ideal approach and framework for supporting parallel and fault-tolerant execution of the tasks while collectively utilizing the resource-constrained Fog devices. To address this issue, in this paper, we propose an Akka framework based on the Actor Model for designing and executing the distributed Fog applications. The Actor Model was conceived as a universal paradigm for concurrent computation with additional requirements such as resiliency and scalability, whereas, the Akka toolkit is a reference implementation of the model. Further, to dynamically deploy the distributed applications on the Fog networks, a Docker containerization approach is used. To validate the proposed actor-based framework, a wireless sensor network case study is designed and implemented for demonstrating the feasibility of conceiving applications on the Fog networks. Besides that, a detailed analysis is produced for showing the performance and parallelization efficiency of the proposed model on the resource-constrained gateway and Fog devices.},
	journal = {Future Generation Computer Systems},
	author = {Srirama, Satish Narayana and Dick, Freddy Marcelo Surriabre and Adhikari, Mainak},
	year = {2021},
	note = {Publisher: Elsevier B.V.},
	keywords = {Internet of Things, Docker, Fog Computing, Actor programming model, Akka toolkit, Distributed processing},
	pages = {439--452},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/L9SKTQE3/1-s2.0-S0167739X20330739-main(1).pdf:application/pdf},
}

@article{perez_abreu_comparative_2020,
	title = {A comparative analysis of simulators for the {Cloud} to {Fog} continuum},
	volume = {101},
	issn = {1569190X},
	url = {https://doi.org/10.1016/j.simpat.2019.102029},
	doi = {10.1016/j.simpat.2019.102029},
	abstract = {The Cloud to Fog continuum is a very dense and complex scenario. At the core level (Cloud) resources are vast, whilst they become scarce at the Edge (Fog). This complexity leads to the need of simulation tools in order to evaluate the performance of novel mechanisms that hardly can be tested in real scenarios. Thus, simulation represents a solution for early stage evaluation before moving to real-world (and more expensive and complex) testbeds. However, selecting the appropriate simulation tool can be complex in itself. This paper presents a conceptual review on six Cloud/Fog Simulation tools, describing their main characteristics and what they allow to experiment. A practical overview of the most representative Cloud/Fog simulators is presented, reporting about their resource consumption and execution time. The aim of this survey is to enlighten other researchers in the selection of the appropriate Cloud/Fog simulation tool for their goals and to know what they can expect from said tools.},
	number = {October 2019},
	journal = {Simulation Modelling Practice and Theory},
	author = {Perez Abreu, David and Velasquez, Karima and Curado, Marilia and Monteiro, Edmundo},
	year = {2020},
	note = {Publisher: Elsevier},
	keywords = {Cloud, Edge, Experimental evaluation, Fog, Simulator},
	pages = {102029},
	file = {Abreu et al_2020_A comparative analysis of simulators for the Cloud to Fog continuum.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/JFE2QVNQ/Abreu et al_2020_A comparative analysis of simulators for the Cloud to Fog continuum.pdf:application/pdf;PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/DVXR4UP7/1-s2.0-S1569190X19301601-main.pdf:application/pdf},
}

@article{yousefpour_fog_2017,
	title = {Fog {Computing}: {Towards} {Minimizing} {Delay} in the {Internet} of {Things}},
	doi = {10.1109/IEEE.EDGE.2017.12},
	abstract = {With the Internet of Things (IoT) becoming a major component of our daily life, understanding how to improve quality of service (QoS) in IoT networks is becoming a challenging problem. Currently most interaction between the IoT devices and the supporting back-end servers is done through large scale cloud data centers. However, with the exponential growth of IoT devices and the amount of data they produce, communication between 'things' and cloud will be costly, inefficient, and in some cases infeasible. Fog computing serves as solution for this as it provides computation, storage, and networking resource for IoT, closer to things and users. One of the promising advantages of fog is reducing service delay for end user applications, whereas cloud provides extensive computation and storage capacity with a higher latency. Thus it is necessary to understand the interplay between fog computing and cloud, and to evaluate the effect of fog computing on the IoT service delay and QoS. In this paper we will introduce a general framework for IoT-fog-cloud applications, and propose a delay-minimizing policy for fog-capable devices that aims to reduce the service delay for IoT applications. We then develop an analytical model to evaluate our policy and show how the proposed framework helps to reduce IoT service delay.},
	journal = {Proceedings - 2017 IEEE 1st International Conference on Edge Computing, EDGE 2017},
	author = {Yousefpour, Ashkan and Ishigaki, Genya and Jue, Jason P.},
	year = {2017},
	note = {ISBN: 9781538620175},
	keywords = {Internet of Things, QoS, Cloud Computing, Fog Computing, Delay Minimizing},
	pages = {17--24},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/R596AKJN/08029252.pdf:application/pdf},
}

@article{karatas_comparison_2016,
	title = {A comparison of p-median and maximal coverage location models with {Q}-coverage requirement},
	volume = {149},
	issn = {18777058},
	url = {http://dx.doi.org/10.1016/j.proeng.2016.06.652},
	doi = {10.1016/j.proeng.2016.06.652},
	abstract = {A facility location problem considers locating a certain number of facilities with the objective of finding their best locations. For most real life situations, it is more realistic to consider the requirement of satisfying a demand with multiple facilities in order to ensure a backup supply. The back-up supply is necessary especially for public or emergency service location problems where a covered demand may not be serviced if its designated facility is engaged serving other demands. Moreover, this issue is more likely to occur when the number of demand locations is much higher. In this study we consider two classic location models, the p-median and maximal coverage location, and compare their performances with respect to five decision criteria under Q-coverage requirement. For this purpose we generate random problem instances and solve each instance with both models for different Q-coverage values. Our comparisons reveal the tradeoffs in selecting the location model for a given problem when the decision maker assesses the performance with multiple criteria.},
	number = {June},
	journal = {Procedia Engineering},
	author = {Karatas, Mumtaz and Razi, Nasuh and Tozan, Hakan},
	year = {2016},
	note = {Publisher: The Author(s)},
	keywords = {Facility problem, Location problem, Maximal coverage, P-Median},
	pages = {169--176},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/3WTRT3CR/1-s2.0-S1877705816311602-main.pdf:application/pdf},
}

@article{farahani_covering_2012,
	title = {Covering problems in facility location: {A} review},
	volume = {62},
	issn = {03608352},
	url = {http://dx.doi.org/10.1016/j.cie.2011.08.020},
	doi = {10.1016/j.cie.2011.08.020},
	abstract = {In this study, we review the covering problems in facility location. Here, besides a number of reviews on covering problems, a comprehensive review of models, solutions and applications related to the covering problem is presented after Schilling, Jayaraman, and Barkhi (1993). This survey tries to review all aspects of the covering problems by stressing the works after Schilling, Jayaraman, and Barkhi (1993). We first present the covering problems and then investigate solutions and applications. A summary and future works conclude the paper.},
	number = {1},
	journal = {Computers and Industrial Engineering},
	author = {Farahani, Reza Zanjirani and Asgari, Nasrin and Heidari, Nooshin and Hosseininia, Mahtab and Goh, Mark},
	year = {2012},
	note = {Publisher: Elsevier Ltd},
	keywords = {Covering problem, Facility location, Mathematical formulation, Survey},
	pages = {368--407},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/KRJR4V6F/1-s2.0-S036083521100249X-main.pdf:application/pdf},
}

@article{markus_survey_2020,
	title = {A survey and taxonomy of simulation environments modelling fog computing},
	volume = {101},
	issn = {1569190X},
	url = {https://doi.org/10.1016/j.simpat.2019.102042},
	doi = {10.1016/j.simpat.2019.102042},
	abstract = {In the past ten years, the latest advances in Information and Communication Technology had a significant impact on distributed systems by giving birth to paradigms such as Cloud Computing, Fog Computing and the Internet of Things (IoT). The environments they created are closely coupled in most cases: IoT sensors and devices generate data that have to be stored, processed and analysed by cloud or fog services, depending on the actual application needs. These IoT-Fog-Cloud systems are very complex, and the use of simulations in their design, development and operational processes is inevitable. Nowadays, there are many simulator solutions available to model and analyse these systems depending our research needs, but in many cases it is hard to grasp their differences, and implementing certain scenarios in different tools is time consuming. The goal of this work is to help researchers and practitioners in this regard by proposing a survey and taxonomy of the available simulators modelling clouds, IoT and specifically fogs, which is the latest, currently still forming paradigm. The main contributions of this study are our novel viewpoints for classification including software quality, which is performed by analysing the source code of the considered simulators. We also propose comparison tables for three groups of simulators that reveal their differences and the way they model the elements of these systems. Finally, we discuss the relevant findings of our classifications, and highlight open issues that need further research.},
	number = {June 2019},
	journal = {Simulation Modelling Practice and Theory},
	author = {Markus, Andras and Kertesz, Attila},
	year = {2020},
	note = {Publisher: Elsevier},
	keywords = {Fog computing, Cloud computing, Internet of things, Survey, Simulation, Taxonomy},
	pages = {102042},
	file = {Markus_Kertesz_2020_A survey and taxonomy of simulation environments modelling fog computing.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/ALJRW7JL/Markus_Kertesz_2020_A survey and taxonomy of simulation environments modelling fog computing.pdf:application/pdf;PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/GZWE9U4C/1-s2.0-S1569190X1930173X-main.pdf:application/pdf},
}

@article{martinez_design_2020,
	title = {Design, {Resource} {Management}, and {Evaluation} of {Fog} {Computing} {Systems}: {A} {Survey}},
	volume = {8},
	issn = {2327-4662},
	doi = {10.1109/jiot.2020.3022699},
	abstract = {A steady increase in Internet of Things (IoT) applications needing large-scale computation and long-term storage has lead to an over-reliance on Cloud computing. The resulting network congestion in Cloud, coupled with the distance of Cloud data centres from IoT, contribute to unreliable end-to-end response delay. Fog computing has been introduced as an alternative to cloud, providing low-latency service by bringing processing and storage resources to the network edge. In this survey, we sequentially present the phases required in the implementation and realization of practical fog computing systems: (1) design \& dimensioning of a fog infrastructure, (2) fog resource provisioning for IoT application use and IoT resource allocation to fog, (3) installation of fog frameworks for fog resource management, and (4) evaluation of fog infrastructure through simulation \& emulation. Our focus is determining the implementation aspects required to build a practical large scale fog computing infrastructure to support the general IoT landscape.},
	number = {4},
	journal = {IEEE Internet of Things Journal},
	author = {Martinez, Ismael and Hafid, Abdelhakim Senhaji and Jarray, Abdallah},
	year = {2020},
	keywords = {⛔ No INSPIRE recid found},
	pages = {2494--2516},
	file = {Martinez et al_2020_Design, resource management, and evaluation of fog computing systems.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/ZWTIHUJU/Martinez et al_2020_Design, resource management, and evaluation of fog computing systems.pdf:application/pdf;PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/94WULGEA/09194714.pdf:application/pdf},
}

@article{mouradian_comprehensive_2018,
	title = {A {Comprehensive} {Survey} on {Fog} {Computing}: {State}-of-the-{Art} and {Research} {Challenges}},
	volume = {20},
	issn = {1553877X},
	doi = {10.1109/COMST.2017.2771153},
	abstract = {Cloud computing with its three key facets (i.e., Infrastructure-as-a-Service, Platform-as-a-Service, and Software-as-a-Service) and its inherent advantages (e.g., elasticity and scalability) still faces several challenges. The distance between the cloud and the end devices might be an issue for latency-sensitive applications such as disaster management and content delivery applications. Service level agreements (SLAs) may also impose processing at locations where the cloud provider does not have data centers. Fog computing is a novel paradigm to address such issues. It enables provisioning resources and services outside the cloud, at the edge of the network, closer to end devices, or eventually, at locations stipulated by SLAs. Fog computing is not a substitute for cloud computing but a powerful complement. It enables processing at the edge while still offering the possibility to interact with the cloud. This paper presents a comprehensive survey on fog computing. It critically reviews the state of the art in the light of a concise set of evaluation criteria. We cover both the architectures and the algorithms that make fog systems. Challenges and research directions are also introduced. In addition, the lessons learned are reviewed and the prospects are discussed in terms of the key role fog is likely to play in emerging technologies such as tactile Internet.},
	number = {1},
	journal = {IEEE Communications Surveys and Tutorials},
	author = {Mouradian, Carla and Naboulsi, Diala and Yangui, Sami and Glitho, Roch H. and Morrow, Monique J. and Polakos, Paul A.},
	year = {2018},
	note = {Publisher: IEEE},
	keywords = {Internet of Things (IoT), latency, Cloud computing, edge computing, fog computing, tactile Internet},
	pages = {416--464},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/JRX52993/08100873(1).pdf:application/pdf},
}

@article{badidi_architecture_2020,
	title = {An {Architecture} for {QoS}-{Aware} {Fog} {Service} {Provisioning}},
	volume = {170},
	issn = {18770509},
	url = {https://doi.org/10.1016/j.procs.2020.03.083},
	doi = {10.1016/j.procs.2020.03.083},
	abstract = {The proliferation of IoT technologies and the broad deployment of sensors and IoT devices are changing the way and the speed of delivery of many services. IoT data streams are typically transmitted to cloud services for processing. However, time-sensitive IoT applications cannot tolerate high latency they may experience when IoT data streams are sent to the cloud. Fog computing-based solutions for this kind of applications are becoming more and more attractive due to the low latency they can provide and guarantee. Given the growing deployments of fog nodes, we propose in this paper an architecture for quality of service (QoS) aware fog service provisioning, which allows to schedule the execution of IoT applications' tasks on a cluster of fog nodes. A fog broker component can implement various scheduling policies to help IoT applications fulfill their QoS requirements. The results of the simulations we performed show that using some simple strategies, it is possible to keep low the latency of applications and distribute the load among the fog nodes of the cluster.},
	journal = {Procedia Computer Science},
	author = {Badidi, Elarbi and Ragmani, Awatif},
	year = {2020},
	note = {Publisher: Elsevier B.V.},
	keywords = {Fog computing, latency, cloud computing, quality-of-service, scheduling},
	pages = {411--418},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/E7S5866I/1-s2.0-S1877050920305202-main.pdf:application/pdf},
}

@article{bermbach_towards_2020,
	title = {Towards {Auction}-{Based} {Function} {Placement} in {Serverless} {Fog} {Platforms}},
	doi = {10.1109/ICFC49376.2020.00012},
	abstract = {The Function-as-a-Service (FaaS) paradigm has a lot of potential as a computing model for fog environments comprising both cloud and edge nodes. When the request rate exceeds capacity limits at the edge, some functions need to be offloaded from the edge towards the cloud.In this position paper, we propose an auction-based approach in which application developers bid on resources. This allows fog nodes to make a local decision about which functions to offload while maximizing revenue. For a first evaluation of our approach, we use simulation.},
	journal = {Proceedings - 2020 IEEE International Conference on Fog Computing, ICFC 2020},
	author = {Bermbach, David and Maghsudi, Setareh and Hasenburg, Jonathan and Pfandzelter, Tobias},
	year = {2020},
	note = {ISBN: 9781728110868},
	keywords = {Fog Computing, Function-as-a-Service, Serverless Computing},
	pages = {25--31},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/PHXDTH8E/09103477.pdf:application/pdf},
}

@article{kassir_service_2020,
	title = {Service {Placement} for {Real}-{Time} {Applications}: {Rate}-{Adaptation} and {Load}-{Balancing} at the {Network} {Edge}},
	doi = {10.1109/CSCloud-EdgeCom49738.2020.00044},
	abstract = {Mobile Edge Computing may become a prevalent platform to support applications where mobile devices have limited compute, storage, energy and/or data privacy concerns. In this paper, we study the efficient provisioning and management of compute resources in the Edge-To-Cloud continuum for different types of real-Time applications with timeliness requirements depending on application-level update rates and communication/compute delays. We begin by introducing a highly stylized network model allowing us to study the salient features of this problem including its sensitivity to compute vs. communication costs, application requirements, and traffic load variability. We then propose an online decentralized service placement algorithm, based on estimating network delays and adapting application update rates, which achieves high service availability. Our results exhibit how placement can be optimized and how a load-balancing strategy can achieve near-optimal service availability in large networks.},
	journal = {Proceedings - 2020 7th IEEE International Conference on Cyber Security and Cloud Computing and 2020 6th IEEE International Conference on Edge Computing and Scalable Cloud, CSCloud-EdgeCom 2020},
	author = {Kassir, Saadallah and Veciana, Gustavo De and Wang, Nannan and Wang, Xi and Palacharla, Paparao},
	year = {2020},
	note = {ISBN: 9781728165509},
	keywords = {Edge Computing, Fog Network Dimensioning, Rate Adaptation, Real-Time Applications, Service Placement},
	pages = {207--215},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/NIFSDBDD/09170993.pdf:application/pdf},
}

@article{apat_energy_2020,
	title = {Energy {Efficient} {Resource} {Management} in {Fog} {Computing} {Supported} {Medical} {Cyber}-{Physical} {System}},
	doi = {10.1109/ICCSEA49143.2020.9132855},
	abstract = {The sufficient resources in the cloud data center allow plenties of the Internet of Things(IoT) application that has to be deployed on the server to provide services for different industries. However the major drawbacks faced nowadays is the centralized nature of computing framework for processing latency sensitive application especially health monitoring, processing medical data generated from the sensor devices attached in the body of the patients. The major drawback being faced in these cloud frameworks is their limited scalability and hence incapable to cater the requirements of the centralized IoT based environment. Fog computing architecture is considered as a promising solution that extends the feature of existing Cloud Computing and brings the resources close to the IoT devices which meets the requirements imposed by the devices in the network of IoT. The main issue of fog computing is the distribution of resources. As fog computing is still in the infancy stage there is no such Service Level Agreement(SLA) defined. In fog computing resource management is an important issue if efficiently managed then we can enhance the performance of the system up to a large extent. In this paper we are considering smart health care which is now a trend for smart city people used to get access health-care from the home, so we have proposed to design an architecture for efficient health-care by using fog computing which is collaboration with cloud. Service placement is considered as an important problem for designing such architecture to process the latency based application that can provide innovative solutions by bringing resources closer to the user and provide low latency and energy-efficient solutions for data processing compared to cloud. We have employed to form a fog cluster based on the hop count and place the services within that cluster so that node to node latency get minimized and network cost is minimized for users perspective, we also minimize the network utilization so that load on the network devices is balanced. In this work, we have discussed service placement problems in fog computing environments for a specific use case of health monitoring over a large geographical area. A new Dynamic Cluster Algorithm has been proposed and compare with existing two other Algorithm named as latency aware and resource aware.The result shown that our algorithm performs better than other two Algorithms.},
	journal = {2020 International Conference on Computer Science, Engineering and Applications, ICCSEA 2020},
	author = {Apat, Hemant Kumar and Bhaisare, Kunal and Sahoo, Bibhudatta and Maiti, Prasenjit},
	year = {2020},
	note = {ISBN: 9781728158303},
	keywords = {Fog computing, Internet of Things(IoT), Energy consumption Optimization, Network Resource Optimization, Response Time, Task Placement},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/Q9MYRW42/09132855.pdf:application/pdf},
}

@article{gedeon_sunstone_2020,
	title = {Sunstone: {Navigating} the {Way} through the {Fog}},
	doi = {10.1109/ICFEC50348.2020.00013},
	abstract = {Fog Computing extends Cloud Computing by placing resources in the core network between cloud resources and (mobile) users. While a lot of frameworks to implement Fog Computing have been proposed, most do not consider loose coupling between federated fog resources. In such environments, the scalable discovery and orchestration of fog resources across multiple administrative domains and autonomous systems remains a challenge.In this paper, we present Sunstone1, a discovery mechanism for Fog Computing that works on Internet-scale by combining on-path and off-path discovery mechanisms. Leveraging protocols present in the global routing infrastructure, Sunstone operates across multiple fog-domains while requiring no modifications to existing network middleboxes in the transit network. Furthermore, Sunstone includes a customizable orchestrator, which - given the results of the discovery process and application-specific policies - allows for a QoS-aware placement of applications in the fog.},
	journal = {Proceedings - 4th IEEE International Conference on Fog and Edge Computing, ICFEC 2020},
	author = {Gedeon, Julien and Zengerle, Sebastian and Alles, Sebastian and Brandherm, Florian and Muhlhauser, Max},
	year = {2020},
	note = {ISBN: 9781728173054},
	keywords = {edge computing, fog computing, mobile edge computing, orchestration, discovery},
	pages = {49--58},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/KLB93SBW/icfec50348.2020.00013.pdf:application/pdf},
}

@article{alharbi_energy_2020,
	title = {Energy efficient virtual machines placement over cloud-fog network architecture},
	volume = {8},
	issn = {21693536},
	doi = {10.1109/ACCESS.2020.2995393},
	abstract = {Fog computing is an emerging paradigm that aims to improve the efficiency and QoS of cloud computing by extending the cloud to the edge of the network. This paper develops a comprehensive energy efficiency analysis framework based on mathematical modeling and heuristics to study the offloading of virtual machine (VM) services from the cloud to the fog. The analysis addresses the impact of different factors including the traffic between the VM and its users, the VM workload, the workload versus number of users profile and the proximity of fog nodes to users. Overall, the power consumption can be reduced if the VM users' traffic is high and/or the VMs have a linear power profile. In such a linear profile case, the creation of multiple VM replicas does not increase the computing power consumption significantly (there may be a slight increase due to idle / baseline power consumption) if the number of users remains constant, however the VM replicas can be brought closer to the end users, thus reducing the transport network power consumption. In our scenario, the optimum placement of VMs over a cloud-fog architecture significantly decreased the total power consumption by 56\% and 64\% under high user data rates compared to optimized distributed clouds placement and placement in the existing ATT network cloud locations, respectively.},
	journal = {IEEE Access},
	author = {Alharbi, Hatem A. and Elgorashi, Taisir E.H. and Elmirghani, Jaafar M.H.},
	year = {2020},
	keywords = {Fog computing, cloud computing, energy efficiency, virtual machine},
	pages = {94697--94718},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/C99L6T8B/09095288.pdf:application/pdf},
}

@article{yosuf_energy_2020,
	title = {Energy {Efficient} {Distributed} {Processing} for {IoT}},
	volume = {8},
	issn = {21693536},
	doi = {10.1109/ACCESS.2020.3020744},
	abstract = {In the near future, the number of Internet connected objects is expected to be between 26 - 50 billion devices. This figure is expected to grow even further due to the production of miniaturized portable devices that are lightweight, energy, and cost-efficient. In this article, the entire IoT-fog-cloud architecture is modeled, the service placement problem is formulated using Mixed Integer Linear Programming (MILP) and the total power consumption is jointly minimized for processing and networking. We evaluate the distributed processing paradigm for both the un-capacitated and capacitated design settings in order to provide solutions for the long-term and short-term basis, respectively. Furthermore, four aspects of the IoT processing placement problem are examined: 1) IoT services with non-splittable tasks, 2) IoT services with splittable tasks, 3) impact of processing overheads needed for inter-service communication and 4) deployment of special-purpose data centers (SP-DCs) as opposed to the conventional general-purpose data center (GP-DC) in the core network. The results showed that for the capacitated problem, task splitting introduces power savings of up to 86\% compared to 46\% with non-splittable tasks. Moreover, it is observed that the overheads due to inter-service communication greatly impacts the total number of splits. However much insignificant the overhead factor, the results showed that this is not a trivial matter and hence much attention needs to be paid to this area to make the best use of the resources that are available at the edge of the network.},
	journal = {IEEE Access},
	author = {Yosuf, Barzan A. and Musa, Mohamed and Elgorashi, Taisir and Elmirghani, Jaafar},
	year = {2020},
	keywords = {IoT, Internet of Things, fog computing, resource allocation, energy efficiency, IoT service placement, MILP, resource provisioning},
	pages = {161080--161108},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/KGPXHPYF/09181536.pdf:application/pdf},
}

@article{huang_ant_2020,
	title = {An {Ant} {Colony} {Optimization}-{Based} {Multiobjective} {Service} {Replicas} {Placement} {Strategy} for {Fog} {Computing}},
	issn = {2168-2267},
	doi = {10.1109/tcyb.2020.2989309},
	abstract = {In recent years, fog computing has emerged as a new paradigm for the future Internet-of-Things (IoT) applications, but at the same time, ensuing new challenges. The geographically vast-distributed architecture in fog computing renders us almost infinite choices in terms of service orchestration. How to properly arrange the service replicas (or service instances) among the nodes remains a critical problem. To be specific, in this article, we investigate a generalized service replicas placement problem that has the potential to be applied to various industrial scenarios. We formulate the problem into a multiobjective model with two scheduling objectives, involving deployment cost and service latency. For problem solving, we propose an ant colony optimization-based solution, called multireplicas Pareto ant colony optimization (MRPACO). We have conducted extensive experiments on MRPACO. The experimental results show that the solutions obtained by our strategy are qualified in terms of both diversity and accuracy, which are the main evaluation metrics of a multiobjective algorithm.},
	journal = {IEEE Transactions on Cybernetics},
	author = {Huang, Tiansheng and Lin, Weiwei and Xiong, Chennian and Pan, Rui and Huang, Jingxuan},
	year = {2020},
	note = {ISBN: 2015307311},
	pages = {1--14},
	file = {Huang et al_2020_An ant colony optimization-based multiobjective service replicas placement.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/N7L87KQM/Huang et al_2020_An ant colony optimization-based multiobjective service replicas placement.pdf:application/pdf;PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/3TTDJ7IM/09098079.pdf:application/pdf},
}

@article{velasquez_rank-based_2020,
	title = {A {Rank}-based {Mechanism} for {Service} {Placement} in the {Fog}},
	abstract = {As communications evolve to give space to new applications, such as augmented reality and virtual reality, new paradigms arise to provide essential characteristics like lower latency levels, mobility support, and location awareness. Such is the case of Fog computing, which extends from the well-known Cloud computing paradigm by bringing processing, communications, and storage capabilities to the edge of the network. By offering these novel features, also new challenges emerge that call for the design and implementation of orchestration mechanisms to deal with resource management. One of these mechanisms is related to the service placement, which consists in the selection of the appropriate execution node for the applications according to a specific optimization objective. In this paper, an Integer Linear Programming model for service placement aimed at latency reduction of popular applications is proposed. Furthermore, a heuristic based on the PageRank algorithm, called Popularity Ranked Placement, is also introduced. Simulation results show that the heuristic has lower execution times and is able to better balance the load in the network nodes, while being close to the ILP-based solution latency levels.},
	journal = {IFIP Networking 2020 Conference and Workshops, Networking 2020},
	author = {Velasquez, Karima and Abreu, David Perez and Paquete, Luís and Curado, Marilia and Monteiro, Edmundo},
	year = {2020},
	note = {ISBN: 9783903176287},
	keywords = {notion},
	pages = {64--72},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/6M5A5WEL/09142750.pdf:application/pdf},
}

@article{salaht_service_2019,
	title = {Service placement in fog computing using constraint programming},
	doi = {10.1109/SCC.2019.00017},
	abstract = {This paper investigates whether the use of Constraint Programming (CP) could enable the development of a generic and easy-to-upgrade placement service for Fog Computing. Our contribution is a new formulation of the placement problem, an implementation of this model leveraging Choco-solver and an evaluation of its scalability in comparison to recent placement algorithms. To the best of our knowledge, our study is the first one to evaluate the relevance of CP approaches in comparison to heuristic ones in this context. CP interleaves inference and systematic exploration to search for solutions, letting users on what matters: the problem description. Thus, our service placement model not only can be easily enhanced (deployment constraints/objectives) but also shows a competitive tradeoff between resolution times and solutions quality.},
	journal = {Proceedings - 2019 IEEE International Conference on Services Computing, SCC 2019 - Part of the 2019 IEEE World Congress on Services},
	author = {Salaht, Farah Ait and Desprez, Frederic and Lebre, Adrien and Prud'Homme, Charles and Abderrahim, Mohamed},
	year = {2019},
	note = {ISBN: 9781728127200},
	keywords = {Edge Computing, Fog Computing, Choco Solver, Constraint Programming, Services Placement},
	pages = {19--27},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/V2AERPYA/08814186.pdf:application/pdf},
}

@article{godinho_optimization_2019,
	title = {Optimization of {Service} {Placement} with {Fairness}},
	volume = {2019-June},
	issn = {15301346},
	doi = {10.1109/ISCC47284.2019.8969652},
	abstract = {Due to the large increase of Internet of Things (IoT) devices in the last years, the cloud has been proved unsuitable to deal with the high demand of requests generated by them. To deal with this, fog computing was proposed in order to provide closer computing services in a distributed manner, acting as a middle layer between IoT devices and the cloud. However, these devices have low energy and low computational power. Therefore, strategies to distribute requested services, bundled in a set of applications, are of particular interest. Furthermore, these applications have deadlines that may be short, which have to be met. Hence, models and algorithms are needed to place the requested services in order to meet the deadlines while using the fog as distributed as possible. In this paper, we present a Mixed Integer Linear Programming (MILP) formulation with two main objectives: maximize the fog usage and maximize the fairness throughout the system (fog and cloud). We also propose an heuristic that obtains approximate solutions as fast as possible. We compare both approaches using a set of randomly generated applications composed by different deadlines and services.},
	journal = {Proceedings - International Symposium on Computers and Communications},
	author = {Godinho, Noe and Curado, Marilia and Paquete, Luis},
	year = {2019},
	note = {ISBN: 9781728129990},
	keywords = {Internet of Things, Fog Computing, Service Placement, Quality of Service},
	pages = {0--5},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/4EK4FVZ9/08969652.pdf:application/pdf},
}

@article{vijouyeh_efficient_2020,
	title = {Efficient application deployment in fog-enabled infrastructures},
	doi = {10.23919/CNSM50824.2020.9269052},
	abstract = {Fog computing is a paradigm that extends cloud computing services to the edge of the network in order to support delay-sensitive Internet of Things (IoT) services. One of the most promising use-cases of fog computing is Smart City scenarios. Fog computing can substantially improve the quality of citywide services by reducing response delays. Owing to geographically distributed and resource-constrained fog nodes and a multitude of IoT devices in Smart Cities, efficient service deployment and end device traffic routing are quite challenging. Therefore, in this paper, we present an Integer Linear Programming (ILP) formulation for the Joint Application Component Placement and Traffic Routing (JAcPTR) problem in which users' delay requirements and the limited traffic processing capacity of application instances are considered. Besides, the JAcPTR enables users and infrastructure managers to easily enforce their locality and management requirements in the deployment of application instances. To cope with the considerably high execution time in large instances of the JAcPTR problem, we propose a fast polynomial-time heuristic to efficiently solve the problem. The performance of the proposed heuristic has been evaluated through extensive simulation. Results show that in large instances of the problem, while the state-of-the-art Mixed Integer Linear Programming (MILP) solver fails to obtain a solution in 50\% of the simulation runs in 300 seconds, our proposed heuristic can obtain a near-optimal solution in less than one second.},
	journal = {16th International Conference on Network and Service Management, CNSM 2020, 2nd International Workshop on Analytics for Service and Application Management, AnServApp 2020 and 1st International Workshop on the Future Evolution of Internet Protocols, IPFutu},
	author = {Vijouyeh, Lyla Naghipour and Sabaei, Masoud and Santos, Jose and Wauters, Tim and Volckaert, Bruno and De Turck, Filip},
	year = {2020},
	note = {ISBN: 9783903176317},
	keywords = {Cloud Computing, Smart City, Fog Computing, Application Deployment, Traffic Routing},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/K3Y263J9/09269052.pdf:application/pdf},
}

@article{donassolo_demo_2019,
	title = {Demo: {Fog} {Based} {Framework} for {IoT} {Service} {Orchestration}},
	doi = {10.1109/CCNC.2019.8651852},
	abstract = {In recent years, Fog computing paradigm has received the attention of academic and industrial communities. By offering nearby computational, storage and network resources, this new architecture deals with the explosion of IoT (Internet of Things) traffic while responding to the stringent requirements of new applications. Unfortunately, as of today, there is a lack of practical solutions to enable the exploitation of this novel paradigm. To deal with this shortcoming, this demo gives an insight into FITOR, our proposed orchestration system for IoT applications in Fog. Our solution makes use of both Grid5000 [1] and FIT/IoT-LAB [2] to build a realistic fog environment. FITOR is responsible for the orchestration of micro-service based IoT applications while making use of a holistic monitoring of the fog infrastructure.},
	journal = {2019 16th IEEE Annual Consumer Communications and Networking Conference, CCNC 2019},
	author = {Donassolo, Bruno and Fajjari, Ilhem and Legrand, Arnaud and Mertikopoulos, Panayotis},
	year = {2019},
	note = {Publisher: IEEE
ISBN: 9781538655535},
	keywords = {fog computing, application placement, iot, service provisioning},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/NS7JURAA/08651835.pdf:application/pdf},
}

@article{brogi_meet_2019,
	title = {Meet {Genetic} {Algorithms} in {Monte} {Carlo}: {Optimised} {Placement} of {Multi}-{Service} {Applications} in the {Fog}},
	doi = {10.1109/EDGE.2019.00016},
	abstract = {Managing multi-service applications on top of dynamic and heterogeneous Fog infrastructures is intrinsically challenging and requires suitable tooling to support decision-making. Indeed, bad service deployment decisions can lead to unsatisfactory application QoS, to waste of computing resources or money, and to application downtime. In this paper, we illustrate how combining Genetic Algorithms with Monte Carlo simulations can considerably improve the efficiency of exhaustively searching for QoS-aware application deployments.},
	journal = {Proceedings - 2019 IEEE International Conference on Edge Computing, EDGE 2019 - Part of the 2019 IEEE World Congress on Services},
	author = {Brogi, Antonio and Forti, Stefano and Guerrero, Carlos and Lera, Isaac},
	year = {2019},
	note = {Publisher: IEEE
ISBN: 9781728127088},
	keywords = {Fog computing, service placement, Monte Carlo simulations, genetic algorithms},
	pages = {13--17},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/PPZNPQH9/08812204.pdf:application/pdf},
}

@article{djemai_discrete_2019,
	title = {A discrete particle swarm optimization approach for energy-efficient {IoT} services placement over fog infrastructures},
	doi = {10.1109/ISPDC.2019.00020},
	abstract = {The Internet of Things (IoT) encompasses both large-scale deployed physical infrastructures and software layers that enable intuitive and transparent creation of applications. This highly distributed, energy-greedy environment must ensure the quality of deployed services while taking into account the heterogeneity of capabilities and protocols as well as users and objects mobility. Deployment infrastructure has been redesigned to provide the necessary features, including paradigms such as software-defined networks and Fog computing. The purpose of this article is to study IoT services placement in a Fog architecture. We propose a model of the infrastructure and IoT applications as well as a placement strategy taking into account system's energy consumption and applications delay violations minimization with a Discrete Particles Swarm Optimization algorithm (DPSO). Simulations have been done with iFogSim simulator. Results have been compared with heuristics coming from the literature: Binary Partical Swarm optimization (BPSO), Dicothomous Module Mapping (DCT), CloudOnly, IoTFogOnly, IoTCloud (IC) and FogCloud (FC) placement approaches.},
	journal = {Proceedings - 2019 18th International Symposium on Parallel and Distributed Computing, ISPDC 2019},
	author = {Djemai, Tanissia and Stolf, Patricia and Monteil, Thierry and Pierson, Jean Marc},
	year = {2019},
	note = {ISBN: 9781728138008},
	keywords = {IoT, Optimization, QoS, Fog, DPSO, IFogSim},
	pages = {32--40},
	file = {Accepted Version:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/2GXH77ID/Djemai et al. - 2019 - A discrete particle swarm optimization approach fo.pdf:application/pdf;PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/CF4SPSYT/08790850.pdf:application/pdf},
}

@article{chhikara_efficient_2020,
	title = {An {Efficient} {Container} {Management} {Scheme} for {Resource} {Constrained} {Intelligent} {IoT} {Devices}},
	volume = {4662},
	issn = {23274662},
	doi = {10.1109/JIOT.2020.3037181},
	abstract = {Virtualization is an essential feature in the IoT-resource constrained environment due to which the service providers are facing challenges to minimize the energy consumption by IoT devices. Energy consumption models are pivotal in designing and optimizing energy-efficient operations to curb excessive energy consumption of IoT devices which are an integral part of the modern data centers. A lot of research work has focused on efficient management of energy consumption by virtue of virtual machine consolidation. The existing virtualization techniques may not be suitable for this problem due to high computational overhead. As containers have been recently getting much popularity to encapsulate Fog services, so they are the best candidate to handle this problem, especially for intelligent IoT devices. Keeping the focus on all these issues, in this paper we propose an energy-efficient container migration scheme by migrating the container from the source host server to the destination host server to meet the container\&\#x2019;s resource requirement. We used a novel approach to find the best destination host for container placement to solve host over-load or under-load problems using the best-fit container placement technique. The results obtained on the benchmark dataset with respect to various performance evaluation metrics prove the efficacy of the designed scheme in comparison to the other existing state-of-the-art schemes.},
	number = {c},
	journal = {IEEE Internet of Things Journal},
	author = {Chhikara, Prateek and Tekchandani, Rajkumar and Kumar, Neeraj and Obaidat, Mohammad S.},
	year = {2020},
	keywords = {Edge computing, IoT, Cloud computing, Servers, Containers, Best fit., Cloud Data Centers, Container Management, Energy consumption, Energy Efficiency, Heap Data Structures, Logic gates, Virtual machining},
	pages = {1--13},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/YBRYMRH7/09253547.pdf:application/pdf},
}

@article{taneja_resource_2017,
	title = {Resource aware placement of {IoT} application modules in {Fog}-{Cloud} {Computing} {Paradigm}},
	doi = {10.23919/INM.2017.7987464},
	abstract = {With the evolving IoT scenario, computing has spread to the most minuscule everyday activities, leading to a momentous shift in the way applications are developed and deployed. With the volume of impact increasing exponentially, a coherent approach of deploying these applications is critical for an efficient utilization of the network infrastructure. A typical IoT application consists of various modules running together with active interdependencies; traditionally running on the Cloud hosted in global data centres. In this paper, we present a Module Mapping Algorithm for efficient utilization of resources in the network infrastructure by efficiently deploying Application Modules in Fog-Cloud Infrastructure for IoT based applications. With Fog computing into picture, computation is dynamically distributed across the Fog and Cloud layer, and the modules of an application can thus be deployed closer to the source on devices in the Fog layer. The result of this work can serve as a Micro-benchmark in studies/research related with IoT and Fog Computing, and can be used for Quality of Service (QoS) and Service Level Objective benchmarking for IoT applications. The approach is generic, and applies to a wide range of standardized IoT applications over varied network topologies irrespective of load.},
	journal = {Proceedings of the IM 2017 - 2017 IFIP/IEEE International Symposium on Integrated Network and Service Management},
	author = {Taneja, Mohit and Davy, Alan},
	year = {2017},
	note = {Publisher: IFIP
ISBN: 9783901882890},
	keywords = {Fog computing, Cloud computing, Application module, Latency sensitive, Resource aware placement},
	pages = {1222--1228},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/XFYVA9I8/07987464.pdf:application/pdf},
}

@article{skarlat_towards_2017,
	title = {Towards {QoS}-{Aware} {Fog} {Service} {Placement}},
	doi = {10.1109/ICFEC.2017.12},
	abstract = {Fog computing provides a decentralized approach to data processing and resource provisioning in the Internet of Things (IoT). Particular challenges of adopting fog-based computational resources are the adherence to geographical distribution of IoT data sources, the delay sensitivity of IoT services, and the potentially very large amounts of data emitted and consumed by IoT devices. Despite existing foundations, research on fog computing is still at its very beginning. A major research question is how to exploit the ubiquitous presence of small and cheap computing devices at the edge of the network in order to successfully execute IoT services. Therefore, in this paper, we study the placement of IoT services on fog resources, taking into account their QoS requirements. We show that our optimization model prevents QoS violations and leads to 35\% less cost of execution if compared to a purely cloud-based approach.},
	journal = {Proceedings - 2017 IEEE 1st International Conference on Fog and Edge Computing, ICFEC 2017},
	author = {Skarlat, Olena and Nardelli, Matteo and Schulte, Stefan and Dustdar, Schahram},
	year = {2017},
	note = {ISBN: 9781509030477},
	keywords = {IoT, Internet of Things, Fog Computing, Resource Provisioning, Service Placement},
	pages = {89--96},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/AMVXFWZH/08014364.pdf:application/pdf},
}

@article{xia_combining_2018,
	title = {Combining hardware nodes and software components ordering-based heuristics for optimizing the placement of distributed {IoT} applications in the fog},
	doi = {10.1145/3167132.3167215},
	abstract = {As fog computing brings compute and storage resources to the edge of the network, there is an increasing need for automated placement (i.e., selection of hosting devices) to deploy distributed applications. Such a placement must conform to applications' resource requirements in a heterogeneous fog infrastructure. The placement decision-making is further complicated by Internet of Things (IoT) applications that are tied to geographical locations of physical objects/things. This paper presents a model, an objective function, and a mechanism to address the problem of placing distributed IoT applications in the fog. Based on a backtrack search algorithm and accompanied heuristics, the proposed mechanism is able to deal with large scale problems, and to efficiently make placement decisions that fit the objective - -to lower placed applications' response time. The proposed approach is validated through comparative simulations of different combinations of the algorithms and heuristics on varying sizes of infrastructures and applications.},
	journal = {Proceedings of the ACM Symposium on Applied Computing},
	author = {Xia, Ye and Etchevers, Xavier and Letondeur, Loïc and Coupaye, Thierry and Desprez, Frédéric},
	year = {2018},
	note = {ISBN: 9781450351911},
	keywords = {Fog computing, IoT, Placement, Heuristics},
	pages = {751--760},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/U8DUASJW/1330_Paper.pdf:application/pdf},
}

@article{karamoozian_fog-cloud_2019,
	title = {On the fog-cloud cooperation: {How} fog computing can address latency concerns of {IoT} applications},
	doi = {10.1109/FMEC.2019.8795320},
	abstract = {Fog computing emerged as a new computing paradigm which moves the computing power to the proximity of users, from core to the edge of the network. It is known as the extension of Cloud computing and it offers inordinate opportunities for real-time and latency-sensitive IoT applications. An IoT application consists of a set of dependent Processing Elements (PEs) defined as operations performed on data streams and can be modeled as a Directed Acyclic Graph (DAG). Each PE performs a variety of low-level computation on the incoming data such as aggregation or filtering. A key challenge is to decide how to distribute such PEs over the resources, in order to minimize the overall response time of the entire PE graph. This problem is known as distributed PE scheduling and placement problem. In this work, we try to address the question of how fog computing paradigm can help reducing the IoT application response time by efficiently distributing PE graphs over the Fog-Cloud continuum. We mathematically formulate the fundamental characteristics of IoT application and Fog infrastructure, then model the system as an optimization problem using Gravitational Search Algorithm (GSA) meta-heuristic technique. Our proposed GSA model is evaluated by comparing it with a well-known evolutionary algorithm in the literature via simulation. Also, a comparative analysis with the legacy cloud infrastructure is done in order to show the significant impact of fog presence on the performance of PE processing. Evaluation of our model demonstrates the efficiency of our approach comparing to the current literature.},
	journal = {2019 4th International Conference on Fog and Mobile Edge Computing, FMEC 2019},
	author = {Karamoozian, Amir and Hafid, Abdelhakim and Aboulhamid, El Mostapha},
	year = {2019},
	note = {Publisher: IEEE
ISBN: 9781728117966},
	keywords = {Internet of Things, Fog/Cloud Computing, IoT stream processing, Scheduling and Placement optimization},
	pages = {166--172},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/96E8NKIF/08795320.pdf:application/pdf},
}

@article{kayal_distributed_2019,
	title = {Distributed service placement in fog computing: {An} iterative combinatorial auction approach},
	volume = {2019-July},
	doi = {10.1109/ICDCS.2019.00211},
	abstract = {A primary concern in fog computing is how to efficiently allocate limited fog resources to applications with diverse resource requirements. In fog computing, applications that consist of a set of interdependent microservices are mapped to computing and communication devices, referred to as fog nodes. While placement of microservices can be done centrally, the essentially decentralized infrastructure of participating end-user devices motivates the search for distributed solutions. In this paper, we present a distributed placement strategy that seeks to optimize energy consumption and communication costs. We devise a game-theoretic approximation method that is inspired by an iterative combinatorial auction. By properly restricting the types of bids that can be made in an auction, we can avoid the need for a centralized auctioneer. We devise a fully distributed service placement algorithm without central coordination or global state information. The algorithm operates in rounds, where the number of rounds is bounded by the number of applications and the total number of microservices. Numerical examples show that our placement algorithm outperforms existing heuristics in terms of efficiency and network utilization while achieving comparable utilization and load balancing.},
	journal = {Proceedings - International Conference on Distributed Computing Systems},
	author = {Kayal, Paridhika and Liebeherr, Jorg},
	year = {2019},
	note = {Publisher: IEEE
ISBN: 9781728125190},
	keywords = {Fog computing, Resource allocation, Iterative combinatorial auction},
	pages = {2145--2156},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/CCCNZ9NL/08885368.pdf:application/pdf},
}

@article{giang_developing_2015,
	title = {Developing {IoT} applications in the {Fog}: {A} {Distributed} {Dataflow} approach},
	doi = {10.1109/IOT.2015.7356560},
	abstract = {In this paper we examine the development of IoT applications from the perspective of the Fog Computing paradigm, where computing infrastructure at the network edge in devices and gateways is leverage for efficiency and timeliness. Due to the intrinsic nature of the IoT: heterogeneous devices/resources, a tightly coupled perception-action cycle and widely distributed devices and processing, application development in the Fog can be challenging. To address these challenges, we propose a Distributed Dataflow (DDF) programming model for the IoT that utilises computing infrastructures across the Fog and the Cloud. We evaluate our proposal by implementing a DDF framework based on Node-RED (Distributed Node-RED or D-NR), a visual programming tool that uses a flow-based model for building IoT applications. Via demonstrations, we show that our approach eases the development process and can be used to build a variety of IoT applications that work efficiently in the Fog.},
	journal = {Proceedings - 2015 5th International Conference on the Internet of Things, IoT 2015},
	author = {Giang, Nam Ky and Blackstock, Michael and Lea, Rodger and Leung, Victor C.M.},
	year = {2015},
	note = {Publisher: IEEE
ISBN: 9781467380584},
	keywords = {Internet of Things, Distributed dataflow, Node-RED, Programming models},
	pages = {155--162},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/HJGH4BKS/07356560.pdf:application/pdf},
}

@article{siasi_tabu_2019,
	title = {Tabu search for efficient service function chain provisioning in fog networks},
	doi = {10.1109/CIC48465.2019.00026},
	abstract = {Fog computing places computation/storage resources at the network edge to overcome delay limitations associated with cloud computing. Namely, fog-based services can provide more responsive relay and caching and alleviate loads at core cloud datacenters. Meanwhile, technologies such as network function virtualization (NFV) are virtualizing atomic network functions and allowing provides to build customized service function chains (SFC). Hence combining NFV with fog computing allows providers to share critical edge resources across clients and achieve much more flexible service designs. However, few efforts have looked at SFC provisioning in fog domains. Hence this paper presents one of the first studies in this area, detailing a Tabu search for virtual function placement and heuristic routing schemes with load balancing for efficient resource utilization. Results show reduced processing and propagation times, and lower energy consumption versus cloud-based methods.},
	number = {Cic},
	journal = {Proceedings - 2019 IEEE 5th International Conference on Collaboration and Internet Computing, CIC 2019},
	author = {Siasi, Nazli and Jaesim, Adrian and Ghani, Nasir},
	year = {2019},
	note = {ISBN: 9781728167398},
	keywords = {Fog computing, Cloud computing, Network function virtualization, Service function chaining, Tabu search},
	pages = {145--150},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/LA64BHCQ/08998512.pdf:application/pdf},
}

@article{lera_analyzing_2019,
	title = {Analyzing the applicability of a multi-criteria decision method in fog computing placement problem},
	doi = {10.1109/FMEC.2019.8795361},
	abstract = {In Fog computing the placement selection of services in network devices with computational and storage features is an NP-hard problem. We analyse the design of Fog scenarios and the placement problem using Electre III a multi-criteria decision method for outranking alternatives. In this study, we model a Fog environment to apply a decision model for determining which alternatives are the most suitable in each application deployment. We compare the results with the weighted average to analyse the applicability of Electre III method in the Fog placement problem. We design a dynamical scenario in which new users appear along the simulation and we use the latency, hop count, cost, deployment penalty and energy consumption criteria to rank placement alternatives. This approach enables the study of how the characteristics of the resources have to be distributed, that is, how to design Fog scenarios, in order to make the allocation of applications more efficient.},
	journal = {2019 4th International Conference on Fog and Mobile Edge Computing, FMEC 2019},
	author = {Lera, Isaac and Guerrero, Carlos and Juiz, Carlos},
	year = {2019},
	note = {Publisher: IEEE
ISBN: 9781728117966},
	keywords = {Fog Computing, fog placement, multi-criteria decision analysis},
	pages = {13--20},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/YH8ZAYHI/08795361.pdf:application/pdf},
}

@article{singh_nature-inspired_2021,
	title = {Nature-inspired algorithms for {Wireless} {Sensor} {Networks}: {A} comprehensive survey},
	volume = {39},
	issn = {15740137},
	url = {https://doi.org/10.1016/j.cosrev.2020.100342},
	doi = {10.1016/j.cosrev.2020.100342},
	abstract = {In order to solve the critical issues in Wireless Sensor Networks (WSNs), with concern for limited sensor lifetime, nature-inspired algorithms are emerging as a suitable method. Getting optimal network coverage is one of those challenging issues that need to be examined critically before any network setup. Optimal network coverage not only minimizes the consumption of limited energy of battery-driven sensors but also reduce the sensing of redundant information. In this paper, we focus on nature-inspired optimization algorithms concerning the optimal coverage in WSNs. In the first half of the paper, we have briefly discussed the taxonomy of the optimization algorithms along with the problem domains in WSNs. In the second half of the paper, we have compared the performance of two nature-inspired algorithms for getting optimal coverage in WSNs. The first one is a combined Improved Genetic Algorithm and Binary Ant Colony Algorithm (IGA-BACA), and the second one is Lion Optimization (LO). The simulation results confirm that LO gives better network coverage, and the convergence rate of LO is faster than that of IGA-BACA. Further, we observed that the optimal coverage is achieved at a lesser number of generations in LO as compared to IGA-BACA. This review will help researchers to explore the applications in this field as well as beyond this area.},
	journal = {Computer Science Review},
	author = {Singh, Abhilash and Sharma, Sandeep and Singh, Jitendra},
	year = {2021},
	note = {Publisher: Elsevier Inc.},
	keywords = {Bio-inspired algorithm, Lion Optimization, Optimal coverage, WSNs},
	pages = {100342},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/FB3EIYZL/1-s2.0-S1574013720304421-main.pdf:application/pdf},
}

@article{gupta_ifogsim_2017,
	title = {{iFogSim}: {A} toolkit for modeling and simulation of resource management techniques in the {Internet} of {Things}, {Edge} and {Fog} computing environments},
	volume = {47},
	issn = {1097024X},
	doi = {10.1002/spe.2509},
	abstract = {Internet of Things (IoT) aims to bring every object (eg, smart cameras, wearable, environmental sensors, home appliances, and vehicles) online, hence generating massive volume of data that can overwhelm storage systems and data analytics applications. Cloud computing offers services at the infrastructure level that can scale to IoT storage and processing requirements. However, there are applications such as health monitoring and emergency response that require low latency, and delay that is caused by transferring data to the cloud and then back to the application can seriously impact their performances. To overcome this limitation, Fog computing paradigm has been proposed, where cloud services are extended to the edge of the network to decrease the latency and network congestion. To realize the full potential of Fog and IoT paradigms for real-time analytics, several challenges need to be addressed. The first and most critical problem is designing resource management techniques that determine which modules of analytics applications are pushed to each edge device to minimize the latency and maximize the throughput. To this end, we need an evaluation platform that enables the quantification of performance of resource management policies on an IoT or Fog computing infrastructure in a repeatable manner. In this paper we propose a simulator, called iFogSim, to model IoT and Fog environments and measure the impact of resource management techniques in latency, network congestion, energy consumption, and cost. We describe two case studies to demonstrate modeling of an IoT environment and comparison of resource management policies. Moreover, scalability of the simulation toolkit of RAM consumption and execution time is verified under different circumstances.},
	number = {9},
	journal = {Software - Practice and Experience},
	author = {Gupta, Harshit and Vahid Dastjerdi, Amir and Ghosh, Soumya K. and Buyya, Rajkumar},
	year = {2017},
	keywords = {Edge computing, Fog computing, Internet of Things (IoT), modeling and simulation},
	pages = {1275--1296},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/NW5F3P3R/1606.02007.pdf:application/pdf},
}

@article{gill_aco_2020,
	title = {{ACO} {Based} {Container} {Placement} for {CaaS} in {Fog} {Computing}},
	volume = {167},
	issn = {18770509},
	url = {https://doi.org/10.1016/j.procs.2020.03.406},
	doi = {10.1016/j.procs.2020.03.406},
	abstract = {With the advancements in Internet of Things, there comes a plethora of applications that require real time response. To always process these applications in a remote cloud server is a time consuming task. This motivates the need of processing and storage capacities near to the data generating IOT sensors. One of such paradigm is that of Fog Computing. Fog Computing relies on the virtualization technology to offer compute and storage services. Containers being a lightweight preference reduce the startup time, migration time resulting in faster response to the application. This paper proposes an optimal placement policy of containers based on Ant Colony Optimization (ACO) with the primary aim to minimize the overall makespan of the tasks. This will help to achieve the desired real time response to applications ensuring QoS to the end users.},
	number = {Iccids 2019},
	journal = {Procedia Computer Science},
	author = {Gill, Monika and Singh, Dinesh},
	year = {2020},
	note = {Publisher: Elsevier B.V.},
	keywords = {Virtualization, Containers, Fog Computing, ACO},
	pages = {760--768},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/IAV7RSU5/1-s2.0-S1877050920308723-main.pdf:application/pdf},
}

@article{souza_towards_2018,
	title = {Towards a proper service placement in combined {Fog}-to-{Cloud} ({F2C}) architectures},
	volume = {87},
	issn = {0167739X},
	doi = {10.1016/j.future.2018.04.042},
	abstract = {The Internet of Things (IoT) has empowered the development of a plethora of new services, fueled by the deployment of devices located at the edge, providing multiple capabilities in terms of connectivity as well as in data collection and processing. With the inception of the Fog Computing paradigm, aimed at diminishing the distance between edge-devices and the IT premises running IoT services, the perceived service latency and even the security risks can be reduced, while simultaneously optimizing the network usage. When put together, Fog and Cloud computing (recently coined as fog-to-cloud, F2C) can be used to maximize the advantages of future computer systems, with the whole greater than the sum of individual parts. However, the specifics associated with cloud and fog resource models require new strategies to manage the mapping of novel IoT services into the suitable resources. Despite few proposals for service offloading between fog and cloud systems are slowly gaining momentum in the research community, many issues in service placement, both when the service is ready to be executed admitted as well as when the service is offloaded from Cloud to Fog, and vice-versa, are new and largely unsolved. In this paper, we provide some insights into the relevant features about service placement in F2C scenarios, highlighting main challenges in current systems towards the deployment of the next-generation IoT services.},
	number = {2018},
	journal = {Future Generation Computer Systems},
	author = {Souza, V. B. and Masip-Bruin, X. and Marín-Tordera, E. and Sànchez-López, S. and Garcia, J. and Ren, G. J. and Jukan, A. and Juan Ferrer, A.},
	year = {2018},
	keywords = {Resource allocation, Quality of service, Cloud \& fog computing, Distributed systems, Service placement and execution},
	pages = {1--15},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/6C74ZPKW/1-s2.0-S0167739X17323051-main.pdf:application/pdf},
}

@article{guerrero_evaluation_2019,
	title = {Evaluation and efficiency comparison of evolutionary algorithms for service placement optimization in fog architectures},
	volume = {97},
	issn = {0167739X},
	url = {https://doi.org/10.1016/j.future.2019.02.056},
	doi = {10.1016/j.future.2019.02.056},
	abstract = {This study compares three evolutionary algorithms for the problem of fog service placement: weighted sum genetic algorithm (WSGA), non-dominated sorting genetic algorithm II (NSGA-II), and multiobjective evolutionary algorithm based on decomposition (MOEA/D). A model for the problem domain (fog architecture and fog applications) and for the optimization (objective functions and solutions) is presented. Our main concerns are related to optimize the network latency, the service spread and the use of the resources. The algorithms are evaluated with a random Barabasi–Albert network topology with 100 devices and with two experiment sizes of 100 and 200 application services. The results showed that NSGA-II obtained the highest optimizations of the objectives and the highest diversity of the solution space. On the contrary, MOEA/D was better to reduce the execution times. The WSGA algorithm did not show any benefit with regard to the other two algorithms.},
	journal = {Future Generation Computer Systems},
	author = {Guerrero, Carlos and Lera, Isaac and Juiz, Carlos},
	year = {2019},
	note = {Publisher: Elsevier B.V.},
	keywords = {Fog computing, Resource management, Service placement, Evolutionary algorithms},
	pages = {131--144},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/K2HRBYFQ/1-s2.0-S0167739X18325147-main.pdf:application/pdf},
}

@article{eyckerman_requirements_2020,
	title = {Requirements for distributed task placement in the fog},
	volume = {12},
	issn = {25426605},
	url = {https://doi.org/10.1016/j.iot.2020.100237},
	doi = {10.1016/j.iot.2020.100237},
	abstract = {As the Internet of Things (IoT) paradigm becomes omnipresent, so does fog computing, a paradigm aimed at bringing applications closer to the end devices, aiding in lowering stress over the network and improving latency. However, to efficiently place application tasks in the fog, task placement coordination is needed. We provide a comprehensive research around task placement in the fog and the design of algorithms to solve the placement. We look at the fundamental issue of solving Multi-Objective Optimization problems and treat several techniques for both centralized and distributed coordination. On this we create a Distributed Reconnaissance Ant Colony Optimization algorithm. We review how this research can be used in a smart vehicle environment, and finish validating our proposed algorithm.},
	number = {2020},
	journal = {Internet of Things},
	author = {Eyckerman, Reinout and Mercelis, Siegfried and Marquez-Barja, Johann and Hellinckx, Peter},
	year = {2020},
	note = {Publisher: Elsevier B.V.},
	keywords = {Fog computing, Ant colony optimization, Distributed software planning, Evolutionary computing, Multi-Objective optimization},
	pages = {100237},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/Z4BY5GB6/1-s2.0-S2542660520300706-main.pdf:application/pdf},
}

@article{mahmud_profit-aware_2020,
	title = {Profit-aware application placement for integrated {Fog}–{Cloud} computing environments},
	volume = {135},
	issn = {07437315},
	url = {https://doi.org/10.1016/j.jpdc.2019.10.001},
	doi = {10.1016/j.jpdc.2019.10.001},
	abstract = {The marketplace for Internet of Things (IoT)-enabled smart systems is rapidly expanding. The integration of Fog and Cloud paradigm aims at harnessing both edge device and remote datacentre-based computing resources to meet Quality of Service (QoS) requirements of these smart systems. Due to lack of instance pricing and revenue maximizing techniques, it becomes difficult for service providers to make comprehensive profit from such integration. This problem further intensifies when associated expenses and allowances are charged from the revenue. Conversely, the rigid revenue maximizing intention of providers affects user's budget and system's service quality. To address these issues, we propose a profit-aware application placement policy for integrated Fog–Cloud environments. It is formulated using constraint Integer Linear Programming model that simultaneously enhances profit and ensures QoS during application placement on computing instances. Furthermore, it provides compensation to users for any violation of Service Level Agreement (SLA) and sets the price of instances according to their ability of reducing service delivery time. The performance of proposed policy is evaluated in a simulated Fog–Cloud environment using iFogSim and the results demonstrate that it outperforms other placement policies in concurrently increasing provider's profit and user's QoS satisfaction rate.},
	number = {2020},
	journal = {Journal of Parallel and Distributed Computing},
	author = {Mahmud, Redowan and Srirama, Satish Narayana and Ramamohanarao, Kotagiri and Buyya, Rajkumar},
	year = {2020},
	note = {Publisher: Elsevier Inc.},
	keywords = {Internet of Things, Application placement, Fog–Cloud integration, Pricing model, Profit-awareness},
	pages = {177--190},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/RRDYQLWD/1-s2.0-S0743731519300346-main.pdf:application/pdf},
}

@article{yadav_ga-pso_2019,
	title = {{GA}-{PSO}: {Service} {Allocation} in {Fog} {Computing} {Environment} {Using} {Hybrid} {Bio}-{Inspired} {Algorithm}},
	volume = {2019-Octob},
	issn = {21593450},
	doi = {10.1109/TENCON.2019.8929234},
	abstract = {Internet of Thing (IoT) applications require an efficient platform for processing big data. Different computing techniques such as Cloud, Edge, and Fog are used for processing big data. The main challenge in the fog computing environment is to minimize both energy consumption and makespan for services. The service allocation techniques on a set of virtual machines (VMs) is the decidable factor for energy consumption and latency in fog servers. Hence, the service allocation in fog environment is referred to as NP-hard problem. In this work, we developed a hybrid algorithm using Genetic Algorithm (GA) and Particle Swarm Optimization (PSO) technique to solve this NP-hard problem. The proposed GA-PSO is used for optimal allocation of services while minimizing the total makespan, energy consumption for IoT applications in the fog computing environment. We implemented the proposed GA-PSO using customized C simulator, and the results demonstrate that the proposed GA-PSO outperforms both GA and PSO techniques when applied individually.},
	journal = {IEEE Region 10 Annual International Conference, Proceedings/TENCON},
	author = {Yadav, Vinita and Natesha, B. V. and Guddeti, Ram Mohana Reddy},
	year = {2019},
	note = {Publisher: IEEE
ISBN: 9781728118956},
	keywords = {IoT, Fog Computing, Service Placement, Energy Optimization, Makespan, Particle Swarm Optimization},
	pages = {1280--1285},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/VYFMLCVY/08929234.pdf:application/pdf},
}

@article{li_understanding_2021,
	title = {Understanding and addressing quality attributes of microservices architecture: {A} {Systematic} literature review},
	volume = {131},
	issn = {09505849},
	url = {https://doi.org/10.1016/j.infsof.2020.106449},
	doi = {10.1016/j.infsof.2020.106449},
	abstract = {Context: As a rapidly adopted architectural style in software engineering, Microservices Architecture (MSA) advocates implementing small-scale and independently distributed services, rather than binding all functions into one monolith. Although many initiatives have contributed to the quality improvement of microservices-based systems, there is still a lack of a systematic understanding of the Quality Attributes (QAs) associated with MSA. Objective: This study aims to investigate the evidence-based state-of-the-art of QAs of microservices-based systems. Method: We carried out a Systematic Literature Review (SLR) to identify and synthesize the relevant studies that report evidence related to QAs of MSA. Results: Based on the data extracted from the 72 selected primary studies, we portray an overview of the six identified QAs most concerned in MSA, scalability, performance, availability, monitorability, security, and testability. We identify 19 tactics that architecturally address the critical QAs in MSA, including two tactics for scalability, four for performance, four for availability, four for monitorability, three for security, and two for testability. Conclusion: This SLR concludes that for MSA-based systems: 1) Although scalability is the commonly acknowledged benefit of MSA, it is still an indispensable concern among the identified QAs, especially when trading-off with other QAs, e.g., performance. Apart from the six identified QAs in this study, other QAs for MSA like maintainability need more attention for effective improvement and evaluation in the future. 3) Practitioners need to carefully make the decision of migrating to MSA based on the return on investment, since this architectural style additionally cause some pains in practice.},
	number = {September 2020},
	journal = {Information and Software Technology},
	author = {Li, Shanshan and Zhang, He and Jia, Zijia and Zhong, Chenxing and Zhang, Cheng and Shan, Zhihao and Shen, Jinfeng and Babar, Muhammad Ali},
	year = {2021},
	note = {Publisher: Elsevier B.V.},
	keywords = {Microservices, Monolith, Quality attributes, Systematic literature review},
	pages = {106449},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/AX9SCJ5H/1-s2.0-S0950584920301993-main.pdf:application/pdf},
}

@article{ray_sdnnfv_2021,
	title = {{SDN}/{NFV} architectures for edge-cloud oriented {IoT}: {A} systematic review},
	volume = {169},
	issn = {1873703X},
	url = {https://doi.org/10.1016/j.comcom.2021.01.018},
	doi = {10.1016/j.comcom.2021.01.018},
	abstract = {Software-defined network (SDN) and network function virtualization (NFV) have entirely changed the way internetwork backhaul should be utilized and behaved for virtualized service provisioning. Several benefits have been observed in multiple domains of applications that has used SDN and NFV in integrated way. Thus, SDN/NFV paradigm has been investigated to seek whether network services could be efficiently delivered, managed, and disseminated to the end users. Internet of Things (IoT) is justifiably associated with the SDN/NFV augmentation to make this task enriched. However, factors related to edge-cloud communication and network services have not been effectively mitigated until now. In this paper, we present an in-depth, qualitative, and comprehensive systematic review to find the answers of following research questions, such as, (i) how does state-of-the-art SDN/NFV architecture look like, (ii) how to solve next generation cellular services via architecture involvement, (iii) what type of application/test-bed need to be studied, and (iv) security framework should be catered. We further, elaborate various key issues and challenges in the existing architecture mitigation for SDN/NFV integration to the IoT-based edge-cloud oriented network service provisioning. Future directions are also prescribed to support fellow researchers to improve existing virtualized service scenario. Lessons learned after performing comparative study with other survey articles dictates that our work presents timely contribution in terms of novel knowledge toward understanding of formulating SDN/NFV virtualization services under the aegis of IoT-centric edge-cloud scenario.},
	number = {June 2020},
	journal = {Computer Communications},
	author = {Ray, Partha Pratim and Kumar, Neeraj},
	year = {2021},
	note = {Publisher: Elsevier B.V.},
	keywords = {IoT, Cloud, Edge, Architecture, NFV, SDN},
	pages = {129--153},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/BLWFDNU2/1-s2.0-S0140366421000396-main.pdf:application/pdf},
}

@article{zamzam_resource_2019,
	title = {Resource {Management} using {Machine} {Learning} in {Mobile} {Edge} {Computing}: {A} {Survey}},
	doi = {10.1109/ICICIS46948.2019.9014733},
	abstract = {Mobile Edge Computing (MEC) aims to overcome the limited terminal battery and processing capabilities associated with running applications in the mobile terminal and the high latency introduced by offloading these applications to the cloud. It extends the computing resources of the cloud at the edge of the cellular network closer to the mobile user. Resource management in mobile edge computing is one of the main issues that are studied recently by many researchers. It consists of resource allocation and computation offloading. Allocation of resources involves managing and scheduling the resources to accomplish the requests of the users. It depends on the availability and the capacity of the resources. According to the deadline of each requested task, the service provider will assign each user the sufficient resources. Computation offloading is the transfer of the tasks to be executed at an external platform (edge or cloud server). It depends on the processing capability and the storage capacity of the device. It is difficult to provide an optimal solution for resource management in a dynamic system due to the random variations of tasks required by the users and the mobility of these users, thus machine learning techniques are proposed to solve this optimization problem. In this paper we provide the state-of-the-art for using machine learning to optimize resource management in mobile edge computing. We divide the research into four categories: 1) minimizing the cost, 2) minimizing the energy consumption, 3) minimizing the latency and 4) minimizing both latency and energy consumption. We then classify the system model, the constraints and the types of machine learning techniques that are used in each optimization problem.},
	journal = {Proceedings - 2019 IEEE 9th International Conference on Intelligent Computing and Information Systems, ICICIS 2019},
	author = {Zamzam, Marwa and Elshabrawy, Tallal and Ashour, Mohamed},
	year = {2019},
	note = {Publisher: IEEE
ISBN: 9781728139951},
	keywords = {allocation, cost, energy, latency, machine learning, Mobile edge computing, offloading},
	pages = {112--117},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/M4NDJ6JM/09014733(2).pdf:application/pdf},
}

@article{mahmud_fog_2018,
	title = {Fog {Computing}: {A} taxonomy, survey and future directions},
	volume = {0},
	issn = {21991081},
	doi = {10.1007/978-981-10-5861-5_5},
	abstract = {In recent years, the number of Internet of Things (IoT) devices/sensors has increased to a great extent. To support the computational demand of real-time latency-sensitive applications of largely geo-distributed IoT devices/sensors, a new computing paradigm named “Fog computing” has been introduced. Generally, Fog computing resides closer to the IoT devices/sensors and extends the Cloud-based computing, storage and networking facilities. In this chapter, we comprehensively analyse the challenges in Fogs acting as an intermediate layer between IoT devices/sensors and Cloud datacentres and review the current developments in this field. We present a taxonomy of Fog computing according to the identified challenges and its key features. We also map the existing works to the taxonomy in order to identify current research gaps in the area of Fog computing. Moreover, based on the observations, we propose future directions for research.},
	number = {9789811058608},
	journal = {Internet of Things},
	author = {Mahmud, Redowan and Kotagiri, Ramamohanarao and Buyya, Rajkumar},
	year = {2018},
	pages = {103--130},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/9G3IW882/1611.05539.pdf:application/pdf},
}

@article{faticanti_cutting_2019,
	title = {Cutting {Throughput} with the {Edge}: {App}-{Aware} {Placement} in {Fog} {Computing}},
	doi = {10.1109/CSCloud/EdgeCom.2019.00026},
	abstract = {Fog computing extends cloud computing technology to the edge of the infrastructure to support dynamic computation for IoT applications. Reduced latency and location awareness in objects' data access is attained by displacing workloads from the central cloud to edge devices. Doing so, it reduces raw data transfers from target objects to the central cloud, thus overcoming communication bottlenecks. This is a key step towards the pervasive uptake of next generation IoT-based services. In this work we study efficient orchestration of applications in fog computing, where a fog application is the cascade of a cloud module and a fog module. The problem results into a mixed integer non linear optimisation. It involves multiple constraints due to computation and communication demands of fog applications, available infrastructure resources and it accounts also the location of target IoT objects. We show that it is possible to reduce the complexity of the original problem with a related placement formulation, which is further solved using a greedy algorithm. This algorithm is the core placement logic of FogAtlas, a fog computing platform based on existing virtualization technologies. Extensive numerical results validate the model and the scalability of the proposed algorithm, showing performance close to the optimal solution with respect to the number of served applications.},
	journal = {Proceedings - 6th IEEE International Conference on Cyber Security and Cloud Computing, CSCloud 2019 and 5th IEEE International Conference on Edge Computing and Scalable Cloud, EdgeCom 2019},
	author = {Faticanti, Francescomaria and De Pellegrini, Francesco and Siracusa, Domenico and Santoro, Daniele and Cretti, Silvio},
	year = {2019},
	note = {ISBN: 9781728116600},
	keywords = {IoT, fog computing, resource allocation, computation offloading, placement},
	pages = {196--203},
	file = {Faticanti et al_2018_Cutting throughput on the Edge.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/DH3IRFL5/Faticanti et al_2018_Cutting throughput on the Edge.pdf:application/pdf;PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/WCNDRBL7/08854035.pdf:application/pdf},
}

@article{djemai_mobility_2020,
	title = {Mobility {Support} for {Energy} and {QoS} aware {IoT} {Services} {Placement} in the {Fog}},
	doi = {10.23919/SoftCOM50211.2020.9238236},
	abstract = {Fog computing has emerged as a strong distributed computation paradigm to support applications with stringent latency requirements. It offers almost ubiquitous computation capacities over a large geographical area. However, Fog systems are highly heterogeneous and dynamic which makes services placement decision quite challenging considering nodes mobility that may decrease the placement decision quality over time. This paper proposes a Mobility-aware Genetic Algorithm (MGA) for services placement in the Fog which aims at supporting nodes' mobility while ensuring both infrastructures energy-efficiency and applications Quality of Service (QoS) requirements. We have compared this approach with two variants of Shortest Access Point migration strategy (SAP) from the literature, a proposed Mobility Greedy Heuristic (MGH) and a baseline Simple Genetic Algorithm (SGA). Experiments conducted with MyiFogSim simulator have shown that MGA ensures good performances in terms of energy and delay violations minimization compared to other methods.},
	journal = {2020 28th International Conference on Software, Telecommunications and Computer Networks, SoftCOM 2020},
	author = {Djemai, Tanissia and Stolf, Patricia and Monteil, Thierry and Pierson, Jean Marc},
	year = {2020},
	note = {ISBN: 9789532900996},
	keywords = {Internet of Things, optimization, QoS, Mobility, Fog Computing, Energy, Smart Campus},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/U6DY9PIE/09238236.pdf:application/pdf},
}

@article{nardelli_efficient_2019,
	title = {Efficient {Operator} {Placement} for {Distributed} {Data} {Stream} {Processing} {Applications}},
	volume = {30},
	issn = {15582183},
	doi = {10.1109/TPDS.2019.2896115},
	abstract = {In the last few years, a large number of real-time analytics applications rely on the Data Stream Processing (DSP) so to extract, in a timely manner, valuable information from distributed sources. Moreover, to efficiently handle the increasing amount of data, recent trends exploit the emerging presence of edge/Fog computing resources so to decentralize the execution of DSP applications. Since determining the Optimal DSP Placement (for short, ODP) is an NP-hard problem, we need efficient heuristics that can identify a good application placement on the computing infrastructure in a feasible amount of time, even for large problem instances. In this paper, we present several DSP placement heuristics that consider the heterogeneity of computing and network resources; we divide them in two main groups: model-based and model-free. The former employ different strategies for efficiently solving the ODP model. The latter implement, for the problem at hand, some of the well-known meta-heuristics, namely greedy first-fit, local search, and tabu search. By leveraging on ODP, we conduct a thorough experimental evaluation, aimed to assess the heuristics' efficiency and efficacy under different configurations of infrastructure size, application topology, and optimization objectives.},
	number = {8},
	journal = {IEEE Transactions on Parallel and Distributed Systems},
	author = {Nardelli, Matteo and Cardellini, Valeria and Grassi, Vincenzo and Lo Presti, Francesco},
	year = {2019},
	note = {Publisher: IEEE},
	keywords = {quality of service, Distributed data stream processing, geo-distributed systems, heuristics, operator placement},
	pages = {1753--1767},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/RAT6EIRS/08630099.pdf:application/pdf},
}

@article{nguyen_studying_2018,
	title = {Studying and {Developing} a {Resource} {Allocation} {Algorithm} in {Fog} {Computing}},
	doi = {10.1109/ACOMP.2018.00020},
	abstract = {Internet of Things (IoT) is becoming popular. Many IoT devices will bring huge data moving within a network infrastructure. Cloud has become so widespread that almost many business or end users are using private and/or public cloud. Cloud servers will be responsible for processing incoming data and sending them back after processing. As a result, the amount of data moving will be extremely large and processing of Big Data will gradually appear. Many enterprise companies included Cisco, Dell, Microsoft, Intel has pioneered Fog computing since 2015. In Fog computing, data will be scattered instead of concentrating data like the traditional Cloud computing. The main goal of this study is to propose a resource allocation algorithm to distribute modules of an IoT application to the entire network in Fog computing environment. This proposed algorithm must run successfully on a simulator. With different environments, the algorithm will allocate different modules depending on the configuration of each device. To evaluate the algorithm, this study uses the iFogSim toolkit, which extends from the CloudSim toolkit, for modeling and simulation of Fog computing environment. Current version of iFogSim is sufficient to be able to implement some criteria necessary for this study.},
	journal = {Proceedings - 2018 International Conference on Advanced Computing and Applications, ACOMP 2018},
	author = {Nguyen, Quang Hung and Truong Pham, Thanh An},
	year = {2018},
	note = {Publisher: IEEE
ISBN: 9781538691861},
	keywords = {Fog computing, Cloud computing, First fit algorithm, Module placement},
	pages = {76--82},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/IMYI5CJI/08589492.pdf:application/pdf},
}

@article{natesha_heuristic-based_2018,
	title = {Heuristic-based iot application modules placement in the fog-cloud computing environment},
	volume = {1},
	doi = {10.1109/UCC-Companion.2018.00027},
	abstract = {Nowadays many Smart City applications make use of Internet of Things (IoT) devices for monitoring the environment. The increase in use of IoT for smart city applications causes exponential increase in the volume of data. Using centralised cloud for time sensitive IoT applications is not feasible due to more delay because of the network congestion. Hence, fog computing is used for processing the data near to the edge of the network, where processing is done by distributed network nodes. But, there is a challenge to select the fog nodes which can host and process the application modules. The placement of application module on these fog devices is known as NP-hard problem. Hence, we need better placement strategies to decide placement of application modules in fog infrastructure to minimize the application latency. In this paper, we design a First-Fit Decreasing (FFD) heuristic based approach for placing IoT application modules on Fog-Cloud and carried out the experiment using iFogsim simulator. The simulation results demonstrate that the proposed method shows significant decrease in both the application latency and energy consumption of Fog-Cloud as compared to the benchmark method.},
	number = {6},
	journal = {Proceedings - 11th IEEE/ACM International Conference on Utility and Cloud Computing Companion, UCC Companion 2018},
	author = {Natesha, B. V. and Guddeti, Ram Mohana Reddy},
	year = {2018},
	note = {Publisher: IEEE
ISBN: 9781728103594},
	keywords = {Internet of Things, Cloud Computing, Fog Computing, Latency, Energy Consumption, Network Usage},
	pages = {24--25},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/3H9JIRJI/08605750.pdf:application/pdf},
}

@article{de_brito_service_2017,
	title = {A service orchestration architecture for {Fog}-enabled infrastructures},
	doi = {10.1109/FMEC.2017.7946419},
	abstract = {The development of Fog Computing technology is crucial to address the challenges to come with the mass adoption of Internet Of Things technology, where the generation of data tends to grow at an unprecedented pace. The technology brings computing power to the surrounds of devices, to offer local processing, filtering, storage and analysis of data and control over actuators. Orchestration is a requirement of Fog Computing technology to deliver services, based on the composition of microservices. It must take into consideration the heterogeneity of the IoT environment and device's capabilities and constraints. This heterogeneity requires a different approach for orchestration, be it regarding infrastructure management, node selection and/or service placement. Orchestrations shall be manually or automatically started through event triggers. Also, the Orchestrator must be flexible enough to work in a centralized or distributed fashion. Orchestration is still a hot topic and can be seen in different areas, especially in the Service Oriented Architectures, hardware virtualization, in the Cloud, and in Network Virtualization Function. However, the architecture of these solutions is not enough to handle Fog Requirements, specially Fog's heterogeneity, and dynamics. In this paper, we propose an architecture for Orchestration for the Fog Computing environment. We developed a prototype to prof some concepts. We discuss in this paper the implementation, and the tools chose, and their roles. We end the paper with a discussion on performance indicators and future direction on the evaluation of non-functional aspects of the Architecture.},
	journal = {2017 2nd International Conference on Fog and Mobile Edge Computing, FMEC 2017},
	author = {De Brito, Mathias Santos and Hoque, Saiful and Magedanz, Thomas and Steinke, Ronald and Willner, Alexander and Nehls, Daniel and Keils, Oliver and Schreiner, Florian},
	year = {2017},
	note = {Publisher: IEEE
ISBN: 9781538628591},
	keywords = {Orchestration, Fog Computing, Infrastructure Management},
	pages = {127--132},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/7ITRF2VQ/07946419.pdf:application/pdf},
}

@article{chekired_multi-tier_2018,
	title = {Multi-tier fog architecture: {A} new delay-tolerant network for iot data processing},
	volume = {2018-May},
	issn = {15503607},
	doi = {10.1109/ICC.2018.8422170},
	abstract = {In order to gather the full profits of Internet of Things (IoT) technologies, it will be necessary to provide efficient networking and computing infrastructure to support low latency and fast response for IoT applications. In this paper, we introduce a new fog architecture for IoT applications. We propose to deploy servers at the network fog level as a tree hierarchy, to efficiently use the cloud resources to serve the peak loads from devices. To schedule different devices demands, we develop an optimal workload placement method by solving a mixed nonlinear integer programming (MNIP). Then, the optimal solution is aggregated over different tiers using the Simulated Annealing Algorithm (SAA) to find out the optimal allocation using numerical iterations. The advantage of the proposed architecture is proved over different performance metrics and trough a probabilistic model and an analytic comparison.},
	journal = {IEEE International Conference on Communications},
	author = {Chekired, Djabir Abdeldjalil and Khoukhi, Lyes},
	year = {2018},
	note = {Publisher: IEEE
ISBN: 9781538631805},
	keywords = {IoT, Data processing, Delay-tolerant network, Multi-tier Fog},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/RQKF7RCL/08422170.pdf:application/pdf},
}

@article{sarkar_optimized_2019,
	title = {An {Optimized} {Task} {Placement} in {Computational} {Offloading} for {Fog}-{Cloud} {Computing} {Networks}},
	volume = {2019-Decem},
	issn = {21531684},
	doi = {10.1109/ANTS47819.2019.9118134},
	abstract = {The association between the fog node and the cloud in fog-cloud computing enables task data offloading for the delay-sensitive services generated from the end-users. Limited by the computational and storage resources, it is nearly impossible to execute the entire task by itself for an end-user. In this paper, we study the cooperation among fog node and the remote cloud. The task data offloading policies becomes a challenging issue when a fog node further offloads the task data to a set of neighbor fog node. We propose a task data offloading policy to find the optimum values of the amount of the offloaded tasks to each of the neighbor fog nodes and to the cloud. Besides, where to process the tasks and how many fog nodes are required for the tasks are also important to be considered. The optimization problem is formulated as a Quadratically Constraint Quadratic Programming (QCQP) and provide a solution. The extensive simulation results show the significant performance improvement in terms of delay minimization compared with several stand-alone task data execution with the increase of traffic intensity levels.},
	journal = {International Symposium on Advanced Networks and Telecommunication Systems, ANTS},
	author = {Sarkar, Indranil and Kumar, Sanjay and Mukherjee, Mithun},
	year = {2019},
	note = {ISBN: 9781728137155},
	pages = {8--12},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/J8LR8CEW/09118134.pdf:application/pdf},
}

@article{tocze_orch_2019,
	title = {{ORCH}: {Distributed} orchestration framework using mobile edge devices},
	doi = {10.1109/CFEC.2019.8733152},
	abstract = {In the emerging edge computing architecture, several types of devices have computational resources available. In order to make efficient use of those resources, deciding on which device a task should execute is of great importance.Existing works on task placement in edge computing focus on a resource supply side consisting of stationary devices only. In this paper, we consider the addition of mobile edge devices. We explore how mobile and stationary edge devices can augment the original task placement problem with a second placement problem: the placement of the mobile edge devices.We propose the ORCH framework in order to solve the joint problem in a distributed manner and evaluate it in the context of a spatially-changing load. Our implementation of the combined task and edge placement algorithms shows a normalized 83\% delay-sensitive task completion rate compared to a perfect edge placement strategy.},
	journal = {2019 IEEE 3rd International Conference on Fog and Edge Computing, ICFEC 2019 - Proceedings},
	author = {Tocze, Klervie and Nadjm-Tehrani, Simin},
	year = {2019},
	note = {Publisher: IEEE
ISBN: 9781728123653},
	keywords = {resource management, task placement, edge mobility, edge placement, Fog/edge computing},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/9XJZHZLD/08733152.pdf:application/pdf},
}

@article{donassolo_load_2019,
	title = {Load {Aware} {Provisioning} of {IoT} {Services} on {Fog} {Computing} {Platform}},
	volume = {2019-May},
	issn = {15503607},
	doi = {10.1109/ICC.2019.8762052},
	abstract = {To support the drastically increasing traffic generated by devices at the edge of the network, 5G players are urged to rethink their infrastructure design. Unfortunately, conventional Cloud infrastructures struggle to adapt to the huge volume of traffic. In this context, Fog computing has been developed to bridge Cloud data centers and edge devices servicing a multitude of heterogeneous devices. These nearby nodes offer analytics and data storage capabilities increasing considerably the capacity of the infrastructure. However, provisioning IoT applications on such a heterogeneous infrastructure, while meeting their stringent requirements is extremely challenging. In this paper, we study the Fog service provisioning issue in a practical manner. In this regard, we propose a novel strategy, which we call GO-FSP. GO-FSP optimizes the placement of IoT application components while coping with their strict performance requirements. To do so, we first propose an Integer Linear Programming (ILP) formulation for the IoT application provisioning problem. The latter targets to minimize the deployment cost while ensuring a load balancing between heterogeneous devices. Then, a GRASP-based approach is proposed to achieve the aforementioned objectives. Finally, we make use of the FITOR orchestration system to evaluate the performance of our solution under real conditions. Obtained results show that our scheme outperforms the related strategies.},
	journal = {IEEE International Conference on Communications},
	author = {Donassolo, Bruno and Fajjari, Ilhem and Legrand, Arnaud and Mertikopoulos, Panayotis},
	year = {2019},
	note = {Publisher: IEEE
ISBN: 9781538680889},
	keywords = {fog computing, application placement, iot, service provisioning},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/LDLP8P5G/08762052(1).pdf:application/pdf},
}

@article{hiessl_optimal_2019,
	title = {Optimal placement of stream processing operators in the fog},
	doi = {10.1109/CFEC.2019.8733147},
	abstract = {Elastic data stream processing enables applications to query and analyze streams of real time data. This is commonly facilitated by processing the flow of the data streams using a collection of stream processing operators which are placed in the cloud. However, the cloud follows a centralized approach which is prone to high latency delay. For avoiding this delay, we leverage on the fog computing paradigm which extends the cloud to the edge of the network.In order to design a stream processing solution for the fog, we first formulate an optimization problem for the placement of stream processing operators, which is tailored to fog computing environments. Then, we build a plugin (for stream processing frameworks) which solves the optimization problem periodically in order to support the dynamic resources of the fog. We evaluate this approach by performing experiments on an OpenStack testbed. The results show that our plugin reduces the response time and the cost by 31.5\% and 8.8\% respectively, compared to optimizing the placement of operators only upon initialization.},
	journal = {2019 IEEE 3rd International Conference on Fog and Edge Computing, ICFEC 2019 - Proceedings},
	author = {Hiessl, Thomas and Karagiannis, Vasileios and Hochreiner, Christoph and Schulte, Stefan and Nardelli, Matteo},
	year = {2019},
	note = {Publisher: IEEE
ISBN: 9781728123653},
	keywords = {Edge computing, Internet of things, Stream processing},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/2EA7323L/08733147.pdf:application/pdf},
}

@article{guerrero_influence_2018,
	title = {On the {Influence} of {Fog} {Colonies} {Partitioning} in {Fog} {Application} {Makespan}},
	doi = {10.1109/FiCloud.2018.00061},
	abstract = {This paper presents a study of the use of network centrality indices as suitable indicators to determine the partitioning of fog colonies. Fog colonies have been used previously to enable a two level (inter and intra colony) resource management for the fog service placement problem. We propose selecting the nodes with highest values, which indicate the node importance, as the colony controllers. The remaining devices are subordinated to the closest controllers. We studied six centrality indices in three network topologies and two architecture sizes. The fog applications are designed as a set of interoperated services which makespan is increased when services are allocated in different colonies, or colonies have highest intra or inter distances. Consequently, we considered the network distance as indicator of the application makespan. The results showed that the smaller network distances was obtained with the Betweenness centrality index and a Barabasi-Albert network topology. It was also observed that the network distance only has significant differences when the colony size is varied between 1 and 20.},
	number = {c},
	journal = {Proceedings - 2018 IEEE 6th International Conference on Future Internet of Things and Cloud, FiCloud 2018},
	author = {Guerrero, Carlos and Lera, Isaac and Juiz, Carlos},
	year = {2018},
	note = {Publisher: IEEE
ISBN: 9781538675038},
	keywords = {Fog computing, complex networks, fog colonies, resource optimization},
	pages = {377--384},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/PUMJNENH/08458038.pdf:application/pdf},
}

@article{nath_ptc_2019,
	title = {{PTC}: {Pick}-test-choose to place containerized micro-services in {IoT}},
	doi = {10.1109/GLOBECOM38437.2019.9013163},
	abstract = {In the presence of the Internet of Things (IoT) devices, the end-users require a response within a short amount of time which the cloud computing alone cannot provide. Fog computing plays an important role in the presence of IoT devices in order to meet such delay requirements. Though beneficial in these latency-sensitive scenarios, the fog has several implementation challenges. In order to solve the problem of micro-service placement in the fog devices, we propose a framework with the objective of achieving low response time. This problem has been formulated as an optimization problem to improve the response time by considering the time-varying resource availability of the fog devices as constraints. We propose an orchestration framework named Pick-Test-Choose (PTC) to solve the problem. PTC uses Bayesian Optimization based iterative reinforcement learning algorithm to find out a micro-service allocation based on the current workload of the fog devices. PTC employs containers for service isolation and migration of the micro-services. The proposed architecture is implemented over an in-house testbed as well as in iFogSim simulator. The experimental results show that the proposed framework performs better in terms of response time compared to various other baselines.},
	journal = {2019 IEEE Global Communications Conference, GLOBECOM 2019 - Proceedings},
	author = {Nath, Shubha Brata and Chattopadhyay, Subhrendu and Karmakar, Raja and Addya, Sourav Kanti and Chakraborty, Sandip and Ghosh, Soumya K.},
	year = {2019},
	note = {Publisher: IEEE
ISBN: 9781728109626},
	keywords = {Internet of Things, Fog Computing, Container Placement, Micro-service Placement, Reinforcement Learning},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/R67R34EC/09013163.pdf:application/pdf},
}

@article{alharbi_energy_2019,
	title = {Energy efficient virtual machine services placement in cloud-fog architecture},
	issn = {23318422},
	abstract = {The proliferation in data volume and processing requests calls for a new breed of on-demand computing. Fog computing is proposed to address the limitations of cloud computing by extending processing and storage resources to the edge of the network. Cloud and fog computing employ virtual machines (VMs) for efficient resource utilization. In order to optimize the virtual environment, VMs can be migrated or replicated over geo-distributed physical machines for load balancing and energy efficiency. In this work, we investigate the offloading of VM services from the cloud to the fog considering the British Telecom (BT) network topology. The analysis addresses the impact of different factors including the VM workload and the proximity of fog nodes to users considering the data rate of state-of-the-art applications. The result show that the optimum placement of VMs significantly decreases the total power consumption by up to 75\% compared to a single cloud placement.},
	journal = {arXiv},
	author = {Alharbi, Hatem A. and Elgorashi, Taisir E.H. and Elmirghani, Jaafar M.H.},
	year = {2019},
	note = {Publisher: IEEE
ISBN: 9781728127798},
	keywords = {Fog computing, Energy efficiency, IP over WDM network, Virtual machine, VM workload},
	pages = {1--6},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/K9ZEQQXZ/08840258.pdf:application/pdf},
}

@article{aryal_dynamic_2018,
	title = {Dynamic application deployment in federations of clouds and edge resources using a multiobjective optimization {AI} algorithm},
	doi = {10.1109/FMEC.2018.8364057},
	abstract = {Cloud federation brings, besides various opportunities, challenges for resource allocation. Optimized allocation of resources to applications is one of these challenges. The challenge is further enhanced by the heterogeneity of provider resources, which can be edge resources or cloud resources, and by the perception of the relative importance of optimization objectives. What is required by a federation broker, in such a context, is an efficient decision-making algorithm for virtual machine (VM) placement. Such an algorithm should first identify eligible resources and, then, select optimal combinations of resources within the federated cloud, considering multiple optimization objectives that are derived from the application requirements. The relative weights of which should be tuned to meet individual application needs. Furthermore, it should be able to work dynamically throughout the application lifecycle rather than only during the initial deployment to address changes in application and user behaviors. This paper proposes such an algorithm for the BASMATI cloud federation architecture. The results of multiple runs of our simulation demonstrate that the algorithm, which is a genetic algorithm, is efficient, can provide optimal solutions for VM placement decision making, and can be tuned to address specific application needs.},
	journal = {2018 3rd International Conference on Fog and Mobile Edge Computing, FMEC 2018},
	author = {Aryal, Ram Govinda and Altmann, Jorn},
	year = {2018},
	note = {Publisher: IEEE
ISBN: 9781538658963},
	keywords = {application deployment, optimization, genetic algorithm, resource allocation, artificial intelligence, cloud federation, cloud service broker, fog and edge computing, mobile cloud computing, platform management, VM placement},
	pages = {147--154},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/PEM66FCT/08364057.pdf:application/pdf},
}

@article{rezazadeh_optimized_2018,
	title = {Optimized {Module} {Placement} in {IoT} {Applications} {Based} on {Fog} {Computing}},
	doi = {10.1109/ICEE.2018.8472469},
	abstract = {Internet of Things (IoT) devices are growing rapidly, which itself produces a lot of data and someone must receive online responses. A typical program of the IoT consists of a set of modules that work together and interconnect. These modules typically run on cloud data centers. Fog computing designed to run these modules near the devices to minimize the response time and also to prevent large and in some cases unnecessary data transfers to the cloud. One of the significant challenges in resource management techniques is determined which modules should be placed on the fog device of the analytics applications to minimize latency and maximize efficiency. This research has focused on module placement, using simulated annealing algorithm, to find the appropriate device for the modules in a fog computing. The results show \%75 cost reduction, \%50 reduction of delay, and up to \%10 energy conception improvement.},
	journal = {26th Iranian Conference on Electrical Engineering, ICEE 2018},
	author = {Rezazadeh, Zahra and Rahbari, Dadmehr and Nickray, Mohsen},
	year = {2018},
	note = {Publisher: IEEE
ISBN: 9781538649169},
	keywords = {Fog computing, Resource management, Module placement, Health care, Simulated annealing},
	pages = {1553--1558},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/K56W7Q2L/08472469.pdf:application/pdf},
}

@article{yosuf_energy_2018,
	title = {Energy efficient service distribution in internet of things},
	issn = {23318422},
	abstract = {The Internet of Things (IoT) networks are expected to involve myriad of devices, ranging from simple sensors to powerful single board computers and smart phones. The great advancement in computational power of embedded technologies have enabled the integration of these devices into the IoT network, allowing for cloud functionalities to be extended near to the source of data. In this paper we study a multi-layer distributed IoT architecture supported by fog and cloud. We optimize the placement of the IoT services in this architecture so that the total power consumption is minimized. Our results show that, introducing local computation at the IoT layer can bring up to 90\% power savings compared with general purpose servers in a central cloud.},
	journal = {arXiv},
	author = {Yosuf, Barzan and Musa, Mohamed and Elgorashi, Taisir and Lawey, Ahmed Q. and Elmirghani, J. M.H.},
	year = {2018},
	note = {Publisher: IEEE},
	keywords = {IoT, Cloud, Edge, Fog, MILP, Service distribution},
	pages = {16--19},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/Y6AX6PN7/08473659.pdf:application/pdf},
}

@article{amarasinghe_data_2018,
	title = {A data stream processing optimisation framework for edge computing applications},
	doi = {10.1109/ISORC.2018.00020},
	abstract = {Data Stream Processing (DSP) is a widely used programming paradigm to process an unbounded event stream. Often, DSP frameworks are deployed on the cloud with a scalable resource model. One of the key requirements of DSP is to produce results with low latency. With the emergence of IoT, many event sources have been located outside the cloud which can result in higher end-To-end latency due to communication overhead. However, due to the abundance of resources at the IoT layer, Edge computing has emerged as a viable computational paradigm. In this paper, we devise an optimisation framework, consisting of a constraint satisfaction formulation and a system model, that aims to minimise end-To-end latency through appropriate placement of DSP operators either on cloud nodes or edge devices, i.e. deployed in an edge-cloud integrated environment. We test our optimisation framework using OMNeT++, with realistic topologies and power consumption data, and show that it is capable of achieving approx 1.65 times reduction of latency compared to edge-only and cloud-only placements, which in turn also reduces the energy consumption per event by up to approx 4\% at the edge layer. To the best of our knowledge our optimisation framework is the first of its kind to integrate power, bandwidth and CPU constraints with latency minimisation.},
	journal = {Proceedings - 2018 IEEE 21st International Symposium on Real-Time Computing, ISORC 2018},
	author = {Amarasinghe, Gayashan and De Assuncao, Marcos D. and Harwood, Aaron and Karunasekera, Shanika},
	year = {2018},
	note = {Publisher: IEEE
ISBN: 9781538658475},
	keywords = {Edge computing, Fog computing, Cloud computing, Internet of things, Distributed stream processing, Optimisation framework, Time sensitive computing},
	pages = {91--98},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/3B5AHAZH/08421151.pdf:application/pdf},
}

@article{apat_service_2018,
	title = {Service {Placement} in {Fog} {Computing} {Environment}},
	doi = {10.1109/ICIT.2018.00062},
	abstract = {Due to the advent of Internet of Things(IoT) plethora of services has been emerged and to perpetuate all these services using cloud computing paradigm is really tiresome. A new promising service provider called as Fog computing came into the picture where the distance between Iot and edge device is small to provide the services efficiently to the end users. There are different considerable factors like service response time, and expected QoS must met without violating other resource constraints. In this paper we try to layout an architecture which is based on the combination of cloud and fog by introducing a middleware called as cloud fog control middleware, which manages the service request according to some constraints. By using this architecture we can maximize the advantages of next generation computer system, however the architecture require new strategies to manage the mapping of services to resources. Despite several Heuristic and Meta Heuristic techniques has been proposed by different authors to solve the service placement in fog computing with considering different parameters like quality of service(QoS), Latency, etc. In this paper we are trying to minimize the energy consumption in fog computing paradigm by formulating the service placement plan in order to utilize the resources efficiently by considering the Active and Idle state of machine. First we calculate the energy consumption by the application(number of tasks) requesting for a particular service. Undoubtedly the service placement problem is a combinatorial optimization problem. The optimal solution obtained distribute the load to some other fog node by appropriate placement of service which leads to reduce the over heat generated by a particular fog node. In this way we can achieve energy minimization in fog computing.},
	journal = {Proceedings - 2018 International Conference on Information Technology, ICIT 2018},
	author = {Apat, Hemant Kumar and Sahoo, Bibhudatta and Maiti, Prasenjit},
	year = {2018},
	note = {Publisher: IEEE
ISBN: 9781728102597},
	keywords = {Fog computing, QoS, Internet of Things(IoT), Resource optimization, Service Placement, Energy Consumption, notion},
	pages = {272--277},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/N29Z2UEG/08724192.pdf:application/pdf},
}

@article{xia_combining_2018-1,
	title = {Combining heuristics to optimize and scale the placement of {IoT} applications in the fog},
	doi = {10.1109/UCC.2018.00024},
	abstract = {As fog computing brings processing and storage resources to the edge of the network, there is an increasing need of automated placement (i.e., host selection) to deploy distributed applications. Such a placement must conform to applications' resource requirements in a heterogeneous fog infrastructure, and deal with the complexity brought by Internet of Things (IoT) applications tied to sensors and actuators. This paper presents four heuristics to address the problem of placing distributed IoT applications in the fog. By combining proposed heuristics, our approach is able to deal with large scale problems, and to efficiently make placement decisions fitting the objective: minimizing placed applications' average response time. The proposed approach is validated through comparative simulation of different heuristic combinations with varying sizes of infrastructures and applications.},
	journal = {Proceedings - 11th IEEE/ACM International Conference on Utility and Cloud Computing, UCC 2018},
	author = {Xia, Ye and Lebre, Adrien and Etchevers, Xavier and Coupaye, Thierry and Letondeur, Loïc and Desprez, Frédéric},
	year = {2018},
	note = {Publisher: IEEE
ISBN: 9781538655047},
	keywords = {Fog computing, IoT, Placement, Heuristics},
	pages = {153--163},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/KFFIHCXS/08603162.pdf:application/pdf},
}

@article{gedeon_scalable_2018,
	title = {On scalable in-network operator placement for edge computing},
	volume = {2018-July},
	issn = {10952055},
	doi = {10.1109/ICCCN.2018.8487419},
	abstract = {The drawbacks encountered in today's cloud computing infrastructures have led to a paradigm shift towards in-network processing, where resources in the core and at the edge of the network are leveraged to perform computations. This can lead to decreased costs and better quality of service for users, e.g., when latency-critical applications are executed close to data sources and users. Deploying applications or parts thereof on these infrastructures requires to place operators (i.e., functional components of applications) on available resources in the network. Solving large instances of this problem in an optimal way is known to be computationally hard and, thus, practically unfeasible. While heuristic approaches exist, they mostly aim at placing functionalities on homogeneous nodes or make unrealistic assumptions for edge computing environments. To address this issue, this paper studies the placement problem in the context of a 3-tier architecture consisting of cloud, fog and edge devices. We provide a comprehensive model and propose a heuristic approach to the problem, in which we introduce constraints on the placement decision to limit the possible solution space, leading to a decrease in the solving time for the problem. These constraints exploit the characteristics of our 3-tier network architecture. To demonstrate the feasibility of the approach, we present a general framework that supports different types of heuristics. We validate the approach by implementing example heuristics for each type. We show that our approach can scale to large instances, i.e., it can significantly reduce the resolution time to find a placement solution while introducing only a small optimality gap.},
	journal = {Proceedings - International Conference on Computer Communications and Networks, ICCCN},
	author = {Gedeon, Julien and Stein, Michael and Wang, Lin and Muehlhaeuser, Max},
	year = {2018},
	note = {ISBN: 9781538651568},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/KIIUVE65/08487419.pdf:application/pdf},
}

@article{iwai_self-organizing_2018,
	title = {Self-organizing map using classification method for services in multilayer computing environments},
	doi = {10.1109/IECON.2018.8591565},
	abstract = {The increasing amount of data running in cloud-computing environments has started inflating networks. To solve the problems caused by network inflation (e.g., latency and privacy), new types of computing environments with multiple layers have been proposed. However, service placement inside these multilayer computing environments has not been proposed. Nodes inside multilayer computing environments have different preferences, and the services deployed also have restrictions on deployment. Therefore, services must be placed carefully inside the computing environment. To place these services, we introduce a service classification method according to their properties and restrictions. However, when accommodating dynamic placement, rapid classification is needed to avoid serious damage caused by restriction changes. Therefore, we propose a classifying method using k-Nearest Neighbor Classification (k-NN). In addition, to accelerate the process, we use a dimension reduction method called Self-Organizing Maps (SOM) to preprocess the data. The proposed classification method is expected to be used as the primary step in service placement. The method will supply service placers with the identification of which layer services should be deployed.},
	journal = {Proceedings: IECON 2018 - 44th Annual Conference of the IEEE Industrial Electronics Society},
	author = {Iwai, Tomomu and Ohno, Yuta and Niwa, Akira and Nakamura, Yuichi and Sakai, Keiya and Matsui, Kanae and Nishi, Hiroaki},
	year = {2018},
	note = {Publisher: IEEE
ISBN: 9781509066841},
	keywords = {Edge computing, Fog computing, IoT services, Self-organizing maps, Service classification},
	pages = {4193--4198},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/FCL73K7E/08591565.pdf:application/pdf},
}

@article{goncalves_proactive_2018,
	title = {Proactive {Virtual} {Machine} {Migration} in {Fog} {Environments}},
	volume = {2018-June},
	issn = {15301346},
	doi = {10.1109/ISCC.2018.8538655},
	abstract = {Fog computing provides a low latency access to resources at the edge of the network for resource-constrained devices. The high mobility of some of these devices, such as vehicles, brings great challenges related to resource allocation and management. In order to improve the management of computing resources utilized by mobile users connected to the Fog infrastructure, this paper proposes a virtual machine placement and migration decision model based on mobility prediction. Simulations have shown that moving the virtual machine to a Fog node ahead of the user's route using the proposed approach can decrease by almost 50\% the number of migrations needed by the user. The Fog architecture provides an average latency of about 15 milliseconds for the users' applications and the proposed approach presents a lower latency compared to a greedy approach for the VM placement problem.},
	journal = {Proceedings - IEEE Symposium on Computers and Communications},
	author = {Goncalves, Diogo and Velasquez, Karima and Curado, Marilia and Bittencourt, Luiz and Madeira, Edmundo},
	year = {2018},
	note = {ISBN: 9781538669501},
	keywords = {Placement, Migration, Fog, Virtual Machine},
	pages = {742--745},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/F5VFTU2D/08538655.pdf:application/pdf},
}

@article{loomba_hybrid_2018,
	title = {A {Hybrid} {Fitness}-{Utility} {Algorithm} for {Improved} {Service} {Chain} {Placement}},
	doi = {10.1109/GLOCOM.2018.8648033},
	abstract = {Optimal placement of service chains (composed of multiple connected service components) on heterogeneous cloud/fog infrastructure is a challenging problem. Even when deploying a small set of service components, the search-space of all possible solutions is quite large. Furthermore, current approaches sacrifice either precision or scalability when presented with heterogeneous platform configurations. In this scenario, the goal is to support orchestration that optimally selects solutions that meet performance constraints, leverages differentiating platform features and delivers these solutions within reasonable run-time. This paper presents the novel Hybrid Fitness-Utility Algorithm that addresses these issues by utilizing concepts derived from evolutionary algorithms to dimensionally reduce complexity, and incorporates the utility of placing each individual service component on an infrastructure resource for optimized selection between potential solutions. Our results show that the algorithm succeeds in determining optimal service chain placement onto distributed infrastructure for a simulated cloud/fog scenario and for a live multi point-of-presence OpenStack-based testbed with over 90 percent confidence.},
	journal = {2018 IEEE Global Communications Conference, GLOBECOM 2018 - Proceedings},
	author = {Loomba, Radhika and Metsch, Thijs and Feehan, Leonard and Butler, Joe},
	year = {2018},
	note = {Publisher: IEEE
ISBN: 9781538647271},
	pages = {1--7},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/ZUDHAFAJ/08648033.pdf:application/pdf},
}

@article{gu_cost_2017,
	title = {Cost efficient resource management in fog computing supported medical cyber-physical system},
	volume = {5},
	issn = {21686750},
	doi = {10.1109/TETC.2015.2508382},
	abstract = {With the recent development in information and communication technology, more and more smart devices penetrate into people's daily life to promote the life quality. As a growing healthcare trend, medical cyber-physical systems (MCPSs) enable seamless and intelligent interaction between the computational elements and the medical devices. To support MCPSs, cloud resources are usually explored to process the sensing data from medical devices. However, the high quality-of-service of MCPS challenges the unstable and long-delay links between cloud data center and medical devices. To combat this issue, mobile edge cloud computing, or fog computing, which pushes the computation resources onto the network edge (e.g., cellular base stations), emerges as a promising solution. We are thus motivated to integrate fog computation and MCPS to build fog computing supported MCPS (FC-MCPS). In particular, we jointly investigate base station association, task distribution, and virtual machine placement toward cost-efficient FC-MCPS.We first formulate the problem into a mixed-integer non-linear linear program and then linearize it into a mixed integer linear programming (LP). To address the computation complexity, we further propose an LP-based two-phase heuristic algorithm. Extensive experiment results validate the high-cost efficiency of our algorithm by the fact that it produces near optimal solution and significantly outperforms a greedy algorithm.},
	number = {1},
	journal = {IEEE Transactions on Emerging Topics in Computing},
	author = {Gu, Lin and Zeng, Deze and Guo, Song and Barnawi, Ahmed and Xiang, Yong},
	year = {2017},
	note = {Publisher: IEEE},
	keywords = {Fog computing, Mobile edge computing, Cost efficiency, Medical cyber physical system},
	pages = {108--119},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/J8DBZHXK/07359164.pdf:application/pdf},
}

@article{rezazadeh_lamp_2019,
	title = {{LAMP}: {A} {Hybrid} {Fog}-{Cloud} {Latency}-{Aware} {Module} {Placement} {Algorithm} for {IoT} {Applications}},
	doi = {10.1109/KBEI.2019.8734958},
	abstract = {The delay in the transmission of data to the cloud and their return impacts on applications performance. Hence, Fog computing with transferring the cloud services to the edge of the network causes to decrease the delay in services of applications such as healthcare, online games, and other IoT applications. Moreover, Fog computing reduces the cost and energy consumption of cloud data centers. One of the most important issues in fog computing is the placement of modules of IoT application on fog devices at the edge of the network to have a minimum of latency and the highest performance. In this paper, we propose a latency-aware module placement algorithm in Fog-Cloud environment, called LAMP, which is an exploratory algorithm for the optimal application modules placement into devices. LAMP provides less delay for IoT applications with reducing the distance between the host device modules. Consequently, improves the functionality of IoT applications. We use iFogsim simulator and evaluate the proposed algorithm compared to four strategies of placing in the fog-cloud environment. According to our results of the simulation, the efficiency of the proposed algorithm is guaranteed.},
	journal = {2019 IEEE 5th Conference on Knowledge Based Engineering and Innovation, KBEI 2019},
	author = {Rezazadeh, Zahra and Rezaei, Mahboobe and Nickray, Mohsen},
	year = {2019},
	note = {Publisher: IEEE
ISBN: 9781728108728},
	keywords = {Fog computing, Internet of Things (IoT), Cloud computing, Healthcare, resource management, module placement},
	pages = {845--850},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/R6DLH8ZQ/08734958.pdf:application/pdf},
}

@article{yadav_trust-aware_2019,
	title = {Trust-aware {Framework} for {Application} {Placement} in {Fog} {Computing}},
	volume = {2019-Decem},
	issn = {21531684},
	doi = {10.1109/ANTS47819.2019.9118122},
	abstract = {Internet of Things (IoT) devices are unable to handle enormous data generated by IoT applications due to limited computing capability. So IoT applications are placed at Cloud for computation, but it also faces latency and bandwidth issues. Fog computing addresses these issues of cloud by providing computation near to IoT users. In selection of fog nodes for application placement problem, trust plays a vital role. In our proposed model, we use trust as dominating factor for selection of fog nodes. The proposed model removes/curtails the malicious fog nodes during placement of applications. A case study is given for showing how trust can give benefits to IoT users.},
	journal = {International Symposium on Advanced Networks and Telecommunication Systems, ANTS},
	author = {Yadav, Ravi and Baranwal, Gaurav},
	year = {2019},
	note = {ISBN: 9781728137155},
	keywords = {Internet of Things (IoT), Fog Computing, Application Placement, Fog Broker, Trust},
	pages = {1--6},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/3K5Q833V/09118122.pdf:application/pdf},
}

@article{xu_plug-and-play_2019,
	title = {Plug-{And}-play for fog: {Dynamic} service placement in wireless multimedia networks},
	doi = {10.1109/ICCChina.2018.8641090},
	abstract = {Initially as an extension of cloud computing, fog computing has been inspiring new ideas about moving computing tasks to the edge of a network. In fog, we often repeat the procedure of placing service because of the geographical distribution of mobile users. We may not expect a fixed demand and supply relationship between users and service providers since users always prefer nearby service with less time delay and transmission consumption. That is, a plug-And-play service mode is what we need in fog. In this paper, we put forward a dynamic placement strategy for fog service in a three-Tier wireless multimedia network to guarantee the normal service provision and optimize the Quality of Service (QoS). The simulation results show that our strategy can achieve better performance under metrics including energy consumption and end-To-end latency compared with existed methods.},
	number = {Iccc},
	journal = {2018 IEEE/CIC International Conference on Communications in China, ICCC 2018},
	author = {Xu, Jianwen and Ota, Kaoru and Dong, Mianxiong},
	year = {2019},
	note = {Publisher: IEEE
ISBN: 9781538670057},
	keywords = {Fog Computing, Service Placement, Quality of Service., Wireless Multimedia Networks},
	pages = {490--494},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/FCQIDWAD/08641090.pdf:application/pdf},
}

@article{aral_decentralized_2018,
	title = {A decentralized replica placement algorithm for edge computing},
	volume = {15},
	issn = {19324537},
	doi = {10.1109/TNSM.2017.2788945},
	abstract = {As the devices that make up the Internet become more powerful, algorithms that orchestrate cloud systems are on the verge of putting more responsibility for computation and storage on these devices. In our current age of Big Data, dissemination and storage of data across end cloud devices is becoming a prominent problem subject to this expansion. In this paper, we propose a distributed data dissemination approach that relies on dynamic creation/replacement/removal of replicas guided by continuous monitoring of data requests coming from edge nodes of the underlying network. Our algorithm exploits geographical locality of data during the dissemination process due to the plenitude of common data requests that stem from the clients within a close proximity. Our results using both real-world and synthetic data demonstrate that a decentralized replica placement approach provides significant cost benefits compared to client side caching that is widely used in traditional distributed systems.},
	number = {2},
	journal = {IEEE Transactions on Network and Service Management},
	author = {Aral, Atakan and Ovatman, Tolga},
	year = {2018},
	note = {Publisher: IEEE},
	keywords = {Edge computing, Cloud computing, Facility location, Data replication, Replica discovery, Replica placement},
	pages = {516--529},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/3I7TUPDZ/08244318(1).pdf:application/pdf},
}

@article{althamary_popularity-based_2018,
	title = {Popularity-{Based} {Cache} {Placement} for {Fog} {Networks}},
	doi = {10.1109/IWCMC.2018.8450495},
	abstract = {Cache placement is a critical issue in fog networks. It is essential to simultaneously consider the quality of network connection, the demand of contents, and the users' activities. This paper proposes an efficient cache placement by placing the files based on popularity categories within a fog node cluster. Requested files are categorized into three popularity levels and strategically cached in fog nodes of various activity levels This work aims to reduce energy consumption by reducing the number of cells to serve the users based on content popularity. Another contribution of this paper is the clustering method for the fog nodes to select the node to host for the cache contents. The effectiveness of the algorithm is tested using the simulation regarding energy efficiency.},
	journal = {2018 14th International Wireless Communications and Mobile Computing Conference, IWCMC 2018},
	author = {Althamary, Ibrahim and Huang, Chih Wei and Lin, Phone and Yang, Shun Ren and Cheng, Chien Wei},
	year = {2018},
	note = {Publisher: IEEE
ISBN: 9781538620700},
	keywords = {Fog computing, 5G, energy efficiency, caching},
	pages = {800--804},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/3EAVDIH6/08450495.pdf:application/pdf},
}

@article{abedi_resource_2020,
	title = {Resource {Allocation} in {Combined} {Fog}-{Cloud} {Scenarios} by {Using} {Artificial} {Intelligence}},
	doi = {10.1109/FMEC49853.2020.9144693},
	abstract = {Although both cloud and fog computing technologies provide great on-demand services for the users, but none of them could singly guarantee the Quality of Service for the Internet of Things (IoT) based delay-sensitive applications. Therefore, cooperation between fog and cloud servers is of great importance. In this paper, we discuss about an artificial intelligence (AI) based task distribution algorithm (AITDA), which aims to reduce the response time and the Internet traffic by distribution of the tasks between fog and cloud servers. Our case study is a delay-sensitive application that runs in a situation where the computing capability of fog servers is restricted, and the internet connection is unstable (like vessels on the oceans). The primary trial of the AITDA shows that this method noticeably reduces the response time and internet traffic in comparison to the cloud-based and foz-based approaches.},
	journal = {2020 5th International Conference on Fog and Mobile Edge Computing, FMEC 2020},
	author = {Abedi, Masoud and Pourkiani, Mohammadreza},
	year = {2020},
	note = {ISBN: 9781728172163},
	keywords = {Machine Learning, Cloud Computing, Fog Computing, Maritime environments, Task Distribution},
	pages = {218--222},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/5NFAKT7E/09144693.pdf:application/pdf},
}

@article{pourkiani_machine_2020,
	title = {Machine {Learning} {Based} {Task} {Distribution} in {Heterogeneous} {Fog}-{Cloud} {Environments}},
	doi = {10.23919/SoftCOM50211.2020.9238309},
	abstract = {In order to improve the quality of service for delay-sensitive applications, in this paper, we propose Machine Learning based Task Distribution (MLTD) technique, which utilizes Artificial Neural Networks to distribute the tasks between the fog and cloud resources intelligently. This technique takes the diversity of servers (in terms of computing power) in addition to their workloads at the time of task distribution into account for providing the best possible response time. Evaluating the performance of our proposed technique, we utilized it in a real-world testbed and investigated its performance in different conditions. In comparison with similar methods, the achieved results show that MLTD improves the response time when the workloads of servers change continuously and reduces the internet bandwidth utilization in most cases.},
	journal = {2020 28th International Conference on Software, Telecommunications and Computer Networks, SoftCOM 2020},
	author = {Pourkiani, Mohammadreza and Abedi, Masoud},
	year = {2020},
	note = {ISBN: 9789532900996},
	keywords = {Cloud Computing, Fog Computing, Response Time, Neural Networks, Smart Task Distribution},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/2QIB4P3M/09238309.pdf:application/pdf},
}

@article{pourkiani_using_2021,
	title = {Using {Machine} {Learning} for {Task} {Distribution} in {Fog}-{Cloud} {Scenarios}: {A} {Deep} {Performance} {Analysis}},
	volume = {2021-Janua},
	issn = {19767684},
	doi = {10.1109/ICOIN50884.2021.9333929},
	abstract = {For efficient utilization of Internet bandwidth and reducing the response time for delay-sensitive applications, we propose Machine Learning Based Task Distribution (MLTD) technique, which uses the Artificial Neural Networks for smart task distribution between the fog and cloud servers. In this paper, we evaluate the efficiency of MLTD in different conditions to detect the parameters that can impact its performance. Also, we compare the performance of MLTD with other similar methods in terms of Internet bandwidth utilization, response time, and resource utilization. The achieved results show that the performance of MLTD can be better or worse than the other methods, and the training procedure of the neural networks plays an important role in increasing the efficiency of MLTD.},
	journal = {International Conference on Information Networking},
	author = {Pourkiani, Mohammadreza and Abedi, Masoud},
	year = {2021},
	note = {ISBN: 9781728191003},
	keywords = {Cloud, Fog, Response Time, Task Distribution, Internet Bandwidth},
	pages = {445--450},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/LIH5XPDV/09333929.pdf:application/pdf},
}

@article{mohammadi_enabling_2018,
	title = {Enabling {Cognitive} {Smart} {Cities} {Using} {Big} {Data} and {Machine} {Learning}: {Approaches} and {Challenges}},
	volume = {56},
	issn = {01636804},
	doi = {10.1109/MCOM.2018.1700298},
	abstract = {The development of smart cities and their fast-paced deployment is resulting in the generation of large quantities of data at unprecedented rates. Unfortunately, most of the generated data is wasted without extracting potentially useful information and knowledge because of the lack of established mechanisms and standards that benefit from the availability of such data. Moreover, the highly dynamic nature of smart cities calls for a new generation of machine learning approaches that are flexible and adaptable to cope with the dynamicity of data to perform analytics and learn from real-Time data. In this article, we shed light on the challenge of underutilizing the big data generated by smart cities from a machine learning perspective. In particular, we present the phenomenon of wasting unlabeled data. We argue that semi-supervision is a must for smart cities to address this challenge. We also propose a three-level learning framework for smart cities that matches the hierarchical nature of big data generated by smart cities with a goal of providing different levels of knowledge abstraction. The proposed framework is scalable to meet the needs of smart city services. Fundamentally, the framework benefits from semi-supervised deep reinforcement learning where a small amount of data that has users' feedback serves as labeled data, while a larger amount without such users' feedback serves as unlabeled data. The framework utilizes a mix of labeled and unlabeled data to converge toward better control policies instead of wasting the unlabeled data. This article also explores how deep reinforcement learning and its shift toward semi-supervision can handle the cognitive side of smart city services and improve their performance by providing several use cases spanning the different domains of smart cities. We also highlight several challenges as well as promising future research directions for incorporating machine learning and high-level intelligence into smart city services.},
	number = {2},
	journal = {IEEE Communications Magazine},
	author = {Mohammadi, Mehdi and Al-Fuqaha, Ala},
	year = {2018},
	note = {Publisher: IEEE},
	pages = {94--101},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/PYLKCTR7/Enabling_Cognitive_Smart_Cities_Using_Big_Data_and_Machine_Learning_Approaches_and_Challenges.pdf:application/pdf},
}

@article{chen_dynamic_2019,
	title = {A dynamic service migration mechanism in edge cognitive computing},
	volume = {19},
	issn = {15576051},
	doi = {10.1145/3239565},
	abstract = {Driven by the vision of edge computing and the success of rich cognitive services based on artificial intelligence, a new computing paradigm, edge cognitive computing (ECC), is a promising approach that applies cognitive computing at the edge of the network. ECC has the potential to provide the cognition of users and network environmental information, and further to provide elastic cognitive computing services to achieve a higher energy efficiency and a higher Quality of Experience (QoE) compared to edge computing. This article first introduces our architecture of the ECC and then describes its design issues in detail. Moreover, we propose an ECC-based dynamic service migration mechanism to provide insight into how cognitive computing is combined with edge computing. In order to evaluate the proposed mechanism, a practical platform for dynamic service migration is built up, where the services are migrated based on the behavioral cognition of a mobile user. The experimental results show that the proposed ECC architecture has ultra-low latency and a high user experience, while providing better service to the user, saving computing resources, and achieving a high energy efficiency.},
	number = {2},
	journal = {ACM Transactions on Internet Technology},
	author = {Chen, Min and Li, Wei and Fortino, Giancarlo and Hao, Yixue and Hu, Long and Humar, Iztok},
	year = {2019},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/HJDMCRA7/1808.07198.pdf:application/pdf},
}

@article{fuchs_matching_2021-1,
	title = {Matching of {Matching}-{Graphs} - {A} {Novel} {Approach} for {Graph} {Classification}},
	doi = {10.1109/icpr48806.2021.9411926},
	author = {Fuchs, Mathias and Riesen, Kaspar},
	year = {2021},
	note = {ISBN: 0000000291453},
	pages = {6570--6576},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/JD639DCE/Matching_of_Matching-Graphs_-_A_Novel_Approach_for_Graph_Classification.pdf:application/pdf},
}

@book{stamile_graph_nodate,
	title = {Graph {Machine} {Learning}},
	isbn = {978-1-80020-449-2},
	author = {Stamile, Claudio and Marzullo, Aldo and Deusebio, Enrico},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/7MHTVWT8/Claudio Stamile, Aldo Marzullo, Enrico Deusebio - Graph Machine Learning_ Take graph data to the next level by applying machine learning techniques and algorithms-Packt Publishing (2021.pdf:application/pdf},
}

@article{lera_yafs_2019,
	title = {{YAFS}: {A} {Simulator} for {IoT} {Scenarios} in {Fog} {Computing}},
	volume = {7},
	issn = {21693536},
	doi = {10.1109/ACCESS.2019.2927895},
	abstract = {Fog computing is a paradigm that extends the cloud to intermediate network devices with computational and storage capacities. This allows the execution of applications closer to edge devices and end-users by allocating services in those intermediate devices. The placement of those services has an influence on the performance of the fog architecture. We propose a fog computing simulator for analyzing the design and deployment of applications through customized and dynamical strategies. We model the relationships among deployed applications, network connections, and infrastructure characteristics through complex network theory, enabling the integration of topological measures in dynamic and customizable strategies, such as the placement of application modules, workload location, and path routing and scheduling of services. We present a comparative analysis of the efficiency and the convergence of results of our simulator with the most referenced one, iFogSim. To highlight the YAFS functionalities, we model three scenarios that, to the best of our knowledge, cannot be implemented with current fog simulators: dynamic allocation of new application modules, dynamic failures of network nodes, and user mobility along with the topology.},
	journal = {IEEE Access},
	author = {Lera, Isaac and Guerrero, Carlos and Juiz, Carlos},
	year = {2019},
	note = {Publisher: IEEE},
	keywords = {Internet of Things, fog computing, Complex networks, simulator, notion},
	pages = {91745--91758},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/LE3TMMRM/YAFS_A_Simulator_for_IoT_Scenarios_in_Fog_Computing.pdf:application/pdf},
}

@article{ahrens_how_2017,
	title = {How to {Take} {Smart} {Notes}: {One} {Simple} {Technique} to {Boost} {Writing}, {Learning} and {Thinking}},
	abstract = {The key to good and efficient writing lies in the intelligent organisation of ideas and notes. This book helps students, academics and nonfiction writers to get more done, write intelligent texts and learn for the long run. It teaches you how to take smart notes and ensure they bring you and your projects forward. The Take Smart Notes principle is based on established psychological insight and draws from a tried and tested note-taking-technique. This is the first comprehensive guide and description of this system in English, and not only does it explain how it works, but also why. It suits students and academics in the social sciences and humanities, nonfiction writers and others who are in the business of reading, thinking and writing. Instead of wasting your time searching for notes, quotes or references, you can focus on what really counts: thinking, understanding and developing new ideas in writing. It does not matter if you prefer taking notes with pen and paper or on a computer, be it Windows, Mac or Linux. And you can start right away.},
	author = {Ahrens, Sönke},
	year = {2017},
	pages = {178},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/DSFUHAVY/Sönke Ahrens - How to Take Smart Notes_ One Simple Technique to Boost Writing, Learning and Thinking - For Students, Academics and Nonfiction Book Writers-Createspace Independent Publis.pdf:application/pdf},
}

@article{fernando_opportunistic_2019,
	title = {Opportunistic {Fog} for {IoT}: {Challenges} and {Opportunities}},
	volume = {6},
	issn = {2327-4662, 2372-2541},
	shorttitle = {Opportunistic {Fog} for {IoT}},
	url = {https://ieeexplore.ieee.org/document/8743456/},
	doi = {10.1109/JIOT.2019.2924182},
	abstract = {With the proliferation of IoT devices, there is a demand for technologies to support high-velocity, dynamic resource provisioning to provide secure, cost-efﬁcient and real-time IoT services in resource-constrained environments. Conventional fog computing by itself cannot address such requirements and needs to be complemented with opportunistic fog computing, by providing mobile fog resources on-demand. In this paper, we discuss key issues in this area, and investigate potential solutions from existing work. We conclude the paper with a summary of gaps, and propose an opportunistic architecture for future work.},
	language = {en},
	number = {5},
	urldate = {2021-11-23},
	journal = {IEEE Internet of Things Journal},
	author = {Fernando, Niroshinie and Loke, Seng W. and Avazpour, Iman and Chen, Fei-Fei and Abkenar, Amin B. and Ibrahim, Amani},
	month = oct,
	year = {2019},
	keywords = {Fog computing, Internet of Things (IoT), mobile, opportunistic},
	pages = {8897--8910},
	file = {Fernando et al. - 2019 - Opportunistic Fog for IoT Challenges and Opportun.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/I3W92NKF/Fernando et al. - 2019 - Opportunistic Fog for IoT Challenges and Opportun.pdf:application/pdf},
}

@article{saleem_fesda_2019,
	title = {{FESDA}: {Fog}-enabled secure data aggregation in smart grid {IoT} network},
	doi = {10.1109/jiot.2019.2957314},
	abstract = {With advances in Fog and edge computing, various problems such as data processing for large Internet of things (IoT) systems can be solved in an efficient manner. One such problem for the next generation smart grid IoT system comprising of millions of smart devices is the data aggregation problem. Traditional data aggregation schemes for smart grids incur high computation and communication costs, and in recent years there have been efforts to leverage fog computing with smart grids to overcome these limitations. In this paper, a new fog-enabled privacy-preserving data aggregation scheme (FESDA) is proposed. Unlike existing schemes, the proposed scheme is resilient to false data injection attacks by filtering out the inserted values from external attackers. To achieve privacy, a modified version of Paillier crypto-system is used to encrypt consumption data of the smart meter users. In addition, FESDA is fault-tolerant, which means, the collection of data from other devices will not be affected even if some of the smart meters malfunction. We evaluate its performance along with three other competing schemes in terms of aggregation, decryption and communication costs. The findings demonstrate that FESDA reduces the communication cost by 50\%, when compared with the PPFA aggregation scheme.},
	journal = {IEEE Internet of Things Journal},
	author = {Saleem, Ahsan and Khan, Abid and Malik, Saif Ur Rehman and Pervaiz, Haris and Malik, Hassan and Alam, Masoom and Jindal, Anish and Jindal, Anish},
	year = {2019},
	pmid = {null},
	note = {tex.mag\_id: 2993170066
tex.pmcid: null},
	file = {Saleem et al_2019_FESDA.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/M773TIWN/Saleem et al_2019_FESDA.pdf:application/pdf;Saleem et al_2019_FESDA.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/WNJNUG8G/Saleem et al_2019_FESDA.pdf:application/pdf},
}

@article{puliafito_mobfogsim_2020,
	title = {{MobFogSim}: {Simulation} of mobility and migration for fog computing},
	doi = {10.1016/j.simpat.2019.102062},
	abstract = {Abstract Fog computing is an extension of the cloud towards the network edge that brings resources and services of computing in closer proximity to end users. This proximity provides several benefits such as reduced latency that improves user experience. However, user mobility may limit such benefits in practice, as the distance to a fog service may vary as a user moves from one location to another. Migration of a fog service may be one possible mitigation strategy, enabling the service to always be close enough to a user. Although many simulators exist for evaluating application behaviour and performance within a fog computing environment, none allows evaluation of service migration solutions to support mobility. MobFogSim is presented in this work to overcome this limitation. It extends iFogSim to enable modelling of device mobility and service migration in fog computing. MobFogSim is validated by comparing simulation results with those obtained from a real testbed where fog services are implemented as containers. Additional experiments are carried out in MobFogSim taking account of various mobility patterns of a user, derived from Luxembourg SUMO Traffic (LuST). We use an experiment-based approach to study the impact of user mobility on container migration in fog computing.},
	journal = {Simulation Modelling Practice and Theory},
	author = {Puliafito, Carlo and Goncalves, Diogo and Lopes, Marcio Moraes and Martins, Leonardo L. and Madeira, Edmundo R. M. and Mingozzi, Enzo and Rana, Omer F. and Bittencourt, Luiz F.},
	year = {2020},
	pmid = {null},
	note = {tex.mag\_id: 2996101703
tex.pmcid: null},
	file = {Puliafito et al_2020_MobFogSim.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/8SFKAYRY/Puliafito et al_2020_MobFogSim.pdf:application/pdf},
}

@article{de_s_xavier_collaborative_2020,
	title = {Collaborative resource allocation for {Cloud} of {Things} systems},
	doi = {10.1016/j.jnca.2020.102592},
	abstract = {Abstract The conceptual approach known as Fog/Edge Computing has recently emerged, aiming to move part of the computing and storage resources from the cloud to the edge of the network. The combination of IoT devices, edge nodes, and the Cloud gives rise to a three-tier Cloud of Things (CoT) architecture. In the complex and dynamic CoT ecosystems, a key issue is how to efficiently and effectively allocate resources to meet the demands of applications. Similar to traditional clouds, the goal of resource allocation in the CoT is to maximize the number of applications served by the infrastructure while ensuring a target operational cost. We propose a resource allocation algorithm for CoT systems that (i) supports heterogeneity of devices and applications, (ii) leverages the distributed nature of edge nodes to promote collaboration during the allocation process and (iii) provides an efficient usage of the system resources while meeting latency requirements and considering different priorities of IoT applications. Our algorithm follows a heuristic-based approach inspired on an economic model for solving the resource allocation problem in CoT. A set of simulations were performed, with promising results, showing that our collaborative resource allocation algorithm is more scalable, reduces the response time for applications and the energy consumption of end devices, in comparison to a two-tier, Cloud-based approach. Moreover, the network traffic between edge nodes, and between the Edge and Cloud tiers, is considerably smaller when using our collaborative solution, in comparison to other evaluated approaches.},
	journal = {Journal of Network and Computer Applications},
	author = {de S. Xavier, Tiago C. and Santos, Igor Leão dos and Santos, Igor and Delicato, Flavia C. and Delicato, Flávia Coimbra and Pires, Paulo F. and Pires, Paulo F. and Alves, Marcelo Pitanga and Calmon, Tiago Salviano and Salviano, Calmon Tiago and Salviano, Calmon Tiago and de Oliveira, Ana Cristina Bernardo and de Amorim, Claudio Luis},
	year = {2020},
	pmid = {null},
	note = {tex.mag\_id: 3013655254
tex.pmcid: null},
	file = {de S. Xavier et al_2020_Collaborative resource allocation for Cloud of Things systems.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/WIUY87HD/de S. Xavier et al_2020_Collaborative resource allocation for Cloud of Things systems.pdf:application/pdf},
}

@article{lin_simtalk_2020,
	title = {Simtalk: {Simulation} of iot applications},
	doi = {10.3390/s20092563},
	abstract = {The correct implementation and behavior of Internet of Things (IoT) applications are seldom investigated in the literature. This paper shows how the simulation mechanism can be integrated well into an IoT application development platform for correct implementation and behavior investigation. We use an IoT application development platform called IoTtalk as an example to describe how the simulation mechanism called SimTalk can be built into this IoT platform. We first elaborate on how to implement the simulator for an input IoT device (a sensor). Then we describe how an output IoT device (an actuator) can be simulated by an animated simulator. We use a smart farm application to show how the simulated sensors are used for correct implementation. We use applications including interactive art (skeleton art and water dance) and the pendulum physics experiment as examples to illustrate how IoT application behavior investigation can be achieved in SimTalk. As the main outcome of this paper, the SimTalk simulation codes can be directly reused for real IoT applications. Furthermore, SimTalk is integrated well with an IoT application verification tool in order to formally verify the IoT application configuration. Such features have not been found in any IoT simulators in the world.},
	journal = {Sensors},
	author = {Lin, Yun-Wei and Lin, Yi-Bing and Yen, Tai-Hsiang and Yen, Tai Hsiang},
	year = {2020},
	pmid = {32365971},
	note = {tex.mag\_id: 3020918498
tex.pmcid: null},
	file = {Lin et al_2020_Simtalk.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/HIWPIWRC/Lin et al_2020_Simtalk.pdf:application/pdf;Lin et al_2020_Simtalk.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/EYI4ZPV6/Lin et al_2020_Simtalk.pdf:application/pdf},
}

@article{margariti_modeling_2020,
	title = {Modeling and simulation tools for fog {Computing}—{A} comprehensive survey from a cost perspective},
	doi = {10.3390/fi12050089},
	abstract = {Fog computing is an emerging and evolving technology, which bridges the cloud with the network edges, allowing computing to work in a decentralized manner. As such, it introduces a number of complex issues to the research community and the industry alike. Both of them have to deal with many open challenges including architecture standardization, resource management and placement, service management, Quality of Service (QoS), communication, participation, to name a few. In this work, we provide a comprehensive literature review along two axes—modeling with an emphasis in the proposed fog computing architectures and simulation which investigates the simulation tools which can be used to develop and evaluate novel fog-related ideas.},
	journal = {Future Internet},
	author = {Margariti, S. V. and Margariti, Spiridoula V. and Margariti, Spiridoula V. and Dimakopoulos, Vassilios V. and Tsoumanis, Georgios and Tsoumanis, Georgios},
	year = {2020},
	pmid = {null},
	note = {tex.mag\_id: 3024209514
tex.pmcid: null},
	file = {Margariti et al_2020_Modeling and simulation tools for fog Computing—A comprehensive survey from a.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/J5XPX764/Margariti et al_2020_Modeling and simulation tools for fog Computing—A comprehensive survey from a.pdf:application/pdf},
}

@article{forti_lightweight_2021,
	title = {Lightweight self-organising distributed monitoring of {Fog} infrastructures},
	doi = {10.1016/j.future.2020.08.011},
	abstract = {Abstract Monitoring will play an enabling role in the orchestration of next-gen Fog applications. Particularly, monitoring of Fog computing infrastructures should deal with platform heterogeneity, scarce resource availability at the edge, and high dynamicity all along the Cloud-IoT continuum. In this article, we describe FogMon , a C++ distributed monitoring prototype targeting Fog computing infrastructures. FogMon monitors hardware resources at different Fog nodes, end-to-end network QoS between such nodes, and connected IoT devices. Besides, it features a self-organising peer-to-peer topology with self-restructuring mechanisms, and differential monitoring updates, which ensure scalability, fault-tolerance and low communication overhead. Experiments on a real testbed show how the footprint of FogMon is limited and how its self-restructuring topology makes it resilient to infrastructure dynamicity.},
	journal = {Future Generation Computer Systems},
	author = {Forti, Stefano and Gaglianese, Marco and Brogi, Antonio},
	year = {2021},
	pmid = {null},
	note = {tex.mag\_id: 3049647812
tex.pmcid: null},
	file = {Forti et al_2021_Lightweight self-organising distributed monitoring of Fog infrastructures.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/GLILVBIU/Forti et al_2021_Lightweight self-organising distributed monitoring of Fog infrastructures.pdf:application/pdf},
}

@article{ahmed_distributed_2020,
	title = {Distributed fog computing for internet of things ({IoT}) based ambient data processing and analysis},
	doi = {10.3390/electronics9111756},
	abstract = {Urban centers across the globe are under immense environmental distress due to an increase in air pollution, industrialization, and elevated living standards. The unmanageable and mushroom growth of industries and an exponential soar in population has made the ascent of air pollution intractable. To this end, the solutions that are based on the latest technologies, such as the Internet of things (IoT) and Artificial Intelligence (AI) are becoming increasingly popular and they have capabilities to monitor the extent and scale of air contaminants and would be subsequently useful for containing them. With centralized cloud-based IoT platforms, the ubiquitous and continuous monitoring of air quality and data processing can be facilitated for the identification of air pollution hot spots. However, owing to the inherent characteristics of cloud, such as large end-to-end delay and bandwidth constraint, handling the high velocity and large volume of data that are generated by distributed IoT sensors would not be feasible in the longer run. To address these issues, fog computing is a powerful paradigm, where the data are processed and filtered near the end of the IoT nodes and it is useful for improving the quality of service (QoS) of IoT network. To further improve the QoS, a conceptual model of distributed fog computing and a machine learning based data processing and analysis model is proposed for the optimal utilization of cloud resources. The proposed model provides a classification accuracy of 99\% while using a Support Vector Machines (SVM) classifier. This model is also simulated in iFogSim toolkit. It affords many advantages, such as reduced load on the central server by locally processing the data and reporting the quality of air. Additionally, it would offer the scalability of the system by integrating more air quality monitoring nodes in the IoT network.},
	journal = {Electronicsweek},
	author = {Ahmed, Mehreen and Ahmed, Mehreen and Mumtaz, Rafia and Zaidi, S. M. H. and Hafeez, Maryam and Zaidi, Syed Ali Raza and Ahmad, Muneer and Ahmad, Muneer},
	year = {2020},
	pmid = {null},
	note = {tex.mag\_id: 3094109761
tex.pmcid: null},
	file = {Ahmed et al_2020_Distributed fog computing for internet of things (IoT) based ambient data.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/2TMH6R6K/Ahmed et al_2020_Distributed fog computing for internet of things (IoT) based ambient data.pdf:application/pdf;Ahmed et al_2020_Distributed fog computing for internet of things (IoT) based ambient data.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/KTWSR3E4/Ahmed et al_2020_Distributed fog computing for internet of things (IoT) based ambient data.pdf:application/pdf},
}

@article{abreu_resilient_2020,
	title = {Resilient service chains through smart replication},
	doi = {10.1109/access.2020.3030537},
	abstract = {The Internet of Things paradigm enables a new set of smart end-user applications. The Cloud-Fog-Mist-Internet of Things infrastructure provides communication, compute, and storage support for these applications. However, this complex, heterogeneous, and distributed landscape requires orchestration and management mechanisms in order to guarantee their proper functioning. One particular factor to manage is the capacity to provide service resilience even in the presence of failures in components of the substrate infrastructure. This research proposes a set of mechanisms to formalize, orchestrate, and embed a batch of service requests for chained Virtual Functions to fulfill the specific requirements of applications while enhancing their availability and ultimately their resilience. In detail, this work introduces a formal grammar to describe customized Service Chains, allowing the definition of replicas for different Virtual Functions, and an Integer Linear Programming model for Virtual Function embedding that prioritizes the use of nodes with higher availability. Additionally, an alternative heuristic is presented to handle more complex scenarios by taking advantage of the multi-tier scenario comprising the Cloud-Fog-Mist-Internet of Things. Simulation results for the embedding mechanisms show that it is possible to increase the resilience of chained Virtual Functions, while balancing the load of the infrastructure nodes.},
	journal = {IEEE access : practical innovations, open solutions},
	author = {Abreu, David Perez and Velasquez, Karima and Paquete, Luís and Curado, Marilia and Monteiro, Edmundo},
	year = {2020},
	pmid = {null},
	note = {tex.mag\_id: 3094173014
tex.pmcid: null},
	file = {Abreu et al_2020_Resilient service chains through smart replication.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/LQ46KXFC/Abreu et al_2020_Resilient service chains through smart replication.pdf:application/pdf},
}

@article{contini_simulating_2020,
	title = {Simulating smart campus applications in edge and fog computing},
	doi = {10.1109/smartcomp50058.2020.00072},
	abstract = {null},
	journal = {null},
	author = {Contini, Denis and de Castro, Lucas Fernando Souza and de Castro, Lucas Fernando Souza and de Castro, Lucas Fernando Souza and Madeira, Edmundo R. M. and Rigo, Sandro and Rigo, Sandro and Rigo, Sandro and Bittencourt, Luiz F.},
	year = {2020},
	pmid = {null},
	note = {tex.mag\_id: 3097760405
tex.pmcid: null},
	file = {Contini et al_2020_Simulating smart campus applications in edge and fog computing.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/4VSTN4TY/Contini et al_2020_Simulating smart campus applications in edge and fog computing.pdf:application/pdf},
}

@article{yang_distributed_2020,
	title = {Distributed edge cloud availability},
	doi = {null},
	abstract = {With 5G being rolled out across the world, new performance-sensitive applications are emerging in various domains. To meet their performance goals, such as availability, latency, etc., a new distri ...},
	journal = {null},
	author = {Yang, Jiayi},
	year = {2020},
	pmid = {null},
	note = {tex.mag\_id: 3111763091
tex.pmcid: null},
}

@article{neto_leveraging_2020,
	title = {Leveraging edge intelligence for video analytics in smart city applications},
	doi = {10.3390/info12010014},
	abstract = {In smart city scenarios, the huge proliferation of monitoring cameras scattered in public spaces has posed many challenges to network and processing infrastructure. A few dozen cameras are enough to saturate the city’s backbone. In addition, most smart city applications require a real-time response from the system in charge of processing such large-scale video streams. Finding a missing person using facial recognition technology is one of these applications that require immediate action on the place where that person is. In this paper, we tackle these challenges presenting a distributed system for video analytics designed to leverage edge computing capabilities. Our approach encompasses architecture, methods, and algorithms for: (i) dividing the burdensome processing of large-scale video streams into various machine learning tasks; and (ii) deploying these tasks as a workflow of data processing in edge devices equipped with hardware accelerators for neural networks. We also propose the reuse of nodes running tasks shared by multiple applications, e.g., facial recognition, thus improving the system’s processing throughput. Simulations showed that, with our algorithm to distribute the workload, the time to process a workflow is about 33\% faster than a naive approach.},
	journal = {Information-an International Interdisciplinary Journal},
	author = {Neto, Aluizio Rocha and da Silva, Thiago Pereira and Batista, Thais and Delicato, Flavia C. and Pires, Paulo F. and Lopes, Frederico},
	year = {2020},
	pmid = {null},
	note = {tex.mag\_id: 3114891473
tex.pmcid: null},
	file = {Neto et al_2020_Leveraging edge intelligence for video analytics in smart city applications.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/H6NAYQTV/Neto et al_2020_Leveraging edge intelligence for video analytics in smart city applications.pdf:application/pdf},
}

@article{goncalves_dynamic_2020,
	title = {Dynamic network slicing in fog computing for mobile users in {MobFogSim}},
	doi = {10.1109/ucc48980.2020.00042},
	abstract = {null},
	journal = {null},
	author = {Goncalves, Diogo and Puliafito, Carlo and Mingozzi, Enzo and Rana, Omer F. and Bittencourt, Luiz F. and Madeira, Edmundo R. M.},
	year = {2020},
	pmid = {null},
	note = {tex.mag\_id: 3118081065
tex.pmcid: null},
	file = {Goncalves et al_2020_Dynamic network slicing in fog computing for mobile users in MobFogSim.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/RVSTWT2G/Goncalves et al_2020_Dynamic network slicing in fog computing for mobile users in MobFogSim.pdf:application/pdf},
}

@article{brogi_towards_2020,
	title = {Towards declarative decentralised application management in the fog},
	doi = {10.1109/issrew51248.2020.00077},
	abstract = {null},
	journal = {null},
	author = {Brogi, Antonio and Forti, Stefano and Guerrero, Carlos and Lera, Isaac},
	year = {2020},
	pmid = {null},
	note = {tex.mag\_id: 3119026922
tex.pmcid: null},
}

@article{godinho_energy_2020,
	title = {Energy and latency-aware resource reconfiguration in fog environments},
	doi = {10.1109/nca51143.2020.9306711},
	abstract = {null},
	journal = {null},
	author = {Godinho, Noe and Silva, Henrique and da Silva, Henrique J. A. and Curado, Marilia and Paquete, Luís},
	year = {2020},
	pmid = {null},
	note = {tex.mag\_id: 3120451011
tex.pmcid: null},
}

@article{buzachis_modeling_2021,
	title = {Modeling and emulation of an osmotic computing ecosystem using {OsmoticToolkit}},
	doi = {10.1145/3437378.3444366},
	abstract = {null},
	journal = {null},
	author = {Buzachis, Alina and Boruta, Daiana and Villari, Massimo and Spillner, Josef},
	year = {2021},
	pmid = {null},
	note = {tex.mag\_id: 3128942744
tex.pmcid: null},
	file = {Buzachis et al_2021_Modeling and emulation of an osmotic computing ecosystem using OsmoticToolkit.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/QKC57I76/Buzachis et al_2021_Modeling and emulation of an osmotic computing ecosystem using OsmoticToolkit.pdf:application/pdf},
}

@article{varghese_cognitive_2021,
	title = {A cognitive {IoT} smart surveillance framework for crowd behavior analysis},
	doi = {10.1109/comsnets51098.2021.9352910},
	abstract = {null},
	journal = {null},
	author = {Varghese, Elizabeth B. and Thampi, Sabu M.},
	year = {2021},
	pmid = {null},
	note = {tex.mag\_id: 3132882902
tex.pmcid: null},
	file = {Varghese_Thampi_2021_A cognitive IoT smart surveillance framework for crowd behavior analysis.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/IHAQ9MAU/Varghese_Thampi_2021_A cognitive IoT smart surveillance framework for crowd behavior analysis.pdf:application/pdf},
}

@article{wiesner_leaf_2021,
	title = {{LEAF}: {Simulating} large energy-aware fog computing environments},
	doi = {null},
	abstract = {Despite constant improvements in efficiency, today's data centers and networks consume enormous amounts of energy and this demand is expected to rise even further. An important research question is whether and how fog computing can curb this trend. As real-life deployments of fog infrastructure are still rare, a significant part of research relies on simulations. However, existing power models usually only target particular components such as compute nodes or battery-constrained edge devices. Combining analytical and discrete-event modeling, we develop a holistic but granular energy consumption model that can determine the power usage of compute nodes as well as network traffic and applications over time. Simulations can incorporate thousands of devices that execute complex application graphs on a distributed, heterogeneous, and resource-constrained infrastructure. We evaluated our publicly available prototype LEAF within a smart city traffic scenario, demonstrating that it enables research on energy-conserving fog computing architectures and can be used to assess dynamic task placement strategies and other energy-saving mechanisms.},
	journal = {arXiv: Distributed, Parallel, and Cluster Computing},
	author = {Wiesner, Philipp and Thamsen, Lauritz},
	year = {2021},
	pmid = {null},
	note = {tex.mag\_id: 3133689042
tex.pmcid: null},
	file = {Wiesner_Thamsen_2021_LEAF.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/QZLAFPLW/Wiesner_Thamsen_2021_LEAF.pdf:application/pdf},
}

@article{truong_using_2021,
	title = {Using {IoTCloudSamples} as a software framework for simulations of edge computing scenarios},
	doi = {10.1016/j.iot.2021.100383},
	abstract = {Abstract Realizing the potential of edge computing and networks connecting the edge and the cloud, researchers from academia and industries have increasingly developed techniques and tools for edge infrastructures and applications. This paper focuses on supporting complex edge application interactions, which span different layers and subsystems in edge-cloud environments. This paper addresses (i) diverse types of software components for emulating realistic functionality and configurations, like data transformation and service API interoperability, and (ii) techniques for connecting emulated scenarios to real edge software development and operations, and to IoT and cloud counterparts. We present IoTCloudSamples as a software framework with (i) modeling and implementation of diverse types of IoT, edge and cloud elements for complex edge scenarios, (ii) methods for constructing and steering emulations to study the interoperability across layers among different edge platforms and protocols, and (iii) extensive emulated scenarios and experiments integrated with real-world IoT and cloud services. IoTCloudSamples supports the approach of edge-simulation-as-codeto allow the reuse and runtime steering of realistic emulation operations. We will present examples from our real-world projects concentrating on edge analytics applications.},
	journal = {null},
	author = {Truong, Hong-Linh},
	year = {2021},
	pmid = {null},
	note = {tex.mag\_id: 3134096850
tex.pmcid: null},
	file = {Truong_2021_Using IoTCloudSamples as a software framework for simulations of edge computing.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/2MTUWA48/Truong_2021_Using IoTCloudSamples as a software framework for simulations of edge computing.pdf:application/pdf},
}

@article{entrialgo_modelling_2021,
	title = {Modelling and simulation for cost optimization and performance analysis of transactional applications in hybrid clouds},
	doi = {10.1016/j.simpat.2021.102311},
	abstract = {Abstract In the design process of a hybrid cloud with the purpose of cost optimization, finding the optimal distribution between the resources to be deployed in both private and public clouds is a complex task. To help the cloud designer in this task, optimizer and simulation tools can be used. In the research presented in this paper, a state-of-the-art optimizer tool, designed for the optimal allocation of virtual machines in public clouds for cost optimization, is analyzed for its use in hybrid cloud scenarios. In addition, based on the system and workload model implemented by this tool, a simulator is developed and presented. The simulator provides detailed run-time performance information corresponding to the virtual machine allocations generated by the optimizer tool, offering essential analysis capabilities to the cloud designer. A motivating scenario is used to show how the combined utilization of the optimizer and simulation tools can offer fundamental help in the design and configuration process of hybrid clouds. The research questions posed in the motivating scenario are addressed in a set of experiments, which provide meaningful insights into the capabilities of the tools. The tools and all the experimental data carried out in this research have been made publicly available.},
	journal = {Simulation Modelling Practice and Theory},
	author = {Entrialgo, Joaquín and García, Manuel and Díaz, José Luis and García, Javier and García, Daniel F.},
	year = {2021},
	pmid = {null},
	note = {tex.mag\_id: 3134459272
tex.pmcid: null},
}

@article{khan_perfsim_2021,
	title = {{PerfSim}: {A} performance simulator for cloud native computing.},
	doi = {null},
	abstract = {Cloud native computing paradigm allows microservice-based applications to take advantage of cloud infrastructure in a scalable, reusable, and interoperable way. However, in a cloud native system, the vast number of configuration parameters and highly granular resource allocation policies can significantly impact the performance and deployment cost of such applications. For understanding and analyzing these implications in an easy, quick, and cost-effective way, we present PerfSim, a discrete-event simulator for approximating and predicting the performance of cloud native service chains in user-defined scenarios. To this end, we proposed a systematic approach for modeling the performance of microservices endpoint functions by collecting and analyzing their performance and network traces. With a combination of the extracted models and user-defined scenarios, PerfSim can simulate the performance behavior of service chains over a given period and provides an approximation for system KPIs, such as requests' average response time. Using the processing power of a single laptop, we evaluated both simulation accuracy and speed of PerfSim in 104 prevalent scenarios and compared the simulation results with the identical deployment in a real Kubernetes cluster. We achieved  81-99\% simulation accuracy in approximating the average response time of incoming requests and  16-1200 times speed-up factor for the simulation.},
	journal = {arXiv: Distributed, Parallel, and Cluster Computing},
	author = {Khan, Michel Gokan and Taheri, Javid and Al-Dulaimy, Auday and Kassler, Andreas},
	year = {2021},
	pmid = {null},
	note = {tex.mag\_id: 3135939878
tex.pmcid: null},
}

@article{le_edge_2021,
	title = {Edge computing simulation platforms: {A} technology survey},
	doi = {10.1007/978-3-030-71906-7_2},
	abstract = {As the interest in Edge Computing (EC) increases, the need for platforms to support building and evaluating EC based systems becomes more evident. EC has been defined as an extension of the cloud, an architecture that consists of moving part of the cloud resources to the edge of the network. EC does not pose any technological limitations on how it needs to be implemented, however, to be considered EC, a set of features need to be supported. Given the scale, heterogeneity, and complexity of the EC environment (e.g., hardware and software), being able to perform real experiments would require substantial investments, without being able to capture all the possible scenarios. In the cloud space, simulation has been used extensively to study and evaluate architectural and quality variations. Simulation platforms have been developed to reduce costs and speed up the design and evaluation phases. However, in many cases, they can be limited to specific properties or application domains. In this paper, we provide an overview of EC simulation platforms, looking first at the main EC features, then comparing the platforms in terms of the features they support.},
	journal = {null},
	author = {Le, Thanh Van and Le, Thanh Van and Le, Van Thanh and Ioini, Nabil El and Pahl, Claus and Barzegar, Hamid R.},
	year = {2021},
	pmid = {null},
	note = {tex.mag\_id: 3136710541
tex.pmcid: null},
	file = {Le et al_2021_Edge computing simulation platforms.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/ZPGTC2E6/Le et al_2021_Edge computing simulation platforms.pdf:application/pdf},
}

@article{markus_investigating_2021,
	title = {Investigating {IoT} application behaviour in simulated fog environments},
	doi = {10.1007/978-3-030-72369-9_11},
	abstract = {In the past decade novel paradigms appeared in distributed systems, such as Cloud Computing, Fog Computing and the Internet of Things (IoT). Sensors and devices of IoT applications need big data to be stored, processed and analysed, and cloud systems offer suitable and scalable solutions for them. Recently fog nodes are utilized to provide data management functionalities closer to users with enhanced privacy and quality, giving birth to the creation of IoT-Fog-Cloud systems. Such infrastructures are so complex that they need simulators for planning, designing and analysis. Though cloud simulation already has a large number of literature, the simulation of fog systems is still evolving. In this paper we plan to take a step forward in this direction by investigating current fog simulation approaches and compare two of them providing the broadest fog modeling features. We also perform evaluations of executing IoT applications in hybrid, Fog-Cloud architectures to show possible advantages of different setups matching different IoT behaviour.},
	journal = {null},
	author = {Markus, Andras and Kertesz, Attila},
	year = {2021},
	pmid = {null},
	note = {tex.mag\_id: 3139257437
tex.pmcid: null},
	file = {Markus_Kertesz_2021_Investigating IoT application behaviour in simulated fog environments.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/TU5X4Y8L/Markus_Kertesz_2021_Investigating IoT application behaviour in simulated fog environments.pdf:application/pdf},
}

@article{gill_comprehensive_2021,
	title = {A comprehensive study of simulation frameworks and research directions in fog computing},
	doi = {10.1016/j.cosrev.2021.100391},
	abstract = {Abstract Context: Fog computing paradigm consists of resource constrained devices that support data processing and service provisioning at the edge of the network. Simulation frameworks play a key role in the design, development and validation of novel approaches for fog environment. The existing fog simulators model one or more aspects of fog environment and hence it becomes a tedious task to analyse and choose them as per the research requirements. Objective: This paper reviews the literature of simulation tools for fog computing and aims to help the novice researchers to explore and assess fog related proposals. Method: The study has employed a systematic search procedure to identify relevant articles published in the duration of 2015-2020. Results: The relevant publications are evaluated to highlight their strengths and underline the limitations. A comparative analysis of studies based on eight characteristic and few non technical features is presented. The scope for improvement in fog simulators is reported. Lastly, the prevailing research challenges in fog that can be addressed with reviewed simulation frameworks are detailed out. Conclusion: The paper has identified an increased interest in the development of novel and extended fog simulators thus emphasizing their importance. Also, the need to develop more advanced fog simulators that can model a wider range of fog environments is recognized. Directions are given for future work.},
	journal = {Computer Science Review},
	author = {Gill, Monika and Singh, Dinesh and Singh, Dinesh},
	year = {2021},
	pmid = {null},
	note = {tex.mag\_id: 3139391699
tex.pmcid: null},
	file = {PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/58J9PI64/1-s2.0-S1574013721000319-main.pdf:application/pdf},
}

@article{abdali_new_2021,
	title = {A new feature in mysejahtera application to monitoring the spread of {COVID}-19 using fog computing},
	doi = {10.1109/crc50527.2021.9392534},
	abstract = {Since the imposition of the Movement Control Order (MCO) by the government of Malaysia on 18th March 2020 due to the COVID-19 pandemic, the Ministry of Health (MOH), in Malaysia introduced an application named "Mysejahtera" to track the infected or suspected cases instead of manual tracking to saving cost and time. However, due to the huge number of users and controlling the spread of the virus we proposed a new framework using Fog Computing (FC) technology, to integrate low power-consumption by adding Identification Generator (IDG), and Risk Detector Fog Computing (RDFC), and improves secure connectivity efficiently. Based on FC concept the mobile users will consider as Internet of Things (IoT) environment, and the central storage is Cloud Computing (CC). This extension ensures the application performance higher than the original version of Mysejahtera application and notifies the users of the affected or suspected cases around.},
	journal = {null},
	author = {Abdali, Taj-Aldeen Naser and Hassan, Rosilah and Hassan, Rosilah and Hassan, Rosilah and Aman, Azana Hafizah Mohd},
	year = {2021},
	pmid = {null},
	note = {tex.mag\_id: 3155224114
tex.pmcid: null},
	file = {Abdali et al_2021_A new feature in mysejahtera application to monitoring the spread of COVID-19.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/BXI3RN3Z/Abdali et al_2021_A new feature in mysejahtera application to monitoring the spread of COVID-19.pdf:application/pdf},
}

@article{caiazza_measurement-driven_2021,
	title = {Measurement-driven design and runtime optimization in edge computing: {Methodology} and tools},
	doi = {10.1016/j.comnet.2021.108140},
	abstract = {Abstract Edge computing is projected to become the dominant form of cloud computing in the future because of the significant advantages it brings to both users (less latency, higher throughput) and telecom operators (less Internet traffic, more local management). However, to fully unlock its potential at scale, system designers and automated optimization systems alike will have to monitor closely the dynamics of both processing and communication facilities. Especially the latter is often neglected in current systems since network performance in cloud computing plays only a minor role. In this paper, we propose the architecture of MECPerf, which is a solution to collect network measurements in a live edge computing domain, to be collected for offline provisioning analysis and simulations, or to be provided in real-time for on-line system optimization. MECPerf has been validated in a realistic testbed funded by the European Commission (Fed4Fire+), and we describe here a summary of the results, which are fully available as open data and through a Python library to expedite their utilization. This is demonstrated via a use case involving the optimization of a system parameter for migrating clients in a federated edge computing system adopting the GSMA platform operator concept.},
	journal = {Computer Networks},
	author = {Caiazza, Chiara and Cicconetti, Claudio and Luconi, Valerio and Vecchio, Alessio},
	year = {2021},
	pmid = {null},
	note = {tex.mag\_id: 3157241861
tex.pmcid: null},
}

@article{aral_simulators_2020,
	title = {Simulators and emulators for edge computing},
	doi = {10.1049/pbpc033e_ch14},
	abstract = {In this chapter, we perform a study of the existing tools for the evaluation of Fog/Edge infrastructures. First, we analyze the state of the art in the simulation of Fog/Edge infrastructures and determine the main challenges in simulation and modeling such infrastructures. Then, we use a scientific methodology to identify the most important simulation and emulation tools, identifying their main characteristics, and define a classification. Each tool is then described in detail, and compared with the others. Finally, we conclude the chapter with a discussion about future research directions in the area.},
	journal = {null},
	author = {Aral, Atakan and Maio, Vincenzo De},
	year = {2020},
	pmid = {null},
	note = {tex.mag\_id: 3171477948
tex.pmcid: null},
}

@article{guo_dynamic_2021,
	title = {Dynamic computation offloading strategy with {DNN} partitioning in {D2D} multi-hop networks},
	doi = {10.1145/3456415.3457224},
	abstract = {The expansion of smart mobile applications has posed great challenges on mobile devices with limited computation resources. Since DNN based applications are usually computation-intensive, it is hard for resource-poor mobile devices to meet delay requirements. Inspired by the DNN model partition strategy, the paradigm of computation offloading in multi-hop D2D networks allows a device to complete tasks with the assistance of other devices. However, with the increase of the number of devices, the complexity of network architecture brings great difficulties to the designment of computation offloading strategy. To cope with this situation, we propose one D2D task offloading strategy based on the complex network theory to find the optimal task offloading assignment. Our proposed strategy can mitigate the routing congestion when transmitting tasks in D2D multi-hop networks, meanwhile it can dynamically find the partition point of DNN models to minimize the overall delay. We finally conduct extensive evaluations and demonstrate the effectiveness of our strategy.},
	journal = {null},
	author = {Guo, Xin and Dong, Chongwu and Wen, Wushao},
	year = {2021},
	pmid = {null},
	note = {tex.mag\_id: 3172133322
tex.pmcid: null},
}

@article{verma_rank_2021,
	title = {Rank based mobility-aware scheduling in {Fog} computing},
	doi = {10.1016/j.imu.2021.100619},
	abstract = {Abstract Providing uninterrupted service in Fog Computing (FC) is a challenging issue due to mobility of the users and end devices. In this paper, the issue is addressed through the proposed Rank-based Mobility-aware Scheduling (RMS) technique that uses contextual information to rank the resources. The proposed technique is implemented in MobFogSim simulation tool and the results are compared with the existing state-of-the-art Distance-based Mobility-aware Scheduling (DMS) technique. The simulation results show that RMS outperforms DMS in terms of migration time, delay, downtime, tuple lost, and execution time.},
	journal = {Informatics in Medicine Unlocked},
	author = {Verma, Kanupriya and Verma, Kanupriya and Kumar, Ashok and Kumar, Ashok and Islam, Mir Salim Ul and Kanwar, Tulika and Bhushan, Megha},
	year = {2021},
	pmid = {null},
	note = {tex.mag\_id: 3172243646
tex.pmcid: null},
}

@article{kaur_systematic_2021,
	title = {A systematic review on task scheduling in {Fog} computing: {Taxonomy}, tools, challenges, and future directions},
	doi = {10.1002/cpe.6432},
	abstract = {null},
	journal = {Concurrency and Computation: Practice and Experience},
	author = {Kaur, Navjeet and Kumar, Ashok and Kumar, Rajesh},
	year = {2021},
	pmid = {null},
	note = {tex.mag\_id: 3172298425
tex.pmcid: null},
}

@article{baheti_violet_2021,
	title = {{VIoLET}: {An} emulation environment for validating {IoT} deployments at large scales},
	doi = {10.1145/3446346},
	abstract = {Internet of Things (IoT) deployments have been growing manifold, encompassing sensors, networks, edge, fog, and cloud resources. Despite the intense interest from researchers and practitioners, most do not have access to large-scale IoT testbeds for validation. Simulation environments that allow analytical modeling are a poor substitute for evaluating software platforms or application workloads in realistic computing environments. Here, we propose a virtual environment for validating Internet of Things at large scales (VIoLET), an emulator for defining and launching large-scale IoT deployments within cloud VMs. It allows users to declaratively specify container-based compute resources that match the performance of native IoT compute devices using Docker. These can be inter-connected by complex topologies on which bandwidth and latency rules are enforced. Users can configure synthetic sensors for data generation as well. We also incorporate models for CPU resource dynamism, and for failure and recovery of the underlying devices. We offer a detailed comparison of VIoLET’s compute and network performance between the virtual and physical deployments, evaluate its scaling with deployments with up to 1, 000 devices and 4, 000 device-cores, and validate its ability to model resource dynamism. Our extensive experiments show that the performance of the virtual IoT environment accurately matches the expected behavior, with deviations levels within what is seen in actual physical devices. It also scales to 1, 000s of devices and at a modest cloud computing costs of under 0.15\% of the actual hardware cost, per hour of use, with minimal management effort. This IoT emulation environment fills an essential gap between IoT simulators and real deployments.},
	journal = {ACM Transactions on Cyber-Physical Systems},
	author = {Baheti, Shrey and Badiger, Shreyas and Simmhan, Yogesh},
	year = {2021},
	pmid = {null},
	note = {tex.mag\_id: 3178169350
tex.pmcid: null},
}

@article{jabba_vitool-bc_2021,
	title = {{ViTool}-{BC}: {Visualization} tool based on cooja simulator for {WSN}},
	doi = {10.3390/app11167665},
	abstract = {Evaluation and monitoring of wireless sensor networks (WSN) and the parameters defining their operations and design, such as energy consumption, latency, and stability, is a complex task due to interaction with real devices. For greater control of these variables, the use of simulators arises as an alternative. Cooja is a WSN simulator/emulator which handles the devices’ controllers and multiple communication protocol implementations, such as RPL (RPL is one of the most used protocol in IoT). However, Cooja does not consider either the implementation of an energy model (it has infinite energy consumption) nor the visual behavior of the topology construction, although these aspects are crucial for effective network analysis and decision taking. This paper presents the design and the implementation of ViTool-BC, a software built on top of Cooja, which allows the creation of different energy estimation models and also to visualize in real time the behavior of WSN topology construction. In addition, ViTool-BC offers a heat map of energy consumption traces. Therefore, this tool helps researchers to monitor in real time the topology construction, node disconnection, and battery depletion, aspects to be considered in the analysis of the available routing protocols in Cooja.},
	journal = {Applied Sciences},
	author = {Jabba, Daladier and Acevedo, Pedro},
	year = {2021},
	pmid = {null},
	note = {tex.mag\_id: 3194368265
tex.pmcid: null},
	file = {Jabba_Acevedo_2021_ViTool-BC.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/GV6IQMX3/Jabba_Acevedo_2021_ViTool-BC.pdf:application/pdf},
}

@article{mahmud_ifogsim2_2021,
	title = {{IFogSim2}: {An} extended {iFogSim} simulator for mobility, clustering, and microservice management in edge and fog computing environments},
	doi = {null},
	abstract = {Internet of Things (IoT) has already proven to be the building block for next-generation Cyber-Physical Systems (CPSs). The considerable amount of data generated by the IoT devices needs latency-sensitive processing, which is not feasible by deploying the respective applications in remote Cloud datacentres. Edge/Fog computing, a promising extension of Cloud at the IoT-proximate network, can meet such requirements for smart CPSs. However, the structural and operational differences of Edge/Fog infrastructure resist employing Cloud-based service regulations directly to these environments. As a result, many research works have been recently conducted, focusing on efficient application and resource management in Edge/Fog computing environments. Scalable Edge/Fog infrastructure is a must to validate these policies, which is also challenging to accommodate in the real-world due to high cost and implementation time. Considering simulation as a key to this constraint, various software has been developed that can imitate the physical behaviour of Edge/Fog computing environments. Nevertheless, the existing simulators often fail to support advanced service management features because of their monolithic architecture, lack of actual dataset, and limited scope for a periodic update. To overcome these issues, we have developed multiple simulation models for service migration, dynamic distributed cluster formation, and microservice orchestration for Edge/Fog computing in this work and integrated with the existing iFogSim simulation toolkit for launching it as iFogSim2. The performance of iFogSim2 and its built-in policies are evaluated using three use case scenarios and compared with the contemporary simulators and benchmark policies under different settings. Results indicate that the proposed solution outperform others in service management time, network usage, ram consumption, and simulation time.},
	journal = {arXiv: Distributed, Parallel, and Cluster Computing},
	author = {Mahmud, Redowan and Mahmud, Md. Redowan and Pallewatta, Samodha and Goudarzi, Mohammad and Buyya, Rajkumar},
	year = {2021},
	pmid = {null},
	note = {tex.mag\_id: 3199069499
tex.pmcid: null},
}

@article{varghese_visual_2021,
	title = {Visual attention based cognitive informative frame extraction method for smart crowd surveillance},
	doi = {10.1109/21cw48944.2021.9532519},
	abstract = {In a smart surveillance system, the amount of video data has increased exponentially due to the increase in the number of monitoring devices and IoT sensors. To make smart and real-time decisions without latency in communication from these voluminous data is a tedious task. In this context, selecting informative frames from the video is of great importance that helps to extract only the salient features for further processing without latency and bandwidth constraints. In this paper, we are proposing a fast and reliable method for selecting informative frames from video sequences based on the human cognition process of visual attention to preserve the Spatio-temporal properties of the video. The proposed method extracts the informative frames using the frame informative score calculated based on visual attention maps, superpixel segmentation, and temporal information. Since our purpose is for analyzing crowd behavior from video data in a smart environment, we take two publicly available crowd video datasets for our experiments. The results show that the proposed approach is successful in extracting relevant video frames in linear time by preserving their spatial and temporal properties. We also analyze the feasibility of the proposed method in a fog computing-based simulated IoT framework, and it has been verified that the proposed cognitive approach could efficiently address the concerns of latency and bandwidth in smart surveillance environments.},
	journal = {null},
	author = {Varghese, Elizabeth B. and Thampi, Sabu M.},
	year = {2021},
	pmid = {null},
	note = {tex.mag\_id: 3199819348
tex.pmcid: null},
}

@article{sharma_scaling_2021,
	title = {Scaling and placing distributed services on vehicle clusters in urban environments},
	doi = {null},
	abstract = {Many vehicles spend a significant amount of time in urban traffic congestion. Due to the evolution of autonomous cars, driver assistance systems, and in-vehicle entertainment, many vehicles have plentiful computational and communication capacity. How can we deploy data collection and processing tasks on these (slowly) moving vehicles to productively use any spare resources? To answer this question, we study the efficient placement of distributed services on a moving vehicle cluster. We present a macroscopic flow model for an intersection in Dublin, Ireland, using real vehicle density data. We show that such aggregate flows are highly predictable (even though the paths of individual vehicles are not known in advance), making it viable to deploy services harnessing vehicles' sensing capabilities. Our main contribution is a detailed mathematical specification for a task-based, distributed service placement model that scales according to the resource requirements and is robust to the changes caused by the mobility of the cluster. We formulate this as a constrained optimization problem, with the objective of minimizing overall processing and communication costs. Our results show that jointly scaling tasks and finding a mobility-aware, optimal placement results in reduced processing and communication costs compared to an autonomous vehicular edge computing-based naive solution.},
	journal = {null},
	author = {Sharma, Kanika and Butler, Bernard and Jennings, Brendan},
	year = {2021},
	pmid = {null},
	note = {tex.mag\_id: 3206994701
tex.pmcid: null},
}

@article{aleyadeh_mobility_2021,
	title = {Mobility aware edge computing segmentation towards localized orchestration},
	doi = {null},
	abstract = {The current trend in end-user devices' advancements in computing and communication capabilities makes edge computing an attractive solution to pave the way for the coveted ultra-low latency services. The success of the edge computing networking paradigm depends on the proper orchestration of the edge servers. Several Edge applications and services are intolerant to latency, especially in 5G and beyond networks, such as intelligent video surveillance, E-health, Internet of Vehicles, and augmented reality applications. The edge devices underwent rapid growth in both capabilities and size to cope with the service demands. Orchestrating it on the cloud was a prominent trend during the past decade. However, the increasing number of edge devices poses a significant burden on the orchestration delay. In addition to the growth in edge devices, the high mobility of users renders traditional orchestration schemes impractical for contemporary edge networks. Proper segmentation of the edge space becomes necessary to adapt these schemes to address these challenges. In this paper, we introduce a segmentation technique employing lax clustering and segregated mobility-based clustering. We then apply latency mapping to these clusters. The proposed scheme's main objective is to create subspaces (segments) that enable light and efficient edge orchestration by reducing the processing time and the core cloud communication overhead. A bench-marking simulation is conducted with the results showing decreased mobility-related failures and reduced orchestration delay.},
	journal = {arXiv: Networking and Internet Architecture},
	author = {Aleyadeh, Sam and Moubayed, Abdallah and Shami, Abdallah},
	year = {2021},
	pmid = {null},
	note = {tex.mag\_id: 3207104282
tex.pmcid: null},
}

@article{sharma_graph-based_2021,
	title = {Graph-based heuristic solution for placing distributed video processing applications on moving vehicle clusters},
	doi = {null},
	abstract = {Vehicular fog computing (VFC) is envisioned as an extension of cloud and mobile edge computing to utilize the rich sensing and processing resources available in vehicles. We focus on slow-moving cars that spend a significant time in urban traffic congestion as a potential pool of on-board sensors, video cameras, and processing capacity. For leveraging the dynamic network and processing resources, we utilize a stochastic mobility model to select nodes with similar mobility patterns. We then design two distributed applications that are scaled in real-time and placed as multiple instances on selected vehicular fog nodes. We handle the unstable vehicular environment by a), Using real vehicle density data to build a realistic mobility model that helps in selecting nodes for service deployment b), Using community-detection algorithms for selecting a robust vehicular cluster using the predicted mobility behavior of vehicles. The stability of the chosen cluster is validated using a graph centrality measure, and c), Graph-based placement heuristics are developed to find the optimal placement of service graphs based on a multi-objective constrained optimization problem with the objective of efficient resource utilization. The heuristic solves an important problem of processing data generated from distributed devices by balancing the trade-off between increasing the number of service instances to have enough redundancy of processing instances to increase resilience in the service in case of node or link failure, versus reducing their number to minimise resource usage. We compare our heuristic to an integer linear program solution and a first-fit heuristic. Our approach performs better than these comparable schemes in terms of resource utilization and/or has a lesser service latency, which is a crucial requirement for safety-related applications.},
	journal = {arXiv: Networking and Internet Architecture},
	author = {Sharma, Kanika and Butler, Bernard and Jennings, Brendan},
	year = {2021},
	pmid = {null},
	note = {tex.mag\_id: 3209098095
tex.pmcid: null},
}

@article{da_costa_bezerra_processing_2021,
	title = {Processing complex events in fog-based internet of things systems for smart agriculture},
	doi = {10.3390/s21217226},
	abstract = {The recent growth of the Internet of Things’ services and applications has increased data processing and storage requirements. The Edge computing concept aims to leverage the processing capabilities of the IoT and other devices placed at the edge of the network. One embodiment of this paradigm is Fog computing, which provides an intermediate and often hierarchical processing tier between the data sources and the remote Cloud. Among the major benefits of this concept, the end-to-end latency can be decreased, thus favoring time-sensitive applications. Moreover, the data traffic at the network core and the Cloud computing workload can be reduced. Combining the Fog computing paradigm with Complex Event Processing (CEP) and data fusion techniques has excellent potential for generating valuable knowledge and aiding decision-making processes in the Internet of Things’ systems. In this context, we propose a multi-tier complex event processing approach (sensor node, Fog, and Cloud) that promotes fast decision making and is based on information with 98\% accuracy. The experiments show a reduction of 77\% in the average time of sending messages in the network. In addition, we achieved a reduction of 82\% in data traffic.},
	journal = {Sensors},
	author = {da Costa Bezerra, Sandy F. and Filho, Airton S. M. and Delicato, Flavia C. and da Rocha, Atslands Rego},
	year = {2021},
	pmid = {null},
	note = {tex.mag\_id: 3210110497
tex.pmcid: null},
	file = {da Costa Bezerra et al_2021_Processing complex events in fog-based internet of things systems for smart.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/N56AKKLT/da Costa Bezerra et al_2021_Processing complex events in fog-based internet of things systems for smart.pdf:application/pdf},
}

@article{alammari_enhanced_2021,
	title = {Enhanced layered fog architecture for {IoT} sensing and actuation as a service.},
	doi = {10.1038/s41598-021-00926-y},
	abstract = {The reduced service cost offered by Sensing and Actuation as a Service paradigm, particularly in Internet of Things (IoT) era, has encouraged many establishments to start without worrying about having their own infrastructure. Such a paradigm is typically managed by a centralized cloud service provider. Fog paradigm has emerged as a mini-cloud that if designed with care to assist the cloud, together will achieve better performance. This article introduces a layered fog architecture called Sensors and Actuator Layered Fog Services Delivery (SALFSD) for IoT ecosystems. The significance of SALFSD is being fault resistant; it dynamically reassigns tasks of the failed node to the nearest active node to maintain the network connection. Besides, SALFSD monitors end users pre-specified cases closer to the physical devices hired by end users to fasten generating the actuation commands. Such node may offload its monitoring responsibility to its parent node in case it is overloaded. SALFSD is evaluated using Yet Another Fog Simulator in different scenarios (numbers of users, sensors, actuators, and areas). A comparison was made for Sensing and Actuating as a Service (SAaaS) with/without layered fog, and layered fog with/without (failure reassignment, pre-specified cases in fog nodes, and offloading). The comparison was conducted in terms of computing/communication latencies and the number of missed messages for both observations and actuation commands. Results show that failure reassignment prevented losing messages and maintained network connectivity. Also, wisely selecting the monitoring fog node per end user pre-specified cases and the offloading scheme decreased actuation latency.},
	journal = {Scientific Reports},
	author = {Alammari, Abdulsalam and Moiz, Salman Abdul and Negi, Atul},
	year = {2021},
	pmid = {34737350},
	note = {tex.mag\_id: 3208676245
tex.pmcid: null},
	file = {Alammari et al_2021_Enhanced layered fog architecture for IoT sensing and actuation as a service.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/XRATKW8K/Alammari et al_2021_Enhanced layered fog architecture for IoT sensing and actuation as a service.pdf:application/pdf},
}

@article{mahadevappa_data_2021,
	title = {A data quarantine model to secure data in edge computing.},
	doi = {null},
	abstract = {Edge computing provides an agile data processing platform for latency-sensitive and communication-intensive applications through a decentralized cloud and geographically distributed edge nodes. Gaining centralized control over the edge nodes can be challenging due to security issues and threats. Among several security issues, data integrity attacks can lead to inconsistent data and intrude edge data analytics. Further intensification of the attack makes it challenging to mitigate and identify the root cause. Therefore, this paper proposes a new concept of data quarantine model to mitigate data integrity attacks by quarantining intruders. The efficient security solutions in cloud, ad-hoc networks, and computer systems using quarantine have motivated adopting it in edge computing. The data acquisition edge nodes identify the intruders and quarantine all the suspected devices through dimensionality reduction. During quarantine, the proposed concept builds the reputation scores to determine the falsely identified legitimate devices and sanitize their affected data to regain data integrity. As a preliminary investigation, this work identifies an appropriate machine learning method, Linear Discriminant Analysis (LDA), for dimensionality reduction. The LDA results in 72.83\% quarantine accuracy and 0.9 seconds training time, which is efficient than other state-of-the-art methods. In future, this would be implemented and validated with ground truth data.},
	journal = {arXiv: Neural and Evolutionary Computing},
	author = {Mahadevappa, Poornima and Murugesan, Raja Kumar},
	year = {2021},
	pmid = {null},
	note = {tex.mag\_id: 3213439587
tex.pmcid: null},
}

@article{mededjel_cloud-fog_2021,
	title = {A cloud-fog architecture for physical-internet-enabled supply chain},
	doi = {10.1080/16258312.2021.1996861},
	abstract = {null},
	journal = {null},
	author = {Mededjel, Mansour and Belalem, Ghalem and Neki, Abdelkader},
	year = {2021},
	pmid = {null},
	note = {tex.mag\_id: 3213650836
tex.pmcid: null},
}

@article{mann_evaluation_2022,
	title = {Evaluation of fog application placement algorithms: a survey},
	doi = {10.1007/s00607-021-01031-8},
	abstract = {Abstract Recently, the concept of cloud computing has been extended towards the network edge. Devices near the network edge, called fog nodes, offer computing capabilities with low latency to nearby end devices. In the resulting fog computing paradigm (also called edge computing), application components can be deployed to a distributed infrastructure, comprising both cloud data centers and fog nodes. The decision which infrastructure nodes should host which application components has a large impact on important system parameters like performance and energy consumption. Several algorithms have been proposed to find a good placement of applications on a fog infrastructure. In most cases, the proposed algorithms were evaluated experimentally by the respective authors. In the absence of a theoretical analysis, a thorough and systematic empirical evaluation is of key importance for being able to make sound conclusions about the suitability of the algorithms. The aim of this paper is to survey how application placement algorithms for fog computing are evaluated in the literature. In particular, we identify good and bad practices that should be utilized respectively avoided when evaluating such algorithms.},
	journal = {Computing. Archives for Scientific Computing},
	author = {Mann, Zoltan Adam},
	year = {2022},
	pmid = {null},
	note = {tex.mag\_id: 4211139085
tex.pmcid: null},
	file = {Mann_2022_Evaluation of fog application placement algorithms.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/7Q7GJUGW/Mann_2022_Evaluation of fog application placement algorithms.pdf:application/pdf},
}

@article{delicato_managing_2022,
	title = {Managing heterogeneous and time-sensitive {IoT} applications through collaborative and energy-aware resource allocation},
	doi = {10.1145/3488248},
	abstract = {In the Internet of Things (IoT) environment, the computing resources available in the cloud are often unable to meet the latency constraints of time critical applications due to the large distance between the cloud and data sources (IoT devices). The adoption of edge computing can help the cloud deliver services that meet time critical application requirements. However, it is challenging to meet the IoT application demands while using the resources smartly to reduce energy consumption at the edge of the network. In this context, we propose a fully distributed resource allocation algorithm for the IoT-edge-cloud environment, which (i) increases the infrastructure resource usage by promoting the collaboration between edge nodes, (ii) supports the heterogeneity and generic requirements of applications, and (iii) reduces the application latency and increases the energy efficiency of the edge. We compare our algorithm with a non-collaborative vertical offloading and with a horizontal approach based on edge collaboration. Results of simulations showed that the proposed algorithm is able to reduce 49.95\% of the IoT application request end-to-end latency, increase 95.35\% of the edge node utilization, and enhance the energy efficiency in terms of the edge node power consumption by 92.63\% in comparison to the best performances of vertical and collaboration approaches.},
	journal = {ACM transactions on the internet of things},
	author = {Delicato, Flavia C. and Pires, Paulo F. and Amorim, Claudio L. and Li, Wei and Zomaya, Albert Y.},
	year = {2022},
	pmid = {null},
	note = {tex.mag\_id: 4213318358
tex.pmcid: null},
}

@article{alonso_wotemu_2022,
	title = {{WoTemu}: {An} emulation framework for edge computing architectures based on the {Web} of {Things}},
	doi = {10.1016/j.comnet.2022.108868},
	abstract = {The edge computing model is an approach to Internet of Things (IoT) architectures based on the redistribution of services and infrastructure from centralized clouds to locations closer to IoT devices. The Web of Things (WoT) is another important IoT trend, currently led by the W3C, which aims at solving the IoT interoperability problem by adopting proven technologies and patterns from the Web. The design and validation of IoT deployments based on these paradigms is a complex task that involves multiple services, heterogeneous hardware and diverse communication technologies. Testing such projects in real world conditions usually requires a significant investment of resources. There are simulation tools that can assist in this process with much lower barriers of entry, however, they involve the designer making modelling assumptions that are not always representative of the real systems. This work presents an emulation tool for IoT projects based on the edge computing model that is able to seamlessly scale horizontally by leveraging container orchestration (Docker swarm mode). Furthermore, the W3C WoT model is included as a first-class citizen, enabling the designer to model all actors in the system as Things. The tool can run the real production code with minimal modifications and provides meaningful insights into the behaviour of the proposed architecture. This knowledge serves to rapidly iterate the optimization process, simplifying design issues and the detection of bottlenecks before committing to a real deployment in the field. A real-world scenario is also emulated in order to demonstrate its capabilities and validate its contribution. • Container orchestration is a great fit for the emulation of IoT systems. • WoTemu gives detailed insight into the behaviour of IoT applications. • WoTemu enables the validation of IoT systems before committing to a deployment.},
	journal = {Computer Networks},
	author = {Alonso, Francisco José Suárez and Garcia, Daniel F. and Díaz, Fidel Díez},
	year = {2022},
	pmid = {null},
	note = {tex.mag\_id: 4214852027
tex.pmcid: null},
}

@article{scarpiniti_deepfogsim_2021,
	title = {{DeepFogSim}: {A} toolbox for execution and performance evaluation of the inference phase of conditional deep neural networks with early exits atop distributed fog platforms},
	doi = {10.3390/app11010377},
	abstract = {null},
	journal = {Applied Sciences},
	author = {Scarpiniti, Michele and Scarpiniti, Michele and Baccarelli, Enzo and Momenzadeh, Alireza and Ahrabi, Sima Sarv},
	year = {2021},
	pmid = {null},
	note = {tex.mag\_id: 3118371900
tex.pmcid: null},
	file = {Scarpiniti et al_2021_DeepFogSim.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/YY42SLU5/Scarpiniti et al_2021_DeepFogSim.pdf:application/pdf},
}

@article{markus_actuator_2021,
	title = {Actuator behaviour modelling in {IoT}-{Fog}-{Cloud} simulation.},
	doi = {10.7717/peerj-cs.651},
	abstract = {The inevitable evolution of information technology has led to the creation of IoT-Fog-Cloud systems, which combine the Internet of Things (IoT), Cloud Computing and Fog Computing. IoT systems are composed of possibly up to billions of smart devices, sensors and actuators connected through the Internet, and these components continuously generate large amounts of data. Cloud and fog services assist the data processing and storage needs of IoT devices. The behaviour of these devices can change dynamically (e.g. properties of data generation or device states). We refer to systems allowing behavioural changes in physical position (i.e. geolocation), as the Internet of Mobile Things (IoMT). The investigation and detailed analysis of such complex systems can be fostered by simulation solutions. The currently available, related simulation tools are lacking a generic actuator model including mobility management. In this paper, we present an extension of the DISSECT-CF-Fog simulator to support the analysis of arbitrary actuator events and mobility capabilities of IoT devices in IoT-Fog-Cloud systems. The main contributions of our work are: (i) a generic actuator model and its implementation in DISSECT-CF-Fog, and (ii) the evaluation of its use through logistics and healthcare scenarios. Our results show that we can successfully model IoMT systems and behavioural changes of actuators in IoT-Fog-Cloud systems in general, and analyse their management issues in terms of usage cost and execution time.},
	journal = {PeerJ},
	author = {Markus, Andras and Biro, Mate and Kecskemeti, Gabor and Kecskemeti, Gabor and Kertesz, Attila},
	year = {2021},
	pmid = {null},
	note = {tex.mag\_id: 3191396870
tex.pmcid: null},
	file = {Markus et al_2021_Actuator behaviour modelling in IoT-Fog-Cloud simulation.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/P8SSD9KJ/Markus et al_2021_Actuator behaviour modelling in IoT-Fog-Cloud simulation.pdf:application/pdf},
}

@article{brogi_declarative_2021,
	title = {Declarative application management in the fog: {A} bacteria-inspired decentralised approach},
	doi = {10.1007/s10723-021-09582-y},
	abstract = {Orchestrating next-gen applications over heterogeneous resources along the Cloud-IoT continuum calls for new strategies and tools to enable scalable and application-specific managements. Inspired by the self-organisation capabilities of bacteria colonies, we propose a declarative, fully decentralised application management solution, targeting pervasive opportunistic Cloud-IoT infrastructures. We present a customisable declarative implementation of the approach and validate its scalability through simulation over motivating scenarios, also considering end-user’s mobility and the possibility to enforce application-specific management policies for different (classes of) applications.},
	journal = {Journal of Grid Computing},
	author = {Brogi, Antonio and Forti, Stefano and Guerrero, Carlos and Lera, Isaac},
	year = {2021},
	pmid = {null},
	note = {tex.mag\_id: 3209697077
tex.pmcid: null},
	file = {Brogi et al_2021_Declarative application management in the fog.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/VK5I49VU/Brogi et al_2021_Declarative application management in the fog.pdf:application/pdf},
}

@article{kirsal_analytical_2022,
	title = {An analytical modelling and {QoS} evaluation of fault-tolerant load balancer and web servers in fog computing},
	doi = {10.1007/s11227-022-04345-2},
	abstract = {Recently, fog computing has become popular due to its high degree of storage and processing capabilities. Thus, very large data can be processed by the users through the fog computing servers. However, the fog computing servers are likely to suffer from failures and need analytical models to predict their behaviour to deliver desired QoS. This paper proposes an analytical model and the solution approach for QoS evaluation of fault-tolerant load balancer and web servers with mobility issues in fog computing. The proposed solution approach combines the Spectral expansion solution and the system of balance equations with the Markov reward model approach to obtain more realistic QoS measurements. The proposed model is compared and contrasted with the existing models to show the effectiveness and accuracy of the proposed work. The results showed that the proposed analytical model and the solution approach are efficient and compatible in the evaluation of such system QoS measurements.},
	journal = {The Journal of Supercomputing},
	author = {Kirsal, Yonal and Ülker, Sadık},
	year = {2022},
	pmid = {null},
	note = {tex.mag\_id: 4214490189
tex.pmcid: null},
}

@article{forti_continuous_2020,
	title = {Continuous reasoning for managing next-gen distributed applications.},
	doi = {10.4204/eptcs.325.22},
	abstract = {Continuous reasoning has proven effective in incrementally analysing changes in application codebases within Continuous Integration/Continuous Deployment (CI/CD) software release pipelines. In this article, we present a novel declarative continuous reasoning approach to support the management of multi-service applications over the Cloud-IoT continuum, in particular when infrastructure variations impede meeting application's hardware, software, IoT or network QoS requirements. We show how such an approach brings considerable speed-ups compared to non-incremental reasoning.},
	journal = {arXiv: Distributed, Parallel, and Cluster Computing},
	author = {Forti, Stefano and Brogi, Antonio},
	year = {2020},
	pmid = {null},
	note = {tex.mag\_id: 3087916853
tex.pmcid: null},
	file = {Forti_Brogi_2020_Continuous reasoning for managing next-gen distributed applications.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/89ZHEVLK/Forti_Brogi_2020_Continuous reasoning for managing next-gen distributed applications.pdf:application/pdf},
}

@article{farooqui_empirical_2020,
	title = {An empirical investigation of performance challenges within context‐aware content sharing for vehicular ad hoc networks},
	doi = {10.1002/ett.4157},
	abstract = {Connected vehicles is a leading use-case within the Industrial Internet of Things (IIoT), which is aimed at automating a range of driving tasks such as navigation, accident avoidance, content sharing and auto-driving. Such systems leverage Vehicular Ad-hoc Networks (VANETs) and include vehicle to vehicle (V2V) and vehicle to roadside infrastructure (V2I) communication along with remote systems such as traffic alerts and weather reports. However, the device endpoints in such networks are typically resource-constrained and, therefore, leverage edge computing, wireless communications and data analytics to improve the overall driving experience, influencing factors such as safety, reliability, comfort, response and economic efficiency. Our focus in this paper is to identify and highlight open challenges to achieve a secure and efficient convergence between the constrained IoT devices and the high-performance capabilities offered by the clouds. Therein, we present a context-aware content sharing scenario for VANETs and identify specific requirements for its achievement. We also conduct a comparative study of simulation software for edge computing paradigm to identify their strengths and weaknesses, especially within the context of VANETs. We use FogNetSim++ to simulate diverse settings within VANETs with respect to latency and data rate highlighting challenges and opportunities for future research.},
	journal = {null},
	author = {Farooqui, M. Najmul Islam and Khan, Muhammad Mubashir and Arshad, Junaid and Arshad, Junaid and Shafiq, Omair and Shafiq, Omair},
	year = {2020},
	pmid = {null},
	note = {tex.mag\_id: 3093586003
tex.pmcid: null},
	file = {Farooqui et al_2020_An empirical investigation of performance challenges within context‐aware.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/FMHMZSPW/Farooqui et al_2020_An empirical investigation of performance challenges within context‐aware.pdf:application/pdf;Farooqui et al_2020_An empirical investigation of performance challenges within context‐aware.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/WPIK5Z2C/Farooqui et al_2020_An empirical investigation of performance challenges within context‐aware.pdf:application/pdf},
}

@article{qayyum_multi-level_2021,
	title = {Multi-level resource sharing framework using collaborative fog environment for smart cities},
	doi = {10.1109/access.2021.3054420},
	abstract = {null},
	journal = {IEEE access : practical innovations, open solutions},
	author = {Qayyum, Tariq and Trabelsi, Zouheir and Malik, Asad Waqar and Hayawi, Kadhim and Hayawi, Kadhim},
	year = {2021},
	pmid = {null},
	note = {tex.mag\_id: 3121787164
tex.pmcid: null},
	file = {Qayyum et al_2021_Multi-level resource sharing framework using collaborative fog environment for.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/4QSEM8B5/Qayyum et al_2021_Multi-level resource sharing framework using collaborative fog environment for.pdf:application/pdf},
}

@article{Forti_2021,
	title = {Osmotic management of distributed complex systems: {A} declarative decentralised approach},
	doi = {10.1002/smr.2405},
	abstract = {null},
	journal = {Journal of Software: Evolution and Process},
	author = {Forti, Stefano and Lera, Isaac and Guerrero, Carlos and Brogi, Antonio},
	year = {2021},
	pmid = {null},
	note = {tex.mag\_id: 3211876637
tex.pmcid: null},
	file = {Forti et al_2021_Osmotic management of distributed complex systems.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/62XLXHJN/Forti et al_2021_Osmotic management of distributed complex systems.pdf:application/pdf},
}

@article{forti_simulating_2020,
	title = {Simulating {FogDirector} application management},
	doi = {10.1016/j.simpat.2019.102021},
	abstract = {Abstract Achieving a correct and effective management of Fog computing applications is a non-trivial task to accomplish, which includes considering specific application requirements as well as dynamic infrastructure characteristics. CISCO FogDirector is a tool that can be used to manage the entire life-cycle of IoT applications over Fog infrastructures by relying on a RESTful API. In this paper, we present a prototype simulation environment, FogDirSim , compliant with FogDirector API. FogDirSim permits comparing different application management policies according to a set of well-defined performance indicators (viz., uptime, energy consumption, resource usage, type of alerts) and by considering probabilistic variations of the applications workload and failures of the underlying infrastructure. A lifelike example is used to validate the prototype and to show its usefulness in selecting the best management policy.},
	journal = {Simulation Modelling Practice and Theory},
	author = {Forti, Stefano and Pagiaro, Alessandro and Brogi, Antonio and Brogi, Antonio},
	year = {2020},
	pmid = {null},
	note = {tex.mag\_id: 2987943387
tex.pmcid: null},
	file = {Forti et al_2020_Simulating FogDirector application management.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/NH2JRJUG/Forti et al_2020_Simulating FogDirector application management.pdf:application/pdf},
}

@article{luo_anomaly_2019,
	title = {Anomaly detection based latency-aware energy consumption optimization for {IoT} data-flow services.},
	doi = {10.3390/s20010122},
	abstract = {The continuous data-flow application in the IoT integrates the functions of fog, edge, and cloud computing. Its typical paradigm is the E-Health system. Like other IoT applications, the energy consumption optimization of IoT devices in continuous data-flow applications is a challenging problem. Since the anomalous nodes in the network will cause the increase of energy consumption, it is necessary to make continuous data flows bypass these nodes as much as possible. At present, the existing research work related to the performance of continuous data-flow is often optimized from system architecture design and deployment. In this paper, a mathematical programming method is proposed for the first time to optimize the runtime performance of continuous data flow applications. A lightweight anomaly detection method is proposed to evaluate the reliability of nodes. Then the node reliability is input into the optimization algorithm to estimate the task latency. The latency-aware energy consumption optimization for continuous data-flow is modeled as a mixed integer nonlinear programming problem. A block coordinate descend-based max-flow algorithm is proposed to solve this problem. Based on the real-life datasets, the numerical simulation is carried out. The simulation results show that the proposed strategy has better performance than the benchmark strategy.},
	journal = {Sensors},
	author = {Luo, Yuansheng and Luo, Yuansheng and Luo, Yuansheng and Li, Wenjia and Li, Wenjia and Qiu, Shi},
	year = {2019},
	pmid = {31878140},
	note = {tex.mag\_id: 2998254466
tex.pmcid: 6983123},
	file = {Luo et al_2019_Anomaly detection based latency-aware energy consumption optimization for IoT.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/L5BK75U2/Luo et al_2019_Anomaly detection based latency-aware energy consumption optimization for IoT.pdf:application/pdf},
}

@article{hasenburg_mockfog_2020,
	title = {{MockFog} 2.0: {Automated} execution of fog application experiments in the cloud.},
	doi = {null},
	abstract = {Fog computing is an emerging computing paradigm that uses processing and storage capabilities located at the edge, in the cloud, and possibly in between. Testing and benchmarking fog applications, however, is hard since runtime infrastructure will typically be in use or may not exist, yet. In this paper, we propose an approach that emulates such infrastructure in the cloud. Developers can freely design emulated fog infrastructure, configure performance characteristics, manage application components, and orchestrate their experiments. We also present our proof-of-concept implementation MockFog 2.0. We use MockFog 2.0 to evaluate a fog-based smart factory application and showcase how its features can be used to study the impact of infrastructure changes and workload variations.},
	journal = {arXiv: Distributed, Parallel, and Cluster Computing},
	author = {Hasenburg, Jonathan and Grambow, Martin and Bermbach, David},
	year = {2020},
	pmid = {null},
	note = {tex.mag\_id: 3088526311
tex.pmcid: null},
}

@article{Al-Tarawneh_2021,
	title = {Bi-objective optimization of application placement in fog computing environments},
	doi = {10.1007/s12652-021-02910-w},
	abstract = {Fog computing has been recently introduced to complement the cloud computing paradigm and offer application services at the edge of the network. The heterogeneity of fog computational nodes makes application placement in fog infrastructures a challenging task that requires proper management in order to satisfy application requirements. This paper proposes a bi-objective application placement algorithm for fog computing environments. The proposed algorithm seeks to optimally place application modules on the underlying fog devices considering applications criticality levels and security requirements. The placement problem has been formulated as a bi-objective knapsack problem and solved using the non-dominated sorting genetic algorithm II (NSGA-II). It has been implemented using a specialized fog computing simulation tool and compared against existing placement algorithms. Simulation results demonstrate the ability of the proposed algorithm to optimize application placement in fog computing environments in terms of application performance, power efficiency and security satisfaction rates.},
	journal = {Journal of Ambient Intelligence and Humanized Computing},
	author = {Al-Tarawneh, Mutaz},
	year = {2021},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3130489378
tex.pmcid: null},
	file = {Al-Tarawneh - 2021 - Bi-objective optimization of application placement:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/SYT8Q72Q/Al-Tarawneh - 2021 - Bi-objective optimization of application placement.pdf:application/pdf;Bi-objective optimization of application placement in fog computing environments:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/HJ6WR2FP/al-tarawneh2021.pdf.pdf:application/pdf},
}

@article{Almurshed_2021,
	title = {Greedy {Nominator} {Heuristic}: {Virtual} function placement on fog resources},
	doi = {10.1002/cpe.6765},
	abstract = {Fog computing is an intermediate infrastructure between edge devices (e.g., Internet of Things) and cloud systems that is used to reduce latency in real‐time applications. An application can be composed of a collection of virtual functions, between which dependency constraints can be captured in a service function chain (SFC). Virtual functions within an SFC can be executed at different geo‐distributed locations. However, virtual functions are prone to failure and often do not complete within a deadline. This results in function reallocation to other nodes within the infrastructure; causing delays, potential data loss during function migration, and increased costs. We proposed Greedy Nominator Heuristic (GNH) to address these issues. GNH is based on redundant deployment and failure tracking of virtual functions. GNH places replicas of each function at multiple locations—taking account of expected completion time, failure risk, and cost. We make use of a MapReduce‐based mechanism, where Mappers find suitable locations in parallel, and a Reducer then ranks these locations. Our results show that GNH reduces latency by up to 68\%, and is more cost effective than other approaches which rely on state‐of‐the‐art optimization algorithms to allocate replicas.},
	journal = {Concurrency and Computation: Practice and Experience},
	author = {Almurshed, Osama and Rana, Omer and Chard, Kyle},
	year = {2021},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 4200123991
tex.pmcid: null},
}

@article{Arif_2020,
	title = {A model-driven framework for optimum application placement in fog computing using a machine learning based approach},
	doi = {10.1007/978-3-030-59506-7_9},
	abstract = {The pervasiveness of ubiquitously connected smart devices are the main factors in shaping the computing. With the advent of Internet of things (IoTs), massive amount of data is being generated from different sources. The centralized architecture of cloud has become inefficient for the services provision to IoT enabled applications. For better support and services, fog layer is introduced in order to manage the IoT applications demands like latency, responsiveness, deadlines, resource availability and access time etc. of the fog nodes. However, there are some issues related to resource management and fog nodes allocation to the requesting application based on user expectations in the fog layer that need to be addressed. In this paper, we have proposed a Framework, based on Model Driven Software Engineering (MDSE) that practices Machine Learning algorithms and places fog enabled IoT applications at a most suitable fog node. MDSE is meant to develop software by exploiting the problem at domain model level. It is the abstract representation of knowledge that enhances productivity by maximization of compatibility between the systems. The proposed framework is a meta-model that prioritizes the placement requests of applications based on their required expectations and calculates the abilities of the fog nodes for different application placement requests. Rules based machine learning methods are used to create rules based on user’s requirements metrics and then results are optimized to get requesting device placement in the fog layer. At the end, a case study is conducted that uses fuzzy logic for application mapping and shows how the actual application placement will be done by the framework. The proposed meta-model reduces complexity and provides flexibility to make further enhancements according to the user’s requirement to use any of the Machine Learning approaches.},
	journal = {ICIST},
	author = {Arif, Madeha and Arif, Madeha and Arif, Madeha and Azam, Farooque and Anwar, Muhammad Waseem and Anwar, Muhammad Waseem and Rasheed, Yawar},
	year = {2020},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3092594860
tex.pmcid: null},
}

@article{Ayoubi_2020,
	title = {An autonomous {IoT} service placement methodology in fog computing},
	doi = {10.1002/spe.2939},
	abstract = {With the increase in the number of Internet of Things (IoT) devices having limited resources, an extension of the cloud‐computing paradigm has emerged so‐called fog computing, where all the fog cells are located at the edge of the network and the latency can be reduced. Meanwhile, an important challenge has attracted much attention with the definition of fog computing is service placement problem that is still at its very beginning research. It allows to deployment IoT applications on computational fog resources, with the objective of optimizing quality of service (QoS) requirements of applications while taking into account maximizing the utilization of fog resources. In this paper, an autonomous IoT service placement methodology including four phases of monitoring, analysis, decision‐making, and execution is proposed called as (MADE). First, the available resources and application services' status are monitored at run time. Next, the requested services are prioritized with respect to application services' deadline. Then, the Strength Pareto Evolutionary Algorithm II is applied to take decisions about the application services placement as a multi‐objective optimization problem. Finally, the decisions made in the previous phases are executed in a fog environment. The experiment results indicate that the proposed methodology outperforms its counterparts in terms of different performance metrics.},
	journal = {Software - Practice and Experience},
	author = {Ayoubi, Masoumeh and Ramezanpour, Mohammadreza and Khorsand, Reihaneh},
	year = {2020},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3111723528
tex.pmcid: null},
	file = {Ayoubi et al_2020_An autonomous IoT service placement methodology in fog computing.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/MW66GZ5Q/Ayoubi et al_2020_An autonomous IoT service placement methodology in fog computing.pdf:application/pdf},
}

@article{Baranwal_2020,
	title = {{QoE} aware {IoT} application placement in fog computing using modified-topsis},
	doi = {10.1007/s11036-020-01563-x},
	abstract = {Over the years, fog computing has emerged as a paradigm to complement the cloud computing in handling the delay sensitive IoT applications in a better manner. Using fog resources, better performance such as in-time service delivery, reduced network load, optimal energy usage etc. can be achieved. With such performance gain, users availing the IoT services are more satisfied. A well-known metric Quality of Experience (QoE), used to measure the satisfaction of IoT users, can be improved by enhancing the performance of the IoT applications. Fog computing is a geographically distributed paradigm and primary service of fog computing may not include the execution of offloaded tasks/applications from the IoT devices. This makes QoE aware placement of applications in fog computing a greater challenge. Since placement algorithm is itself a computational task and both IoT applications and fog nodes need a mediator fog node to execute the placement algorithm, the placement policy should be light weighted in terms of computational complexity. This work proposes a lightweight QoE aware application placement policy in fog computing using Modified TOPSIS that prioritizes the applications and fog instances based on their expectation and computational capability respectively for the placement. Modified TOPSIS inherits all the features of classical TOPSIS while it removes rank reversal problem of classical TOPSIS. Simulation experiments, for a comparative study, depict that the proposed model not only achieves the desired resource utilization, processing time, and reduced network congestion but reduces the application placement time also significantly compared to the state of art.},
	journal = {Mobile Networks and Applications},
	author = {Baranwal, Gaurav and Yadav, Ravi P. and Vidyarthi, Deo Prakash},
	year = {2020},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3047230478
tex.pmcid: null},
	file = {Baranwal et al_2020_QoE aware IoT application placement in fog computing using modified-topsis.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/F4BB4XA5/Baranwal et al_2020_QoE aware IoT application placement in fog computing using modified-topsis.pdf:application/pdf},
}

@article{Baranwal_2021,
	title = {{FONS}: {A} fog orchestrator node selection model to improve application placement in fog computing},
	doi = {10.1007/s11227-021-03702-x},
	abstract = {Fog computing not only executes applications in the vicinity of the IoT devices/users but also keeps transient data which removes the need for data transfer to the cloud on regular basis. For applications’ placement, an orchestrator considers the requirement of the application and the current fog status to place the application on suitable fog nodes. The orchestrator itself may be placed on fog or cloud nodes. In a centralized approach, a fixed entity that works as an orchestrator is prone to single point failure, less mobility support, etc. Therefore, the literature advises for a decentralized approach in which a nearby fog node is selected to act as an orchestrator. Poor selection of Fog Orchestrator Nodes (FONs) may result in the performance degradation of the system. None of the earlier work proposed the selection of FON for the placement of the applications on the fog nodes. Towards this, a brief but latest survey of the works, to understand the FON selection problem, is done along with the importance of decentralized approach in the FON selection problem. Further, few performance metrics have been identified which helps in the FON selection. A lightweight FON Selection model (FONS) is proposed so that even the least powerful IoT devices can select a FON. The proposed work is validated by incorporating the FON selection algorithm in one state of art to observe a remarkable improvement in application placement.},
	journal = {The Journal of Supercomputing},
	author = {Baranwal, Gaurav and Vidyarthi, Deo Prakash},
	year = {2021},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3133873763
tex.pmcid: null},
	file = {Baranwal_Vidyarthi_2021_FONS.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/WT3FSPHW/Baranwal_Vidyarthi_2021_FONS.pdf:application/pdf},
}

@article{Baranwal_2022,
	title = {{TRAPPY}: {A} truthfulness and reliability aware application placement policy in fog computing},
	doi = {10.1007/s11227-021-04187-4},
	abstract = {Fog computing facilitates the satisfaction of Internet of things (IoT) users by running time-sensitive offloaded applications. Heterogeneity, dynamism, and the growing number of computational devices in fog computing make reliability a challenge because failure is inevitable in such an environment. This work replicates an application on more than one fog node to ensure required reliability. But fog nodes may not offer the services free of cost. Therefore, to meet reliability requirement, IoT user has to pay more. Further, since fog owners may be autonomous, rational, and intelligent, they may hide the true cost of their fog resources. Therefore, the truthfulness of fog owners also becomes an important challenge. To address increased payment by IoT users and to ensure reliability and the truthfulness of fog owners, this work formulates the application placement problem considering the computational and reliability requirement of the IoT devices/users to minimize total payment. It is proved that the formulated problem is NP-hard. For a sub-optimal solution in polynomial time, this work proposes a greedy-based truthfulness and reliability-aware application placement policy (TRAPPY). The proposed work is simulated and compared with state-of-art work, and it is observed that the proposed work outperforms the state-of-art work.},
	journal = {The Journal of Supercomputing},
	author = {Baranwal, Gaurav and Vidyarthi, Deo Prakash},
	year = {2022},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 4206121398
tex.pmcid: null},
}

@article{Benamer_2018,
	title = {Latency-aware placement heuristic in fog computing environment},
	doi = {10.1007/978-3-030-02671-4_14},
	abstract = {With the rise of IoT applications popularity, a new paradigm has emerged so-called Fog Computing. To facilitate their deployment on fog nodes, IoT applications are decomposed into a set of modules. These modules interact with each other in order to achieve a global goal. Placing these modules without a prior strategy may affect the overall performance of the application. Moreover, the restricted capacity of the fog nodes vis-a-vis the modules’ requirements arises the problem of placement. In this paper, we focus on minimizing the overall latency of the application while placing modules on fog nodes. In order to address the module placement problem, we propose both exact and approximate solutions. Experiments were conducted using CPLEX and iFogSim-simulated Fog environment respectively. The results show the effectiveness of our final approach.},
	journal = {OTM Conferences},
	author = {Benamer, Amira Rayane and Teyeb, Hana and Hadj-Alouane, Nejib Ben},
	year = {2018},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2896469856
tex.pmcid: null},
	file = {Benamer et al_2018_Latency-aware placement heuristic in fog computing environment.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/S84WIBWF/Benamer et al_2018_Latency-aware placement heuristic in fog computing environment.pdf:application/pdf},
}

@article{Benamer_2020,
	title = {Online games servers placement in fog computing: {An} hybrid bio-inspired approach},
	doi = {10.1109/lcnsymposium50271.2020.9363254},
	abstract = {Fog computing is a promising paradigm to enable online games at the rim of the network, especially for First Person Shooter games with a restrict deadline. In this context, server placement is a fundamental issue. The latter concerns where game services providers should place their servers in order to meet players expectations in terms of quality of experience while maximizing their profit. In this paper, we investigate the server placement problem, at the fog landscape, to minimize the allocation cost and the potential penalty in terms of resources due to the limited fog capacity and deadline violation. We formulate this problem as an integer nonlinear programming. As the latter is time consuming, we propose an hybrid bio-inspired heuristic composed of Grouping Genetic Algorithm and Particle Swarm Optimization. Performance results demonstrate that our proposal can generate solutions at reduced time with a gap to optimal less than 5\%.},
	journal = {2020 IEEE 45th LCN Symposium on Emerging Topics in Networking (LCN Symposium)},
	author = {Benamer, Amira Rayane and Hadj-Alouane, Nejib Ben and Boussetta, Khaled and Boussetta, Khaled},
	year = {2020},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3134663324
tex.pmcid: null},
	file = {Benamer et al_2020_Online games servers placement in fog computing.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/ZFH6R673/Benamer et al_2020_Online games servers placement in fog computing.pdf:application/pdf},
}

@article{Bermbach_2021,
	title = {{AuctionWhisk}: {Using} an {Auction}‐inspired approach for function placement in serverless fog platforms},
	doi = {10.1002/spe.3058},
	abstract = {The Function-as-a-Service (FaaS) paradigm has a lot of potential as a computing model for fog environments comprising both cloud and edge nodes, as compute requests can be scheduled across the entire fog continuum in a fine-grained manner. When the request rate exceeds capacity limits at the resource-constrained edge, some functions need to be offloaded towards the cloud. In this paper, we present an auction-inspired approach in which application developers bid on resources while fog nodes decide locally which functions to execute and which to offload in order to maximize revenue. Unlike many current approaches to function placement in the fog, our approach can work in an online and decentralized manner. We also present our proof-of-concept prototype AuctionWhisk that illustrates how such an approach can be implemented in a real FaaS platform. Through a number of simulation runs and system experiments, we show that revenue for overloaded nodes can be maximized without dropping function requests.},
	journal = {Software - Practice and Experience},
	author = {Bermbach, David and Bader, Jonathan and Hasenburg, Jonathan and Pfandzelter, Tobias and Thamsen, Lauritz},
	year = {2021},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 4200313769
tex.pmcid: null},
	file = {Bermbach et al_2021_AuctionWhisk.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/REQ6FTLM/Bermbach et al_2021_AuctionWhisk.pdf:application/pdf},
}

@article{bourhim_inter-container_2019,
	title = {Inter-container communication aware container placement in fog computing},
	doi = {10.23919/cnsm46954.2019.9012671},
	abstract = {In recent years, fog computing has increasingly become popular with the advent of Internet of Things (IoT) applications characterized by strict Quality of Service (QoS) requirements. To deploy applications, applications are typically decomposed into services then embedded with fog nodes. However, an overlooked aspect in container placement strategies is the heterogeneous inter-container network communication technologies and their impact on application performances in fog networks. We propose and evaluate in this paper, a near optimal genetic algorithm based container placement strategy that takes into account Remote Direct Memory Access as well host and overlay mode for inter-container communication to ensure application response time requirements.},
	journal = {2019 15th International Conference on Network and Service Management (CNSM)},
	author = {Bourhim, El Houssine and Elbiaze, Halima and Dieye, Mouhamad},
	year = {2019},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3009609784
tex.pmcid: null},
	keywords = {Fog computing, container placement, Genetic algorithms, Inter-container communication, RDMA, Service chaining},
	file = {Bourhim et al_2019_Inter-container communication aware container placement in fog computing.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/YH4DTQPU/Bourhim et al_2019_Inter-container communication aware container placement in fog computing.pdf:application/pdf},
}

@article{Chaudhary_2020,
	title = {Governor: {Operator} placement for a unified fog-cloud environment.},
	doi = {10.5441/002/edbt.2020.81},
	abstract = {The processing of geo-distributed data streams is a key challenge for many Internet of Things (IoT) applications. Cloud-based SPEs process data centrally and thus require all data to be present in the cloud before processing. However, this centralized approach becomes a bottleneck for processing data from millions of geodistributed sensors on a large scale IoT infrastructure. A new line of research extends the centralized cloud with decentralized fog devices to mitigate this bottleneck. One major challenge for an SPE in this unified fog-cloud environment is to fulfill user requirements by placing operators on fog or cloud nodes. In this demonstration, we introduce Governor, an operator placement approach for a unified fog-cloud environment. Our approach consists of the Governor placement process and Governor policies (GPs). The Governor placement process utilizes heuristicbased GPs to optimize operator placement for a user query. Using GPs, administrators can control the operator placement process to fulfill specific Service-Level-Agreement (SLA). We implement Governor in the NebulaStream Platform (NES), a data and application management system for the IoT. We showcase the impact of GPs on operator placement for different example queries. Our demonstration invites participants to simulate the operator placement of queries and discover their characteristics. This demonstration represents a first step towards an efficient operator placement approach for upcoming IoT infrastructures with millions of sensors and thousands of queries.},
	journal = {EDBT},
	author = {Chaudhary, Ankit and Zeuch, Steffen and Markl, Volker},
	year = {2020},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3013992681
tex.pmcid: null},
	file = {Chaudhary et al_2020_Governor.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/UL7Y7EFU/Chaudhary et al_2020_Governor.pdf:application/pdf},
}

@article{Djemai_2021,
	title = {Investigating mobility-aware strategies for {IoT} services placement in the fog under energy and {QoS} constraints},
	doi = {10.24138/jcomss-2020-0024},
	abstract = {Mobility of Internet of Things (IoT) objects is a key characteristic of IoT environments. It brings dynamicity, uncertainty and raises many challenges when it is associated with computation and network resources management for IoT applications. The resources management problem under objects mobility consideration is even more sensitive if we consider that various IoT applications have stringent Quality of Service (QoS) needs. Fog Computing is a distributed computation paradigm that increases data centers computation and storage abilities with nodes between end-users and the Cloud. Fog computing offers a large distributed infrastructure to support IoT applications needs by bringing services closer to end users. However, Fog infrastructures inherit the energy greediness characteristics of both data centers and network infrastructures. This work investigates the IoT services placement problem in the Fog as an optimization problem to minimize energy consumption and enhance QoS while considering mobility of IoT objects. We model the placement problem as a multi-objective optimization problem and we propose a location history based mobility model (HTM) to estimate future locations of IoT mobile nodes. We propose a framework composed of online strategies for IoT services placement and a Mobility-aware Genetic Algorithm (MGA) for services migrations. We evaluate our strategies through iFogSim simulator and compare the proposed framework to migrations and placement strategies from the literature based on Shortest Access Point migration strategy (SAP) and with Penguins Search Optimization Algorithm (PeSOA). Experiments show that the proposed framework outperforms literature approaches for the considered objectives and for various configurations of the mobile environment.},
	journal = {Journal of communications software and systems},
	author = {Djemai, Tanissia and Stolf, Patricia and Monteil, Thierry and Pierson, Jean-Marc},
	year = {2021},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3156330219
tex.pmcid: null},
	file = {Djemai et al_2021_Investigating mobility-aware strategies for IoT services placement in the fog.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/4WH4CBD6/Djemai et al_2021_Investigating mobility-aware strategies for IoT services placement in the fog.pdf:application/pdf},
}

@article{Gao_2021,
	title = {History-aware online cache placement in fog-assisted {IoT} systems: {An} integration of learning and control},
	doi = {10.1109/jiot.2021.3072115},
	abstract = {In Fog-assisted IoT systems, it is a common practice to cache popular content at the network edge to achieve high quality of service. Due to uncertainties in practice such as unknown file popularities, cache placement scheme design is still an open problem with unresolved challenges: 1) how to maintain time-averaged storage costs under budgets, 2) how to incorporate online learning to aid cache placement to minimize performance loss (a.k.a. regret), and 3) how to exploit offline historical information to further reduce regret. In this paper, we formulate the cache placement problem with unknown file popularities as a constrained combinatorial multi-armed bandit (CMAB) problem. To solve the problem, we employ virtual queue techniques to manage time-averaged storage cost constraints, and adopt history-aware bandit learning methods to integrate offline historical information into the online learning procedure to handle the exploration-exploitation tradeoff. With an effective combination of online control and history-aware online learning, we devise a Cache Placement scheme with History-aware Bandit Learning called CPHBL. Our theoretical analysis and simulations show that CPHBL achieves a sublinear time-averaged regret bound. Moreover, the simulation results verify CPHBL’s advantage over the deep reinforcement learning based approach.},
	journal = {IEEE Internet of Things Journal},
	author = {Gao, Xin and Huang, Xi and Huang, Xi and Tang, Yinxu and Shao, Ziyu and Yang, Yang and Yang, Yang},
	year = {2021},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3153000374
tex.pmcid: null},
	file = {Gao et al_2021_History-aware online cache placement in fog-assisted IoT systems.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/WTJXEEPV/Gao et al_2021_History-aware online cache placement in fog-assisted IoT systems.pdf:application/pdf},
}

@article{Gavaber_2020,
	title = {{MFP}: {An} approach to delay and energy-efficient module placement in {IoT} applications based on multi-fog},
	doi = {10.1007/s12652-020-02525-7},
	abstract = {One of the challenges of using fog computing in IoT systems is the efficient placement of resources in IoT applications. This paper presents a resource placement method for fog-based IoT systems to reduce their latency and energy consumption. Given the limited processing power of fog nodes, only a limited number of modules can be run on these nodes. In fog-cloud systems, placing the modules on fog nodes instead of the cloud layer can be expected to reduce system latency. Therefore, to achieve enhanced latency and energy consumption, this paper introduces a multi-zone fog layer architecture where each zone is a multi-fog. The core idea of the proposal is to use the idle processing capacity of fog nodes in each zone through the maximal placement of modules on these nodes. The paper also presents an algorithm called MFP for carrying out this placement. To evaluate the proposed algorithm, it was simulated in iFogSim for two scenarios with different topologies. The simulation results showed that the proposed scheme offers 16.81\% lower latency and 17.75\% lower energy consumption than the existing schemes.},
	journal = {Journal of Ambient Intelligence and Humanized Computing},
	author = {Gavaber, Morteza Dadashi and Rajabzadeh, Amir},
	year = {2020},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3084855602
tex.pmcid: null},
	file = {Gavaber_Rajabzadeh_2020_MFP.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/AESNW98J/Gavaber_Rajabzadeh_2020_MFP.pdf:application/pdf},
}

@article{Goudarzi_2021,
	title = {A distributed deep reinforcement learning technique for application placement in edge and fog computing environments},
	doi = {10.1109/tmc.2021.3123165},
	abstract = {Fog/Edge computing is a novel computing paradigm supporting resource-constrained Internet of Things (IoT) devices by the placement of their tasks on the edge and/or cloud servers. Recently, several Deep Reinforcement Learning (DRL)-based placement techniques have been proposed in fog/edge computing environments, which are only suitable for centralized setups. The training of well-performed DRL agents requires manifold training data while obtaining training data is costly. Hence, these centralized DRL-based techniques lack generalizability and quick adaptability, thus failing to efficiently tackle application placement problems. Moreover, many IoT applications are modeled as Directed Acyclic Graphs (DAGs) with diverse topologies. Satisfying dependencies of DAG-based IoT applications incur additional constraints and increase the complexity of placement problems. To overcome these challenges, we propose an actor-critic-based distributed application placement technique, working based on the IMPortance weighted Actor-Learner Architectures (IMPALA). IMPALA is known for efficient distributed experience trajectory generation that significantly reduces the exploration costs of agents. Besides, it uses an adaptive off-policy correction method for faster convergence to optimal solutions. Our technique uses recurrent layers to capture temporal behaviors of input data and a replay buffer to improve the sample efficiency. The performance results, obtained from simulation and testbed experiments, demonstrate that our technique significantly improves the execution cost of IoT applications up to 30\% compared to its counterparts.},
	journal = {IEEE Transactions on Mobile Computing},
	author = {Goudarzi, Mohammad and Palaniswami, Marimuthu and Buyya, Rajkumar},
	year = {2021},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3208229128
tex.pmcid: null},
	file = {Goudarzi et al_2021_A distributed deep reinforcement learning technique for application placement.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/S8FAQ3HX/Goudarzi et al_2021_A distributed deep reinforcement learning technique for application placement.pdf:application/pdf},
}

@article{Gowri_2021,
	title = {Comprehensive analysis of resource allocation and service placement in fog and cloud computing},
	doi = {10.14569/ijacsa.2021.0120308},
	abstract = {The voluminous data produced and consumed by digitalization, need resources that offer compute, storage, and communication facility. To withstand such demands, Cloud and Fog computing architectures are the viable solutions, due to their utility kind and accessibility nature. The success of any computing architecture depends on how efficiently its resources are allocated to the service requests. Among the existing survey articles on Cloud and Fog, issues like scalability and time-critical requirements of the Internet of Things (IoT) are rarely focused on. The proliferation of IoT leads to energy crises too. The proposed survey is aimed to build a Resource Allocation and Service Placement (RASP) strategy that addresses these issues. The survey recommends techniques like Reinforcement Learning (RL) and Energy Efficient Computing (EEC) in Fog and Cloud to escalate the efficacy of RASP. While RL meets the time-critical requirements of IoT with high scalability, EEC empowers RASP by saving cost and energy. As most of the early works are carried out using reactive policy, it paves the way to build RASP solutions using alternate policies. The findings of the survey help the researchers, to focus their attention on the research gaps and devise a robust RASP strategy in Fog and Cloud environment.},
	journal = {International Journal of Advanced Computer Science and Applications},
	author = {Gowri, A. S. and Bala, P. Shanthi and Ramdinthara, Immanuel Zion},
	year = {2021},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3149178227
tex.pmcid: null},
	file = {Gowri et al_2021_Comprehensive analysis of resource allocation and service placement in fog and.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/ELM9262K/Gowri et al_2021_Comprehensive analysis of resource allocation and service placement in fog and.pdf:application/pdf},
}

@article{Guerrero_2019,
	title = {Optimization policy for file replica placement in fog domains},
	doi = {10.1002/cpe.5343},
	abstract = {Fog computing architectures distribute computational and storage resources along the continuum from the cloud to things. Therefore, the execution of services or the storage of files can be closer to the users. The main objectives of fog computing domains are to reduce the user latency and the network usage. Availability is also an issue in fog architectures because the topology of the network does not guarantee redundant links between devices. Consequently, the definition of placement polices is a key challenge. We propose a placement policy for data replication to increase data availability that contrasts with other storage policies that only consider a single replica of the files. The system is modeled with complex weighted networks and topological features, such as centrality indices. Graph partition algorithms are evaluated to select the fog devices that store data replicas. Our approach is compared with two other placement policies: one that stores only one replica and FogStore, which also stores file replicas but uses a greedy approach (the shortest path). We analyze 22 experiments with simulations. The results show that our approach obtains the shortest latency times, mainly for writing operations, a smaller network usage increase, and a similar file availability to FogStore.},
	journal = {Concurrency and Computation: Practice and Experience},
	author = {Guerrero, Carlos and Guerrero, Carlos and Lera, Isaac and Juiz, Carlos},
	year = {2019},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2945505693
tex.pmcid: null},
	file = {Guerrero et al_2019_Optimization policy for file replica placement in fog domains.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/K2W832B9/Guerrero et al_2019_Optimization policy for file replica placement in fog domains.pdf:application/pdf},
}

@article{Happ_2020,
	title = {On the impact of clustering for {IoT} analytics and message broker placement across cloud and edge},
	doi = {10.1145/3378679.3394538},
	abstract = {With edge computing emerging as a promising solution to cope with the challenges of Internet of Things (IoT) systems, there is an increasing need to automate the deployment of large-scale applications along with the publish/subscribe brokers they communicate over. Such a placement must adjust to the resource requirements of both applications and brokers in the heterogeneous environment of edge, fog, and cloud. In contrast to prior work focusing only on the placement of applications, this paper addresses the problem of jointly placing IoT applications and the pub/sub brokers on a set of network nodes, considering an application provider who aims at minimizing total end-to-end delays of all its subscribers. More specifically, we devise two heuristics for joint deployment of brokers and applications and analyze their performance in comparison to the current cloud-based IoT solutions wherein both the IoT applications and the brokers are located solely in the cloud. As an application provider should consider not only the location of the application users but also how they are distributed across different network components, we use von Mises distributions to model the degree of clustering of the users of an IoT application. Our simulations show that superior performance of our heuristics in comparison to cloud-based IoT operation is most pronounced under a high degree of clustering. When users of an IoT application are in close network proximity of the IoT sensors, cloud-based IoT unnecessarily introduces latency to move the data from the edge to the cloud and vice versa while processing could be performed at the edge or the fog layers.},
	journal = {EdgeSys@EuroSys},
	author = {Happ, Daniel and Bayhan, Suzan and Bayhan, Suzan},
	year = {2020},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3027707203
tex.pmcid: null},
	file = {Happ et al_2020_On the impact of clustering for IoT analytics and message broker placement.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/Y4RMSP4W/Happ et al_2020_On the impact of clustering for IoT analytics and message broker placement.pdf:application/pdf},
}

@article{Hu_2018,
	title = {Inline wireless mobile sensors and fog nodes placement for leakage detection in water distribution systems},
	doi = {10.1002/spe.2631},
	abstract = {Burst or leakage in drinkable water distribution system has occurred frequently in recent years, causing severe damages, economic loss, and long‐lasting society impact. A viable solution is to use agile inline mobile sensors to detect and so as to mitigate the burst or leakage. Distinguishing from online fixed sensors, mobile sensors can swim freely along the piles in water distribution network, thus giving a more precise detection. To combat the low power, low computation, and low communication capability of mobile sensors, the newly emerged fog computing provides a promising means to gather and preprocess the sensing data. In practice, due to the budget limitation, we can deploy a limited number of sensors and fog nodes in the system. This introduces a challenging problem on how to deploy them in the system, ie, sensor and fog node placement. We first formulate mobile sensor placement (MSP) as a path cover problem and prove it as NP‐complete, and then we propose a customized genetic algorithm and a mixed greedy algorithm to solve MSP and fog node placement, respectively. The correctness and efficiency of the proposed algorithm are illustrated by a comprehensive experiment. Moreover, some critical factors, eg, sensor battery lifetime and movement pattern, are all extensively investigated and the results show the coverage ratio is sensitive to these factors.},
	journal = {Software - Practice and Experience},
	author = {Hu, Chengyu and Shu, Xin and Yan, Xuesong and Zeng, Deze and Gong, Wenyin and Wang, Lei},
	year = {2018},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2888485109
tex.pmcid: null},
	file = {Hu et al_2018_Inline wireless mobile sensors and fog nodes placement for leakage detection in.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/TP5YVGFT/Hu et al_2018_Inline wireless mobile sensors and fog nodes placement for leakage detection in.pdf:application/pdf},
}

@article{Huang_2019,
	title = {A latency-aware multiple data replicas placement strategy for fog computing},
	doi = {10.1007/s11265-019-1444-5},
	abstract = {With the rapid increase of the number of IoT devices, transmitting big amount of data from these devices to data centers which are far away will cause problems like high latency or network congestions. Fog Computing provides a better solution for Fog-enabled latency sensitive data services to place data on Fog nodes which are closer to the data generators. However, recent studies only focus on the data placement problem of placing one single data replica to the proper Fog node. Under the situation that there are several data consumers whose topology positions are different subscribing the same data, one single data replica cannot meet the latency requirement of all the consumers. Hence, we build a multi-replica data placement model iFogStorM for Fog Computing to formulate the problem of how many data replicas need to be placed on Fog nodes and how to optimize the data placement. Furthermore, we propose a greedy algorithm based data replica placement strategy, MultiCopyStorage, to reduce the overall latency. MultiCopyStorage uses a pruning method to filter the inferior solutions calculates the overall latency and chooses the solution with the minimum overall latency as the final solution. We conducted experiments on iFogSim, a toolkit for modeling and simulation of Fog Computing, evaluated the proposed strategy with the CloudStorage strategy, Closest Node strategy, iFogStor strategy, and two kinds of heuristic strategy, iFogStorZ, and iFogStorG. The experiment result demonstrates that MultiCopyStorage strategy reduces the overall latency by 6\% and 10\% compared to iFogStor and iFogStorG strategy respectively. Meanwhile, execution time of the MultiCopyStorage is less than the heuristic strategy, iFogStorG and iFogStorZ, which proves that the proposed strategy can support real-time scheduling.},
	journal = {Journal of Signal Processing Systems},
	author = {Huang, Tiansheng and Lin, Weiwei and Lin, Weiwei and Li, Yin and Li, Yin and He, LiGang and He, Ligang and Peng, ShaoLiang and Peng, Shaoliang},
	year = {2019},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2917992310
tex.pmcid: null},
	file = {Huang et al_2019_A latency-aware multiple data replicas placement strategy for fog computing.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/D7U6JYU7/Huang et al_2019_A latency-aware multiple data replicas placement strategy for fog computing.pdf:application/pdf},
}

@article{Khosroabadi_2021,
	title = {{SCATTER}: {Service} placement in real-time fog-assisted {IoT} networks},
	doi = {10.3390/jsan10020026},
	abstract = {Internet of Things (IoT) networks dependent on cloud services usually fail in supporting real-time applications as there is no response time guarantees. The fog computing paradigm has been used to alleviate this problem by executing tasks at the edge of the network, where it is possible to provide time bounds. One of the challenging topics in a fog-assisted architecture is to task placement on edge devices in order to obtain a good performance. The process of task mapping into computational devices is known as Service Placement Problem (SPP). In this paper, we present a heuristic algorithm to solve SPP, dubbed as clustering of fog devices and requirement-sensitive service first (SCATTER). We provide simulations using iFogSim toolkit and experimental evaluations using real hardware to verify the feasibility of the SCATTER algorithm by considering a smart home application. We compared the SCATTER with two existing works: edge-ward and cloud-only approaches, in terms of Quality of Service (QoS) metrics. Our experimental results have demonstrated that SCATTER approach has better performance compared with the edge-ward and cloud-only, 42.1\% and 60.2\% less application response times, 22\% and 27.8\% less network usage, 45\% and 65.7\% less average application loop delays, and 2.33\% and 3.2\% less energy consumption.},
	journal = {Journal of Sensor and Actuator Networks},
	author = {Khosroabadi, Fariba and Fotouhi-Ghazvini, Faranak and Fotouhi-Ghazvini, Faranak and Fotouhi-Ghazvini, Faranak and Fotouhi-Ghazvini, Faranak and Fotouhi, Hossein and Fotouhi, Hossein and Fotouhi, Hossein},
	year = {2021},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3146568941
tex.pmcid: null},
	file = {Khosroabadi et al_2021_SCATTER.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/55HQ5NAC/Khosroabadi et al_2021_SCATTER.pdf:application/pdf},
}

@article{Kochovski_2019,
	title = {An architecture and stochastic method for database container placement in the edge-fog-cloud continuum},
	doi = {10.1109/ipdps.2019.00050},
	abstract = {Databases as software components may be used to serve a variety of smart applications. Currently, the Internet of Things (IoT), Artificial Intelligence (AI) and Cloud technologies are used in the course of projects such as the Horizon 2020 EU-Korea DECENTER project in order to implement four smart applications in the domains of Smart Homes, Smart Cities, Smart Construction and Robot Logistics. In these smart applications the Big Data pipeline starts from various sensor and video streams to which AI and feature extraction methods are applied. The resulting information is stored in database containers, which have to be placed on Edge, Fog or Cloud infrastructures. The placement decision depends on complex application requirements, including Quality of Service (QoS) requirements. Information that must be considered when making placement decisions includes the expected workload, the list of candidate infrastructures, geolocation, connectivity and similar. Software engineers currently perform such decisions manually, which usually leads to QoS threshold violations. This paper aims to automate the process of making such decisions. Therefore, the goals of this paper are to: (1) develop a decision making method for database container placement; (2) formally verify each placement decision and provide probability assurances to the software engineer for high QoS; and (3) design and implement a new architecture that automates the whole process. A new optimisation method is introduced, which is based on the theory and practice of stochastic Markov Decision Processes (MDP). It uses as input monitoring data from the container runtime, the expected workload and user-related metrics in order to automatically construct a probabilistic finite automaton. The generated automaton is used for both automated decision making and placement success verification. The method is implemented in Java. It also uses the PRISM model-checking tool. Kubernetes is used in order to automate the whole process when orchestrating database containers across Edge, Fog and Cloud infrastructures. Experiments are performed for NoSQL Cassandra database containers for three representative workloads of 50000 (workload 1), 200000 (workload 2) and 500000 (workload 3) CRUD database operations. Five computing infrastructures serve as candidates for database container placement. The new MDP-based method is compared with the widely used Analytic Hierarchy Process (AHP) method. The obtained results are used to analyse container placement decisions. When using the new MDP based method there were no QoS violations in any of the placement cases, while when using the AHP based method the placement results in some QoS threshold violations in all workload cases. Due to its properties, the new MDP method is particularly suitable for implementation. The paper also describes a multi-tier distributed computing system that uses multi-level (infrastructure, container, application) monitoring metrics and Kubernetes in order to orchestrate database containers across Edge, Fog and Cloud nodes. This architecture demonstrates fully automated decision making and high QoS container operation.},
	journal = {2019 IEEE International Parallel and Distributed Processing Symposium (IPDPS)},
	author = {Kochovski, Petar and Sakellariou, Rizos and Bajec, Marko and Drobintsev, Pavel and Stankovski, Vlado},
	year = {2019},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2971697724
tex.pmcid: null},
	file = {Kochovski et al_2019_An architecture and stochastic method for database container placement in the.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/QLA73IDW/Kochovski et al_2019_An architecture and stochastic method for database container placement in the.pdf:application/pdf},
}

@article{Krichen_2019,
	title = {Towards optimizing the placement of security testing components for internet of things architectures},
	doi = {10.1109/aiccsa47632.2019.9035301},
	abstract = {In this article we are interested in optimizing the placement problem of security testing components for Internet of Things Architectures. Our goal is to extend existing techniques used in Fog computing to distribute application components over computational nodes. For that purpose, we identify several types of constraints, objectives functions and algorithms that can be adopted.},
	journal = {2019 IEEE/ACS 16th International Conference on Computer Systems and Applications (AICCSA)},
	author = {Krichen, Moez and Alroobaea, Roobaea},
	year = {2019},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3011357511
tex.pmcid: null},
	file = {Krichen_Alroobaea_2019_Towards optimizing the placement of security testing components for internet of.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/XXND5U4L/Krichen_Alroobaea_2019_Towards optimizing the placement of security testing components for internet of.pdf:application/pdf},
}

@article{Krzyszton_2020,
	title = {Simulation of watchdog placement for cooperative anomaly detection in {Bluetooth} {Mesh} {Intrusion} {Detection} {System}},
	doi = {10.1016/j.simpat.2019.102041},
	abstract = {Abstract Cyber-attacks on the Internet of Things (IoT) are growing at an alarming rate as IoT technologies are literally connecting everything into networks. In 2020 more than 25\% of identified attacks in enterprises will involve the IoT. Hence, it is very important to treat IoT security as a mandatory design factor. Moreover the deployed IoT system should be continuously monitored to detect malicious behaviour such as packet dropping, worm propagation or jammer attacks. In the paper we propose the anomaly based Intrusion Detection System dedicated to Bluetooth Mesh networks. The machine learning algorithm is used to classify traffic and detect malicious behaviour in IoT networks. The proposed solution involve cooperative decision making which is done by multiple watchdogs distributed in different regions of the considered network – which are responsible for processing of mostly local traffic. The optimal placement of watchdogs is proposed based on simulations done by BMWatchSim software. The experimental results coming from our testbed confirm that the watchdog placement proposed by simulator allow on effective detection of real-world intrusions.},
	journal = {Simulation Modelling Practice and Theory},
	author = {Krzyszton, Mateusz and Marks, Michal},
	year = {2020},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2995173428
tex.pmcid: null},
	file = {Krzyszton_Marks_2020_Simulation of watchdog placement for cooperative anomaly detection in Bluetooth.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/6S6A7Q4Y/Krzyszton_Marks_2020_Simulation of watchdog placement for cooperative anomaly detection in Bluetooth.pdf:application/pdf},
}

@article{Lähderanta_2020,
	title = {Edge computing server placement with capacitated location allocation},
	doi = {10.1016/j.jpdc.2021.03.007},
	abstract = {The deployment of edge computing infrastructure requires a careful placement of the edge servers. The aim is to improve application latencies and reduce data transfer load in the opportunistic Internet of Things systems. Practical limitations are faced in the available deployment budget, capacity and hardware requirements of the edge servers and the underlying backbone network topology. In this paper, we survey the existing literature in edge server placement and identify gaps and an extensive set of parameters to be considered. Then, we develop a novel algorithm, called PACK, for server placement as a capacitated location-allocation problem. PACK minimizes the distances between servers and their associated access points, while taking into account capacity constraints for load balancing and enabling workload sharing between servers. Moreover, PACK allows consideration of practical issues, including prioritized locations and reliability concerns. The algorithm is evaluated in two distinct scenarios, with high capacity servers for edge computing in general and low capacity servers for Fog computing. In the evaluation, we utilize a data set collected in a real-world network, consisting of both dense and sparse deployments of access points across a city area. Lastly, PACK is published as an open source software.},
	journal = {arXiv: Networking and Internet Architecture},
	author = {Lähderanta, Tero and Leppänen, Teemu and Ruha, Leena and Lovén, Lauri and Harjula, Erkki and Ylianttila, Mika and Riekki, Jukka and Sillanpää, Mikko J.},
	year = {2020},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3013299604
tex.pmcid: null},
	file = {Lähderanta et al_2020_Edge computing server placement with capacitated location allocation.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/PLVRYZR9/Lähderanta et al_2020_Edge computing server placement with capacitated location allocation.pdf:application/pdf},
}

@article{Lahmar_2020,
	title = {Resource allocation in fog computing: {A} systematic mapping study},
	doi = {10.1109/fmec49853.2020.9144705},
	abstract = {The Cloud computing has already proven its worth to manage the computational-intensive tasks of IoT applications. Despite its popularity, Cloud is not recommended for latency-critical applications due to the high latency added by network connections to datacenters and excessive dataflow that may congest the network. Towards this challenge, Fog computing was introduced to extend the computational capabilities of the Cloud computing and to improve the quality of service (QoS) of such latency-critical applications. Compared to Cloud datacenters, the Fog devices are highly dynamic and heterogeneous. One of the key challenging in running IoT application in Fog environment, is the resource allocation issue. This paper aims to review recent work related to resource allocation in Fog environment by applying a systematic mapping study methodology for a comprehensive overview on what has been investigated on resource allocation and what are the open issues to be addressed in the future.},
	journal = {2020 Fifth International Conference on Fog and Mobile Edge Computing (FMEC)},
	author = {Lahmar, Imen and Boukadi, Khouloud},
	year = {2020},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3045454491
tex.pmcid: null},
	file = {Lahmar_Boukadi_2020_Resource allocation in fog computing.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/W3IDRNC5/Lahmar_Boukadi_2020_Resource allocation in fog computing.pdf:application/pdf},
}

@article{Lera_2018,
	title = {Comparing centrality indices for network usage optimization of data placement policies in fog devices},
	doi = {10.1109/fmec.2018.8364053},
	abstract = {This paper presents an optimization policy for data placement in fog architectures to reduce the network usage. The proposal is based on modeling the devices (sensors, gateways, fog devices and the cloud provider) through complex weighted networks using the hop count between the fog devices and the data sources (sensors). Centrality indices are evaluated to select the fog devices that store the data generated by the sensors of the same type. The experiments were conducted to evaluate the improvements obtained with 3 centrality indices (eigenvector, betweenness centrality, and current flow) and four different types of network topologies (Barabasi-Albert, Grid, Random Euclidean, and Lobster). The results were validated by comparing between the network usage obtained with our placement proposal and the case of storing all the data in the cloud provider. Important benefits were measured in the case of the eigenvector centrality, reducing the number of transmitted packets to only the 31.84\% of packets that are transmitted when the data is placed in the cloud provider. The other two centrality indices showed worst results.},
	journal = {2018 Third International Conference on Fog and Mobile Edge Computing (FMEC)},
	author = {Lera, Isaac and Guerrero, Carlos and Guerrero, Carlos and Juiz, Carlos},
	year = {2018},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2806040473
tex.pmcid: null},
	file = {Lera et al_2018_Comparing centrality indices for network usage optimization of data placement.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/FH42WZHD/Lera et al_2018_Comparing centrality indices for network usage optimization of data placement.pdf:application/pdf},
}

@article{Liu_2022,
	title = {Solving the multi-objective problem of {IoT} service placement in fog computing using cuckoo search algorithm},
	doi = {10.1007/s11063-021-10708-2},
	abstract = {null},
	journal = {Neural Processing Letters},
	author = {Liu, Chang and Wang, Jin and Zhou, Liang and Rezaeipanah, Amin},
	year = {2022},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 4206935088
tex.pmcid: null},
	file = {Liu et al_2022_Solving the multi-objective problem of IoT service placement in fog computing.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/9VSE8BRM/Liu et al_2022_Solving the multi-objective problem of IoT service placement in fog computing.pdf:application/pdf},
}

@article{Majd_2016,
	title = {Placement of smart mobile access points in wireless sensor networks and cyber-physical systems using fog computing},
	doi = {10.1109/uic-atc-scalcom-cbdcom-iop-smartworld.2016.0112},
	abstract = {Increasingly sophisticated, complex,, energy-efficient cyber-physical systems, wireless sensor networks are emerging, facilitated by recent advances in computing, sensor technologies. Integration of cyber-physical systems, wireless sensor networks with other contemporary technologies, such as unmanned aerial vehicles, fog or edge computing, enable creation of completely new smart solutions. We present the concept of a Smart Mobile Access Point (SMAP), which is a key building block for a smart network,, propose an efficient placement approach for such SMAPs. SMAPs predict the behavior of the network, based on information collected from the network,, select the best approach to support the network at any given time. When needed, they autonomously change their positions to obtain a better configuration from the network performance perspective. Therefore, placement of SMAPs is an important issue in such a system. Initial placement of SMAPs is an NP problem,, evolutionary algorithms provide an efficient means to solve it. Specifically, we present a parallel implementation of the imperialistic competitive algorithm, an efficient evaluation or fitness function to solve the initial placement of SMAPs in the fog computing context.},
	journal = {2016 Intl IEEE Conferences on Ubiquitous Intelligence \& Computing, Advanced and Trusted Computing, Scalable Computing and Communications, Cloud and Big Data Computing, Internet of People, and Smart World Congress (UIC/ATC/ScalCom/CBDCom/IoP/SmartWorld)},
	author = {Majd, Amin and Sahebi, Golnaz and Daneshtalab, Masoud and Plosila, Juha and Tenhunen, Hannu and Tenhunen, Hannu},
	year = {2016},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2576567757
tex.pmcid: null},
	file = {Majd et al_2016_Placement of smart mobile access points in wireless sensor networks and.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/7372YTRA/Majd et al_2016_Placement of smart mobile access points in wireless sensor networks and.pdf:application/pdf},
}

@article{Manihar_2021,
	title = {Learning based task placement algorithm in the {IoT} fog-cloud environment},
	doi = {10.22247/ijcna/2021/209987},
	abstract = {Task scheduling means allocating resources to the tasks in such a way that processing can be accomplished in the most optimal way possible. Here the optimal strategy means processing all the tasks in such a way that it incur the least delay, hence the least response time can be achieved by all the tasks. This becomes a major concern when dealing with the Fog computing environment. Fog have limitations on storage capacity and processing power. So all the real time applications cannot be scheduled at the Fog environment. Also it is required to allocate these resources in the most optimal way possible. So it is best suggested to schedule latency critical applications on the fog and other applications to the cloud. This paper proposes a learning based task placement algorithm (LBTP) which used supervised feed forward neural network to recognize the latency critical applications. This algorithm executes in two phases. In the first phase, the features of the tasks serve as the input to this machine learning based framework for decision making regarding whether to schedule task at the fog environment or forward it to the cloud for execution. In the second phase if the tasks scheduled at fog, then tasks are rearranged in the fog queue based on the priority to achieve the most optimal resource utilization. The simulation results were evaluated using the Matlab 8.0 and Aneka 5.0 platform. The results revealed that the proposed method LBTP recorded the best response time, waiting time and resource utilization when compared with the task scheduling at the fog only and task scheduling at the Cloud only environment. LBTP also recorded better results on horizontal scaling by raising the number of virtual machines at the fog environment.},
	journal = {International Journal of Computer Networks and Applications},
	author = {Manihar, Shifa and Patel, Ravindra and Patel, Ravindra and Agrawal, Sanjay},
	year = {2021},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3208940336
tex.pmcid: null},
	file = {Manihar et al_2021_Learning based task placement algorithm in the IoT fog-cloud environment.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/MELLVSW4/Manihar et al_2021_Learning based task placement algorithm in the IoT fog-cloud environment.pdf:application/pdf},
}

@article{Mann_2020,
	title = {Secure software placement and configuration},
	doi = {10.1016/j.future.2020.03.064},
	abstract = {Abstract Finding the best way to place the components of an application on a set of heterogeneous servers is a challenging task, especially if some components are associated with security requirements. To address security requirements, several security controls may be available, some of them software-based (e.g., encryption), others hardware-based (e.g., trusted execution environments). Security controls may incur widely varying performance overhead. There is a non-trivial interplay between application placement (which component to place on which server) and the configuration of security controls (which security control to activate for which component). On the one hand, placing a component on a secure server may make it unnecessary to use software-based security controls for the component. On the other hand, the overhead of using a specific security control may increase the resource requirements of a component so that it does not fit onto its designated server. Therefore, this paper addresses the joint problem of application placement and configuration of security controls. We formalize the problem and use mixed integer quadratic programming to solve it. A case study is used to demonstrate that the proposed approach can automatically determine the placement and configuration of complex applications.},
	journal = {Future Generation Computer Systems},
	author = {Mann, Zoltán Ádám},
	year = {2020},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3015943424
tex.pmcid: null},
	file = {Mann_2020_Secure software placement and configuration.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/T9PL69WU/Mann_2020_Secure software placement and configuration.pdf:application/pdf},
}

@article{Mann_2022,
	title = {Security- and privacy-aware {IoT} application placement and user assignment},
	doi = {10.1007/978-3-030-95484-0_18},
	abstract = {Applications for the Internet of Things (IoT) may use, beyond the IoT devices themselves, also edge and cloud resources. Thus, the modules of an application can be placed on a variety of nodes with different capabilities in terms of security, trustworthiness, and capacity. Application modules may exist in multiple instances. This makes it possible to assign users to the most appropriate module instances, taking into account requirements on security, privacy, and latency. There is a non-trivial interplay between application placement decisions and user assignment decisions. For example, if a certain user is assigned to a module, then that module may not be allowed to be placed on nodes not trusted by the user. However, most existing research neglects this interplay and its implications on security and privacy. In this paper, we address the joint problem of application placement and user assignment. Beside capacity and latency constraints, we consider several types of security and privacy constraints: (i) module-level location constraints, (ii) user-level location constraints, (iii) co-location constraints, and (iv) k-anonymity constraints. We formalize the problem and develop an algorithm to solve it using quadratically constrained mixed integer programming. We demonstrate the applicability of the proposed approach by applying it to an IoT system in the smart home domain. Controlled experiments on problem instances of increasing size show that the algorithm can solve even large problem instances in acceptable time.},
	journal = {Lecture Notes in Computer Science},
	author = {Mann, Zoltán Ádám},
	year = {2022},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 4210911122
tex.pmcid: null},
}

@article{Mann_2022,
	title = {Decentralized application placement in fog computing},
	doi = {10.1109/tpds.2022.3148985},
	abstract = {In recent years, cloud computing concepts have been extended towards the network edge, leading to paradigms like edge computing and fog computing. As a result, applications can be placed on a variety of resources, including fog nodes and cloud data centers. Application placement has significant impact on important metrics like latency. Finding an optimal application placement is computationally challenging, particularly because of the potentially huge number of infrastructure nodes and application components. To overcome the limited scalability of application placement algorithms, optimization can be decentralized, i.e., performed separately for different parts of the infrastructure. The infrastructure can be split into fog colonies, where a fog colony consists of the computational resources in a given geographical region. Application placement can then be performed for the individual fog colonies, thus mitigating the scalability problem. However, independent optimization of application placement in different fog colonies may lead to missed synergies and thus to sub-optimal overall results. Hence, some kind of coordination between fog colonies may be beneficial. In this paper, we analyze the effects of decentralization and coordination on the optimization results. In particular, we compare empirically four different approaches: (i) centralized decision-making, where decisions are made in one go for the entire infrastructure, (ii) independent fog colonies, where optimization is carried out in each fog colony independently from each other, (iii) fog colonies with communication, where excess application components in one fog colony can be sent to a neighboring fog colony, and (iv) fog colonies with overlaps, where shared resources may be dynamically distributed between neighboring fog colonies. Our experiments show that, for large problem instances, decentralization combined with coordination leads to the best results.},
	journal = {IEEE Transactions on Parallel and Distributed Systems},
	author = {Mann, Zoltan Adam},
	year = {2022},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 4210913893
tex.pmcid: null},
	file = {Mann_2022_Decentralized application placement in fog computing.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/IWVCZT2B/Mann_2022_Decentralized application placement in fog computing.pdf:application/pdf},
}

@article{Manogaran_2021,
	title = {An efficient resource allocation scheme with optimal node placement in {IoT}-{Fog}-{Cloud} architecture},
	doi = {10.1109/jsen.2021.3057224},
	abstract = {Internet of Everything (IoE) encompasses smart devices, users, applications, and services through the internet with digital features. Fog Computing is a recent emergent that bridges the gap between cloud and Internet of Things (IoT) devices to provide services at the network edge. Communication and deployment of fog nodes in a network rely on the type of application and service request. With the prominent features exhibited by the fog nodes, this manuscript proposes an Efficient Resource Allocation (RA) with Optimal Node Placement (ONP) for delay-controlled communications in the IoE environment. Resource allocation is facilitated by defining a profit function that must be achieved for controlling resource exploitation. The deployment of less density fog nodes will adhere to the available resources and aids service reliability by increasing seamlessness in communication. The nodes’ dual-feature is utilized at resource allocation, such that communication delays and cost less. IoE terminals and fog nodes’ advantages are assimilated to ensure appropriate non-delay tolerant seamless service provided to the encompassed user from the desired platform or infrastructure. The idea of administering fog nodes based on their behavior ensures less complex service provisioning and ease of access.},
	journal = {IEEE Sensors Journal},
	author = {Manogaran, Gunasekaran and Manogaran, Gunasekaran and Rawal, Bharat S.},
	year = {2021},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3158666330
tex.pmcid: null},
	file = {Manogaran et al_2021_An efficient resource allocation scheme with optimal node placement in.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/6QQTM7QH/Manogaran et al_2021_An efficient resource allocation scheme with optimal node placement in.pdf:application/pdf},
}

@article{Mehran_2019,
	title = {{MAPO}: {A} multi-objective model for {IoT} application placement in a fog environment},
	doi = {10.1145/3365871.3365892},
	abstract = {The emergence of the Fog computing paradigm that leverages in-network virtualized resources raises important challenges in terms of resource and IoT application management in a heterogeneous environment offering only limited computing resources. In this work, we propose a novel Pareto-based approach for application placement close to the data sources called Multiobjective IoT application Placement in fOg (MAPO). MAPO models applications based on a finite state machine and uses three conflicting optimization objectives, namely completion time, energy consumption, and economic cost, considering both the computation and communication aspects. In contrast to existing solutions that optimize a single objective value, MAPO enables multi-objective energy and cost-aware application placement. To evaluate the quality of the MAPO placements, we created both simulated and real-world testbeds tailored for a set of medical IoT application case studies. Compared to the state-of-the-art approaches, MAPO reduces the economic cost by up to 27\%, while decreasing the energy requirements by 23-68\%, and optimizes the completion time by up to 7.3 times.},
	journal = {arXiv: Distributed, Parallel, and Cluster Computing},
	author = {Mehran, Narges and Kimovski, Dragi and Prodan, Radu and Prodan, Radu},
	year = {2019},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2966141488
tex.pmcid: null},
	file = {Mehran et al_2019_MAPO.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/ZQNM8HYB/Mehran et al_2019_MAPO.pdf:application/pdf},
}

@article{Mehta_2018,
	title = {Distributed cost-optimized placement for latency-critical applications in heterogeneous environments},
	doi = {10.1109/icac.2018.00022},
	abstract = {Mobile Edge Clouds (MECs) with 5G will create new opportunities to develop latency-critical applications in domains such as intelligent transportation systems, process automation, and smart grids. However, it is not clear how one can cost-efficiently deploy and manage a large number of such applications given the heterogeneity of devices, application performance requirements, and workloads. This work explores cost and performance dynamics for IoT applications, and proposes distributed algorithms for automatic deployment of IoT applications in heterogeneous environments. Placement algorithms were evaluated with respect to metrics including number of required runtimes, applications' slowdown, and the number of iterations used to place an application. Iterative search-based distributed algorithms such as Size Interval Actor Assignment in Groups (SIAA$_{\textrm{G}}$) outperformed random and bin packing algorithms, and are therefore recommended for this purpose. Size Interval Actor Assignment in Groups at Least Utilized Runtime (SIAA$_{\textrm{GL}}$UR) algorithm is also recommended when minimizing the number of iterations is important. The tradeoff of using SIAA$_{\textrm{G}}$ algorithms is a few extra runtimes compared to bin packing algorithms.},
	journal = {2018 IEEE International Conference on Autonomic Computing (ICAC)},
	author = {Mehta, Amardeep and Elmroth, Erik},
	year = {2018},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2897959904
tex.pmcid: null},
	file = {Mehta_Elmroth_2018_Distributed cost-optimized placement for latency-critical applications in.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/XPK4L5GS/Mehta_Elmroth_2018_Distributed cost-optimized placement for latency-critical applications in.pdf:application/pdf},
}

@article{Minh_2017,
	title = {Toward service placement on {Fog} computing landscape},
	doi = {10.1109/nafosted.2017.8108080},
	abstract = {This paper proposes an approach to optimize service placement on Fog landscape in the context of the Internet of Things (IoT). A multi-tier fog computing architecture that supports IoT service provision is devised. Based on this architecture, a novel service placement mechanism that optimizes service decentralization on Fog landscape leveraging context-aware information such as location, time, quality of services (QoS) has been proposed. An experiment has been conducted to evaluate the proposed approach with several simulations applying to smart grid applications. The results reveal the effectiveness of the proposed approach in terms of reducing latency, energy consumption, and network load in comparison with the conventional cloud computing model.},
	journal = {2017 4th NAFOSTED Conference on Information and Computer Science},
	author = {Minh, Quang Tran and Nguyen, Duy Tai and Le, An Van and Nguyen, Hai Duc and Truong, Anh and Truong, Anh and Truong, Anh},
	year = {2017},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2770896011
tex.pmcid: null},
	file = {Minh et al_2017_Toward service placement on Fog computing landscape.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/YJSV8AC3/Minh et al_2017_Toward service placement on Fog computing landscape.pdf:application/pdf},
}

@article{moallemi_evolutionary-based_2019,
	title = {An evolutionary-based algorithm for smart-living applications placement in fog networks},
	doi = {10.1109/gcwkshps45667.2019.9024660},
	abstract = {Fog computing is an emerging model, complementing the cloud computing platform, introduced to support the Internet of Things (IoT) processing requests at the edge of the network. Smart-living IoT scenarios require the execution of multiple processing tasks at the edge of the network and leveraging on the Fog Computing approach results to be a worthwhile solution. Genetic Algorithms (GA) are a heuristic search and optimization class of techniques inspired by natural evolution. We propose two GA-based approaches for optimizing the processing task placement in a fog computing edge infrastructure aiming to support the Smart-living IoT nodes requests. The numerical results obtained in Matlab show that both GA-based approaches allow to maximize the covered areas while minimizing the resource wastage through the minimization of the overlapping areas.},
	journal = {2019 IEEE Globecom Workshops (GC Wkshps)},
	author = {Moallemi, Raheleh and Bozorgchenani, Arash and Tarchi, Daniele},
	year = {2019},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3007712194
tex.pmcid: null},
	file = {Moallemi et al_2019_An evolutionary-based algorithm for smart-living applications placement in fog.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/Q5NYHQJH/Moallemi et al_2019_An evolutionary-based algorithm for smart-living applications placement in fog.pdf:application/pdf;PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/6S6D5XRF/09024660.pdf:application/pdf},
}

@article{mouradian_application_2019,
	title = {Application component placement in {NFV}-{Based} hybrid {Cloud}/{Fog} systems with mobile fog nodes},
	doi = {10.1109/jsac.2019.2906790},
	abstract = {Fog computing reduces the latency induced by distant clouds by enabling the deployment of some application components at the edge of the network, on fog nodes, while keeping others in the cloud. Application components can be implemented as Virtual Network Functions (VNFs) and their execution sequences can be modeled by a combination of sub-structures like sequence, parallel, selection, and loops. Efficient placement algorithms are required to map the application components onto the infrastructure nodes. Current solutions do not consider the mobility of fog nodes, a phenomenon which may happen in real systems. In this paper, we use the random waypoint mobility model for fog nodes to calculate the expected makespan and application execution cost. We then model the problem as an Integer Linear Programming (ILP) formulation which minimizes an aggregated weighted function of the makespan and cost. We propose a Tabu Search-based Component Placement (TSCP) algorithm to find sub-optimal placements. The results show that the proposed algorithm improves the makespan and the application execution cost.},
	journal = {IEEE Journal on Selected Areas in Communications},
	author = {Mouradian, Carla and Kianpisheh, Somayeh and Abu-Lebdeh, Mohammad and Ebrahimnezhad, Fereshteh and Jahromi, Narjes Tahghigh and Glitho, Roch},
	year = {2019},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2951507749
tex.pmcid: null},
	file = {Mouradian et al_2019_Application component placement in NFV-Based hybrid Cloud-Fog systems with.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/G96Q3FB9/Mouradian et al_2019_Application component placement in NFV-Based hybrid Cloud-Fog systems with.pdf:application/pdf},
}

@article{Odun-Ayo_2019,
	title = {A systematic mapping study of cloud, fog, and {Edge}/{Mobile} devices management, hierarchy models and business models},
	doi = {10.25046/aj040212},
	abstract = {Cloud computing is an exceptional paradigm, which is facilitating the developments and utilization of resources over the internet. Fog computing operates at the edge of the network saving bandwidth, by not sending all information to the cloud, while edge computing does processing of data at the edge of the cloud. Edge computing reduces the distance data must travel on the network. The unique relationship between cloud, fog and edge computing makes research in these areas mandatory. Deciding on a specific area of research as regards these subjects could be a bulky procedure for a scientist. Therefore, reviews and paper studies for recognizing potential research gaps are required. A systematic mapping study is utilized in giving a summary of the conducted research in a particular study area. The objective of this paper is to conduct systematic mapping studies on cloud, fog, edge/mobile devices management, hierarchy models and business models. The results showed that publications that discussed process in relations to the field of study is 14.04\% out of the 114 papers included. Also method contributed 24.56\%, model had 42.98\% and tool contributed 18.42\%. Furthermore, evaluation research in terms of the field of study was 27.5\% out of 120 papers included. Also, validation was discussed in 17.5\% of the papers, solution was 32.5\%, philosophical was 5.83\%, experience was 15.83\% and opinion was 0.83\%. The clearly highlighted gaps ought to inspire more enthusiasm for additional research by both researchers and industry practitioners.},
	journal = {Advances in Science, Technology and Engineering Systems Journal},
	author = {Odun-Ayo, Isaac and Goddy-Worlu, Rowland and Geteloma, Victor and Grant, Emanuel S.},
	year = {2019},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2922240219
tex.pmcid: null},
	file = {Odun-Ayo et al_2019_A systematic mapping study of cloud, fog, and Edge-Mobile devices management,.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/JIXFVZHN/Odun-Ayo et al_2019_A systematic mapping study of cloud, fog, and Edge-Mobile devices management,.pdf:application/pdf},
}

@article{Pallewatta_2022,
	title = {{QoS}-aware placement of microservices-based {IoT} applications in {Fog} computing environments},
	doi = {10.1016/j.future.2022.01.012},
	abstract = {The Fog computing paradigm, offering cloud-like services at the edge of the network, has become a feasible model to support computing and storage capabilities required by latency-sensitive and bandwidth-hungry Internet of Things (IoT) applications. As fog devices are distributed, heterogeneous and resource-constrained, efficient application scheduling mechanisms are required to harvest the full potential of such computing environments. Due to the rapid evolution in IoT ecosystems and also to better suit fog environment characteristics, IoT application development has moved from the monolithic architecture towards the microservices architecture that enhances scalability, maintainability and extensibility of the applications. This architecture improves the granularity of service decomposition, thus providing scope for improvement in QoS-aware placement policies. Existing application placement policies lack proper utilisation of these features of microservices architecture, thus failing to produce efficient placements. In this paper, we harvest the characteristics of microservice architecture to propose a scalable QoS-aware application scheduling policy for batch placement of microservices-based IoT applications within fog environments. Our proposed policy, QoS-aware Multi-objective Set-based Particle Swarm Optimisation (QMPSO), aims at maximising the satisfaction of multiple QoS parameters (makespan, budget and throughput) while focusing on the utilisation of limited fog resources. Besides, QMPSO adapts and improves the Set-based Comprehensive Learning Particle Swarm Optimisation (S-CLPSO) algorithm to achieve better convergence in the fog application placement problem. We evaluate our policy in a simulated fog environment. The results show that compared to the state-of-the-art solutions, our placement algorithm significantly improves QoS in terms of makespan satisfaction (up to 35\% improvement) and budget satisfaction (up to 70\% improvement) and ensures optimum usage of computing and network resources, thus providing a robust approach for QoS-aware placement of microservices-based heterogeneous applications within fog environments. • We utilize granularity and scalability provided by the microservice architecture to propose a scalable QoS-aware application scheduling policy for Fog environments. • We formulate the microservice-based fog application placement problem as a Lexicographic Combinatorial Optimisation Problem considering QoS satisfaction (in terms of makespan, budget, and throughput) as the primary objective and optimum resource usage as the secondary objective. • We propose an IoT application batch placement technique based on Set-based Comprehensive Learning Particle Swarm Optimisation (S-CLPSO). To improve the convergence rate, we introduce a heuristic-driven swarm initialisation and fitness parameter normalisation method and further incorporate a priority-based particle construction technique to overcome premature convergence due to the resource constraints of the fog devices. • We implement our policy using iFogSim2 simulated fog environment and compare it against existing scheduling approaches based on their resultant QoS satisfaction and balanced fog and cloud resource usage.},
	journal = {Future Generation Computer Systems},
	author = {Pallewatta, Samodha and Kostakos, Vassilis and Buyya, Rajkumar},
	year = {2022},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 4210354420
tex.pmcid: null},
	file = {Alqahtani 2021.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/IHJRQ2I5/Alqahtani 2021.pdf:application/pdf;Benamer 2021.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/ML3AYG6B/Benamer 2021.pdf:application/pdf;document-1.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/YT6I2XL4/document-1.pdf:text/html;Ghobaei-Arani 2022.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/GXQPBA37/Ghobaei-Arani 2022.pdf:application/pdf;Goethals 2019.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/LXVQ4LAN/Goethals 2019.pdf:application/pdf;Hassan 2020.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/X23G9WCV/Hassan 2020.pdf:application/pdf;Nashaat 2020.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/WAP2I8TU/Nashaat 2020.pdf:application/pdf;Pallewatta et al_2022_QoS-aware placement of microservices-based IoT applications in Fog computing.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/B7UKNTF2/Pallewatta et al_2022_QoS-aware placement of microservices-based IoT applications in Fog computing.pdf:application/pdf;Pallewatta et al_2022_QoS-aware placement of microservices-based IoT applications in Fog computing.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/8KIEYZC2/Pallewatta et al_2022_QoS-aware placement of microservices-based IoT applications in Fog computing.pdf:application/pdf;Salimian 2021.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/94LZMVVD/Salimian 2021.pdf:application/pdf;Zhao 2022.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/26BP3K65/Zhao 2022.pdf:application/pdf},
}

@article{Patro_2021,
	title = {Module placement scheme using {MPC4}.5 with markov chain process for mobile fog computing environment},
	doi = {10.1109/icccis51004.2021.9397232},
	abstract = {Mobile Fog computing (MFC) is an elongation to cloud computing in which the processing is performed near the IoT devices. It reduces latency and energy consumption in the system and the idle choice for healthcare applications, smart cities, etc. In MFC, the mobile devices (MDs) select the best fog device (FD) and offload FDs' task. The submitted applications to the system are divided into modules, and the best FD has been selected for the module using the Module Placement C4.5 (MPC45) algorithm. If the MD's power consumption is more than that the power consumption of Wi-Fi, then only offloading has been performed. There are many factors, such as authenticity, confidentiality, availability, capacity, integrity, cost, and speed are used as the decision parameters for selecting the best FD. In the present research paper, a novel module placement scheme has proposed for optimizing the MPC45 with the Markov chain. The proposed approach is compared with the state of art algorithms in terms of power consumption, performance, and response time, which shows that the proposed method of task offloading is better compared to the other existing ones.},
	journal = {2021 International Conference on Computing, Communication, and Intelligent Systems (ICCCIS)},
	author = {Patro, Rasmita and Patra, Sudhansu Shekhar and Barik, Lalbihari and Prusty, Ajaya Dev and Barik, Rabindra K.},
	year = {2021},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3153174964
tex.pmcid: null},
	file = {Patro et al_2021_Module placement scheme using MPC4.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/MLNIVMMI/Patro et al_2021_Module placement scheme using MPC4.pdf:application/pdf},
}

@article{raghavendra_deedsp_2021,
	title = {{DEEDSP}: {Deadline}‐aware and {Energy}‐efficient dynamic service placement in integrated {Internet} of {Things} and fog computing environments},
	doi = {10.1002/ett.4368},
	abstract = {null},
	author = {Raghavendra, Meeniga Sri and Chawla, Priyanka and Gill, Sukhpal Singh},
	year = {2021},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3203629272
tex.pmcid: null},
}

@article{Rahman_2020,
	title = {Off-street vehicular fog for catering applications in {5G}/{B5G}: {A} trust-based task mapping solution and open research issues},
	doi = {10.1109/access.2020.3004738},
	abstract = {One of the key enablers in serving the applications requiring stringent latency in 5G networks is fog computing as it is situated closer to the end users. With the technological advancement of vehicles’ on-board units, their computing capabilities are becoming robust, and considering the underutilization of the off-street vehicles, we envision that the off-street vehicles can be an enormously useful computational source for the fog computing. Additionally, clustering the vehicles would be advantageous in order to improve the service availability. As the vehicles become highly connected, trust is needed especially in distributed environments. However, vehicles are made from different manufacturers, and have different platforms, security mechanisms, and varying parking duration. These lead to the unpredictable behavior of the vehicles where quantifying trust value of vehicles would be difficult. A trust-based solution is necessary for task mapping as a task has a set of properties including expected time to complete, and trust requirements that need to be met. However, the existing metrics used for trust evaluation in the vehicular fog computing such as velocity and direction are not applicable in the off-street vehicle fog environments. In this paper, we propose a framework for quantifying the trust value of off-street vehicle fog computing facilities in 5G networks and forming logical clusters of vehicles based on the trust values. This allows tasks to be shared with multiple vehicles in the same cluster that meets the tasks’ trust requirements. Further, we propose a novel task mapping algorithm to increase the vehicle resource utilization and meet the desired trust requirements while maintaining imposed latency requirements of 5G applications. Results obtained using iFogSim simulator demonstrate that the proposed solution increases vehicle resource utilization and reduces task drop noticeably. This paper presents open research issues pertaining to the study to lead...},
	journal = {IEEE access : practical innovations, open solutions},
	author = {Rahman, Fatin Hamadah and Newaz, S.H. Shah and Au, Thien Wan and Suhaili, Wida Susanty and Lee, Gyu Myoung},
	year = {2020},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3038075750
tex.pmcid: null},
	file = {Rahman et al_2020_Off-street vehicular fog for catering applications in 5G-B5G.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/J65TB6RN/Rahman et al_2020_Off-street vehicular fog for catering applications in 5G-B5G.pdf:application/pdf},
}

@article{Sahoo_2021,
	title = {Optimal secure placement of {IoT} applications for smart farming},
	doi = {10.1109/iotsms53705.2021.9704936},
	abstract = {Smart farming is a recent innovation in the agriculture sector that can improve agricultural yield by using smarter, automated, and data-driven farm processes that interact with the Internet of Things (IoT) devices deployed on farms. A cloud-fog infrastructure provides an effective platform to execute IoT applications for smart farming. While fog computing satisfies the real-time processing need of delay-sensitive IoT applications by bringing virtualized resources closer to the farm, cloud computing allows the execution of applications with higher computational requirements. The deployment of IoT applications is a critical challenge as cloud and fog nodes vary in terms of their resource availability, security status, and cost models. Moreover, diversity in resources, quality of service (QoS), and security requirements of IoT applications make the problem even more complex. In this paper, we model IoT application placement as an optimization problem that aims at minimizing the resource cost while satisfying the QoS and security constraints. The problem is formulated using Integer Linear Programming (ILP). The ILP model is evaluated for a small-scale scenario. The evaluation shows the impact of QoS and security requirements on the cost. We also study the impact of relaxing security constraints on the placement decision.},
	journal = {2021 8th International Conference on Internet of Things: Systems, Management and Security (IOTSMS)},
	author = {Sahoo, Jagruti},
	year = {2021},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 4210951208
tex.pmcid: null},
	keywords = {notion},
	file = {Sahoo_2021_Optimal secure placement of IoT applications for smart farming.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/S6HJ3G3L/Sahoo_2021_Optimal secure placement of IoT applications for smart farming.pdf:application/pdf},
}

@article{Salah_2021,
	title = {An {IoT}-oriented multiple data replicas placement strategy in hybrid fog-cloud environment},
	doi = {10.1145/3437959.3459251},
	abstract = {The growing adoption of Fog computing for the sensitive-time IoT applications allows to facilitate the real-time actions and to enhance their efficiency and performance. In fact, keeping the data in the distributed Fog network brings the advantages and power of the Cloud closer to where data are generated while saving network bandwidth and reducing latency and operational costs. However, due to the diversity of the Fog nodes, IoT system distribution and data sharing, how and where to place the produced data with low latency is a main challenge. Moreover, a data placement based on a single replica cannot meet the data access requirements of all data consumers that have different topology positions. Thus, in this paper, we propose a multi-objective optimization data placement model in a hybrid Fog-Cloud environment based on multiple data replicas. It aims to find better distributed data storage while optimizing the overall system latency and the used storage space by minimizing the data replicas and following full and partial data replication methods. Further, we propose a greedy algorithm iFogDPₕ which uses a refined method to find a solution for assigning the IoT data to the appropriate data hosts in polynomial time by reducing the time required to transfer data for storage, access and replication. We conducted the experiments on iFogSim, a toolkit for modeling and simulation of Fog environments. The experimental results show the effectiveness of our proposed solution in terms of latency, storage overhead and the number of data replicas compared to the existing strategies.},
	journal = {null},
	author = {Salah, Noura Ben and Saoud, Narjès Bellamine Ben},
	year = {2021},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3164223404
tex.pmcid: null},
	file = {Salah_Saoud_2021_An IoT-oriented multiple data replicas placement strategy in hybrid fog-cloud.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/229TTVA4/Salah_Saoud_2021_An IoT-oriented multiple data replicas placement strategy in hybrid fog-cloud.pdf:application/pdf},
}

@article{Salah_2021,
	title = {{IoT} {Data} {Placement} in the {Fog} infrastructure with mobile devices},
	doi = {10.1109/ccgrid51090.2021.00012},
	abstract = {With the growth of the worldwide number of IoT devices, finding the right placement and storage of the massive created data is a major challenge. In fact, most IoT applications are time-sensitive applications implemented in critical sectors where any delay can hinder their decision-making, operational execution and decrease their performance. Fog Computing is a better solution to reduce latency by storing and processing real-time data locally on the edge network. Efficient placement strategies are required to map data to distributed infrastructure nodes. Current solutions do not consider the mobility of IoT devices which exists in almost all the real systems. In this paper, we use the random waypoint model to shape the mobility of an IoT system. Furthermore, we formulate our data placement using multiple replicas as a multi-objective linear programming problem aimed at minimizing the overall system latency and the number of data replicas. Then, we propose a greedy heuristic algorithm for IoT devices mobility modeling and data assignments in a feasible time. It uses a refined method to filter possible solutions in order to find the final solution with minimum overall latency while fulfilling producer data storage resource requirements and taking into account data sharing between the distributed consumers in Fog infrastructure. We conducted the experiments with iFogSim simulator respecting two data consistency models for data replicas synchronization. The results show that the proposed data placement strategy improves significantly the overall system latency and the number of data replicas to use.},
	journal = {2021 IEEE/ACM 21st International Symposium on Cluster, Cloud and Internet Computing (CCGrid)},
	author = {Salah, Noura Ben and Saoud, Narjès Bellamine Ben},
	year = {2021},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3190446058
tex.pmcid: null},
	file = {Salah_Saoud_2021_IoT Data Placement in the Fog infrastructure with mobile devices.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/AUVPKMR9/Salah_Saoud_2021_IoT Data Placement in the Fog infrastructure with mobile devices.pdf:application/pdf},
}

@article{Salimian_2021,
	title = {Toward an autonomic approach for {Internet} of {Things} service placement using gray wolf optimization in the fog computing environment},
	doi = {10.1002/spe.2986},
	abstract = {Divers and the huge amount of data produced by the Internet of Things (IoT) applications on the one hand, and inherent limitations of local equipment to handle these data, on the other hand, leads to present emerging closer technologies to the end‐users such as fog computing environment. Nevertheless, despite the numerous advantages of such an environment, it still needs state‐of‐the‐art approaches to cope with some inherent limitations. In the literature, resource placement strategies are generally proposed to address such problems, in which the IoT applications are mapped to fog nodes. However, despite its importance, different approaches attempt to enhance the overall system's performance and users' expectations: none of such approaches is satisfactory. In this article, to deploy IoT applications on fog nodes, an autonomic IoT service placement approach based on the gray wolf optimization scheme is proposed, enhancing the system's performance while considering execution costs. Besides, the autonomic concepts help make an appropriate automanagement system that fits better the fog environment's dynamic behavior. Simulation results demonstrate that the proposed approach outperforms the other approaches and converges to the solution in near‐optimal application deployment on fog nodes in respect of the performance of performing services that are 93.7\%, the performance of the average waiting time for performed services that are 100\%, the remaining services sent to an extra provisioned period that is zero.},
	journal = {Software - Practice and Experience},
	author = {Salimian, Mahboubeh and Ghobaei-Arani, Mostafa and Shahidinejad, Ali},
	year = {2021},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3162969011
tex.pmcid: null},
	file = {Salimian et al_2021_Toward an autonomic approach for Internet of Things service placement using.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/ZVTH9ZDV/Salimian et al_2021_Toward an autonomic approach for Internet of Things service placement using.pdf:application/pdf},
}

@article{Santoyo-González_2018,
	title = {Latency-aware cost optimization of the service infrastructure placement in {5G} networks},
	doi = {10.1016/j.jnca.2018.04.007},
	abstract = {Under 5G use case scenarios latency is a main challenge that must be addressed, since mission critical environments are mostly delay sensitive. To achieve this goal, the service infrastructure placement optimization is needed in the interest of minimizing the delays in the service access layer. To solve this problem, this paper mathematically models the placement problem in a Fog Computing/NFV environment as a Mixed-Integer Linear Programming problem and proposes a heuristic-based solution considering 5G mobile network requirements. As a practical result, an application was developed to achieve usability and flexibility while ensuring operational applicability of the proposed methods.},
	journal = {Journal of Network and Computer Applications},
	author = {Santoyo-González, Alejandro and Cervello-Pastor, Cristina},
	year = {2018},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2799996045
tex.pmcid: null},
	file = {Santoyo-González_Cervello-Pastor_2018_Latency-aware cost optimization of the service infrastructure placement in 5G.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/7LXT6A8B/Santoyo-González_Cervello-Pastor_2018_Latency-aware cost optimization of the service infrastructure placement in 5G.pdf:application/pdf},
}

@article{Sarkar_2021,
	title = {Dynamic task placement for deadline-aware {IoT} applications in federated fog networks},
	doi = {10.1109/jiot.2021.3088227},
	abstract = {In the era of the Internet of Things (IoT), fog computing has become an enticing concept for supporting delay-sensitive tasks by offering versatile and convenient computing and communication services to the end-users, in conjunction with cloud services. Most of the existing researches mainly draws attention to the communication delay minimization and completion time reduction in the hierarchical fog networks without giving the priority to select the suitable computing device during failure or resource unavailability of the current computing devices. By motivating the above-mentioned challenges, in this paper, we propose a deadline-aware dynamic task placement (DDTP) strategy to offload and place the tasks to a suitable computing device in fog networks. In this context, we design a new federated fog framework consisting of several fog clusters in which the cluster head, termed as master fog node, acts as a fog controller that controls and manages the data distribution among the other fog nodes, termed as slave fog nodes. The proposed DDTP strategy selects the suitable computing device for each incoming task as per the deadline and ensures to meet the deadline constraints of the tasks using a dynamic task allocation policy. Finally, a dispatch-constrained offloading policy is developed to reassign the failed tasks to the available fog nodes in the network. Comprehensive simulation results depict the efficiency of the proposed strategy over the existing baseline algorithms in terms of various performance matrices.},
	journal = {IEEE Internet of Things Journal},
	author = {Sarkar, Indranil and Adhikari, Mainak and Kumar, Neeraj and Kumar, Sanjay and Kumar, Sanjay and Kumar, Sanjay and Kumar, Sanjay and Kumar, Sanjay and Kumar, Sanjay},
	year = {2021},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3169760573
tex.pmcid: null},
	file = {Sarkar et al_2021_Dynamic task placement for deadline-aware IoT applications in federated fog.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/AXVTDP4J/Sarkar et al_2021_Dynamic task placement for deadline-aware IoT applications in federated fog.pdf:application/pdf},
}

@article{Shahin_2021,
	title = {Fog node optimum placement and configuration technique for {VANETs}},
	doi = {10.1109/iccspa49915.2021.9385710},
	abstract = {Intelligent Transportation Systems (ITS) are nowadays considered very important applications of smart cities. One of the most important technologies that are utilized to support ITS is Vehicular Ad-hoc Networks (VANETs). In VANETs, vehicles communicate with each other (V2V) or with the infrastructure (Roadside Units) (V2I). Roadside Units (RSUs) collect data from vehicles in the coverage area and send it to cloud servers through the Internet. Cloud servers have high performance computational and storage capabilities that ITS applications require for data processing. However, due to the real-time requirements of the ITS applications, cloud approach alone cannot be guaranteed to satisfy the strict time constraints due to long latency access of the centralized cloud server. Fog Computing is an emerging approach that extends the services of cloud computing to the edge of the network. Fog Computing can be utilized in VANETs through deployment of fog nodes into RSUs. One of the major challenges is identifying the optimum number, locations and computational capabilities of the RSUs particularly in urban regions where obstacles exist heavily inside the coverage area of the RSUs. In this paper, we consider the optimization problem of fog-based RSU placement where the objective is to maximize the achieved level of service quality in a cost-effective way. The problem is formulated as a Satisfiability Modulo Theories (SMT) problem and solved using Microsoft Z3. The proposed approach is able to generate a set of solutions as Pareto front. We obtained data from OpenStreetMap for Cairo city. Our approach outperforms other solutions in the literature in terms of cost.},
	journal = {2020 International Conference on Communications, Signal Processing, and their Applications (ICCSPA)},
	author = {Shahin, Rehab and El-Moursy, Ali A. and Saif, Sherif M. and Abbas, Hazem M. and Nassar, Salwa M.},
	year = {2021},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3147881557
tex.pmcid: null},
	file = {Shahin et al_2021_Fog node optimum placement and configuration technique for VANETs.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/LRQ4R7EV/Shahin et al_2021_Fog node optimum placement and configuration technique for VANETs.pdf:application/pdf},
}

@article{Sharma_2021,
	title = {An adaptive service placement framework in fog computing environment},
	doi = {10.1007/978-3-030-81462-5_64},
	abstract = {In the present scenario, the world is poignant towards smart devices, particularly after the Internet of Things (IoT). The IoT devices usually accumulate the data from the sensing environment. It has inhibited the capabilities of computation and storage. This leads to an increase in IoT integration with cloud computing operations. Fog computing is the extension of cloud computing environment and enhances the performance of the cloud. The main concern in fog computing is basically the reliability of the fog nodes that communicates with the various IoT devices and further with the cloud. In this work, we have proposed a fault detection framework with service placement to efficient fog node. This model implements an Adaptive Quality of Service (QoS) conscious technique with the amalgamation of two methods i.e. Checkpoints and Replication(CR) and utilize a novel Bee mutation(BM) algorithm with improved features for best possible service placement to fog node. In the proposed technique, the performance of the fog nodes is monitored using a fog service monitor. We have also evaluated the proposed framework with various metrics for its performance. The proposed framework is also compared with the existing algorithm based framework. The total execution cost and usage of network of the proposed model are about 84023 USD and 618950 Mbps, respectively.},
	journal = {Communications in Computer and Information Science},
	author = {Sharma, Pankaj and Gupta, Pradeep Kumar},
	year = {2021},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3209357073
tex.pmcid: null},
}

@article{Silva_2019,
	title = {An analysis of fog computing data placement algorithms},
	doi = {10.1145/3360774.3368201},
	abstract = {This work evaluates three Fog Computing data placement algorithms via experiments carried out with the iFogSim simulator. The paper describes the three algorithms (Cloud-only, Mapping, Edge-ward) in the context of an Internet of Things scenario, which has been based on an e-Health system with variations in applications and network topology. Results achieved show that edge placement strategies are beneficial to assist cloud computing in lowering latency and cloud energy expenditure.},
	journal = {MobiQuitous},
	author = {da Silva, Daniel Maniglia A. and Asaamoning, Godwin and Orrillo, Hector and Sofia, Rute C. and Mendes, Paulo and Mendes, Paulo and Mendes, Paulo},
	year = {2019},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3005072535
tex.options: useprefix=true
tex.pmcid: null},
	file = {da Silva et al_2019_An analysis of fog computing data placement algorithms.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/ZSQ79RFX/da Silva et al_2019_An analysis of fog computing data placement algorithms.pdf:application/pdf},
}

@article{Subbaraj_2021,
	title = {Performance oriented task-resource mapping and scheduling in fog computing environment},
	doi = {10.1016/j.cogsys.2021.07.004},
	abstract = {Abstract Resource allocation and task scheduling is a complex task in fog computing environment because of the inherent heterogeneity among the fog devices. The proposed work attempts to solve the problem by using the popular multi criteria decision making methods such as AHP and TOPSIS. The goal of this paper is to propose a model for performance oriented task - resource mapping in a fog computing environment. MIPS, RAM \& storage, uplink latency, downlink latency, uplink bandwidth, downlink bandwidth, trust, cost per MIPS, cost per memory, cost per storage and cost per bandwidth are the various performance characteristics considered in this work for task – resource mapping. Two different multi-criteria decision making methods are employed in order to assess the performance characteristics of the fog devices. In the first method, Analytic Hierarchy Process (AHP) is used for both priority weight calculation and ranking of fog devices. In the second method, AHP is used for priority weight calculation, based on the weights yielded by AHP, Technique for Order Preference by Similarity to Ideal Solution (TOPSIS) algorithm is executed in order to rank the fog devices. Then the fog devices can be allocated to the tasks based on its rank. Furthermore, a motivational example is also demonstrated to validate the proposed method. Simulation results show that the proposed technique exhibits superior performance over other scheduling algorithms in the fog environment by incorporating performance, security, and cost metrics into scheduling decisions.},
	journal = {Cognitive Systems Research},
	author = {Subbaraj, Saroja and Thiyagarajan, Revathi},
	year = {2021},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3184835307
tex.pmcid: null},
	file = {Subbaraj_Thiyagarajan_2021_Performance oriented task-resource mapping and scheduling in fog computing.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/SWS35ZVP/Subbaraj_Thiyagarajan_2021_Performance oriented task-resource mapping and scheduling in fog computing.pdf:application/pdf},
}

@article{Taghizadeh_2021,
	title = {A {Metaheuristic}‐based data replica placement approach for {Data}‐intensive {IoT} applications in the fog computing environment},
	doi = {10.1002/spe.3032},
	abstract = {Over the past few years, Internet of Things (IoT) applications have grown rapidly. The data‐intensive IoT applications that take advantage of cloud servers for computations and data storage will result in higher latency and other network traffic in the Internet core. IoT applications are characterized by their sensitivity to latency. As an example, delays will result in irreparable damage in the medical and healthcare industries. Cloud servers are no longer necessary because cloud computing utilizes fog nodes that are closer to users. Nodes with different hardware capabilities pose a significant challenge since they differ significantly in latency and traffic reduction. This article presented a metaheuristic‐based method using the non‐dominated sorting genetic algorithm II for data‐intensive IoT applications in fog infrastructure. Besides, we provide a new automatic method for managing data replica transmissions, including deploying them in a fog cloud environment. The proposed solution was evaluated in the iFogSim simulator and compared with two other data replica placement methods in different scenarios. The results showed a decrease in latency and cost for data access and an increase in data availability.},
	journal = {Software - Practice and Experience},
	author = {Taghizadeh, Jaber and Ghobaei-Arani, Mostafa and Shahidinejad, Ali},
	year = {2021},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3211268622
tex.pmcid: null},
}

@article{Taghizadeh_2021,
	title = {An efficient data replica placement mechanism using biogeography-based optimization technique in the fog computing environment},
	doi = {10.1007/s12652-021-03495-0},
	abstract = {In recent years, the rapid growth of IoT devices has led to an increase significantly the amount of data generated. Transferring a huge amount of datasets from IoT devices to remote cloud servers will result in high latency and bandwidth usage. Fog computing has emerged as an Internet-based distributed computing model to store datasets generated by IoT devices near the user. Since IoT devices generate continuously massive amounts of datasets, placing them on the storage fog nodes with various capabilities to reduce latency and costs of data access and increase reliability and availability of data datasets while satisfying the QoS requirements as one of the challenging tasks to be considered. This paper proposes a metaheuristic-based data replica placement mechanism using biogeography-based optimization (BBO) for data-intensive IoT applications on the fog ecosystem. Besides, we design an autonomous framework to illustrate transferring data replicas between IoT devices and storage fog nodes for data replica placement problem in the fog ecosystem. The obtained simulation results by varying the number of data replicas and fog nodes demonstrate that the proposed mechanism is a cost-effective solution and it increases the average reliability and availability by up 13\% and 15\% and reduces the total cost and the latency 25\% and 3\%, respectively, compared with the other baseline mechanisms.},
	journal = {Journal of Ambient Intelligence and Humanized Computing},
	author = {Taghizadeh, Jaber and Ghobaei-Arani, Mostafa and Shahidinejad, Ali},
	year = {2021},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3203051717
tex.pmcid: null},
}

@article{Tang_2020,
	title = {{UAV} placement optimization for internet of medical things.},
	doi = {10.1109/iwcmc48107.2020.9148581},
	abstract = {Internet of Medical Things (IoMT), intended for real-time health monitoring, are generating quantity of health data such as electrocardiogram, oxygen saturation, and blood pressure every second. The captured data should be processed and analyzed in a delay sensitive way which is vital to the survival rate for cardiovascular and cerebrovascular diseases. In this regard, Unmanned Aerial Vehicles (UAVs) have already demonstrated the enormous potentials. To begin with, due to better line-of-sight, wider communication and more flexible on-demand deployment, UAVs can realize seamless wireless connection to IoMT. Furthermore, UAVs can act as fog nodes to provision services for IoMTs such as task performing and data analysis. We in this paper focus on a sub-problem, i.e., the placement of UAVs over the serving area when they function as fog nodes. In the airborne fog computing, the placement of UAVs has an important influence on energy consumption and exploration area, let alone the communication coverage of the personal health devices on the ground. Therefore, we in this paper propose a particle swarm optimization (PSO) based algorithm to optimize the UAV placement over the serving area for the IoMT devices. We have conducted extensive simulations to evaluate it. The results show that our approach can significantly reduce the number of UAVs needed to deploy while considering the communication coverage and other factors.},
	journal = {2020 International Wireless Communications and Mobile Computing (IWCMC)},
	author = {Tang, Chaogang and Zhu, Chunsheng and Wei, Xianglin and Rodrigues, Joel J. P. C. and Guizani, Mohsen and Jia, Weijia},
	year = {2020},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3046186337
tex.pmcid: null},
	file = {Tang et al_2020_UAV placement optimization for internet of medical things.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/Z9KYTK4I/Tang et al_2020_UAV placement optimization for internet of medical things.pdf:application/pdf},
}

@article{Tasiopoulos_2018,
	title = {Edge-map: {Auction} markets for edge resource provisioning},
	doi = {10.1109/wowmom.2018.8449792},
	abstract = {New and emerging applications in the entertainment (e.g., Virtual/Augmented Reality), IoT and automotive domains will soon demand response times an order of magnitude smaller than can be achieved by the current “client-to-cloud” network model. Edge-and Fog-computing have been proposed as the promise to deal with such extremely latency-sensitive applications. According to Edge-/Fog-Computing, computing resources are available at the edge of the network for applications to run their virtualised instances. We assume a distributed computing environment, where In-Network Computing Providers (IN CPs) deploy and lease edge resources, while Application Service Providers (AppSPs) have the opportunity to rent those resources to meet their application's latency demands. We build an auction-based resource allocation and provisioning mechanism which produces a map of application instances in the edge computing infrastructure (hence, acronymed Edge-MAP). Edge-MAP takes into account users' mobility (i.e., users connecting to different cell stations over time) and the limited computing resources available in edge micro-clouds to allocate resources to bidding applications. On the micro-level, Edge-MAP relies on Vickrey-English-Dutch (VED) auctions to perform robust resource allocation, while on the macro-level it fosters competition among neighbouring IN CPs. In contrast to related studies in the area, Edge-MAP can scale to any number of applications, adapt to dynamic network conditions rapidly and reallocate resources in polynomial time. Our evaluation demonstrates Edge-MAP's capability of taking into account the inherent challenges of the provisioning problem we consider.},
	journal = {2018 IEEE 19th International Symposium on "A World of Wireless, Mobile and Multimedia Networks" (WoWMoM)},
	author = {Tasiopoulos, Argyrios G. and Ascigil, Onur and Psaras, Ioannis and Pavlou, George},
	year = {2018},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2888857789
tex.pmcid: null},
	file = {Tasiopoulos et al_2018_Edge-map.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/TDFHK9WL/Tasiopoulos et al_2018_Edge-map.pdf:application/pdf},
}

@article{Tran_2019,
	title = {Task placement on fog computing made efficient for {IoT} application provision},
	doi = {10.1155/2019/6215454},
	abstract = {Fog computing is one of the promising technologies for realizing global-scale Internet of Things (IoT) applications as it allows moving compute and storage resources closer to IoT devices, where data is generated, in order to solve the limitations in cloud-based technologies such as communication delay, network load, energy consumption, and operational cost. However, this technology is still in its infancy stage containing essential research challenges. For instance, what is a suitable fog computing scheme where effective service provision models can be deployed is still an open question. This paper proposes a novel multitier fog computing architecture that supports IoT service provisioning. Concretely, a solid service placement mechanism that optimizes service decentralization on fog landscape leveraging context-aware information such as location, response time, and resource consumption of services has been devised. The proposed approach optimally utilizes virtual resources available on the network edges to improve the performance of IoT services in terms of response time, energy, and cost reduction. The experimental results from both simulated data and use cases from service deployments in real-world applications, namely, the intelligent transportation system (ITS) in Ho Chi Minh City, show the effectiveness of the proposed solution in terms of maximizing fog device utilization while reducing latency, energy consumption, network load, and operational cost. The results confirm the robustness of the proposed scheme revealing its capability to maximize the IoT potential.},
	journal = {Wireless Communications and Mobile Computing},
	author = {Tran, Minh Quang and Nguyen, Duy Tai and Le, Van An and Le, Van An and Nguyen, Duc Hai and Pham, Tran Vu},
	year = {2019},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2909089926
tex.pmcid: null},
	file = {Tran et al_2019_Task placement on fog computing made efficient for IoT application provision.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/3H6G4VFM/Tran et al_2019_Task placement on fog computing made efficient for IoT application provision.pdf:application/pdf},
}

@article{Tsipis_2020,
	title = {Elastic distributed rendering service placement in capacitated {Cloud}/{Fog} gaming systems},
	doi = {10.1109/iisa50023.2020.9284390},
	abstract = {Fog-assisted cloud computing advances have paved the way for new solutions in online gaming, by integrating all rendering resources directly into the edges of the cloud. However, despite the numerous benefits, these systems still remain prone to network delays, ergo, the discovery of an optimal rendering service placement in the fog layer, that effectively reduces capital deployment cost for the game providers and access latency cost for the game clients, is a challenging issue. In fact, it falls into the category of the well-known (NP-hard) facility location problems. As such, conventional centralized approaches, that require global network knowledge, in most cases are deemed unscalable and cost-prohibitive, thus, distributed solutions must be further explored. The approach followed here, introduces a Rendering Service Allocation Policy (RSAP) to autonomously allocate services towards an optimal placement, based strictly on local information available to the fog renderers regarding their aggregate rendering demands, yielding reduced access latency and deployment costs, whilst meeting their stringent capacity bounds. Simulation results showcase the efficiency of RSAP and verify its elastic behavior under different deployment scenarios.},
	journal = {2020 11th International Conference on Information, Intelligence, Systems and Applications (IISA},
	author = {Tsipis, Athanasios and Komianos, Vasileios and Oikonomou, Konstantinos and Stavrakakis, Ioannis},
	year = {2020},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3113137086
tex.pmcid: null},
	file = {Tsipis et al_2020_Elastic distributed rendering service placement in capacitated Cloud-Fog gaming.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/TL2H7ZDR/Tsipis et al_2020_Elastic distributed rendering service placement in capacitated Cloud-Fog gaming.pdf:application/pdf},
}

@article{Tun_2020,
	title = {Resource aware placement of {IoT} devices in fog computing},
	doi = {10.1109/icait51105.2020.9261787},
	abstract = {Fog computing is the new favorable technology that can support real-time cloud application services near to the physical IoT device at the network edge rather than the cloud. It is the decentralized internet-based computing and a layer between the cloud and IoT devices. For real time analytics and critical services, it must process the data as fast as possible. Fog computing can process and manipulate the data at the network edge devices in near real time. However, there is a resource limitation because the services are performed by the fog devices at network edge. So, it needs to utilize the resources of the fog devices. As a result, the placement of IoT (edge) devices on what fog devices is considered to get the efficient resource utilization of the fog devices in this paper. In order to get efficient resource utilization of the fog devices and reduce application delay, network usage and cost of execution in cloud, Fog Node Placement algorithm that finds the fog devices which is minimum distance and enough resource for the IoT (edge) devices is proposed. In addition, the effectiveness of the algorithm will be showed by comparing with traditional cloud placement and fog cloud placement with nearest distance.},
	journal = {2020 International Conference on Advanced Information Technologies (ICAIT)},
	author = {Tun, Khin Nandar and Paing, Aye Myat Myat},
	year = {2020},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3106789060
tex.pmcid: null},
	file = {Tun_Paing_2020_Resource aware placement of IoT devices in fog computing.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/7LWWQGQQ/Tun_Paing_2020_Resource aware placement of IoT devices in fog computing.pdf:application/pdf},
}

@article{Azimzadeh_2022,
	title = {Placement of {IoT} services in fog environment based on complex network features: {A} genetic-based approach},
	doi = {10.1007/s10586-022-03571-w},
	abstract = {The growth of the Internet of Things (IoT) has caused an ever-increasing number of devices to be added to the network. Fog computing is an emerging technology that aims to overcome the common challenges, such as delay, bandwidth usage, and security, by bringing the process and the storage closer to the user. Services that should serve IoT nodes usually have complex multi-component structures. Thus, mapping such structures onto the dynamic and complex fog environment is challenging. In this paper, we propose a novel Fog Service Placement algorithm based on Complex Networks feature (FSPCN) by considering the community concept to overcome this issue. Previous research commonly formed communities solely based on the network structure. We argue that grouping fog nodes into balanced communities before service placement, based on the network structure and nodes and links attributes, can lead to more effective placement of IoT services concerning resource use and application delay. In addition, we have defined a neighborhood distance metric, calculated based on the number of common neighbors among communities, to prioritize communities. This improves the average number of hops from requesting nodes to the requested services and reduces delay and traffic within the network. The experimental results show that the proposed algorithm significantly outperforms state-of-the-art algorithms in terms of resource use and response time. Thus, the FSPCN method deploys more applications in the fog environment and decreases up to 17\% the number of applications placed in the cloud. This method also reduces the average delay about 30\%.},
	journal = {Cluster Computing},
	author = {Azimzadeh, Masomeh and Rezaee, Ali and Jafarali Jassbi, Somayyeh and Esnaashari, Mehdi},
	year = {2022},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: null
tex.pmcid: null},
	keywords = {notion},
	file = {2022_Placement of IoT services in fog environment based on complex network features.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/X2GLWAED/2022_Placement of IoT services in fog environment based on complex network features.pdf:application/pdf},
}

@article{undefined_2022,
	title = {A genetic-based approach for service placement in fog computing},
	doi = {10.1007/s11227-021-04254-w},
	abstract = {The combination of cloud computing with the Internet of Things has made fundamental changes in areas from industry, healthcare, traffic, and transportation to home appliances and even personal lives. Billions of devices and users are connected through these platforms disseminating enormous amounts of data leading to performance degradation, which has generated a demand for prior application placement planning. This paper focuses on the minimization of application delay and network usage by proposing a genetic-based service placement algorithm in fog-cloud environments. Throughout this work, a penalty-based approach to target both the delay and the number of time-consuming cloud placements is introduced, which explores the solution pool as a function of generations. This helps in exploring a wider space at the beginning and gradually intensifying the effect of penalty in the next generations. In a separate phase, the proximity of the applications to the users is taken into account as well. This is done through the chromosome selection process by using a priority value that identifies the proximity of dependent modules. The results of simulations demonstrate that the proposed algorithm achieved improvements regarding delay, network usage, energy consumption, and cost.},
	journal = {The Journal of Supercomputing},
	author = {Sarrafzade, Nazanin and Entezari‑Maleki, Reza and Sousa, Leonel},
	year = {2022},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: null
tex.pmcid: null},
	file = {Sarrafzade et al. - 2022 - A genetic-based approach for service placement in .pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/L9V65MRA/Sarrafzade et al. - 2022 - A genetic-based approach for service placement in .pdf:application/pdf},
}

@article{velasquez_service_2021,
	title = {Service placement for latency reduction in the fog using application profiles},
	doi = {10.1109/access.2021.3085370},
	abstract = {The Cloud-Fog-Internet of Things continuum combines different paradigms to provide connectivity and ubiquity for end-users, while also granting low latency and low jitter to cope with different challenges, including the requirements of latency-sensitive applications, such as virtual/augmented reality and online gaming. This constitutes a complex and dynamic environment with heterogeneous resources that need to be managed or orchestrated, in order to accomplish application requirements for low latency. Common orchestration solutions make placement decisions based only on the resources of the underlying network and the application resource requests; however, using the profiles of applications to make placement decisions has the potential to enhance the final performance perceived by the end-users. This paper proposes the use of application profiles according to their popularity to guide their placement. To corroborate the effectiveness of the use of the profiles, two placement mechanisms are presented, one based on Genetic Algorithm and the other inspired on graph partitions. Simulation results show that it is possible to reduce the latency and jitter of applications via a service placement guided by the profiles. The mechanism based on graph partitions showed better results for all scenarios, followed closely by the Genetic Algorithm in the scenarios with lower load.},
	journal = {IEEE access : practical innovations, open solutions},
	author = {Velasquez, Karima and Abreu, David Perez and Curado, Marilia and Monteiro, Edmundo},
	year = {2021},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3168843131
tex.pmcid: null},
	file = {Velasquez et al_2021_Service placement for latency reduction in the fog using application profiles.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/FVWRACBP/Velasquez et al_2021_Service placement for latency reduction in the fog using application profiles.pdf:application/pdf},
}

@article{Velasquez.etal2017,
	title = {Service placement for latency reduction in the internet of things},
	volume = {72},
	issn = {0003-4347, 1958-9395},
	url = {http://link.springer.com/10.1007/s12243-016-0524-9},
	doi = {10.1007/s12243-016-0524-9},
	abstract = {New services and applications become part of our daily activities as we evolve into new solutions supported by cutting-edge paradigms, like the Internet of Things and Smart Cities. In order to properly achieve the benefits theoretically provided by these models, new kinds of services must be designed. These new services have special requirements, as well as the users that access to them. One of these requirements is low latency levels, since a delayed reply could render to chaos for applications such as eHealth and public safety. The communication infrastructure must cope with these challenges by offering innovative solutions. One of these solutions is a smart service placement system that facilitates the location of services in the proper position according to specific needs. On this paper, a service placement architecture for the Internet of Things is proposed, with especial emphasis in its main module, the Service Orchestrator, for which implementation details are provided, including a model for the service placement task. Furthermore, technologies to implement the modules from the architecture are suggested. This proposal, as well as its validation, is framed within the scope of the SusCity project.},
	language = {english},
	number = {1-2},
	urldate = {2022-03-28},
	journal = {Annals of Telecommunications},
	author = {Velasquez, Karima and Abreu, David Perez and Curado, Marilia and Monteiro, Edmundo},
	month = feb,
	year = {2017},
	pages = {105--115},
	file = {Velasquez et al_2017_Service placement for latency reduction in the internet of things.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/PJF8PZ59/Velasquez et al_2017_Service placement for latency reduction in the internet of things.pdf:application/pdf},
}

@article{Xu_2018,
	title = {Connection is power: {Near} optimal advertisement infrastructure placement for vehicular fogs},
	doi = {10.1007/s12083-017-0571-7},
	abstract = {Mobile advertisement infrastructure (MAI) becomes popular but is still subjected to the relatively high deployment cost. Previous studies overlook the effective placement of MAIs where the geographical distances among them should be fully respected. In this work, we optimize the placement of MAIs where the maximum distances between MAIs are incorporated, which could be regarded as a kind of connectivity constraint. Vehicular users form a virtual fog to get the mobile advertisements when approaching the MAIs. We investigated the interplay between the connected MAIs and vehicular fogs. We found that such kind of deployment could effectively maximize the number of covered vehicular users, which could be modeled with a submodular set function. Unfortunately, the investigated deployment problem is more complicated than traditional maximum submodular set function problem, e.g. the maximum coverage problem. Because it requires all the MAIs could be “virtually connected” to each other and thereby form a connected network. To address aforementioned challenges, this paper introduces a near optimal algorithm, which incorporates an O(k) -approximation algorithm, where k is the number of mobile advertisement infrastructures. To this end, we make extensive experimental studies using synthetic data. Our results show that the proposed algorithm achieves an improved performance, i.e., 40\% for typical multi-hop case (e.g. 4 to 8 hops), than the baseline scheme where random selection is applied. In addition, our results show very close performance comparing with the global optimal results achieved by exhaustive search method.},
	journal = {Peer-to-peer Networking and Applications},
	author = {Xu, Wanru and Xu, Wanru and Xu, Wanru and Yang, Panlong and Yang, Panlong and Yang, Panlong and Jiang, Lijing},
	year = {2018},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2626685424
tex.pmcid: null},
	file = {Xu et al_2018_Connection is power.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/R2A5MVS2/Xu et al_2018_Connection is power.pdf:application/pdf},
}

@article{Xu_2019,
	title = {A real plug-and-play fog: {Implementation} of service placement in wireless multimedia networks},
	doi = {10.23919/jcc.2019.10.012},
	abstract = {Initially as an extension of cloud computing, fog computing has been inspiring new ideas about moving computing tasks to the edge of networks. In fog, we often repeat the procedure of placing services because of the geographical distribution of mobile users. We may not expect a fixed demand and supply relationship between users and service providers since users always prefer nearby service with less time delay and transmission consumption. That is, a plug-and-play service mode is what we need in fog. In this paper, we put forward a dynamic placement strategy for fog service to guarantee the normal service provision and optimize the Quality of Service (QoS). The simulation results show that our strategy can achieve better performance under metrics including energy consumption and end-to-end latency. Moreover, we design a real Plug-and-Play Fog (PnPF) based on Raspberry Pi and OpenWrt to provide fog services for wireless multimedia networks.},
	journal = {China Communications},
	author = {Xu, Jianwen and Ota, Kaoru and Dong, Mianxiong},
	year = {2019},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3023276019
tex.pmcid: null},
	file = {Xu et al_2019_A real plug-and-play fog.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/2ZWEUPFC/Xu et al_2019_A real plug-and-play fog.pdf:application/pdf},
}

@article{Yan_2020,
	title = {Fog server placement for multimodality data fusion in neuroimaging.},
	doi = {10.1007/978-3-030-62223-7_20},
	abstract = {Since the findings of the single modality data are unable to provide sufficient sensitivity and specificity for diagnostic measures, multimodality data fusion is adopted in the neuroimaging to detect the important differences between patients and healthy people. Applying fog computing contributes to reducing the redundant modality data transmission and processing brought by the multimodality data fusion. Due to the budget, the scale and the storage space of the fog servers are limited. What’s more, the proper location of the fog servers depends on the distribution of the data fusion points and the detailed contents of the data fusion tasks. Therefore, a fog server placement strategy for multimodality data fusion in neuroimaging, named FSPF, is put forward to determine the proper scale and location of the fog servers. Technically, the performance of the fog server location is evaluated by the data fusion time and the hit rate. Then, non-dominated sorting genetic algorithm-III (NSGA-III) is adopted in FSPF to obtain the proper solutions of the next generation and a reference solution is applied to optimize the initial population of the evolution. Finally, adequate experiments have been conducted to testify the efficiency and reliability of our method.},
	journal = {ML4CS},
	author = {Yan, Xuan and Xu, Xiaolong and Xu, Xiaolong and Zheng, Yu and Zheng, Yu and Zheng, Yu and Dai, Fei and Dai, Fei and Dai, Fei},
	year = {2020},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 3100358072
tex.pmcid: null},
}

@article{Zamani_2018,
	title = {A novel approach for service function chain ({SFC}) mapping with multiple {SFC} instances in a fog-to-cloud computing system},
	doi = {10.1109/icspis.2018.8700535},
	abstract = {Internet of Things (IoT) has been ever-growing over the last few years. The IoT devices generate a massive amount of data that should be transmitted to the cloud for computing. Cloud consolidation and centralization lead to many network hops between the IoT devices and its associated cloud which makes two critical problems: (i) high latencies (ii) high bandwidth consumption in the IoT domain. Network Function Virtualization (NFV), Software Defined Network (SDN) and fog computing have been emerged to address these problems. In the Fog-to-Cloud (F2C) architecture, Fog and cloud work together to provide computing, storage, and application services in the IoT domain. To build complex services a specific set of virtual network functions can be chained together in a specific order which is known as Service Function Chaining (SFC). The joint VNF placement and traffic routing are called SFC mapping. In this paper, we propose an Integer Linear Program (ILP) model to solve SFC mapping in the fog-to-cloud Computing System in order to minimize the overall end-to-end (e2e) latency of IoT devices. We observe that our approach reduces the overall e2e latency of IoT devices significantly. Moreover, our approach helps us to analyze the effect of a number of instances in the end-to-end latency of IoT devices.},
	journal = {2018 4th Iranian Conference on Signal Processing and Intelligent Systems (ICSPIS)},
	author = {Zamani, Ali and Zamani, Ali Reza and Sharifian, Saeed},
	year = {2018},
	note = {tex.eprint: null
tex.eprinttype: pmid
tex.mag\_id: 2943422123
tex.pmcid: null},
	file = {Zamani et al_2018_A novel approach for service function chain (SFC) mapping with multiple SFC.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/MWEZEAWL/Zamani et al_2018_A novel approach for service function chain (SFC) mapping with multiple SFC.pdf:application/pdf},
}

@misc{noauthor_zotero_nodate,
	title = {Zotero {\textbar} {Downloads}},
	url = {https://www.zotero.org/download/},
	urldate = {2022-04-22},
}

@misc{noauthor_zotero_nodate-1,
	title = {Zotero {\textbar} {Downloads}},
	url = {https://www.zotero.org/download/},
	urldate = {2022-04-22},
	file = {Zotero | Downloads:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/6CUR532P/download.html:text/html},
}

@inproceedings{alqahtani_energy_2021,
	address = {Thessaloniki, Greece},
	title = {Energy {Efficient} {Resource} {Allocation} in {Federated} {Fog} {Computing} {Networks}},
	isbn = {978-1-66542-349-6},
	url = {https://ieeexplore.ieee.org/document/9686117/},
	doi = {10.1109/CSCN53733.2021.9686117},
	abstract = {There is a continuous growth in demand for time sensitive applications which has shifted the cloud paradigm from a centralized computing architecture towards distributed heterogeneous computing platforms where resources located at the edge of the network are used to provide cloud-like services. This paradigm is widely known as fog computing. Virtual machines (VMs) have been widely utilized in both paradigms to enhance the network scalability, improve resource utilization, and energy efficiency. Moreover, Passive Optical Networks (PONs) are a technology suited to handling the enormous volumes of data generated in the access network due to their energy efficiency and large bandwidth. In this paper, we utilize a PON to provide the connectivity between multiple distributed fog units to achieve federated (i.e., cooperative) computing units in the access network to serve intensive demands. We propose a mixed integer linear program (MILP) to optimize the VM placement in the federated fog computing units with the objective of minimizing the total power consumption while considering inter-VM traffic. The results show a significant power saving as a result of the proposed optimization model by up to 52\%, in the VM-allocation compared to a baseline approach that allocates the VM requests while neglecting the power consumption and inter-VMs traffic in the optimization framework.},
	language = {en},
	urldate = {2022-05-23},
	booktitle = {2021 {IEEE} {Conference} on {Standards} for {Communications} and {Networking} ({CSCN})},
	publisher = {IEEE},
	author = {Alqahtani, Abdullah M. and Yosuf, Barzan and Mohamed, Sanaa H. and El-Gorashi, Taisir E.H. and Elmirghani, Jaafar M.H.},
	month = dec,
	year = {2021},
	pages = {199--204},
	file = {Alqahtani et al. - 2021 - Energy Efficient Resource Allocation in Federated .pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/SYTIXN4K/Alqahtani et al. - 2021 - Energy Efficient Resource Allocation in Federated .pdf:application/pdf},
}

@inproceedings{benamer_genetic_2021,
	address = {Madrid, Spain},
	title = {A {Genetic} {Algorithm} for the {Placement} of {Latency}-{Sensitive} {Multiplayer} {Game} {Servers} in the {Fog}},
	isbn = {978-1-72818-104-2},
	url = {https://ieeexplore.ieee.org/document/9685952/},
	doi = {10.1109/GLOBECOM46510.2021.9685952},
	abstract = {Fog computing can be a promising paradigm, for enabling online, multiplayer games with stringent delays. An important problem to be addressed, within this context, deals with the placement of game servers. It consists of selecting suitable Fog nodes, for hosting the servers, inline with the Quality of Service (QoS) requirements of the respective games, while offering the needed computing capacities, at optimal costs.},
	language = {en},
	urldate = {2022-05-23},
	booktitle = {2021 {IEEE} {Global} {Communications} {Conference} ({GLOBECOM})},
	publisher = {IEEE},
	author = {Benamer, Amira Rayane and Boussetta, Khaled and Hadj-Alouane, Nejib Ben},
	month = dec,
	year = {2021},
	pages = {1--6},
	file = {Benamer et al. - 2021 - A Genetic Algorithm for the Placement of Latency-S.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/ND7ZB2HG/Benamer et al. - 2021 - A Genetic Algorithm for the Placement of Latency-S.pdf:application/pdf},
}

@article{ghobaei-arani_cost-efficient_2022,
	title = {A cost-efficient {IoT} service placement approach using whale optimization algorithm in fog computing environment},
	volume = {200},
	issn = {09574174},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0957417422004304},
	doi = {10.1016/j.eswa.2022.117012},
	abstract = {The rapid development of Internet of Things (IoT)-based applications and the era of 5G networks has led to an exponential increase in the amount of data required for processing the IoT services. The fog computing paradigm has emerged as a distributed computing solution for serving these applications using available fog nodes near the IoT devices. Since the IoT applications are developed in the form of several IoT services with various quality of service (QoS) requirements that can be deployed on the fog nodes with different resource capabilities in the fog ecosystem, finding an efficient service placement plan is one of the challenging issues to be considered. In this paper, we propose an efficient IoT service placement solution based on the autonomic methodology for deploying IoT applications on the fog infrastructure. Our proposed solution monitors the QoS requirements of IoT services and capabilities of available fog nodes to determine an efficient service placement plan using the whale opti­ mization algorithm (WOA) meta-heuristic technique. Besides, our evolutionary-based mechanism utilized the throughput and the energy consumption as objective functions for finding desirable IoT service placement plan while meeting the QoS requirements of each IoT service. Also, we develop an autonomous service placement framework according to a three-tier architecture of the fog ecosystem to show the interaction between the main components of the IoT device and fog layers for deploying IoT applications. The simulation results demonstrate that the proposed solution increases the resource usage and service acceptance ratio and reduces the service delay and the energy consumption compared with the other metaheuristic-based mechanisms.},
	language = {en},
	urldate = {2022-05-23},
	journal = {Expert Systems with Applications},
	author = {Ghobaei-Arani, Mostafa and Shahidinejad, Ali},
	month = aug,
	year = {2022},
	keywords = {notion},
	pages = {117012},
	file = {Ghobaei-Arani and Shahidinejad - 2022 - A cost-efficient IoT service placement approach us.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/2SQCWW8K/Ghobaei-Arani and Shahidinejad - 2022 - A cost-efficient IoT service placement approach us.pdf:application/pdf},
}

@article{zhao_qos-aware_2022,
	title = {A {QoS}-{Aware} {IoT} {Service} {Placement} {Mechanism} in {Fog} {Computing} {Based} on {Open}-{Source} {Development} {Model}},
	volume = {20},
	issn = {1570-7873, 1572-9184},
	url = {https://link.springer.com/10.1007/s10723-022-09604-3},
	doi = {10.1007/s10723-022-09604-3},
	language = {en},
	number = {2},
	urldate = {2022-05-23},
	journal = {Journal of Grid Computing},
	author = {Zhao, Defu and Zou, Qunying and Boshkani Zadeh, Milad},
	month = jun,
	year = {2022},
	pages = {12},
	file = {Zhao et al. - 2022 - A QoS-Aware IoT Service Placement Mechanism in Fog.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/HESIHWJE/Zhao et al. - 2022 - A QoS-Aware IoT Service Placement Mechanism in Fog.pdf:application/pdf},
}

@article{goethals_near_2020,
	title = {Near real-time optimization of fog service placement for responsive edge computing},
	volume = {9},
	issn = {2192-113X},
	url = {https://journalofcloudcomputing.springeropen.com/articles/10.1186/s13677-020-00180-z},
	doi = {10.1186/s13677-020-00180-z},
	abstract = {In recent years, computing workloads have shifted from the cloud to the fog, and IoT devices are becoming powerful enough to run containerized services. While the combination of IoT devices and fog computing has many advantages, such as increased efficiency, reduced network traffic and better end user experience, the scale and volatility of the fog and edge also present new problems for service deployment scheduling. Fog and edge networks contain orders of magnitude more devices than cloud data centers, and they are often less stable and slower. Additionally, frequent changes in network topology and the number of connected devices are the norm in edge networks, rather than the exception as in cloud data centers. This article presents a service scheduling algorithm, labeled “Swirly”, for fog and edge networks containing hundreds of thousands of devices, which is capable of incorporating changes in network conditions and connected devices. The theoretical performance is explored, and a model of the behaviour and limits of fog nodes is constructed. An evaluation of Swirly is performed, showing that it is capable of managing service meshes for at least 300.000 devices in near real-time.},
	language = {en},
	number = {1},
	urldate = {2022-05-23},
	journal = {Journal of Cloud Computing},
	author = {Goethals, Tom and De Turck, Filip and Volckaert, Bruno},
	month = dec,
	year = {2020},
	pages = {34},
	file = {Goethals et al. - 2020 - Near real-time optimization of fog service placeme.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/JTSPVTRA/Goethals et al. - 2020 - Near real-time optimization of fog service placeme.pdf:application/pdf},
}

@article{hassan_priority_2020,
	title = {Priority, network and energy‐aware placement of {IoT}‐based application services in fog‐cloud environments},
	volume = {14},
	issn = {1751-8636, 1751-8636},
	url = {https://onlinelibrary.wiley.com/doi/10.1049/iet-com.2020.0007},
	doi = {10.1049/iet-com.2020.0007},
	abstract = {Fog computing is a decentralised model which can help cloud computing for providing high quality-of-service (QoS) for the Internet of Things (IoT) application services. Service placement problem (SPP) is the mapping of services among fog and cloud resources. It plays a vital role in response time and energy consumption in fog–cloud environments. However, providing an efficient solution to this problem is a challenging task due to difficulties such as different requirements of services, limited computing resources, different delay, and power consumption profile of devices in fog domain. Motivated by this, in this study, we propose an efficient policy, called MinRE, for SPP in fog–cloud systems. To provide both QoS for IoT services and energy efficiency for fog service providers, we classify services into two categories: critical services and normal ones. For critical services, we propose MinRes, which aims to minimise response time, and for normal ones, we propose MinEng, whose goal is reducing the energy consumption of fog environment. Our extensive simulation experiments show that our policy improves the energy consumption up to 18\%, the percentage of deadline satisfied services up to 14\% and the average response time up to 10\% in comparison with the second-best results.},
	language = {en},
	number = {13},
	urldate = {2022-05-23},
	journal = {IET Communications},
	author = {Hassan, Hiwa Omer and Azizi, Sadoon and Shojafar, Mohammad},
	month = aug,
	year = {2020},
	pages = {2117--2129},
	file = {Hassan et al. - 2020 - Priority, network and energy‐aware placement of Io.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/XUX59XQC/Hassan et al. - 2020 - Priority, network and energy‐aware placement of Io.pdf:application/pdf},
}

@article{salimian_evolutionary_2022,
	title = {An {Evolutionary} {Multi}-objective {Optimization} {Technique} to {Deploy} the {IoT} {Services} in {Fog}-enabled {Networks}: {An} {Autonomous} {Approach}},
	volume = {36},
	issn = {0883-9514, 1087-6545},
	shorttitle = {An {Evolutionary} {Multi}-objective {Optimization} {Technique} to {Deploy} the {IoT} {Services} in {Fog}-enabled {Networks}},
	url = {https://www.tandfonline.com/doi/full/10.1080/08839514.2021.2008149},
	doi = {10.1080/08839514.2021.2008149},
	abstract = {The Internet of Things (IoT) generates countless amounts of data, much of which is processed in cloud data centers. When data is transferred to the cloud over longer distances, there is a long latency in IoT services. Therefore, in order to increase the speed of service provision, resources should be placed close to the user (i.e., at the edge of the network). To address this challenge, a new paradigm called Fog Computing was introduced and added as a layer in the IoT architecture. Fog computing is a decentralized computing infrastructure in which provides storage and computing in the vicinity of IoT devices instead of sending to the cloud. Hence, fog computing can provide less latency and better Quality of Service (QoS) for real-time applications than cloud computing. In general, the theoretical foundations of fog computing have already been presented, but the problem of IoT services placement to fog nodes is still challenging and has attracted much attention from researchers. In this paper, a conceptual computing frame­ work based on fog-cloud control middleware is proposed to optimally IoT services placement. Here, this problem is formu­ lated as an automated planning model for managing service requests due to some limitations that take into account the heterogeneity of applications and resources. To solve the pro­ blem of IoT services placement, an automated evolutionary approach based on Particle Swarm Optimization (PSO) has been proposed with the aim of making maximize the utiliza­ tion of fog resources and improving QoS. Experimental studies on a synthetic environment have been evaluated based on various metrics including services performed, waiting time, failed services, services cost, services remaining, and runtime. The results of the comparisons showed that the proposed framework based on PSO performs better than the state-ofthe-art methods.},
	language = {en},
	number = {1},
	urldate = {2022-05-23},
	journal = {Applied Artificial Intelligence},
	author = {Salimian, Mahboubeh and Ghobaei-Arani, Mostafa and Shahidinejad, Ali},
	month = dec,
	year = {2022},
	pages = {2008149},
	file = {Salimian et al. - 2022 - An Evolutionary Multi-objective Optimization Techn.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/7CUI7JEK/Salimian et al. - 2022 - An Evolutionary Multi-objective Optimization Techn.pdf:application/pdf},
}

@article{aldossary_towards_2021,
	title = {Towards a {Green} {Approach} for {Minimizing} {Carbon} {Emissions} in {Fog}-{Cloud} {Architecture}},
	volume = {9},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/9543678/},
	doi = {10.1109/ACCESS.2021.3114514},
	abstract = {Fog computing is developed to complement cloud computing by extending the cloud services (computing, storage, networking, and management) to the edge of the network in order to reduce service latency. Correspondingly, the incremental use of cloud/fog resources and their applications has increased energy consumption and carbon emissions (CO2) of the data centers, which caused signiﬁcant environmental challenges. Optimizing the placement of the requested resources and applications (e.g., in the form of virtual machines (VMs)) is one of the main solutions, which has a primary effect in reducing the energy consumption of cloud/fog architectures and consequently their CO2 emissions. However, due to the geographic distribution of cloud and fog data centers, there are varying levels of CO2 emissions to consider, which makes optimizing the placement of resources and applications in distributed cloud/fog more challenging than in centralized clouds in terms of carbon efﬁciency. In this paper, we propose a multi-level approach using a mixed-integer linear programming (MILP) model to minimize the CO2 emissions of data centers by optimizing the resources usage and the placement of VMs in fog-cloud environments. This approach calculates the CO2 emissions of the British Telecom (BT) network based on the carbon intensity data from the National Grid ESO, considering several scenarios of trafﬁc demand during different times of the day and year. The results show that the optimal location to host applications highly relies on the carbon intensity and trafﬁc demands. The results also show there is a trade-off between CO2 emission reduced by shortening network journey, and CO2 emission increased by hosting more applications into the fog nodes. In addition, the results demonstrate that the proposed green fog-cloud architecture outperforms the central cloud and the distributed clouds in terms of reducing the total CO2 emission by up to 91\% and 71\%, respectively. Finally, we develop a heuristic algorithm to mimic and validate the presented work, and it shows comparable results to the MILP model.},
	language = {en},
	urldate = {2022-05-23},
	journal = {IEEE Access},
	author = {Aldossary, Mohammad and Alharbi, Hatem A.},
	year = {2021},
	pages = {131720--131732},
	file = {Aldossary and Alharbi - 2021 - Towards a Green Approach for Minimizing Carbon Emi.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/A7WMXP66/Aldossary and Alharbi - 2021 - Towards a Green Approach for Minimizing Carbon Emi.pdf:application/pdf},
}

@article{natesha_meta-heuristic_2022,
	title = {Meta-heuristic {Based} {Hybrid} {Service} {Placement} {Strategies} for {Two}-{Level} {Fog} {Computing} {Architecture}},
	volume = {30},
	issn = {1064-7570, 1573-7705},
	url = {https://link.springer.com/10.1007/s10922-022-09660-w},
	doi = {10.1007/s10922-022-09660-w},
	abstract = {The smart manufacturing industry (Industry 4.0) uses the Internet of Things (IoT) devices referred to as Industrial IoT (IIoT) to automate the industrial environment. These IIoT devices generate a massive amount of data called big data. Using fog computing architecture for processing this extensive data will reduce the service time and the service cost for the IIoT applications. The primary challenge is to design better service placement strategies to deploy the IIoT service requests on the fog nodes to minimize service costs and ensure the Quality of Service (QoS) of IIoT applications. Hence, the placement of IIoT services on the fog nodes can be considered as NP-hard problem. In this work, the meta-heuristic-based hybrid algorithms, namely: MGAPSO and EGAPSO, are developed by combining the GA \& PSO and Elitism-based GA (EGA) \& PSO, respectively. Further, carried out experiments on the two-level fog computing framework developed using docker and containers on 1.4 GHz, 64-bit quad-core processor devices. Experimental results demonstrate that the proposed hybrid EGAPSO algorithm minimizes service time, service cost, and energy consumption and ensures the IIoT applications’ QoS compared to other proposed and state-of-the-art service placement strategies considered for the performance evaluation.},
	language = {en},
	number = {3},
	urldate = {2022-06-13},
	journal = {Journal of Network and Systems Management},
	author = {Natesha, B. V. and Guddeti, Ram Mohana Reddy},
	month = jul,
	year = {2022},
	pages = {47},
	file = {Natesha and Guddeti - 2022 - Meta-heuristic Based Hybrid Service Placement Stra.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/BSDEPMBQ/Natesha and Guddeti - 2022 - Meta-heuristic Based Hybrid Service Placement Stra.pdf:application/pdf},
}

@article{strobelt_seq2seq-vis_2019,
	title = {Seq2seq-{Vis}: {A} {Visual} {Debugging} {Tool} for {Sequence}-to-{Sequence} {Models}},
	volume = {25},
	issn = {1077-2626, 1941-0506, 2160-9306},
	shorttitle = {Seq2seq-{Vis}},
	url = {https://ieeexplore.ieee.org/document/8494828/},
	doi = {10.1109/TVCG.2018.2865044},
	language = {en},
	number = {1},
	urldate = {2022-10-06},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Strobelt, Hendrik and Gehrmann, Sebastian and Behrisch, Michael and Perer, Adam and Pfister, Hanspeter and Rush, Alexander M.},
	month = jan,
	year = {2019},
	keywords = {⛔ No INSPIRE recid found},
	pages = {353--363},
	file = {Strobelt et al_2019_Seq2seq-Vis.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/B6VCK7PW/Strobelt et al_2019_Seq2seq-Vis.pdf:application/pdf;Strobelt et al. - 2019 - Seq2seq-Vis A Visual Debugging Tool for Sequence-.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/XBUYRHZ5/Strobelt et al. - 2019 - Seq2seq-Vis A Visual Debugging Tool for Sequence-.pdf:application/pdf},
}

@article{zhang_keyphrase_2018,
	title = {Keyphrase {Generation} {Based} on {Deep} {Seq2seq} {Model}},
	volume = {6},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/8438457/},
	doi = {10.1109/ACCESS.2018.2865589},
	abstract = {Keyphrase can provide highly summative information which can help us improve information utilization efﬁciency in the era of information overload. Though previous researches about keyphrase generation have provided some workable solutions, they generate keyphrase by ranking and selecting meaningful words from the source text. These approaches belong to an extractive method, by which they cannot effectively use semantic meaning of the source text, and are unable to generate keyphrases which do not appear in the source text. So we propose a sequence-to-sequence framework with attention mechanism, copy mechanism, and coverage mechanism, which can effectively deal with the above-mentioned drawbacks. The experimental results on ﬁve data sets reveal that our proposed model can achieve a better performance than the traditional extraction approaches and can also generate absent keyphrases which do not appear in the source text.},
	language = {en},
	urldate = {2022-10-06},
	journal = {IEEE Access},
	author = {Zhang, Yong and Xiao, Weidong},
	year = {2018},
	keywords = {⛔ No INSPIRE recid found},
	pages = {46047--46057},
	file = {Zhang_Xiao_2018_Keyphrase Generation Based on Deep Seq2seq Model.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/YUQFEE7G/Zhang_Xiao_2018_Keyphrase Generation Based on Deep Seq2seq Model.pdf:application/pdf},
}

@article{zhang_keyphrase_2018-1,
	title = {Keyphrase {Generation} {Based} on {Deep} {Seq2seq} {Model}},
	volume = {6},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/8438457/},
	doi = {10.1109/ACCESS.2018.2865589},
	abstract = {Keyphrase can provide highly summative information which can help us improve information utilization efﬁciency in the era of information overload. Though previous researches about keyphrase generation have provided some workable solutions, they generate keyphrase by ranking and selecting meaningful words from the source text. These approaches belong to an extractive method, by which they cannot effectively use semantic meaning of the source text, and are unable to generate keyphrases which do not appear in the source text. So we propose a sequence-to-sequence framework with attention mechanism, copy mechanism, and coverage mechanism, which can effectively deal with the above-mentioned drawbacks. The experimental results on ﬁve data sets reveal that our proposed model can achieve a better performance than the traditional extraction approaches and can also generate absent keyphrases which do not appear in the source text.},
	language = {en},
	urldate = {2022-10-06},
	journal = {IEEE Access},
	author = {Zhang, Yong and Xiao, Weidong},
	year = {2018},
	keywords = {⛔ No INSPIRE recid found},
	pages = {46047--46057},
	file = {Zhang and Xiao - 2018 - Keyphrase Generation Based on Deep Seq2seq Model.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/JUYNR8MH/Zhang and Xiao - 2018 - Keyphrase Generation Based on Deep Seq2seq Model.pdf:application/pdf;Zhang_Xiao_2018_Keyphrase Generation Based on Deep Seq2seq Model.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/72EMDV3T/Zhang_Xiao_2018_Keyphrase Generation Based on Deep Seq2seq Model.pdf:application/pdf},
}

@inproceedings{wiseman_sequence--sequence_2016,
	address = {Austin, Texas},
	title = {Sequence-to-{Sequence} {Learning} as {Beam}-{Search} {Optimization}},
	url = {http://aclweb.org/anthology/D16-1137},
	doi = {10.18653/v1/D16-1137},
	abstract = {Sequence-to-Sequence (seq2seq) modeling has rapidly become an important generalpurpose NLP tool that has proven effective for many text-generation and sequence-labeling tasks. Seq2seq builds on deep neural language modeling and inherits its remarkable accuracy in estimating local, next-word distributions. In this work, we introduce a model and beamsearch training scheme, based on the work of Daume´ III and Marcu (2005), that extends seq2seq to learn global sequence scores. This structured approach avoids classical biases associated with local training and uniﬁes the training loss with the test-time usage, while preserving the proven model architecture of seq2seq and its efﬁcient training approach. We show that our system outperforms a highlyoptimized attention-based seq2seq system and other baselines on three different sequence to sequence tasks: word ordering, parsing, and machine translation.},
	language = {en},
	urldate = {2022-10-06},
	booktitle = {Proceedings of the 2016 {Conference} on {Empirical} {Methods} in {Natural}           {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Wiseman, Sam and Rush, Alexander M.},
	year = {2016},
	keywords = {⛔ No INSPIRE recid found},
	pages = {1296--1306},
	file = {Wiseman_Rush_2016_Sequence-to-Sequence Learning as Beam-Search Optimization.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/LYHV6WF5/Wiseman_Rush_2016_Sequence-to-Sequence Learning as Beam-Search Optimization.pdf:application/pdf},
}

@inproceedings{jiang_why_2018,
	address = {Brussels, Belgium},
	title = {Why are {Sequence}-to-{Sequence} {Models} {So} {Dull}? {Understanding} the {Low}-{Diversity} {Problem} of {Chatbots}},
	shorttitle = {Why are {Sequence}-to-{Sequence} {Models} {So} {Dull}?},
	url = {http://aclweb.org/anthology/W18-5712},
	doi = {10.18653/v1/W18-5712},
	abstract = {Diversity is a long-studied topic in information retrieval that usually refers to the requirement that retrieved results should be non-repetitive and cover different aspects. In a conversational setting, an additional dimension of diversity matters: an engaging response generation system should be able to output responses that are diverse and interesting. Sequence-to-sequence (Seq2Seq) models have been shown to be very effective for response generation. However, dialogue responses generated by Seq2Seq models tend to have low diversity. In this paper, we review known sources and existing approaches to this low-diversity problem. We also identify a source of low diversity that has been little studied so far, namely model over-conﬁdence. We sketch several directions for tackling model over-conﬁdence and, hence, the low-diversity problem, including conﬁdence penalties and label smoothing.},
	language = {en},
	urldate = {2022-10-06},
	booktitle = {Proceedings of the 2018 {EMNLP} {Workshop} {SCAI}: {The} 2nd {International} {Workshop} on {Search}-{Oriented} {Conversational} {AI}},
	publisher = {Association for Computational Linguistics},
	author = {Jiang, Shaojie and de Rijke, Maarten},
	year = {2018},
	keywords = {⛔ No INSPIRE recid found},
	pages = {81--86},
	file = {Jiang_de Rijke_2018_Why are Sequence-to-Sequence Models So Dull.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/IFX9RN6M/Jiang_de Rijke_2018_Why are Sequence-to-Sequence Models So Dull.pdf:application/pdf},
}

@article{zhang_abstract_2019,
	title = {Abstract {Text} {Summarization} with a {Convolutional} {Seq2seq} {Model}},
	volume = {9},
	issn = {2076-3417},
	url = {https://www.mdpi.com/2076-3417/9/8/1665},
	doi = {10.3390/app9081665},
	abstract = {Abstract text summarization aims to offer a highly condensed and valuable information that expresses the main ideas of the text. Most previous researches focus on extractive models. In this work, we put forward a new generative model based on convolutional seq2seq architecture. A hierarchical CNN framework is much more efficient than the conventional RNN seq2seq models. We also equip our model with a copying mechanism to deal with the rare or unseen words. Additionally, we incorporate a hierarchical attention mechanism to model the keywords and key sentences simultaneously. Finally we verify our model on two real-life datasets, GigaWord and DUC corpus. The experiment results verify the effectiveness of our model as it outperforms state-of-the-art alternatives consistently and statistical significantly.},
	language = {en},
	number = {8},
	urldate = {2022-10-06},
	journal = {Applied Sciences},
	author = {Zhang, Yong and Li, Dan and Wang, Yuheng and Fang, Yang and Xiao, Weidong},
	month = apr,
	year = {2019},
	keywords = {⛔ No INSPIRE recid found},
	pages = {1665},
	file = {Zhang et al_2019_Abstract Text Summarization with a Convolutional Seq2seq Model.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/EWXGL9NT/Zhang et al_2019_Abstract Text Summarization with a Convolutional Seq2seq Model.pdf:application/pdf;Zhang et al. - 2019 - Abstract Text Summarization with a Convolutional S.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/435AWQ4D/Zhang et al. - 2019 - Abstract Text Summarization with a Convolutional S.pdf:application/pdf},
}

@article{palasundram_seq2seq_2021,
	title = {{SEQ2SEQ}++: {A} {Multitasking}-{Based} {Seq2seq} {Model} to {Generate} {Meaningful} and {Relevant} {Answers}},
	volume = {9},
	issn = {2169-3536},
	shorttitle = {{SEQ2SEQ}++},
	url = {https://ieeexplore.ieee.org/document/9638628/},
	doi = {10.1109/ACCESS.2021.3133495},
	abstract = {Question-answering chatbots have tremendous potential to complement humans in various ﬁelds. They are implemented using either rule-based or machine learning-based systems. Unlike the former, machine learning-based chatbots are more scalable. Sequence-to-sequence (Seq2Seq) learning is one of the most popular approaches in machine learning-based chatbots and has shown remarkable progress since its introduction in 2014. However, chatbots based on Seq2Seq learning show a weakness in that it tends to generate answers that can be generic and inconsistent with the questions, thereby becoming meaningless and, therefore, may lower the chatbot adoption rate. This weakness can be attributed to three issues: question encoder overﬁt, answer generation overﬁt, and language model inﬂuence. Several recent methods utilize multitask learning (MTL) to address this weakness. However, the existing MTL models show very little improvement over single-task learning, wherein they still generate generic and inconsistent answers. This paper presents a novel approach to MTL for the Seq2Seq learning model called SEQ2SEQ++, which comprises a multifunctional encoder, an answer decoder, an answer encoder, and a ternary classiﬁer. Additionally, SEQ2SEQ++ utilizes a dynamic tasks loss weight mechanism for MTL loss calculation and a novel attention mechanism called the comprehensive attention mechanism. Experiments on NarrativeQA and SQuAD datasets were conducted to gauge the performance of the proposed model in comparison with two recently proposed models. The experimental results show that SEQ2SEQ++ yields noteworthy improvements over the two models on bilingual evaluation understudy, word error rate, and Distinct-2 metrics.},
	language = {en},
	urldate = {2022-10-06},
	journal = {IEEE Access},
	author = {Palasundram, Kulothunkan and Mohd Sharef, Nurfadhlina and Kasmiran, Khairul Azhar and Azman, Azreen},
	year = {2021},
	keywords = {⛔ No INSPIRE recid found},
	pages = {164949--164975},
	file = {Palasundram et al_2021_SEQ2SEQ++.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/L5XPU3T4/Palasundram et al_2021_SEQ2SEQ++.pdf:application/pdf},
}

@inproceedings{yang_overview_2022,
	title = {An {Overview} \& {Analysis} of {Sequence}-to-{Sequence} {Emotional} {Voice} {Conversion}},
	url = {https://www.isca-speech.org/archive/interspeech_2022/yang22t_interspeech.html},
	doi = {10.21437/Interspeech.2022-10636},
	language = {en},
	urldate = {2022-10-06},
	booktitle = {Interspeech 2022},
	publisher = {ISCA},
	author = {Yang, Zijiang and Jing, Xin and Triantafyllopoulos, Andreas and Song, Meishu and Aslan, Ilhan and Schuller, Björn W.},
	month = sep,
	year = {2022},
	keywords = {⛔ No INSPIRE recid found},
	pages = {4915--4919},
	file = {Yang et al_2022_An Overview & Analysis of Sequence-to-Sequence Emotional Voice Conversion.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/YRHC8CEU/Yang et al_2022_An Overview & Analysis of Sequence-to-Sequence Emotional Voice Conversion.pdf:application/pdf},
}

@article{shao_transformer-based_2019,
	title = {Transformer-{Based} {Neural} {Network} for {Answer} {Selection} in {Question} {Answering}},
	volume = {7},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/8648373/},
	doi = {10.1109/ACCESS.2019.2900753},
	abstract = {Answer selection is a crucial subtask in the question answering (QA) system. Conventional avenues for this task mainly concentrate on developing linguistic tools that are limited in both performance and practicability. Answer selection approaches based on deep learning have been well investigated with the tremendous success of deep learning in natural language processing. However, the traditional neural networks employed in existing answer selection models, i.e., recursive neural network or convolutional neural network, typically suffer from obtaining the global text information due to their operating mechanisms. The recent Transformer neural network is considered to be good at extracting the global information by employing only self-attention mechanism. Thus, in this paper, we design a Transformer-based neural network for answer selection, where we deploy a bidirectional long short-term memory (BiLSTM) behind the Transformer to acquire both global information and sequential features in the question or answer sentence. Different from the original Transformer, our Transformer-based network focuses on sentence embedding rather than the seq2seq task. In addition, we employ a BiLSTM rather than utilizing the position encoding to incorporate sequential features as the universal Transformer does. Furthermore, we apply three aggregated strategies to generate sentence embeddings for question and answer, i.e., the weighted mean pooling, the max pooling, and the attentive pooling, leading to three corresponding Transformer-based models, i.e., QA-TFWP, QA-TFMP, and QA-TFAP, respectively. Finally, we evaluate our proposals on a popular QA dataset WikiQA. The experimental results demonstrate that our proposed Transformer-based answer selection models can produce a better performance compared with several competitive baselines. In detail, our best model outperforms the state-of-the-art baseline by up to 2.37\%, 2.83\%, and 3.79\% in terms of MAP, MRR, and accuracy, respectively.},
	language = {en},
	urldate = {2022-10-06},
	journal = {IEEE Access},
	author = {Shao, Taihua and Guo, Yupu and Chen, Honghui and Hao, Zepeng},
	year = {2019},
	keywords = {⛔ No INSPIRE recid found},
	pages = {26146--26156},
	file = {Shao et al_2019_Transformer-Based Neural Network for Answer Selection in Question Answering.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/Z7PUXSLU/Shao et al_2019_Transformer-Based Neural Network for Answer Selection in Question Answering.pdf:application/pdf;Shao et al. - 2019 - Transformer-Based Neural Network for Answer Select.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/DBMB9C6Z/Shao et al. - 2019 - Transformer-Based Neural Network for Answer Select.pdf:application/pdf},
}

@article{keneshloo_deep_2019,
	title = {Deep {Reinforcement} {Learning} for {Sequence}-to-{Sequence} {Models}},
	issn = {2162-237X, 2162-2388},
	url = {https://ieeexplore.ieee.org/document/8801910/},
	doi = {10.1109/TNNLS.2019.2929141},
	abstract = {In recent times, sequence-to-sequence (seq2seq) models have gained a lot of popularity and provide stateof-the-art performance in a wide variety of tasks, such as machine translation, headline generation, text summarization, speech-to-text conversion, and image caption generation. The underlying framework for all these models is usually a deep neural network comprising an encoder and a decoder. Although simple encoder–decoder models produce competitive results, many researchers have proposed additional improvements over these seq2seq models, e.g., using an attention-based model over the input, pointer-generation models, and self-attention models. However, such seq2seq models suffer from two common problems: 1) exposure bias and 2) inconsistency between train/test measurement. Recently, a completely novel point of view has emerged in addressing these two problems in seq2seq models, leveraging methods from reinforcement learning (RL). In this survey, we consider seq2seq problems from the RL point of view and provide a formulation combining the power of RL methods in decision-making with seq2seq models that enable remembering long-term memories. We present some of the most recent frameworks that combine the concepts from RL and deep neural networks. Our work aims to provide insights into some of the problems that inherently arise with current approaches and how we can address them with better RL models. We also provide the source code for implementing most of the RL models discussed in this paper to support the complex task of abstractive text summarization and provide some targeted experiments for these RL models, both in terms of performance and training time.},
	language = {en},
	urldate = {2022-10-05},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	author = {Keneshloo, Yaser and Shi, Tian and Ramakrishnan, Naren and Reddy, Chandan K.},
	year = {2019},
	keywords = {⛔ No INSPIRE recid found},
	pages = {1--21},
	file = {Keneshloo et al. - 2019 - Deep Reinforcement Learning for Sequence-to-Sequen.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/AUBTK8CT/Keneshloo et al. - 2019 - Deep Reinforcement Learning for Sequence-to-Sequen.pdf:application/pdf},
}

@article{strobelt_seq2seq-vis_2019-1,
	title = {Seq2seq-{Vis}: {A} {Visual} {Debugging} {Tool} for {Sequence}-to-{Sequence} {Models}},
	volume = {25},
	issn = {1077-2626, 1941-0506, 2160-9306},
	shorttitle = {Seq2seq-{Vis}},
	url = {https://ieeexplore.ieee.org/document/8494828/},
	doi = {10.1109/TVCG.2018.2865044},
	language = {en},
	number = {1},
	urldate = {2022-10-05},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Strobelt, Hendrik and Gehrmann, Sebastian and Behrisch, Michael and Perer, Adam and Pfister, Hanspeter and Rush, Alexander M.},
	month = jan,
	year = {2019},
	keywords = {⛔ No INSPIRE recid found},
	pages = {353--363},
	file = {Strobelt et al. - 2019 - Seq2seq-Vis A Visual Debugging Tool for Sequence-.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/Y8KL6NUF/Strobelt et al. - 2019 - Seq2seq-Vis A Visual Debugging Tool for Sequence-.pdf:application/pdf},
}

@misc{neubig_neural_2017,
	title = {Neural {Machine} {Translation} and {Sequence}-to-sequence {Models}: {A} {Tutorial}},
	shorttitle = {Neural {Machine} {Translation} and {Sequence}-to-sequence {Models}},
	url = {http://arxiv.org/abs/1703.01619},
	abstract = {This tutorial introduces a new and powerful set of techniques variously called "neural machine translation" or "neural sequence-to-sequence models". These techniques have been used in a number of tasks regarding the handling of human language, and can be a powerful tool in the toolbox of anyone who wants to model sequential data of some sort. The tutorial assumes that the reader knows the basics of math and programming, but does not assume any particular experience with neural networks or natural language processing. It attempts to explain the intuition behind the various methods covered, then delves into them with enough mathematical detail to understand them concretely, and culiminates with a suggestion for an implementation exercise, where readers can test that they understood the content in practice.},
	language = {en},
	urldate = {2022-10-09},
	publisher = {arXiv},
	author = {Neubig, Graham},
	month = mar,
	year = {2017},
	note = {arXiv:1703.01619 [cs, stat]},
	keywords = {⛔ No INSPIRE recid found, Computer Science - Computation and Language, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Neubig - 2017 - Neural Machine Translation and Sequence-to-sequenc.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/PXRXF2J9/Neubig - 2017 - Neural Machine Translation and Sequence-to-sequenc.pdf:application/pdf},
}

@inproceedings{karthikayani_k_survey_2020,
	address = {Kuala Lumpur, Malaysia},
	title = {A survey on deep learning feature extraction techniques},
	url = {http://aip.scitation.org/doi/abs/10.1063/5.0028564},
	doi = {10.1063/5.0028564},
	abstract = {The major advancing techniques in machine learning are mainly two, they are deep learning and computer vision. The advanced deep learning techniques are highly promising to increase the interest in research within the upcoming years. This is often because the eminent benefits in overcoming the drawbacks within the outdated techniques for producing the result accurately. The theme of this paper is to provide a comprehensive description on the convolution neural network and its recent improvements which includes the CNN – S convolution neural network segmentation, CNN – CBIR convolution neural network – content-based image retrieval system. This survey paper provides a detailed summary within the latest advancements in the domain of CNN with various extended applications through its classification for improved understanding. Analysing the performance is done considering the speed, accuracy and ease.},
	language = {en},
	urldate = {2022-10-11},
	author = {{Karthikayani K.} and Arunachalam, A. R.},
	year = {2020},
	keywords = {⛔ No INSPIRE recid found},
	pages = {020035},
	file = {Karthikayani K. and Arunachalam - 2020 - A survey on deep learning feature extraction techn.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/CSQFHNLF/Karthikayani K. and Arunachalam - 2020 - A survey on deep learning feature extraction techn.pdf:application/pdf},
}

@inproceedings{kalaiselvi_comparative_2022,
	address = {Coimbatore, India},
	title = {A comparative analysis of multiple methodologies of brain tumor detection in machine learning techniques},
	url = {http://aip.scitation.org/doi/abs/10.1063/5.0109719},
	doi = {10.1063/5.0109719},
	abstract = {Detecting the brain tumor via Magnetic Resonance Image is difficult within the scientific imaging studies area. MRI is a scientific method, frequently utilized with the x-rays for visual images of the inside shape of the physical body with no surgical operation. The primary expectation of medical imaging is to split essential and precise statistics from these pics with the least blunder doable. Out of the m o r e t h a n a couple of forms of clinical imaging paperwork reachable to us, MRI is the most reliable and secure. It does no longer incorporate providing the body w i t h any hurtful radiation. This MRI could then be capable of bei n g handled, and the tumor can be portioned. Tumor Segmentation incorporates the utilization of particular diverse methods. The entire approach of distinguishing tumor from a Magnetic Resonance Image into three specific training: Pre-Processing, Segmentation, and Post Processing. Aside from summarizing the literature, this paper evaluate s multiple techniques utilized in the literature survey.},
	language = {en},
	urldate = {2022-10-11},
	author = {Kalaiselvi, S. and Thailambal, G.},
	year = {2022},
	keywords = {⛔ No INSPIRE recid found},
	pages = {030064},
	file = {Kalaiselvi and Thailambal - 2022 - A comparative analysis of multiple methodologies o.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/2W4V4PKF/Kalaiselvi and Thailambal - 2022 - A comparative analysis of multiple methodologies o.pdf:application/pdf},
}

@inproceedings{jayandhi_mammogram_2022,
	address = {Brunei},
	title = {Mammogram image classification system using deep learning for breast cancer diagnosis},
	url = {http://aip.scitation.org/doi/abs/10.1063/5.0109640},
	doi = {10.1063/5.0109640},
	abstract = {Mammography is the common screening method of breast cancer, a deadly disease among women in the world with a high mortality rate. Breast cancer is the uncontrollable cell growth as a tumor that may be cancerous or noncancerous. This study employs a Deep Convolution Neural Network (DCNN) with Transfer Learning (TL) that utilizes mammogram image samples for breast cancer diagnosis. The contrast enhancement of the suspicious image tumor is done by using the Contrast Limited Adaptive Histogram Equalization (CLAHE) technique on Region of Interest (ROI). The VGG-16 network model is utilized with reduced convolution layers and max-pooling layers providing more feature datasets for efficient mammogram classification into either benign or malignant cancer for early diagnosis for its appropriate treatment. The performance of the VGG16 model is compared with the VGG-19 net. Results show that VGG-16 architecture provides promising results than VGG-19 on Mammographic Image Analysis Society (MIAS) database images with 82.5\% accuracy.},
	language = {en},
	urldate = {2022-10-11},
	author = {Jayandhi, G. and Jasmine, J. S. Leena and Joans, S. Mary},
	year = {2022},
	keywords = {⛔ No INSPIRE recid found},
	pages = {030066},
	file = {Jayandhi et al. - 2022 - Mammogram image classification system using deep l.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/RK52Z2L7/Jayandhi et al. - 2022 - Mammogram image classification system using deep l.pdf:application/pdf},
}

@article{zhang_keywords_2020,
	title = {Keywords extraction with deep neural network model},
	volume = {383},
	issn = {09252312},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S092523121931687X},
	doi = {10.1016/j.neucom.2019.11.083},
	abstract = {Keywords can express the main content of an article or a sentence. Keywords extraction is a critical issue in many Natural Language Processing (NLP) applications and can improve the performance of many NLP systems. The traditional methods of keywords extraction are based on machine learning or graph model. The performance of these methods is inﬂuenced by the feature selection and the manually deﬁned rules. In recent years, with the emergence of deep learning technology, learning features automatically with the deep learning algorithm can improve the performance of many tasks. In this paper, we propose a deep neural network model for the task of keywords extraction. We make two extensions on the basis of traditional LSTM model. First, to better utilize both the historic and following contextual information of the given target word, we propose a target center-based LSTM model (TC-LSTM), which learns to encode the target word by considering its contextual information. Second, on the basis of TCLSTM model, we apply the self-attention mechanism, which enables our model has an ability to focus on informative parts of the associated text. In addition, we also introduce a two-stage training method, which takes advantage of large-scale pseudo training data. Experimental results show the advantage of our method, our model beats all the baseline systems all across the board. And also, the two-stage training method is of great signiﬁcance for improving the effectiveness of the model.},
	language = {en},
	urldate = {2022-11-08},
	journal = {Neurocomputing},
	author = {Zhang, Yu and Tuo, Mingxiang and Yin, Qingyu and Qi, Le and Wang, Xuxiang and Liu, Ting},
	month = mar,
	year = {2020},
	keywords = {⛔ No INSPIRE recid found},
	pages = {113--121},
	file = {Zhang et al. - 2020 - Keywords extraction with deep neural network model.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/SG8DTM73/Zhang et al. - 2020 - Keywords extraction with deep neural network model.pdf:application/pdf},
}

@misc{meng_deep_2021,
	title = {Deep {Keyphrase} {Generation}},
	url = {http://arxiv.org/abs/1704.06879},
	abstract = {Keyphrase provides highly-condensed information that can be effectively used for understanding, organizing and retrieving text content. Though previous studies have provided many workable solutions for automated keyphrase extraction, they commonly divided the to-be-summarized content into multiple text chunks, then ranked and selected the most meaningful ones. These approaches could neither identify keyphrases that do not appear in the text, nor capture the real semantic meaning behind the text. We propose a generative model for keyphrase prediction with an encoder-decoder framework, which can effectively overcome the above drawbacks. We name it as deep keyphrase generation since it attempts to capture the deep semantic meaning of the content with a deep learning method. Empirical analysis on six datasets demonstrates that our proposed model not only achieves a signiﬁcant performance boost on extracting keyphrases that appear in the source text, but also can generate absent keyphrases based on the semantic meaning of the text. Code and dataset are available at https://github.com/memray/OpenNMTkpg-release.},
	language = {en},
	urldate = {2022-11-08},
	publisher = {arXiv},
	author = {Meng, Rui and Zhao, Sanqiang and Han, Shuguang and He, Daqing and Brusilovsky, Peter and Chi, Yu},
	month = may,
	year = {2021},
	note = {arXiv:1704.06879 [cs]},
	keywords = {⛔ No INSPIRE recid found, Computer Science - Computation and Language},
	file = {Meng et al. - 2021 - Deep Keyphrase Generation.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/2XXAKCDN/Meng et al. - 2021 - Deep Keyphrase Generation.pdf:application/pdf},
}

@inproceedings{prabhavalkar_analysis_2017,
	title = {An {Analysis} of “{Attention}” in {Sequence}-to-{Sequence} {Models}},
	url = {https://www.isca-speech.org/archive/interspeech_2017/prabhavalkar17b_interspeech.html},
	doi = {10.21437/Interspeech.2017-232},
	abstract = {In this paper, we conduct a detailed investigation of attentionbased models for automatic speech recognition (ASR). First, we explore different types of attention, including “online” and “full-sequence” attention. Second, we explore different subword units to see how much of the end-to-end ASR process can reasonably be captured by an attention model. In experimental evaluations, we ﬁnd that although attention is typically focused over a small region of the acoustics during each step of next label prediction, “full-sequence” attention outperforms “online” attention, although this gap can be signiﬁcantly reduced by increasing the length of the segments over which attention is computed. Furthermore, we ﬁnd that context-independent phonemes are a reasonable sub-word unit for attention models. When used in the second-pass to rescore N-best hypotheses, these models provide over a 10\% relative improvement in word error rate.},
	language = {en},
	urldate = {2022-11-07},
	booktitle = {Interspeech 2017},
	publisher = {ISCA},
	author = {Prabhavalkar, Rohit and Sainath, Tara N. and Li, Bo and Rao, Kanishka and Jaitly, Navdeep},
	month = aug,
	year = {2017},
	keywords = {⛔ No INSPIRE recid found},
	pages = {3702--3706},
	file = {Prabhavalkar et al. - 2017 - An Analysis of “Attention” in Sequence-to-Sequence.PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/FMV4QQCQ/Prabhavalkar et al. - 2017 - An Analysis of “Attention” in Sequence-to-Sequence.PDF:application/pdf},
}

@article{wulandari_targets_2022,
	title = {The {Targets} for {Stunting} {Prevention} {Policies} in {Papua}, {Indonesia}: {What} {Mothers}’ {Characteristics} {Matter}?},
	volume = {14},
	issn = {2072-6643},
	shorttitle = {The {Targets} for {Stunting} {Prevention} {Policies} in {Papua}, {Indonesia}},
	url = {https://www.mdpi.com/2072-6643/14/3/549},
	doi = {10.3390/nu14030549},
	abstract = {The study aimed to analyze the most appropriate maternal characteristics for stunting prevention policies. The study employed secondary data from the 2017 Indonesia Nutritional Status Monitoring Survey. The study obtained weighted samples of 11,887 Papuan children under ﬁve years of age. On the other hand, the study used the nutritional status as an outcome variable and maternal characteristics as an exposure variable. The research employed the following four control variables: residence, region, under-ﬁve age, and gender. The study occupied the binary logistic regression. The results show that mothers who graduated from primary school and under were 1.263 times more likely than mothers with a college education to have stunted children. Mothers who graduated from junior high school are 1.222 times more likely than mothers with a college education to have stunted children. Mothers who graduated from senior high school were 1.122 times more likely than mothers with a college education to have stunted children. Mothers with a never-married status have a 1.138 times greater probability than divorced/widowed mothers to have stunted children. Meanwhile, married mothers are 0.936 times more likely than divorced/widowed mothers to have stunted children. The study concluded that the target group for stunting prevention policies are mothers with poor education and who are single.},
	language = {en},
	number = {3},
	urldate = {2022-11-14},
	journal = {Nutrients},
	author = {Wulandari, Ratna Dwi and Laksono, Agung Dwi and Kusrini, Ina and Tahangnacca, Minsarnawati},
	month = jan,
	year = {2022},
	keywords = {⛔ No INSPIRE recid found},
	pages = {549},
	file = {Wulandari et al. - 2022 - The Targets for Stunting Prevention Policies in Pa.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/SQKTQ9Q9/Wulandari et al. - 2022 - The Targets for Stunting Prevention Policies in Pa.pdf:application/pdf},
}

@article{you_st-seq2seq_2020,
	title = {{ST}-{Seq2Seq}: {A} {Spatio}-{Temporal} {Feature}-{Optimized} {Seq2Seq} {Model} for {Short}-{Term} {Vessel} {Trajectory} {Prediction}},
	volume = {8},
	issn = {2169-3536},
	shorttitle = {{ST}-{Seq2Seq}},
	url = {https://ieeexplore.ieee.org/document/9276488/},
	doi = {10.1109/ACCESS.2020.3041762},
	abstract = {Deep learning provides appropriate mechanisms to predict vessel trajectories for safer and efﬁcient shipping, but still existing models are mainly oriented to longer-term prediction trends and do not fully support real time navigation needs. While most recent works have been largely exploiting Automatic Identiﬁcation System (AIS), the complete semantics of these data haven’t so far fully exploited. The research presented in this paper introduced an extended sequence-to-sequence model using AIS data. A Gated Recurrent Unit (GRU) network encodes historical spatio-temporal sequences as a context vector, which not only preserves the sequential relationships among trajectory locations, but also alleviates the gradient descent problem. The GRU network acts as a decoder, outputting target trajectory location sequences. Real AIS data from the Chongqing and Wuhan sections of the Yangzi River were selected as typical experimental areas for evaluation purposes. The proposed ST-Seq2Seq model has been tested against the LSTM-RNN and GRU-RNN baseline models for short term trajectory prediction experiments. A 10-minute historical trajectory sequence was used to predict the trajectory sequence for the next ﬁve minutes. Overall, the ﬁndings show that LSTM and GRU networks, while applying a recursive method to predict a sequence of continuous trajectory points, when the number of predicted trajectory points increases accuracy decreases. Conversely, the extended sequence-to-sequence model shows satisfactory stability on different ship channels.},
	language = {en},
	urldate = {2022-11-25},
	journal = {IEEE Access},
	author = {You, Lan and Xiao, Siyu and Peng, Qingxi and Claramunt, Christophe and Han, Xuewei and Guan, Zhengyi and Zhang, Jiahe},
	year = {2020},
	keywords = {⛔ No INSPIRE recid found},
	pages = {218565--218574},
	file = {You et al. - 2020 - ST-Seq2Seq A Spatio-Temporal Feature-Optimized Se.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/6QGA4B82/You et al. - 2020 - ST-Seq2Seq A Spatio-Temporal Feature-Optimized Se.pdf:application/pdf},
}

@inproceedings{yu_computation_2017,
	address = {Montreal, QC},
	title = {Computation offloading for mobile edge computing: {A} deep learning approach},
	isbn = {978-1-5386-3529-2 978-1-5386-3531-5},
	shorttitle = {Computation offloading for mobile edge computing},
	url = {http://ieeexplore.ieee.org/document/8292514/},
	doi = {10.1109/PIMRC.2017.8292514},
	abstract = {Computation ofﬂoading has already shown itself to be successful for enabling resource-intensive applications on mobile devices. Moreover, in view of mobile edge computing (MEC) system, mobile devices can ofﬂoad compute-intensive tasks to a nearby cloudlet, so as to save the energy and enhance the processing speed. However, due to the varying network conditions and limited computation resources of cloudlets, the ofﬂoading actions taken by a mobile user may not achieve the lowest cost. In this paper, we develop a dynamic ofﬂoading framework for mobile users, considering the local overhead in the mobile terminal side, as well as the limited communication and computation resources in the network side. We formulate the ofﬂoading decision problem as a multi-label classiﬁcation problem and develop the Deep Supervised Learning (DSL) method to minimize the computation and ofﬂoading overhead. Simulation results show that our proposal can reduce system cost up to 49.24\%, 23.87\%, 15.69\%, and 11.18\% compared to the “no ofﬂoading” scheme, “random ofﬂoading” scheme, “total ofﬂoading” scheme and “multi-label linear classiﬁerbased ofﬂoading” scheme, respectively.},
	language = {en},
	urldate = {2022-11-30},
	booktitle = {2017 {IEEE} 28th {Annual} {International} {Symposium} on {Personal}, {Indoor}, and {Mobile} {Radio} {Communications} ({PIMRC})},
	publisher = {IEEE},
	author = {Yu, Shuai and Wang, Xin and Langar, Rami},
	month = oct,
	year = {2017},
	keywords = {⛔ No INSPIRE recid found},
	pages = {1--6},
	file = {Yu et al. - 2017 - Computation offloading for mobile edge computing .pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/WFGAFDMT/Yu et al. - 2017 - Computation offloading for mobile edge computing .pdf:application/pdf},
}

@article{lan_you_st-seq2seq_2020,
	title = {{ST}-{Seq2Seq}: {A} {Spatio}-{Temporal} {Feature}-{Optimized} {Seq2Seq} {Model} for {Short}-{Term} {Vessel} {Trajectory} {Prediction}},
	volume = {8},
	doi = {10.1109/access.2020.3041762},
	abstract = {Deep learning provides appropriate mechanisms to predict vessel trajectories for safer and efficient shipping, but still existing models are mainly oriented to longer-term prediction trends and do not fully support real time navigation needs. While most recent works have been largely exploiting Automatic Identification System (AIS), the complete semantics of these data haven’t so far fully exploited. The research presented in this paper introduced an extended sequence-to-sequence model using AIS data. A Gated Recurrent Unit (GRU) network encodes historical spatio-temporal sequences as a context vector, which not only preserves the sequential relationships among trajectory locations, but also alleviates the gradient descent problem. The GRU network acts as a decoder, outputting target trajectory location sequences. Real AIS data from the Chongqing and Wuhan sections of the Yangzi River were selected as typical experimental areas for evaluation purposes. The proposed ST-Seq2Seq model has been tested against the LSTM-RNN and GRU-RNN baseline models for short term trajectory prediction experiments. A 10-minute historical trajectory sequence was used to predict the trajectory sequence for the next five minutes. Overall, the findings show that LSTM and GRU networks, while applying a recursive method to predict a sequence of continuous trajectory points, when the number of predicted trajectory points increases accuracy decreases. Conversely, the extended sequence-to-sequence model shows satisfactory stability on different ship channels.},
	journal = {IEEE Access},
	author = {{Lan You} and You, Lan and Xiao, Siyu and Peng, Qingxi and Peng, Qingxi and Claramunt, Christophe and {Christophe Claramunt} and Claramunt, Christophe and Han, Xuewei and Guan, Zhengyi and Zhang, Jiahe},
	year = {2020},
	doi = {10.1109/access.2020.3041762},
	note = {MAG ID: 3108542629
S2ID: 6bcbddc43a369c0915c4611f6929ab5aa5f4ff1f},
	keywords = {⛔ No INSPIRE recid found},
	pages = {218565--218574},
}

@inproceedings{nguyen_vessel_2018,
	address = {Hamilton New Zealand},
	title = {Vessel {Trajectory} {Prediction} using {Sequence}-to-{Sequence} {Models} over {Spatial} {Grid}},
	isbn = {978-1-4503-5782-1},
	url = {https://dl.acm.org/doi/10.1145/3210284.3219775},
	doi = {10.1145/3210284.3219775},
	abstract = {In this paper, we propose a neural network based system to predict vessels’ trajectories including the destination port and estimated arrival time. The system is designed to address DEBS Grand Challenge 2018, which provides a set of data streams containing vessel information and coordinates ordered by time. Our goal is to design a system which can accurately predict future trajectories, destination port and arrival time for a vessel.},
	language = {en},
	urldate = {2022-12-05},
	booktitle = {Proceedings of the 12th {ACM} {International} {Conference} on {Distributed} and {Event}-based {Systems}},
	publisher = {ACM},
	author = {Nguyen, Duc-Duy and Le Van, Chan and Ali, Muhammad Intizar},
	month = jun,
	year = {2018},
	keywords = {⛔ No INSPIRE recid found},
	pages = {258--261},
	file = {Nguyen et al. - 2018 - Vessel Trajectory Prediction using Sequence-to-Seq.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/5H7L2A3D/Nguyen et al. - 2018 - Vessel Trajectory Prediction using Sequence-to-Seq.pdf:application/pdf},
}

@article{forti_prediction_nodate,
	title = {{PREDICTION} {OF} {VESSEL} {TRAJECTORIES} {FROM} {AIS} {DATA} {VIA} {SEQUENCE}-{TO}-{SEQUENCE} {RECURRENT} {NEURAL} {NETWORKS}},
	abstract = {In this paper, we address the problem of predicting vessel trajectories based on Automatic Identiﬁcation System (AIS) data. The goal is to learn the predictive distribution of maritime trafﬁc patterns using historical data during the training phase, in order to be able to forecast future target trajectory samples online on the basis of both the extracted knowledge and the available observation sequence. We explore neural sequence-to-sequence models based on the Long Short-Term Memory (LSTM) encoder-decoder architecture to effectively capture long-term temporal dependencies of sequential AIS data and increase the overall predictive power. The experimental evaluation on a real-world AIS dataset demonstrates the effectiveness of sequence-to-sequence recurrent neural networks (RNNs) for vessel trajectory prediction and shows their potential beneﬁts compared to model-based methods.},
	language = {en},
	author = {Forti, Nicola and Milleﬁori, Leonardo M and Braca, Paolo and Willett, Peter},
	keywords = {⛔ No INSPIRE recid found},
	pages = {5},
	file = {Forti et al. - PREDICTION OF VESSEL TRAJECTORIES FROM AIS DATA VI.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/SATHIEXD/Forti et al. - PREDICTION OF VESSEL TRAJECTORIES FROM AIS DATA VI.pdf:application/pdf},
}

@article{capobianco_deep_2021,
	title = {Deep {Learning} {Methods} for {Vessel} {Trajectory} {Prediction} based on {Recurrent} {Neural} {Networks}},
	volume = {57},
	issn = {0018-9251, 1557-9603, 2371-9877},
	url = {http://arxiv.org/abs/2101.02486},
	doi = {10.1109/TAES.2021.3096873},
	abstract = {Data-driven methods open up unprecedented possibilities for maritime surveillance using Automatic Identiﬁcation System (AIS) data. In this work, we explore deep learning strategies using historical AIS observations to address the problem of predicting future vessel trajectories with a prediction horizon of several hours. We propose novel sequence-tosequence vessel trajectory prediction models based on encoderdecoder recurrent neural networks (RNNs) that are trained on historical trajectory data to predict future trajectory samples given previous observations. The proposed architecture combines Long Short-Term Memory (LSTM) RNNs for sequence modeling to encode the observed data and generate future predictions with different intermediate aggregation layers to capture spacetime dependencies in sequential data. Experimental results on vessel trajectories from an AIS dataset made freely available by the Danish Maritime Authority show the effectiveness of deeplearning methods for trajectory prediction based on sequenceto-sequence neural networks, which achieve better performance than baseline approaches based on linear regression or on the Multi-Layer Perceptron (MLP) architecture. The comparative evaluation of results shows: i) the superiority of attention pooling over static pooling for the speciﬁc application, and ii) the remarkable performance improvement that can be obtained with labeled trajectories, i.e., when predictions are conditioned on a low-level context representation encoded from the sequence of past observations, as well as on additional inputs (e.g., port of departure or arrival) about the vessel’s high-level intention which may be available from AIS.},
	language = {en},
	number = {6},
	urldate = {2022-12-05},
	journal = {IEEE Transactions on Aerospace and Electronic Systems},
	author = {Capobianco, Samuele and Millefiori, Leonardo M. and Forti, Nicola and Braca, Paolo and Willett, Peter},
	month = dec,
	year = {2021},
	note = {arXiv:2101.02486 [cs]},
	keywords = {⛔ No INSPIRE recid found, Computer Science - Computer Vision and Pattern Recognition},
	pages = {4329--4346},
	file = {Capobianco et al. - 2021 - Deep Learning Methods for Vessel Trajectory Predic.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/9UA8TFWV/Capobianco et al. - 2021 - Deep Learning Methods for Vessel Trajectory Predic.pdf:application/pdf},
}

@article{natesha_meta-heuristic_2022-1,
	title = {Meta-heuristic {Based} {Hybrid} {Service} {Placement} {Strategies} for {Two}-{Level} {Fog} {Computing} {Architecture}},
	volume = {30},
	issn = {1064-7570, 1573-7705},
	url = {https://link.springer.com/10.1007/s10922-022-09660-w},
	doi = {10.1007/s10922-022-09660-w},
	abstract = {The smart manufacturing industry (Industry 4.0) uses the Internet of Things (IoT) devices referred to as Industrial IoT (IIoT) to automate the industrial environment. These IIoT devices generate a massive amount of data called big data. Using fog computing architecture for processing this extensive data will reduce the service time and the service cost for the IIoT applications. The primary challenge is to design better service placement strategies to deploy the IIoT service requests on the fog nodes to minimize service costs and ensure the Quality of Service (QoS) of IIoT applications. Hence, the placement of IIoT services on the fog nodes can be considered as NP-hard problem. In this work, the meta-heuristic-based hybrid algorithms, namely: MGAPSO and EGAPSO, are developed by combining the GA \& PSO and Elitism-based GA (EGA) \& PSO, respectively. Further, carried out experiments on the two-level fog computing framework developed using docker and containers on 1.4 GHz, 64-bit quad-core processor devices. Experimental results demonstrate that the proposed hybrid EGAPSO algorithm minimizes service time, service cost, and energy consumption and ensures the IIoT applications’ QoS compared to other proposed and state-of-the-art service placement strategies considered for the performance evaluation.},
	language = {en},
	number = {3},
	urldate = {2023-01-08},
	journal = {Journal of Network and Systems Management},
	author = {Natesha, B. V. and Guddeti, Ram Mohana Reddy},
	month = jul,
	year = {2022},
	keywords = {⛔ No INSPIRE recid found},
	pages = {47},
	file = {Natesha and Guddeti - 2022 - Meta-heuristic Based Hybrid Service Placement Stra.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/LBI7KD24/Natesha and Guddeti - 2022 - Meta-heuristic Based Hybrid Service Placement Stra.pdf:application/pdf},
}

@article{zeng_trajectory-as--sequence_2023,
	title = {Trajectory-as-a-{Sequence}: {A} novel travel mode identification framework},
	volume = {146},
	issn = {0968-090X},
	url = {https://www.sciencedirect.com/science/article/pii/S0968090X22003709},
	doi = {10.1016/j.trc.2022.103957},
	abstract = {Identifying travel modes from GPS tracks, as an essential technique to understand the travel behavior of a population, has received widespread interest over the past decade. While most previous Travel Mode Identification (TMI) methods separately identify the mode of each track segment of a GPS trajectory, in this paper, we propose a sequence-based TMI framework that constructs a feature sequence for each GPS trajectory and sent it to a sequence-to-sequence (seq2seq) model to obtain the corresponding travel mode label sequence, named Trajectory-as-a-Sequence (TaaS). The proposed seq2seq model consists of a Convolutional Encoder (CE) and a Recurrent Conditional Random Field (RCRF), where the CE extracts high-level features from the point-level trajectory features and the RCRF learns the context information of trajectories at both feature and label levels, thus outputting accurate and reasonable travel mode label sequences. To alleviate the lack of data, we adopted a two-stage model training strategy. Additionally, we design two novel bus-related features to assist the seq2seq model distinguishing different high-speed travel modes (i.e., bus, car, and railway) in the sequence. Besides the classical performance metrics such as accuracy, we propose a new metric that evaluates the rationality of the travel mode label sequence at the trajectory level. Comprehensive evaluations corresponding to the real-world TMI applications show that the sequence-based TaaS outperforms the segment-based models in practice. Furthermore, the results of ablation studies demonstrate that the elements integrated into the TaaS framework are helpful to improve the efficiency and accuracy of TMI.},
	journal = {Transportation Research Part C: Emerging Technologies},
	author = {Zeng, Jiaqi and Yu, Yi and Chen, Yong and Yang, Di and Zhang, Lei and Wang, Dianhai},
	month = jan,
	year = {2023},
	keywords = {Deep learning, GIS information, GPS data, Sequence-to-sequence model, Travel mode identification},
	pages = {103957},
}

@book{noauthor_internet_nodate,
	title = {Internet {Computing}},
	keywords = {⛔ No INSPIRE recid found},
}

@article{badidi_fog_2020,
	title = {Fog {Computing} for {Smart} {Cities}’ {Big} {Data} {Management} and {Analytics}: {A} {Review}},
	volume = {12},
	issn = {1999-5903},
	shorttitle = {Fog {Computing} for {Smart} {Cities}’ {Big} {Data} {Management} and {Analytics}},
	url = {https://www.mdpi.com/1999-5903/12/11/190},
	doi = {10.3390/fi12110190},
	abstract = {Demographic growth in urban areas means that modern cities face challenges in ensuring a steady supply of water and electricity, smart transport, livable space, better health services, and citizens’ safety. Advances in sensing, communication, and digital technologies promise to mitigate these challenges. Hence, many smart cities have taken a new step in moving away from internal information technology (IT) infrastructure to utility-supplied IT delivered over the Internet. The beneﬁt of this move is to manage the vast amounts of data generated by the various city systems, including water and electricity systems, the waste management system, transportation system, public space management systems, health and education systems, and many more. Furthermore, many smart city applications are time-sensitive and need to quickly analyze data to react promptly to the various events occurring in a city. The new and emerging paradigms of edge and fog computing promise to address big data storage and analysis in the ﬁeld of smart cities. Here, we review existing service delivery models in smart cities and present our perspective on adopting these two emerging paradigms. We speciﬁcally describe the design of a fog-based data pipeline to address the issues of latency and network bandwidth required by time-sensitive smart city applications.},
	language = {en},
	number = {11},
	urldate = {2023-03-20},
	journal = {Future Internet},
	author = {Badidi, Elarbi and Mahrez, Zineb and Sabir, Essaid},
	month = oct,
	year = {2020},
	keywords = {⛔ No INSPIRE recid found},
	pages = {190},
	file = {Badidi et al. - 2020 - Fog Computing for Smart Cities’ Big Data Managemen.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/TA9IYFZK/Badidi et al. - 2020 - Fog Computing for Smart Cities’ Big Data Managemen.pdf:application/pdf},
}

@article{mir_antifragile_2022,
	title = {Antifragile and {Resilient} {Geographical} {Information} {System} {Service} {Delivery} in {Fog} {Computing}},
	volume = {22},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/22/22/8778},
	doi = {10.3390/s22228778},
	abstract = {The demand for cloud computing has drastically increased recently, but this paradigm has several issues due to its inherent complications, such as non-reliability, latency, lesser mobility support, and location-aware services. Fog computing can resolve these issues to some extent, yet it is still in its infancy. Despite several existing works, these works lack fault-tolerant fog computing, which necessitates further research. Fault tolerance enables the performing and provisioning of services despite failures and maintains anti-fragility and resiliency. Fog computing is highly diverse in terms of failures as compared to cloud computing and requires wide research and investigation. From this perspective, this study primarily focuses on the provision of uninterrupted services through fog computing. A framework has been designed to provide uninterrupted services while maintaining resiliency. The geographical information system (GIS) services have been deployed as a test bed which requires high computation, requires intensive resources in terms of CPU and memory, and requires low latency. Keeping different types of failures at different levels and their impacts on service failure and greater response time in mind, the framework was made anti-fragile and resilient at different levels. Experimental results indicate that during service interruption, the user state remains unaffected.},
	language = {en},
	number = {22},
	urldate = {2023-03-24},
	journal = {Sensors},
	author = {Mir, Tahira Sarwar and Liaqat, Hannan Bin and Kiren, Tayybah and Sana, Muhammad Usman and Alvarez, Roberto Marcelo and Miró, Yini and Pascual Barrera, Alina Eugenia and Ashraf, Imran},
	month = nov,
	year = {2022},
	keywords = {⛔ No INSPIRE recid found},
	pages = {8778},
	file = {Mir et al. - 2022 - Antifragile and Resilient Geographical Information.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/4ZQTL46W/Mir et al. - 2022 - Antifragile and Resilient Geographical Information.pdf:application/pdf},
}

@article{w_saeed_fault_2021,
	title = {A {Fault} {Tolerant} {Data} {Management} {Scheme} for {Healthcare} {Internet} of {Things} in {Fog} {Computing}},
	doi = {10.3837/tiis.2021.01.003},
	abstract = {Fog computing aims to provide the solution of bandwidth, network latency and energy consumption problems of cloud computing Likewise, management of data generated by healthcare IoT devices is one of the significant applications of fog computing Huge amount of data is being generated by healthcare IoT devices and such types of data is required to be managed efficiently, with low latency, without failure, and with minimum energy consumption and low cost Failures of task or node can cause more latency, maximum energy consumption and high cost Thus, a failure free, cost efficient, and energy aware management and scheduling scheme for data generated by healthcare IoT devices not only improves the performance of the system but also saves the precious lives of patients because of due to minimum latency and provision of fault tolerance Therefore, to address all such challenges with regard to data management and fault tolerance, we have presented a Fault Tolerant Data management (FTDM) scheme for healthcare IoT in fog computing In FTDM, the data generated by healthcare IoT devices is efficiently organized and managed through well-defined components and steps A two way fault-tolerant mechanism i e , task-based fault-tolerance and node-based fault-tolerance, is provided in FTDM through which failure of tasks and nodes are managed The paper considers energy consumption, execution cost, network usage, latency, and execution time as performance evaluation parameters The simulation results show significantly improvements which are performed using iFogSim Further, the simulation results show that the proposed FTDM strategy reduces energy consumption 3 97\%, execution cost 5 09\%, network usage 25 88\%, latency 44 15\% and execution time 48 89\% as compared with existing Greedy Knapsack Scheduling (GKS) strategy Moreover, it is worthwhile to mention that sometimes the patients are required to be treated remotely due to non-availability of facilities or due to some infectious diseases such as COVID-19 Thus, in such circumstances, the proposed strategy is significantly efficient © 2021 Korean Society for Internet Information All rights reserved},
	journal = {KSII Transactions on Internet and Information Systems},
	author = {{W. Saeed} and {Z. Ahmad} and {A. I. Jehangiri} and {N. Mohamed} and {A. Umar} and {J. Ahmad}},
	year = {2021},
	doi = {10.3837/tiis.2021.01.003},
	note = {S2ID: 654926c78c6f20e72e86457267c920126041a359},
	keywords = {⛔ No INSPIRE recid found},
}

@article{mohamed_towards_2019,
	title = {Towards {Fault} {Tolerant} {Fog} {Computing} for {IoT}-{Based} {Smart} {City} {Applications}},
	doi = {10.1109/ccwc.2019.8666447},
	abstract = {Fog computing can provide many services to support IoT-based smart city applications. Fog computing usually consists of multiple nodes that are distributed across a smart city to enable IoT-based smart city applications such as intelligent transportation, smart energy, smart water, smart health, smart infrastructure monitoring, and smart environmental monitoring. The Fog platform will allow executing services geographically close to the IoT-based smart city applications to provide low latency, location awareness, mobility, streaming, management, and real-time support. One of the main issues with this support is the reliability and fault tolerance of the fog platform. This paper discusses the issues of reliability and fault tolerance for fog platforms supporting IoT-based smart city applications. It investigates different considerations to achieve a good degree of fault-tolerance for fog computing supporting smart city applications. The paper also proposes fault tolerance middleware services for fog computing to help solve reliability and fault tolerance issues. These services can provide a more reliable environment to operate IoT-based smart city applications.},
	journal = {Computing and Communication Workshop and Conference},
	author = {Mohamed, Nader and Al-Jaroodi, Jameela and Jawhar, Imad},
	month = jan,
	year = {2019},
	doi = {10.1109/ccwc.2019.8666447},
	note = {MAG ID: 2922338351
S2ID: 33ffc8895d678209d210827cbe2e829fa5ec3fb3},
	keywords = {⛔ No INSPIRE recid found},
	pages = {752--757},
}

@article{yash_shah_fault_2021,
	title = {Fault {Tolerance} in {Cloud} and {Fog} {Computing}—{A} {Holistic} {View}},
	doi = {10.1007/978-981-15-4474-3_46},
	abstract = {Cloud computing is paramount in information technology, and cloud computing has revolutionized the traditional ways of dealing with IT resources. Fog computing can be used in both large cloud systems and big data structures which is used for solving growing difficulties in information technology. Cloud computing and fog computing are used for large amount of storage, data and applications for the end users. Compared to cloud, fog computing is near to the end users. The major difference between cloud computing and fog computing is that cloud computing is centralized system and fog computing is distributed decentralized infrastructure. Many faults occur in cloud and fog computing, and there are various methods for fault tolerant techniques.},
	journal = {Lecture Notes on Data Engineering and Communications Technologies},
	author = {{Yash Shah} and {Yash Shah} and Shah, Yash and Thakkar, Ekta and Bhavsar, Sejal},
	month = jan,
	year = {2021},
	doi = {10.1007/978-981-15-4474-3_46},
	note = {MAG ID: 3037996492
S2ID: c5efe473cf738ec4834724bff030a815c9b22634},
	keywords = {⛔ No INSPIRE recid found},
	pages = {415--422},
}

@article{mohd_hariz_naim_fault_2022,
	title = {Fault {Tolerance} {Mechanism} for {Software} {Application} {Through} {Fog} {Computing} as {Middleware}},
	doi = {10.12785/ijcds/120105},
	abstract = {: Fault tolerance is a paradigm for providing high availability in a computerized system where application services are replicated to multiple nodes. The paradigm is widely used in a cloud computing environment where users may benefit from automatic backup when an application such as a clinic support system is deployed in the cloud. However, applications residing in premises such as small clinics are still prone to an outage and would require certain time with human involvement when performing recovery. Thus, this research aims to provide a prototype of a backup mechanism for a health system residing in-premise of a clinic. The study will also act as a feasibility investigation of fault tolerance mechanism in edge of network where we proposed the use of fog computing model that acts as middleware for detecting and failover solution when an outage has temporarily occurred. The middleware will perform failure detection through heartbeat and replicate the services at the same time. When an outage is detected, the middleware will take over as a secondary service provider to ensure applications may be used seamlessly. There are four test simulations for testing the proposed mechanism where three has shown successful recovery actions and only one fail test case due to limitation at the client side.},
	journal = {International Journal of Computing and Digital Systems},
	author = {{Mohd Hariz Naim} and {Jasni Mohamad Zain} and {Kamarularifin Abd Jalil}},
	year = {2022},
	doi = {10.12785/ijcds/120105},
	note = {S2ID: 7558b76d44b6ebca4db2fa8529aadae3d438878d},
	keywords = {⛔ No INSPIRE recid found},
}

@article{liang_chang_fault_2022,
	title = {A fault tolerance data aggregation scheme for fog computing},
	volume = {17},
	doi = {10.1504/ijics.2022.10046349},
	number = {3/4},
	journal = {International Journal of Information and Computer Security},
	author = {{Liang Chang} and {Yining Liu} and {Zhixin Zeng}},
	month = jan,
	year = {2022},
	doi = {10.1504/ijics.2022.10046349},
	note = {MAG ID: 4226434984
S2ID: bed67af6ffad585d395bca5ddd06f70c7779501a},
	keywords = {⛔ No INSPIRE recid found},
	pages = {351--351},
}

@article{sayed_towards_2020,
	title = {Towards {Resilient} {Adaptive} {Vehicular} {Fog} {Computing}},
	doi = {10.1109/iemcon51383.2020.9284836},
	abstract = {Vehicles have seen a tremendous development in their capabilities, equipped by many sensors, high computational resources and became smarter than the past. To best utilize the vehicles resources, Vehicular fog computing (VFC) was introduced as a platform for resource sharing. VFC followed the traditional cloud model in many aspects. However, the major challenge facing VFC was infrastructure stability. unpredictable and unplanned arrive and departure of involved vehicles in VFC have a big effect in the system reliability and task completion time. In this paper, we proposed a reliable mitigation for abrupt vehicle departure by live task migration to induce fault tolerant VFC platform capable of hosting state-full and stateless applications. Results showed that the proposed system had a massive positive impact on the task execution time of a fast departing VFC.},
	journal = {IEEE Annual Information Technology, Electronics and Mobile Communication Conference},
	author = {Sayed, Muhammad Magdy and Kashkoush, Mona S. and Azab, Mohamed and {Mohamed Azab} and Azab, Mohamed},
	year = {2020},
	doi = {10.1109/iemcon51383.2020.9284836},
	note = {MAG ID: 3115797318
S2ID: c29352b7d3ff0e9f6628eb61bf52e9f4846549e2},
	keywords = {⛔ No INSPIRE recid found},
}

@article{whaiduzzaman_resilient_2021,
	title = {A {Resilient} {Fog}-{IoT} {Framework} for {Seamless} {Microservice} {Execution}},
	doi = {10.1109/scc53864.2021.00034},
	abstract = {Microservices have been proposed as the software architecture style for fog-IoT network applications ecosystems. Recently, microservices have been extensively used in fog-IoT ecosystems. Here, master-worker fog-based frameworks have been widely adopted in the ecosystem to ensure resilience. However, the architecture’s reliability, including the possibility of the master fog node failure, and service unavailability, is not reflected adequately in the literature. Therefore, we present a resilient master-citizen fog-IoT framework to ensure efficient resource management and overall system reliability. In this work, we develop a master fog node and layered citizen nodes in the distributed ecosystem. Our fault-tolerant fog-IoT-based microservice execution framework can ensure efficient recovery from a single point of failure, unavailability, and unexpected events in the master fog node, which means the network can continue working after a system failure. We use different fault-tolerance strategies and algorithms for selecting the master fog node that synchronizes with other citizen fog nodes and the upper layer cloud for efficient microservice execution. Finally, we developed and implemented a resilient fog-IoT network for providing uninterrupted services in the event of master fog node failure.},
	journal = {IEEE International Conference on Services Computing},
	author = {{Whaiduzzaman} and Barros, Alistair and Shovon, Ahmedur Rahman and Hossain, Razon and Fidge, Colin J.},
	month = sep,
	year = {2021},
	doi = {10.1109/scc53864.2021.00034},
	note = {MAG ID: 3214225081
S2ID: dd8789524989db2fb0a3d15333142da855496655},
	keywords = {⛔ No INSPIRE recid found},
	pages = {213--221},
	file = {Whaiduzzaman et al_2021_A Resilient Fog-IoT Framework for Seamless Microservice Execution.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/3Z4TI9SX/Whaiduzzaman et al_2021_A Resilient Fog-IoT Framework for Seamless Microservice Execution.pdf:application/pdf},
}

@article{poonam_rana_challenges_2021,
	title = {Challenges in {Conglomerating} {Fog} computing with {IOT} for building {Smart} {City}},
	doi = {10.1109/iccmst54943.2021.00019},
	abstract = {IoT and Fog Computing are the latest solutions that help in better analytics and decision-making for many of the market domains. The Internet of Things (IoT) is a term used to signify the number of devices or objects that are attached together using an Internet connection. Fog Computing is a decentralized and flexible system that helps to deliver and transport data and useful information across the Cloud and IoT. Fog computing's goal is to locate basic computation services at the edge of the network where they are needed this helps in the reduction of the distance the data has to travel resulting in an increase in the performance. Fog computing enhances the concept of Cloud Computing. There are various Cloud services available in the market viz Microsoft Azure Cloud, Amazon Web Services, Google Cloud, Alibaba Cloud, IBM Cloud, etc. IoT and Fog Computing go hand in hand and work together in providing an overall better IoT service. This paper discussed the benefits of using Fog Computing and IoT together in Minimizing latency, Conserve network bandwidth, less operating cost, more security, more reliability, and many more for building smart infrastructure for cities.},
	journal = {2021 2nd International Conference on Computational Methods in Science \& Technology (ICCMST)},
	author = {{Poonam Rana} and {Kirti Walia} and {Amanpreet Kaur}},
	year = {2021},
	doi = {10.1109/iccmst54943.2021.00019},
	note = {S2ID: efb04e9f388c771f0dc314f3ae1717ec378f8dbc},
	keywords = {⛔ No INSPIRE recid found},
}

@article{alsmadi_fog_2021,
	title = {Fog computing scheduling algorithm for smart city},
	volume = {11},
	doi = {10.11591/ijece.v11i3.pp%p},
	abstract = {With the advent of the number of smart devices across the globe, increasing the number of users using the Internet. The main aim of the Fog Computing (FC) paradigm is to connect huge number of smart objects (billions of object) that can make a bright future for smart cities. Due to the large deployments of smart devices, devices are expected to generate huge amounts of data and forward the data through the Internet. FC also refers to an edge computing framework that mitigates the issue by applying the process of knowledge discovery using a data analysis approach to the edges. Thus, the FC approaches can work together with the Internet of Things (IoT) world, which can build a sustainable infrastructure for smart cities. In this paper, we propose a scheduling algorithm namely the weighted round-robin (WRR) scheduling algorithm to execute the task from one Fog Node (FN) to another fog node to the cloud. Firstly, a fog simulator is used with the emergent concept of FC to design IoT infrastructure for smart cities. Then, Spanning-Tree Routing (STP) protocol is used for data collection and routing. Further, 5G networks are proposed to establish fast transmission and communication between users. Finally, the performance of our proposed system is evaluated in terms of response time, latency, and amount of data used.},
	number = {3},
	journal = {International Journal of Electrical and Computer Engineering},
	author = {Alsmadi, Ahmad Mohammad and Aloglah, Roba Mahmoud Ali and Abu-darwish, Nisrein Jamal sanad and Smadi, Ahmad Al and Alshabanah, Muneerah and Alrajhi, Daniah and Alkhaldi, Hanouf and Alsmadi, Mutasem K.},
	year = {2021},
	doi = {10.11591/ijece.v11i3.pp%p},
	note = {MAG ID: 3109171007
S2ID: 298d95bcc008a9e2fa0a2d4df8e8b56867487f47},
	keywords = {⛔ No INSPIRE recid found},
	pages = {2219--2228},
}

@article{thiago_pereira_da_silva_fog_2022,
	title = {Fog {Computing} {Platforms} for {Smart} {City} {Applications} - {A} {Survey}},
	doi = {10.1145/3488585},
	abstract = {Emerging IoT applications with stringent requirements on latency and data processing have posed many challenges to cloud-centric platforms for Smart Cities. Recently, Fog Computing has been advocated as a promising approach to support such new applications and handle the increasing volume of IoT data and devices. The Fog Computing paradigm is characterized by a horizontal system-level architecture where devices close to end-users and IoT devices are used for processing, storage, and networking functions. Fog Computing platforms aim to facilitate the development of applications and systems for Smart Cities by providing services and abstractions designed to integrate data from IoT devices and various information systems deployed in the city. Despite the potential of the Fog Computing paradigm, the literature still lacks a broad, comprehensive overview of what has been investigated on the use of such paradigm in platforms for Smart Cities and open issues to be addressed in future research and development. In this paper, a systematic mapping study was performed and we present a comprehensive understanding of the use of the Fog Computing paradigm in Smart Cities platforms, providing an overview of the current state of research on this topic, and identifying important gaps in the existing approaches and promising research directions.},
	journal = {ACM Transactions on Internet Technology},
	author = {{Thiago Pereira da Silva} and {Thais Batista} and {Frederico Lopes} and {Aluizio Rocha Neto} and {Flávia C. Delicato} and {Paulo F. Pires} and {Atslands R. da Rocha}},
	month = feb,
	year = {2022},
	doi = {10.1145/3488585},
	note = {MAG ID: 4210397446
S2ID: a20cf50977e1fec07517b39e1f627ef2b7cd488b},
	keywords = {⛔ No INSPIRE recid found},
}

@article{tahira_sarwar_mir_antifragile_2022,
	title = {Antifragile and {Resilient} {Geographical} {Information} {System} {Service} {Delivery} in {Fog} {Computing}},
	volume = {22},
	doi = {10.3390/s22228778},
	abstract = {The demand for cloud computing has drastically increased recently, but this paradigm has several issues due to its inherent complications, such as non-reliability, latency, lesser mobility support, and location-aware services. Fog computing can resolve these issues to some extent, yet it is still in its infancy. Despite several existing works, these works lack fault-tolerant fog computing, which necessitates further research. Fault tolerance enables the performing and provisioning of services despite failures and maintains anti-fragility and resiliency. Fog computing is highly diverse in terms of failures as compared to cloud computing and requires wide research and investigation. From this perspective, this study primarily focuses on the provision of uninterrupted services through fog computing. A framework has been designed to provide uninterrupted services while maintaining resiliency. The geographical information system (GIS) services have been deployed as a test bed which requires high computation, requires intensive resources in terms of CPU and memory, and requires low latency. Keeping different types of failures at different levels and their impacts on service failure and greater response time in mind, the framework was made anti-fragile and resilient at different levels. Experimental results indicate that during service interruption, the user state remains unaffected.},
	number = {22},
	journal = {Sensors},
	author = {{Tahira Sarwar Mir} and {Hannan Bin Liaqat} and {Tayybah Kiren} and Sana, Muhammad Usman and {Roberto Álvarez} and {Yini Miro} and {Alina Eugenia Pascual Barrera} and Ashraf, Imran},
	month = nov,
	year = {2022},
	doi = {10.3390/s22228778},
	pmcid = {9696224},
	pmid = {36433374},
	note = {MAG ID: 4309027246
S2ID: 51e279b2254ea45965538eb0c5b8bd1a3eaad03e},
	keywords = {⛔ No INSPIRE recid found},
	pages = {8778--8778},
}

@article{ramirez_lopez_sustainability_2020,
	title = {Sustainability and {Resilience} in {Smart} {City} {Planning}: {A} {Review}},
	volume = {13},
	issn = {2071-1050},
	shorttitle = {Sustainability and {Resilience} in {Smart} {City} {Planning}},
	url = {https://www.mdpi.com/2071-1050/13/1/181},
	doi = {10.3390/su13010181},
	abstract = {Urban planning is recognized as an interaction between the state and society, which aims to articulate public policies in the territory, facilitating their administration in favor of greater development and well-being of society. However, this interaction becomes complex because consumption demands increase, and the carrying capacity of the urban ecosystem to supply them is exceeded, hindering its sustainable functionality. With this overview, it becomes relevant to study urban planning from a sustainable environmental planning perspective, based on four topics: urban planning, sustainability, resilience, and smart cities, which are developed throughout the document by means of a chronological study. A bibliometric study was used through a Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) adjustment to 87 articles, supported by VOSviewer®, which allowed for the construction and visualization of the co-occurrence networks of key words extracted from the selected articles. Likewise, 16 documents more were used for the co-occurrence analysis. The main result is to consider cities with a complex systems approach that works like a gear; the relationship between inter-urban and intra-urban processes is the key factor that allows for an understanding of their synchronization; therefore, deepening of each of these topics is crucial to the ideal of a territorial administration involving time scales and adaptive cycles, allowing for the provision of new tools for concepts such as carrying capacity and the measurement of the ecological footprint.},
	language = {en},
	number = {1},
	urldate = {2023-03-28},
	journal = {Sustainability},
	author = {Ramirez Lopez, Leonardo Juan and Grijalba Castro, Angela Ivette},
	month = dec,
	year = {2020},
	pages = {181},
	file = {Ramirez Lopez and Grijalba Castro - 2020 - Sustainability and Resilience in Smart City Planni.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/UIPGNDQ6/Ramirez Lopez and Grijalba Castro - 2020 - Sustainability and Resilience in Smart City Planni.pdf:application/pdf},
}

@article{fajriyah_transformation_2021,
	title = {The {Transformation} of {Smart} {City} {Concept} in {Urban} {Development} ({Case} {Study}: {Semarang} {City})},
	volume = {764},
	issn = {1755-1307, 1755-1315},
	shorttitle = {The {Transformation} of {Smart} {City} {Concept} in {Urban} {Development} ({Case} {Study}},
	url = {https://iopscience.iop.org/article/10.1088/1755-1315/764/1/012028},
	doi = {10.1088/1755-1315/764/1/012028},
	abstract = {The urban development in line with technology growth has created a smart city concept. Semarang city is one of the metropolitan cities that has applied a smart city concept since 2013 by implementing information technology in their programs. It was successfully made Semarang getting an award as the best city of Development Regional Awards by Bappenas (Ministry of National Development Planning) in 2019. But over time, the smart city concept in Semarang has transformed in its implementation to solve the city's problems and adapt to their needs. The purpose of this study is to describe the phenomena in the transformation of the smart city concept in urban development with case study of Semarang city. This study uses an abductive approach by the methodology of case study that armed with a few of theory and has a lot of exploration about the phenomena. The results of this study indicate that the transformation of the smart city concept in Semarang affected by several factors in urban and regional development, which consist of internal and external factors.},
	language = {en},
	number = {1},
	urldate = {2023-03-29},
	journal = {IOP Conference Series: Earth and Environmental Science},
	author = {Fajriyah, N O and Djunaedi, A},
	month = may,
	year = {2021},
	keywords = {⛔ No INSPIRE recid found},
	pages = {012028},
	file = {Fajriyah and Djunaedi - 2021 - The Transformation of Smart City Concept in Urban .pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/C7PA2G8P/Fajriyah and Djunaedi - 2021 - The Transformation of Smart City Concept in Urban .pdf:application/pdf},
}

@techreport{noauthor_notitle_nodate,
	keywords = {⛔ No INSPIRE recid found},
}

@article{noauthor_notitle_nodate-1,
	url = {https://www.sciencedirect.com/science/article/pii/S2210670718325794},
	keywords = {⛔ No INSPIRE recid found},
}

@article{arafah_redefining_2017,
	title = {Redefining smart city concept with resilience approach},
	volume = {70},
	issn = {1755-1307, 1755-1315},
	url = {https://iopscience.iop.org/article/10.1088/1755-1315/70/1/012065},
	doi = {10.1088/1755-1315/70/1/012065},
	abstract = {The smart city concept originally aimed at dealing with various urban problems, in particular, those related to the urban environment and infrastructure, such as modeling transport flow in a city. As it developed, the concept is now widely used to accelerate the process of urban management by using IT technology and by the availability of big data. However, the smart city discourses are still debated. There is a number of critical literature on the discourses; some are more concerned with the use and development of information communication technology (ICT). ICT and modern technology are considered the key aspect of the smart city concept. Meanwhile, others emphasize the importance of the people who operate the technology. Very few, if any, literature emphasizes the importance of resilience in the smart city discourse. The city as a complex system should have the ability to be resilient, especially when technology fails either due to technical/man-made or natural disasters. This paper aims to redefine the smart city concept in urban planning through a literature study in the context of planning using a resilience approach. This paper describes and defines what the smart city concept is, what it means, as well as explains the relation and linkage of the importance of using resilience approach in defining the smart city. Factors of resilience will lead to a soft infrastructure approach, such as enhancement in many aspects, e.g. community capacity, social and human capital, knowledge inclusion, participation, social innovation, and social equity. Discussion and analysis are conducted through a deep literature study using systematic literature review methodology.},
	language = {en},
	urldate = {2023-03-29},
	journal = {IOP Conference Series: Earth and Environmental Science},
	author = {Arafah, Y and Winarso, H},
	month = jun,
	year = {2017},
	keywords = {⛔ No INSPIRE recid found},
	pages = {012065},
	file = {Arafah and Winarso - 2017 - Redefining smart city concept with resilience appr.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/5TPEFM7E/Arafah and Winarso - 2017 - Redefining smart city concept with resilience appr.pdf:application/pdf},
}

@article{zhu_is_2019,
	title = {Is smart city resilient? {Evidence} from {China}},
	volume = {50},
	issn = {22106707},
	shorttitle = {Is smart city resilient?},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2210670718325794},
	doi = {10.1016/j.scs.2019.101636},
	abstract = {Smart city is originally aimed at dealing with various urban problems due to rapid urbanization, like energy shortage, congestion, and environmental pollution. The Chinese government has been devoting to the promotion of smart cities for many years. However, it is unconﬁrmed whether the city is more resilient with all the modern technologies provided when unexpected predicaments like climate changes or disasters occur. Therefore, it is urgent to consider resilience in the smart city. This paper provides a MCDM approach to assess and rank the resilience of 187 smart cities in China. The results demonstrate that the overall resilience of smart cities is at a relatively low level. There is also a signiﬁcant unbalance of resilience between smart cities due to diﬀerent infrastructural, economic, social, institutional, and environmental conditions. The potential links between urban smartness and resilience were also explored, and the results showed signiﬁcant positive relationship between the smartness of a city and its resilience. Evidence also proved that developing smartness is more or less useful for improving urban resilience. Suggestions such as strengthening the development of infrastructure and economy, and enhancing the multi-stakeholders’ cooperation are proposed to further promote the smart and resilient development in China.},
	language = {en},
	urldate = {2023-03-29},
	journal = {Sustainable Cities and Society},
	author = {Zhu, Shiyao and Li, Dezhi and Feng, Haibo},
	month = oct,
	year = {2019},
	keywords = {⛔ No INSPIRE recid found},
	pages = {101636},
	file = {Zhu et al. - 2019 - Is smart city resilient Evidence from China.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/L8AI7D6E/Zhu et al. - 2019 - Is smart city resilient Evidence from China.pdf:application/pdf},
}

@article{ezugwu_conceptual_2020,
	title = {A conceptual comparison of several metaheuristic algorithms on continuous optimisation problems},
	volume = {32},
	issn = {1433-3058},
	url = {https://doi.org/10.1007/s00521-019-04132-w},
	doi = {10.1007/s00521-019-04132-w},
	abstract = {The field of continuous optimisation has witnessed an explosion of the so-called new or novel metaheuristic algorithms. Though not all of these algorithms are efficient as proclaimed by their inventors, a few of them have proved to be very efficient and thus have become popular tools for solving complex optimisation problems. Therefore, there is a need for a systematic analysis approach to fairly evaluate and compare the results of some of these optimisation algorithms. In this paper, a set of well-known mathematical benchmark functions are compiled to provide an easily accessible collection of standard benchmark test problems for continuous global optimisation. This set of test problems are used to investigate the computational capabilities and the microscopic behaviour of twelve different metaheuristic algorithms. The required number of function evaluations for reaching the best solution and the run-time complexity of the algorithms are compared. Furthermore, statistical tests are conducted to validate the concluding remarks.},
	language = {en},
	number = {10},
	urldate = {2023-04-05},
	journal = {Neural Computing and Applications},
	author = {Ezugwu, Absalom E. and Adeleke, Olawale J. and Akinyelu, Andronicus A. and Viriri, Serestina},
	month = may,
	year = {2020},
	keywords = {⛔ No INSPIRE recid found, Continuous domain optimisation, Metaheuristics, Population-based metaheuristics, Swarm intelligence},
	pages = {6207--6251},
	file = {Ezugwu et al_2020_A conceptual comparison of several metaheuristic algorithms on continuous.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/X2HURP3E/Ezugwu et al_2020_A conceptual comparison of several metaheuristic algorithms on continuous.pdf:application/pdf},
}

@article{torquato_comprehensive_2018,
	title = {A {Comprehensive} {Assessment} of {PV} {Hosting} {Capacity} on {Low}-{Voltage} {Distribution} {Systems}},
	volume = {33},
	issn = {1937-4208},
	doi = {10.1109/TPWRD.2018.2798707},
	abstract = {Rooftop photovoltaic (PV) hosting capacity has become a concern for utilities in scenarios of high penetration due to impacts on voltage quality, such as over/undervoltage and voltage unbalance, and on equipment loading (conductors and transformers). This paper uses a simplified Monte Carlo-based method to analyze this issue, which is applied to 50 000 real low-voltage (LV) systems. Results show that it is possible to perform a risk-based analysis of hosting capacity by means of a lognormal distribution. Furthermore, overvoltage is found to be the most restrictive impact of PV integration; such information can help to guide utility actions to avoid technical violations. Extensive sensitivity studies are also presented to quantify the effects of several factors on the PV hosting capacity. The effects of number of customers with PV generators, PV power factor, voltage magnitude on the medium-voltage system, load level, and conductor impedances are investigated. It is also shown that the hosting capacity for the entire utility can be estimated by performing simulations only on 1\% of the circuits randomly selected. In addition to providing a comprehensive overview of PV hosting capacity in real systems, the method can be used by utilities to improve the management of LV systems with high PV penetration.},
	number = {2},
	journal = {IEEE Transactions on Power Delivery},
	author = {Torquato, Ricardo and Salles, Diogo and Oriente Pereira, Caio and Meira, Paulo Cesar Magalhaes and Freitas, Walmir},
	month = apr,
	year = {2018},
	note = {Conference Name: IEEE Transactions on Power Delivery},
	keywords = {⛔ No INSPIRE recid found, Conductors, Generators, Indexes, Integrated circuit modeling, Load modeling, Loading, Low voltage systems, Monte Carlo methods, Monte Carlo simulation, rooftop photovoltaic generation, voltage quality},
	pages = {1002--1012},
	file = {IEEE Xplore Abstract Record:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/ZC93RTYF/8270364.html:text/html;Torquato et al_2018_A Comprehensive Assessment of PV Hosting Capacity on Low-Voltage Distribution.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/MI3KSXYM/Torquato et al_2018_A Comprehensive Assessment of PV Hosting Capacity on Low-Voltage Distribution.pdf:application/pdf},
}

@article{zhang_short-term_2020,
	title = {Short-term wind power forecasting approach based on {Seq2Seq} model using {NWP} data},
	volume = {213},
	issn = {03605442},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S036054422031478X},
	doi = {10.1016/j.energy.2020.118371},
	abstract = {Wind power is one of the main sources of renewable energy. Precise forecast of the power output of wind farms could greatly decrease the negative impact of wind power on power grid operation and reduce the cost of the power system operation. In this paper, a wind power output forecast model was proposed by integrating multivariate times series clustering algorithm with deep learning network. The NWP data and actual wind farm historical data were used as the input of the proposed model. 78 typical characteristic and statistical features were extracted from the inputs. Dimension reduction algorithm t-SNE was used to project the feature vectors into lower dimension and K-means algorithm was used to cluster the inputs into different clusters afterwards. At last, Seq2Seq with attention models were built for each cluster for power output prediction. The forecasting horizon is 1 day and the data resolution is 10 min. The results showed that the Seq2Seq model outperformed other existing forecasting methods such as Deep Belief Network and Random Forest. Clustering the input data into different clusters indeed improved the forecasting accuracy.},
	language = {en},
	urldate = {2023-04-12},
	journal = {Energy},
	author = {Zhang, Yu and Li, Yanting and Zhang, Guangyao},
	month = dec,
	year = {2020},
	keywords = {⛔ No INSPIRE recid found},
	pages = {118371},
	file = {Zhang et al. - 2020 - Short-term wind power forecasting approach based o.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/MIKDUC9X/Zhang et al. - 2020 - Short-term wind power forecasting approach based o.pdf:application/pdf},
}

@article{vadera_methods_2022,
	title = {Methods for {Pruning} {Deep} {Neural} {Networks}},
	volume = {10},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/9795013/},
	doi = {10.1109/ACCESS.2022.3182659},
	abstract = {This paper presents a survey of methods for pruning deep neural networks. It begins by categorising over 150 studies based on the underlying approach used and then focuses on three categories: methods that use magnitude based pruning, methods that utilise clustering to identify redundancy, and methods that use sensitivity analysis to assess the effect of pruning. Some of the key inﬂuencing studies within these categories are presented to highlight the underlying approaches and results achieved. Most studies present results which are distributed in the literature as new architectures, algorithms and data sets have developed with time, making comparison across different studied difﬁcult. The paper therefore provides a resource for the community that can be used to quickly compare the results from many different methods on a variety of data sets, and a range of architectures, including AlexNet, ResNet, DenseNet and VGG. The resource is illustrated by comparing the results published for pruning AlexNet and ResNet50 on ImageNet and ResNet56 and VGG16 on the CIFAR10 data to reveal which pruning methods work well in terms of retaining accuracy whilst achieving good compression rates. The paper concludes by identifying some research gaps and promising directions for future research.},
	language = {en},
	urldate = {2023-04-12},
	journal = {IEEE Access},
	author = {Vadera, Sunil and Ameen, Salem},
	year = {2022},
	keywords = {⛔ No INSPIRE recid found},
	pages = {63280--63300},
	file = {Vadera and Ameen - 2022 - Methods for Pruning Deep Neural Networks.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/GPTQWWV8/Vadera and Ameen - 2022 - Methods for Pruning Deep Neural Networks.pdf:application/pdf},
}

@inproceedings{ng_discriminative_2001,
	title = {On {Discriminative} vs. {Generative} {Classifiers}: {A} comparison of logistic regression and naive {Bayes}},
	volume = {14},
	shorttitle = {On {Discriminative} vs. {Generative} {Classifiers}},
	url = {https://papers.nips.cc/paper_files/paper/2001/hash/7b7a53e239400a13bd6be6c91c4f6c4e-Abstract.html},
	abstract = {We  compare discriminative  and  generative learning as  typified  by  logistic regression and naive Bayes.  We show,  contrary to a widely(cid:173) held  belief  that  discriminative  classifiers  are  almost  always  to  be  preferred,  that  there  can  often  be  two  distinct  regimes  of  per(cid:173) formance  as  the  training  set  size  is  increased,  one  in  which  each  algorithm  does  better.  This  stems  from  the  observation- which  is  borne  out  in  repeated  experiments- that  while  discriminative  learning has lower asymptotic error, a generative classifier may also  approach its  (higher)  asymptotic error  much faster.},
	urldate = {2023-04-12},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {MIT Press},
	author = {Ng, Andrew and Jordan, Michael},
	year = {2001},
	keywords = {⛔ No INSPIRE recid found},
	file = {Full Text PDF:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/9UES6XPX/Ng and Jordan - 2001 - On Discriminative vs. Generative Classifiers A co.pdf:application/pdf},
}

@inproceedings{bajaj_comparative_2022,
	title = {Comparative {Analysis} of {Simulators} for {IoT} {Applications} in {Fog}/{Cloud} {Computing}},
	doi = {10.1109/ICSCDS53736.2022.9760897},
	abstract = {In order to make people's life easier, a significant number of Internet of Things (IoT) applications have become a part of a global world. The internet of things is strongly intertwined to cloud computing, and sensor data handling is one of the most urgent issues with cloud computing. Sensors and other cloud-connected smart devices are frequently used to operate IoT-Cloud systems; as a result, these devices generate a large volume of data that must be preserved and processed efficiently. Simulators have the advantage of allowing complex systems to be explored without the requirement to purchase and install physical resources. The purpose of this article is to look at several cloud implementation simulators and see which ones are best for today's IoT demands. With the moving of the trend and computing needs, this paper provides a brief examination of the different most widely used simulators in the research field by categorising the simulators into three categories: cloud, edge, and fog simulators. Finally, various future research direction in accordance with the simulator's evolution is given.},
	booktitle = {2022 {International} {Conference} on {Sustainable} {Computing} and {Data} {Communication} {Systems} ({ICSCDS})},
	author = {Bajaj, Karan and Sharma, Bhisham and Singh, Raman},
	month = apr,
	year = {2022},
	keywords = {IoT, Internet of Things, Cloud computing, Scalability, Edge Computing, Cloud Computing, Computational modeling, Fog Computing, ⛔ No INSPIRE recid found, notion, Data handling, Data models, Market research, Simulators},
	pages = {983--988},
	file = {IEEE Xplore Abstract Record:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/4DHMHNIC/9760897.html:text/html},
}

@inproceedings{li_pedestrian_2019,
	title = {Pedestrian {Trajectory} {Prediction} with {Learning}-based {Approaches}: {A} {Comparative} {Study}},
	shorttitle = {Pedestrian {Trajectory} {Prediction} with {Learning}-based {Approaches}},
	doi = {10.1109/IVS.2019.8814183},
	abstract = {To enable safe and efficient navigations through the urban environment, autonomous vehicles need to anticipate the future motions of the walking pedestrians who might collide with them. The dynamic and stochastic behavior characteristics of the pedestrians make the trajectory prediction challengeable for most kinematics-based approaches. This paper presents a comparative study of six state-of-the-art learning-based methods for pedestrian trajectory prediction, including Gaussian Process (GP), LSTM, GP-LSTM, Character-based LSTM, Sequence-to-Sequence (Seq2Seq), and attention-based Seq2Seq. The trajectory prediction is formulated as the regression task or sequence generation problem that predicts future trajectories based on observed trajectories. We evaluate the performance of the learning-based methods on a public real-world pedestrian dataset. To address the concern of data scarcity, we employ three forms of data augmentation (i.e., translation, rotation, and stretch) to enlarge the dataset, which produce the transformed trajectories from the original trajectories. By comparison, those learning-based approaches are ranked based on prediction accuracy from high to low as Seq2Seq, attention-based Seq2Seq, C-LSTM, LSTM, GP, and GP-LSTM. Particularly, Seq2Seq model outperforms all baseline approaches, with the mean and final point errors less than 15cm in normal scenarios when predicting 1s ahead.},
	booktitle = {2019 {IEEE} {Intelligent} {Vehicles} {Symposium} ({IV})},
	author = {Li, Yang and Xin, Long and Yu, Dameng and Dai, Pengwen and Wang, Jianqiang and Li, Shengbo Eben},
	month = jun,
	year = {2019},
	note = {ISSN: 2642-7214},
	keywords = {⛔ No INSPIRE recid found, Dynamics, Hidden Markov models, Kernel, Predictive models, Task analysis, Trajectory, Vehicle dynamics},
	pages = {919--926},
	file = {IEEE Xplore Abstract Record:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/CLTSZAW8/8814183.html:text/html},
}

@misc{raman_transforming_2022,
	title = {Transforming {Sequence} {Tagging} {Into} {A} {Seq2Seq} {Task}},
	url = {http://arxiv.org/abs/2203.08378},
	abstract = {Pretrained, large, generative language models (LMs) have had great success in a wide range of sequence tagging and structured prediction tasks. Casting a sequence tagging task as a Seq2Seq one requires deciding the formats of the input and output sequences. However, we lack a principled understanding of the tradeoffs associated with these formats (such as the effect on model accuracy, sequence length, multilingual generalization, hallucination). In this paper, we rigorously study different formats one could use for casting input text sentences and their output labels into the input and target (i.e., output) of a Seq2Seq model. Along the way, we introduce a new format, which we show to to be both simpler and more effective. Additionally the new format demonstrates signiﬁcant gains in the multilingual settings – both zero-shot transfer learning and joint training. Lastly, we ﬁnd that the new format is more robust and almost completely devoid of hallucination – an issue we ﬁnd common in existing formats. With well over a 1000 experiments studying 14 different formats, over 7 diverse public benchmarks –including 3 multilingual datasets spanning 7 languages – we believe our ﬁndings provide a strong empirical basis in understanding how we should tackle sequence tagging tasks.},
	language = {en},
	urldate = {2023-05-15},
	publisher = {arXiv},
	author = {Raman, Karthik and Naim, Iftekhar and Chen, Jiecao and Hashimoto, Kazuma and Yalasangi, Kiran and Srinivasan, Krishna},
	month = oct,
	year = {2022},
	note = {arXiv:2203.08378 [cs]},
	keywords = {⛔ No INSPIRE recid found, Computer Science - Computation and Language},
	file = {Raman et al. - 2022 - Transforming Sequence Tagging Into A Seq2Seq Task.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/TNHHFMLZ/Raman et al. - 2022 - Transforming Sequence Tagging Into A Seq2Seq Task.pdf:application/pdf},
}

@article{niu_review_2021,
	title = {A review on the attention mechanism of deep learning},
	volume = {452},
	issn = {09252312},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S092523122100477X},
	doi = {10.1016/j.neucom.2021.03.091},
	abstract = {Attention has arguably become one of the most important concepts in the deep learning ﬁeld. It is inspired by the biological systems of humans that tend to focus on the distinctive parts when processing large amounts of information. With the development of deep neural networks, attention mechanism has been widely used in diverse application domains. This paper aims to give an overview of the state-of-theart attention models proposed in recent years. Toward a better general understanding of attention mechanisms, we deﬁne a uniﬁed model that is suitable for most attention structures. Each step of the attention mechanism implemented in the model is described in detail. Furthermore, we classify existing attention models according to four criteria: the softness of attention, forms of input feature, input representation, and output representation. Besides, we summarize network architectures used in conjunction with the attention mechanism and describe some typical applications of attention mechanism. Finally, we discuss the interpretability that attention brings to deep learning and present its potential future trends.},
	language = {en},
	urldate = {2023-05-15},
	journal = {Neurocomputing},
	author = {Niu, Zhaoyang and Zhong, Guoqiang and Yu, Hui},
	month = sep,
	year = {2021},
	keywords = {⛔ No INSPIRE recid found},
	pages = {48--62},
	file = {Niu et al. - 2021 - A review on the attention mechanism of deep learni.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/EZAQUVJ4/Niu et al. - 2021 - A review on the attention mechanism of deep learni.pdf:application/pdf},
}

@book{tunstall_natural_nodate,
	title = {Natural {Language} {Processing} with {Transformers}},
	language = {en},
	author = {Tunstall, Lewis},
	keywords = {⛔ No INSPIRE recid found},
	file = {Tunstall - Natural Language Processing with Transformers.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/UKU5Z7LF/Tunstall - Natural Language Processing with Transformers.pdf:application/pdf},
}

@misc{regenwetter_deep_2022,
	title = {Deep {Generative} {Models} in {Engineering} {Design}: {A} {Review}},
	shorttitle = {Deep {Generative} {Models} in {Engineering} {Design}},
	url = {http://arxiv.org/abs/2110.10863},
	abstract = {Automated design synthesis has the potential to revolutionize the modern engineering design process and improve access to highly optimized and customized products across countless industries. Successfully adapting generative Machine Learning to design engineering may enable such automated design synthesis and is a research subject of great importance. We present a review and analysis of Deep Generative Machine Learning models in engineering design. Deep Generative Models (DGMs) typically leverage deep networks to learn from an input dataset and synthesize new designs. Recently, DGMs such as feedforward Neural Networks (NNs), Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and certain Deep Reinforcement Learning (DRL) frameworks have shown promising results in design applications like structural optimization, materials design, and shape synthesis. The prevalence of DGMs in engineering design has skyrocketed since 2016. Anticipating continued growth, we conduct a review of recent advances to benefit researchers interested in DGMs for design. We structure our review as an exposition of the algorithms, datasets, representation methods, and applications commonly used in the current literature. In particular, we discuss key works that have introduced new techniques and methods in DGMs, successfully applied DGMs to a design-related domain, or directly supported the development of DGMs through datasets or auxiliary methods. We further identify key challenges and limitations currently seen in DGMs across design fields, such as design creativity, handling constraints and objectives, and modeling both form and functional performance simultaneously. In our discussion, we identify possible solution pathways as key areas on which to target future work.},
	language = {en},
	urldate = {2023-06-02},
	publisher = {arXiv},
	author = {Regenwetter, Lyle and Nobari, Amin Heyrani and Ahmed, Faez},
	month = mar,
	year = {2022},
	note = {arXiv:2110.10863 [cs, stat]},
	keywords = {⛔ No INSPIRE recid found, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Regenwetter et al. - 2022 - Deep Generative Models in Engineering Design A Re.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/WF7KH7U4/Regenwetter et al. - 2022 - Deep Generative Models in Engineering Design A Re.pdf:application/pdf},
}

@misc{khandelwal_sequence_2020,
	title = {Sequence 2 {Sequence} model with {Attention} {Mechanism}},
	url = {https://towardsdatascience.com/sequence-2-sequence-model-with-attention-mechanism-9e9ca2a613a},
	abstract = {Detailed explanation about Attention mechanism in a sequence 2 sequence model suggested by Bahdanau and Luong},
	language = {en},
	urldate = {2023-06-02},
	journal = {Medium},
	author = {Khandelwal, Renu},
	month = feb,
	year = {2020},
	keywords = {⛔ No INSPIRE recid found},
	file = {Snapshot:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/UP4ZMETN/sequence-2-sequence-model-with-attention-mechanism-9e9ca2a613a.html:text/html},
}

@misc{noauthor_bentrevettpytorch-seq2seq_nodate,
	title = {bentrevett/pytorch-seq2seq: {Tutorials} on implementing a few sequence-to-sequence (seq2seq) models with {PyTorch} and {TorchText}.},
	shorttitle = {bentrevett/pytorch-seq2seq},
	url = {https://github.com/bentrevett/pytorch-seq2seq},
	abstract = {Tutorials on implementing a few sequence-to-sequence (seq2seq) models with PyTorch and TorchText. - bentrevett/pytorch-seq2seq: Tutorials on implementing a few sequence-to-sequence (seq2seq) models...},
	language = {en},
	urldate = {2023-06-02},
	journal = {GitHub},
	keywords = {⛔ No INSPIRE recid found},
}

@article{dahrouj_overview_2021,
	title = {An {Overview} of {Machine} {Learning}-{Based} {Techniques} for {Solving} {Optimization} {Problems} in {Communications} and {Signal} {Processing}},
	volume = {9},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/9429227/},
	doi = {10.1109/ACCESS.2021.3079639},
	abstract = {Despite the growing interest in the interplay of machine learning and optimization, existing contributions remain scattered across the research board, and a comprehensive overview on such reciprocity still lacks at this stage. In this context, this paper visits one particular direction of interplay between learning-driven solutions and optimization, and further explicates the subject matter with a clear background and summarized theory. For instance, machine learning and its offsprings are trending because of their enhanced capabilities in automating analytical modeling. In this realm, learning-based techniques (supervised, unsupervised, and reinforcement) have grown to complement many of the optimization problems in testing and training. This paper overviews how machine learning-based techniques, namely deep neural networks, echo-state networks, reinforcement learning, and federated learning, can be used to solve complex and analytically intractable optimization problems, for which speciﬁc cases are examined in this paper. The paper particularly overviews when learning-based algorithms are useful at solving particular optimizing problems, especially those of random, dynamic, and mathematically complex nature. The paper then illustrates such applications by presenting particular use-cases in communications and signal processing including wireless scheduling, wireless ofﬂoading and resource management, power control, aerial base station placement, virtual reality, and vehicular networks. Lastly, the paper sheds light on some future research directions, where the dynamicity and randomness of the underlying optimization problems make deep learning-driven techniques a necessity, namely in sensing at the terahertz (THz) bands, cellular vehicleto-everything, 6G communication networks, underwater optical networks, distributed optimization, and applications of emerging learning-based techniques.},
	language = {en},
	urldate = {2023-06-05},
	journal = {IEEE Access},
	author = {Dahrouj, Hayssam and Alghamdi, Rawan and Alwazani, Hibatallah and Bahanshal, Sarah and Ahmad, Alaa Alameer and Faisal, Alice and Shalabi, Rahaf and Alhadrami, Reem and Subasi, Abdulhamit and Al-Nory, Malak T. and Kittaneh, Omar and Shamma, Jeff S.},
	year = {2021},
	pages = {74908--74938},
	file = {Dahrouj et al. - 2021 - An Overview of Machine Learning-Based Techniques f.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/VTUVWNYU/Dahrouj et al. - 2021 - An Overview of Machine Learning-Based Techniques f.pdf:application/pdf},
}

@incollection{idoumghar_feature_2020,
	address = {Cham},
	title = {From {Feature} {Selection} to {Continuous} {Optimization}},
	volume = {12052},
	isbn = {978-3-030-45714-3 978-3-030-45715-0},
	url = {http://link.springer.com/10.1007/978-3-030-45715-0_1},
	abstract = {Metaheuristic algorithms (MAs) have seen unprecedented growth thanks to their successful applications in ﬁelds including engineering and health sciences. In this work, we investigate the use of a deep learning (DL) model as an alternative tool to do so. The proposed method, called MaNet, is motivated by the fact that most of the DL models often need to solve massive nasty optimization problems consisting of millions of parameters. Feature selection is the main adopted concepts in MaNet that helps the algorithm to skip irrelevant or partially relevant evolutionary information and uses those which contribute most to the overall performance. The introduced model is applied on several unimodal and multimodal continuous problems. The experiments indicate that MaNet is able to yield competitive results compared to one of the best hand-designed algorithms for the aforementioned problems, in terms of the solution accuracy and scalability.},
	language = {en},
	urldate = {2023-06-05},
	booktitle = {Artificial {Evolution}},
	publisher = {Springer International Publishing},
	author = {Rakhshani, Hojjat and Idoumghar, Lhassane and Lepagnot, Julien and Brévilliers, Mathieu},
	editor = {Idoumghar, Lhassane and Legrand, Pierrick and Liefooghe, Arnaud and Lutton, Evelyne and Monmarché, Nicolas and Schoenauer, Marc},
	year = {2020},
	doi = {10.1007/978-3-030-45715-0_1},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {1--12},
	file = {Rakhshani et al. - 2020 - From Feature Selection to Continuous Optimization.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/JXCUDWQJ/Rakhshani et al. - 2020 - From Feature Selection to Continuous Optimization.pdf:application/pdf},
}

@article{bengio_machine_2021,
	title = {Machine learning for combinatorial optimization: {A} methodological tour d’horizon},
	volume = {290},
	issn = {03772217},
	shorttitle = {Machine learning for combinatorial optimization},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0377221720306895},
	doi = {10.1016/j.ejor.2020.07.063},
	language = {en},
	number = {2},
	urldate = {2023-06-05},
	journal = {European Journal of Operational Research},
	author = {Bengio, Yoshua and Lodi, Andrea and Prouvost, Antoine},
	month = apr,
	year = {2021},
	keywords = {notion},
	pages = {405--421},
	file = {Bengio et al. - 2021 - Machine learning for combinatorial optimization A.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/DXDW7X92/Bengio et al. - 2021 - Machine learning for combinatorial optimization A.pdf:application/pdf},
}

@article{dahrouj_overview_2021-1,
	title = {An {Overview} of {Machine} {Learning}-{Based} {Techniques} for {Solving} {Optimization} {Problems} in {Communications} and {Signal} {Processing}},
	volume = {9},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/9429227/},
	doi = {10.1109/ACCESS.2021.3079639},
	abstract = {Despite the growing interest in the interplay of machine learning and optimization, existing contributions remain scattered across the research board, and a comprehensive overview on such reciprocity still lacks at this stage. In this context, this paper visits one particular direction of interplay between learning-driven solutions and optimization, and further explicates the subject matter with a clear background and summarized theory. For instance, machine learning and its offsprings are trending because of their enhanced capabilities in automating analytical modeling. In this realm, learning-based techniques (supervised, unsupervised, and reinforcement) have grown to complement many of the optimization problems in testing and training. This paper overviews how machine learning-based techniques, namely deep neural networks, echo-state networks, reinforcement learning, and federated learning, can be used to solve complex and analytically intractable optimization problems, for which speciﬁc cases are examined in this paper. The paper particularly overviews when learning-based algorithms are useful at solving particular optimizing problems, especially those of random, dynamic, and mathematically complex nature. The paper then illustrates such applications by presenting particular use-cases in communications and signal processing including wireless scheduling, wireless ofﬂoading and resource management, power control, aerial base station placement, virtual reality, and vehicular networks. Lastly, the paper sheds light on some future research directions, where the dynamicity and randomness of the underlying optimization problems make deep learning-driven techniques a necessity, namely in sensing at the terahertz (THz) bands, cellular vehicleto-everything, 6G communication networks, underwater optical networks, distributed optimization, and applications of emerging learning-based techniques.},
	language = {en},
	urldate = {2023-06-05},
	journal = {IEEE Access},
	author = {Dahrouj, Hayssam and Alghamdi, Rawan and Alwazani, Hibatallah and Bahanshal, Sarah and Ahmad, Alaa Alameer and Faisal, Alice and Shalabi, Rahaf and Alhadrami, Reem and Subasi, Abdulhamit and Al-Nory, Malak T. and Kittaneh, Omar and Shamma, Jeff S.},
	year = {2021},
	keywords = {notion},
	pages = {74908--74938},
	file = {Dahrouj et al. - 2021 - An Overview of Machine Learning-Based Techniques f.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/T3ZSSVVQ/Dahrouj et al. - 2021 - An Overview of Machine Learning-Based Techniques f.pdf:application/pdf},
}

@article{apat_service_2018-1,
	title = {Service {Placement} in {Fog} {Computing} {Environment}},
	doi = {10.1109/icit.2018.00062},
	abstract = {Due to the advent of Internet of Things(IoT) plethora of services has been emerged and to perpetuate all these services using cloud computing paradigm is really tiresome. A new promising service provider called as Fog computing came into the picture where the distance between Iot and edge device is small to provide the services efficiently to the end users. There are different considerable factors like service response time, and expected QoS must met without violating other resource constraints. In this paper we try to layout an architecture which is based on the combination of cloud and fog by introducing a middleware called as cloud fog control middleware, which manages the service request according to some constraints. By using this architecture we can maximize the advantages of next generation computer system, however the architecture require new strategies to manage the mapping of services to resources. Despite several Heuristic and Meta Heuristic techniques has been proposed by different authors to solve the service placement in fog computing with considering different parameters like quality of service(QoS), Latency, etc. In this paper we are trying to minimize the energy consumption in fog computing paradigm by formulating the service placement plan in order to utilize the resources efficiently by considering the Active and Idle state of machine. First we calculate the energy consumption by the application(number of tasks) requesting for a particular service. Undoubtedly the service placement problem is a combinatorial optimization problem. The optimal solution obtained distribute the load to some other fog node by appropriate placement of service which leads to reduce the over heat generated by a particular fog node. In this way we can achieve energy minimization in fog computing.},
	journal = {2018 International Conference on Information Technology (ICIT)},
	author = {Apat, Hemant Kumar and Sahoo, Bibhudatta and Maiti, Prasenjit},
	month = dec,
	year = {2018},
	doi = {10.1109/icit.2018.00062},
	note = {MAG ID: 2947843883
S2ID: f3a9c7a4f3c6805c5944dccc05f16f2f5da487ce},
	pages = {272--277},
}

@article{kool_attention_2019,
	title = {Attention, learn to solve routing problems!},
	abstract = {The recently presented idea to learn heuristics for combinatorial optimization problems is promising as it can save costly development. However, to push this idea towards practical implementation, we need better models and better ways of training. We contribute in both directions: we propose a model based on attention layers with benefits over the Pointer Network and we show how to train this model using REINFORCE with a simple baseline based on a deterministic greedy rollout, which we find is more efficient than using a value function. We significantly improve over recent learned heuristics for the Travelling Salesman Problem (TSP), getting close to optimal results for problems up to 100 nodes. With the same hyperparameters, we learn strong heuristics for two variants of the Vehicle Routing Problem (VRP), the Orienteering Problem (OP) and (a stochastic variant of) the Prize Collecting TSP (PCTSP), outperforming a wide range of baselines and getting results close to highly optimized and specialized algorithms.},
	author = {Kool, Wouter and {Wouter Kool} and van Hoof, Herke and Welling, Max},
	month = feb,
	year = {2019},
	note = {MAG ID: 2912555327},
	file = {Kool et al. - 2019 - Attention, learn to solve routing problems!.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/CBBT7BH9/Kool et al. - 2019 - Attention, learn to solve routing problems!.pdf:application/pdf},
}

@article{bichi_energy-aware_2022,
	title = {An energy-aware application module for the fog-based internet of military things},
	volume = {2},
	issn = {2730-7239},
	url = {https://link.springer.com/10.1007/s43926-022-00024-z},
	doi = {10.1007/s43926-022-00024-z},
	abstract = {Smart devices in various application areas are becoming increasingly prevalent for efficient handling of multiple critical activities. One such area of interest is high-security militarized environments. Due to military zones’ harsh and unpredictable nature, monitoring devices deployed in such environments must operate without power interruption for extended time periods. Therefore, it is essential to choose an appropriate application design for operating these “things” in the internet of things (IoT) environment such that energy can be conserved throughout the operating span of an application. This paper presents two application modules and analyzes their performance in terms of energy conservation considering a military-based IoT-Fog architecture. The two modules are: A sequential application module, and a master-worker application module. Experimental results show that the master-worker module incurs lower energy consumption and communication overhead than the sequential application module. Significantly, the master-worker module exhibits a lower delay in tuple execution by almost four milliseconds while also accounting for lower simulation time and higher network utilization. The module achieves significant savings in energy consumption, making it more effective in handling smart devices.},
	language = {en},
	number = {1},
	urldate = {2023-06-21},
	journal = {Discover Internet of Things},
	author = {Bichi, Bashir Yusuf and Islam, Saif Ul and Kademi, Anas Maazu and Ahmad, Ishfaq},
	month = dec,
	year = {2022},
	pages = {4},
	file = {Bichi et al. - 2022 - An energy-aware application module for the fog-bas.pdf:/Users/michaelpakpahan/Library/CloudStorage/OneDrive-UGM365/Zotero/storage/B4XX6HAJ/Bichi et al. - 2022 - An energy-aware application module for the fog-bas.pdf:application/pdf},
}
